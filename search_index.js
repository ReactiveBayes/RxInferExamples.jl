var documenterSearchIndex = {"docs":
[{"location":"categories/advanced_examples/conjugate-computational_variational_message_passing/","page":"Conjugate-Computational Variational Message Passing","title":"Conjugate-Computational Variational Message Passing","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/conjugate-computational_variational_message_passing/#Conjugate-Computational-Variational-Message-Passing-(CVI)","page":"Conjugate-Computational Variational Message Passing","title":"Conjugate-Computational Variational Message Passing (CVI)","text":"using RxInfer, Random, LinearAlgebra, Plots, Optimisers, StableRNGs, SpecialFunctions\n\nIn this notebook, the usage of Conjugate-NonConjugate Variational Inference (CVI) will be described. The implementation of CVI follows the paper Probabilistic programming with stochastic variational message passing.\n\nThis notebook will first describe an example in which CVI is used, then it discusses several limitations, followed by an explanation on how to extend upon CVI.","category":"section"},{"location":"categories/advanced_examples/conjugate-computational_variational_message_passing/#An-example:-nonlinear-dynamical-system","page":"Conjugate-Computational Variational Message Passing","title":"An example: nonlinear dynamical system","text":"A group of researchers is performing a tracking experiment on some moving object along a 1-dimensional trajectory. The object is moving at a constant velocity, meaning that its position increases constantly over time. However, the researchers do not have access to the absolute position z_t at time t. Instead they have access to the observed squared distance y_t between the object and some reference point s. Because of budget cuts, the servo moving the object and the measurement devices are quite outdated and therefore lead to noisy measurements:\n\n# data generating process\nnr_observations = 50\nreference_point = 53\nhidden_location = collect(1:nr_observations) + rand(StableRNG(124), NormalMeanVariance(0.0, sqrt(5)), nr_observations)\nmeasurements = (hidden_location .- reference_point).^2 + rand(MersenneTwister(124), NormalMeanVariance(0.0, 5), nr_observations);\n\n# plot hidden location and reference frame\np1 = plot(1:nr_observations, hidden_location, linewidth=3, legend=:topleft, label=\"hidden location\")\nhline!([reference_point], linewidth=3, label=\"reference point\")\nxlabel!(\"time [sec]\"), ylabel!(\"location [cm]\")\n\n# plot measurements\np2 = scatter(1:nr_observations, measurements, linewidth=3, label=\"measurements\")\nxlabel!(\"time [sec]\"), ylabel!(\"squared distance [cm2]\")\n\nplot(p1, p2, size=(1200, 500))\n\n(Image: )\n\nThe researchers are interested in quantifying this noise and in tracking the unobserved location of the object. As a result of this uncertainty, the researchers employ a probabilistic modeling approach. They formulate the probabilistic model\n\nbeginaligned\n p(tau)  = Gamma(tau mid alpha_tau beta_tau)\n p(gamma)  = Gamma(gamma mid alpha_gamma beta_gamma)\n p(z_t mid z_t - 1 tau)  = mathcalN(z_t mid z_t - 1 + 1 tau^-1)\n p(y_t mid z_t gamma)  = mathcalN(y_t mid (z_t - s)^2 gamma^-1)\nendaligned\n\nwhere the researchers put priors on the process and measurement noise parameters, tau and gamma, respectively. They do this, because they do not know the accuracy of their devices.\n\nThe researchers have recently heard of this cool probabilistic programming package RxInfer.jl. They decided to give it a try and create the above model as follows:\n\nfunction compute_squared_distance(z)\n    (z - reference_point)^2\nend;\n\n@model function measurement_model(y)\n\n    # set priors on precision parameters\n    œÑ ~ Gamma(shape = 0.01, rate = 0.01)\n    Œ≥ ~ Gamma(shape = 0.01, rate = 0.01)\n    \n    # specify estimate of initial location\n    z[1] ~ Normal(mean = 0, precision = œÑ)\n    y[1] ~ Normal(mean = compute_squared_distance(z[1]), precision = Œ≥)\n\n    # loop over observations\n    for t in 2:length(y)\n\n        # specify state transition model\n        z[t] ~ Normal(mean = z[t-1] + 1, precision = œÑ)\n\n        # specify non-linear observation model\n        y[t] ~ Normal(mean = compute_squared_distance(z[t]), precision = Œ≥)\n        \n    end\n\nend\n\nBut here is the problem, our compute_squared_distance function is already compelx enough such that the exact Bayesian inference is intractable in this model. But the researchers knew that the RxInfer.jl supports a various collection of approximation methods for exactly such cases. One of these approximations is called CVI. CVI allows us to perform probabilistic inference around the non-linear measurement function. In general, for any (non-)linear relationship y = f(x1, x2, ..., xN) CVI can be employed, by specifying the function f and by adding this relationship inside the @model macro as y ~ f(x1, x2, ...,xN). The @model macro will generate a factor node with node function p(y | x1, x2, ..., xN) = Œ¥(y - f(x1, x2, ...,xN)).\n\nThe use of this non-linearity requires us to specify that we would like to use CVI. This can be done by specifying the metadata using the @meta macro as:\n\n@meta function measurement_meta(rng, nr_samples, nr_iterations, optimizer)\n    compute_squared_distance() -> CVI(rng, nr_samples, nr_iterations, optimizer)\nend;\n\nIn general, for any (non-)linear function f(), CVI can be enabled with the @meta macro as:\n\n@meta function model_meta(...)\n    f() -> CVI(args...)\nend\n\nSee ?CVI for more information about the args....\n\nIn our model, the z variables are connected to the non-linear node function. So in order to run probabilstic inference with CVI we need to enforce a constraint on the joint posterior distribution. Specifically, we need to create a factorization in which the variables that are directly connected to non-linearities are assumed to be independent from the rest of the variables.\n\nIn the above example, we will assume the following posterior factorization:\n\n@constraints function measurement_constraints()\n    q(z, œÑ, Œ≥) = q(z)q(œÑ)q(Œ≥)\nend;\n\nThis constraint can be explained by the set of two constraints, one for getting CVI to run, and one for assuming a mean-field factorization around the normal node as \n\n@constraints function posterior_constraints()\n    q(z, Œ≥) = q(z)q(Œ≥) # CVI\n    q(z, œÑ) = q(z)q(œÑ) # the mean-field assumption around normal node\nend\n\nBecause the engineers are using RxInfer.jl, they can automate the inference procedure. They track the inference performance using the Bethe free energy.\n\ninitialization = @initialization begin\n    Œº(z) = NormalMeanVariance(0, 5)\n    q(z) = NormalMeanVariance(0, 5)\n    q(œÑ) = GammaShapeRate(1e-12, 1e-3)\n    q(Œ≥) = GammaShapeRate(1e-12, 1e-3)\nend\n\nresults = infer(\n    model = measurement_model(),\n    data = (y = measurements,),\n    iterations = 50,\n    free_energy = true,\n    returnvars = (z = KeepLast(),),\n    constraints = measurement_constraints(),\n    meta = measurement_meta(StableRNG(42), 1000, 1000, Optimisers.Descent(0.001)),\n    initialization = initialization\n)\n\nInference results:\n  Posteriors       | available for (z)\n  Free Energy:     | Real[506.224, 327.426, 325.122, 320.962, 315.966, 312.\n922, 311.014, 309.621, 308.792, 308.776  ‚Ä¶  306.958, 306.514, 306.427, 306.\n842, 306.876, 306.751, 306.631, 306.762, 306.91, 306.734]\n\n# plot estimates for location\np1 = plot(collect(1:nr_observations), hidden_location, label = \"hidden location\", legend=:topleft, linewidth=3, color = :red)\nplot!(map(mean, results.posteriors[:z]), label = \"estimated location (¬±2œÉ)\", ribbon = map(x -> 2*std(x), results.posteriors[:z]), fillalpha=0.5, linewidth=3, color = :orange)\nxlabel!(\"time [sec]\"), ylabel!(\"location [cm]\")\n\n# plot Bethe free energy\np2 = plot(results.free_energy, linewidth=3, label = \"\")\nxlabel!(\"iteration\"), ylabel!(\"Bethe free energy [nats]\")\n\nplot(p1, p2, size = (1200, 500))\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/conjugate-computational_variational_message_passing/#Requirements","page":"Conjugate-Computational Variational Message Passing","title":"Requirements","text":"There are several main requirements for the CVI procedure to satisfy:\n\nThe out interface of the non-linearity must be independently factorized with respect to other variables in the model.\nThe messages on input interfaces (x1, x2, ..., xN) are required to be from the exponential family of distributions.\n\nIn RxInfer, you can satisfy the first requirement by using appropriate factor nodes (Normal, Gamma, Bernoulli, etc) and second requirement by specifying the @constraints macro. In general you can specify this procedure as\n\n@model function model(...)\n    ...\n    y ~ f(x1, x2, ..., xN)\n    ... ~ Node2(z1,..., y, zM) # some node that is using the out interface of the non-linearity\n    ... \nend\n\n@constraints function constraints_meta()\n    q(y, z1, ..., zn) = q(y)q(z1,...,zM)\n    ...\nend\n\n@meta function model_meta(...)\n    f() -> CVI(rng, nr_samples, nr_iterations, optimizer))\nend\n\nNote that not all exponential family distributions are implemented.","category":"section"},{"location":"categories/advanced_examples/conjugate-computational_variational_message_passing/#Extensions","page":"Conjugate-Computational Variational Message Passing","title":"Extensions","text":"","category":"section"},{"location":"categories/advanced_examples/conjugate-computational_variational_message_passing/#Using-a-custom-optimizer","page":"Conjugate-Computational Variational Message Passing","title":"Using a custom optimizer","text":"CVI only supports Optimisers optimizers out of the box.\n\nBelow an explanation on how to extend to it to a custom optimizer.\n\nSuppose we have CustomDescent structure which we want to use inside CVI for optimization.\n\nTo do so, we need to implement ReactiveMP.cvi_update!(opt::CustomDescent, Œª, ‚àá).\n\nReactiveMP.cvi_update! incapsulates the gradient step:\n\nopt is used to select your optimizer structure\nŒª is the current value\n‚àá is a gradient value computed inside CVI.\n\nstruct CustomDescent \n    learning_rate::Float64\nend\n\n# Must return an optimizer and its initial state\nfunction ReactiveMP.cvi_setup(opt::CustomDescent, q)\n     return (opt, nothing)\nend\n\n# Must return an updated (opt, state) and an updated Œª (can use new_Œª for inplace operation)\nfunction ReactiveMP.cvi_update!(opt_and_state::Tuple{CustomDescent, Nothing}, new_Œª, Œª, ‚àá)\n    opt, _ = opt_and_state\n    ŒªÃÇ = vec(Œª) - (opt.learning_rate .* vec(‚àá))\n    copyto!(new_Œª, ŒªÃÇ)\n    return opt_and_state, new_Œª\nend\n\nLet's try to apply it to a model: beginaligned  p(x)  = mathcalN(0 1)\n p(y_imid x)  = mathcalN(y_i mid x^2 1)\nendaligned\n\nLet's generate some synthetic data for the model\n\n# generate data\ny = rand(StableRNG(123), NormalMeanVariance(19^2, 10), 1000)\nhistogram(y)\n\n(Image: )\n\nAgain we can create the corresponding model as:\n\n# specify non-linearity\nf(x) = x ^ 2\n\n# specify model\n@model function normal_square_model(y)\n    # describe prior on latent state, we set an arbitrary prior \n    # in a positive domain\n    x ~ Normal(mean = 5, precision = 1e-3)\n    # transform latent state\n    mean := f(x)\n    # observation model\n    y .~ Normal(mean = mean, precision = 0.1)\nend\n\n# specify meta\n@meta function normal_square_meta(rng, nr_samples, nr_iterations, optimizer)\n    f() ->  CVI(rng, nr_samples, nr_iterations, optimizer)\nend\n\nnormal_square_meta (generic function with 1 method)\n\nWe will use the inference function from ReactiveMP to run inference, where we provide an instance of the CustomDescent structure in our meta macro function:\n\nres = infer(\n    model = normal_square_model(),\n    data = (y = y,),\n    iterations = 5,\n    free_energy = true,\n    meta = normal_square_meta(StableRNG(123), 1000, 1000, CustomDescent(0.001)),\n    free_energy_diagnostics = nothing\n)\n\nmean(res.posteriors[:x][end])\n\n18.992828536095285\n\nThe mean inferred value of x is indeed close to 19, which was used to generate the data. Inference is working! \n\np1 = plot(mean.(res.posteriors[:x]), ribbon = 3std.(res.posteriors[:x]), label = \"Posterior estimation\", ylim = (0, 40))\np2 = plot(res.free_energy, label = \"Bethe Free Energy\")\n\nplot(p1, p2, layout = @layout([ a b ]))\n\n(Image: )\n\nNote: x^2 can not be inverted; the sign information can be lost: -19 and 19 are both equally good solutions.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n‚åÖ [3bd65402] Optimisers v0.3.4\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [276daf66] SpecialFunctions v2.7.1\n  [860ef19b] StableRNGs v1.0.4\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\nInfo Packages marked with ‚åÖ have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated`\n\n\n","category":"section"},{"location":"categories/advanced_examples/robotic_arm/","page":"Robotic Arm","title":"Robotic Arm","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/robotic_arm/#Motion-Planning-of-Robotic-Arm-in-Joint-Space","page":"Robotic Arm","title":"Motion Planning of Robotic Arm in Joint Space","text":"This example demonstrates motion planning for a robotic arm using RxInfer. It's important to understand that the probabilistic inference for motion planning occurs in joint space rather than Cartesian space:\n\nJoint Space: The space of all possible joint angles (Œ∏‚ÇÅ, Œ∏‚ÇÇ, Œ∏‚ÇÉ, ...) of the robotic arm. Our inference model directly plans trajectories in this space, finding optimal joint angle sequences and the control torques needed to achieve them.\nCartesian Space: The 3D space (x, y, z) where the end effector operates. While our targets are specified in Cartesian space, they are translated to joint space targets using inverse kinematics before planning begins.\n\nThis approach has several advantages:\n\nIt directly models the physical dynamics of the arm's joints\nIt respects the arm's natural degrees of freedom\nIt allows for more efficient inference in the space where control actually happens\n\nThe workflow is:\n\nSpecify target positions in Cartesian space (user-friendly)\nConvert targets to joint angles using inverse kinematics\nUse RxInfer to plan optimal trajectories between joint configurations\nVisualize the resulting motion in Cartesian space using forward kinematics\n\nNote: These examples demonstrate the use of RxInfer for motion planning for a robotic arm. The animations show the inferred trajectories from probabilistic inference, rather than simulated executions. For more realistic simulations the model would need to be extended with a reactive environment that responds to the robotic arm's actions during plan execution. If you're interested in collaborating on a more realistic implementation, please open a discussion and let's work on it together!\n\nusing RxInfer, LinearAlgebra, Plots\n\nThe next couple of blocks are spent on defining the structures that form the foundation of our 3D robotic arm simulation. This is boring but important stuff, as we need to define the state and environment of our robotic arm before doing any inference.","category":"section"},{"location":"categories/advanced_examples/robotic_arm/#Defining-Structures","page":"Robotic Arm","title":"Defining Structures","text":"The structures defined below form the foundation of our 3D robotic arm simulation:\n\nEnvironment: Encapsulates physical properties of the world, such as gravity, that affect the arm's dynamics. This allows us to simulate different environmental conditions.\nRoboticArm3D{N}: Represents a robotic arm with N links in 3D space. The type parameter N ensures type safety and consistency across the codebase. Properties include:\nPhysical dimensions (link lengths)\nMass distribution (important for dynamics calculations)\nTorque limits (physical constraints of the motors)\nThe parametric type allows for compile-time optimizations and type checking.\nArmState3D: Captures the complete state of the arm at any moment, including:\nJoint angles (position)\nJoint velocities (motion)\nThis state representation is crucial for both forward dynamics (predicting motion) and inverse kinematics (planning motion) that we will define later.\n\n\"\"\"\n    Environment(; gravitational_constant::Float64 = 9.81)\n\nStructure containing environmental properties.\n\"\"\"\nBase.@kwdef struct Environment\n    gravitational_constant::Float64 = 9.81\nend\nget_gravity(env::Environment) = env.gravitational_constant\n\n\"\"\"\nRoboticArm3D(num_links, link_lengths, link_masses, joint_torque_limits)\n\nStructure containing properties of a 3D robotic arm.\n\"\"\"\nBase.@kwdef struct RoboticArm3D{N}\n    num_links::Int64 = N                    # Number of links in the arm\n    link_lengths::Vector{Float64}           # Length of each link\n    link_masses::Vector{Float64}            # Mass of each link\n    joint_torque_limits::Vector{Float64}    # Maximum torque for each joint\n    \n    function RoboticArm3D{N}(num_links, link_lengths, link_masses, joint_torque_limits) where {N}\n        @assert num_links == N \"Number of links must match type parameter\"\n        @assert length(link_lengths) == N \"Length of link_lengths must match number of links\"\n        @assert length(link_masses) == N \"Length of link_masses must match number of links\"\n        @assert length(joint_torque_limits) == 2*N \"Length of joint_torque_limits must match 2*number of links (2 DOF per joint)\"\n        new{N}(num_links, link_lengths, link_masses, joint_torque_limits)\n    end\nend\n\n# Constructor that infers N from the number of links\nfunction RoboticArm3D(;\n    num_links::Int64,\n    link_lengths::Vector{Float64},\n    link_masses::Vector{Float64},\n    joint_torque_limits::Vector{Float64}\n)\n    RoboticArm3D{num_links}(num_links, link_lengths, link_masses, joint_torque_limits)\nend\n\nfunction get_properties(arm::RoboticArm3D{N}) where {N}\n    return (arm.num_links, arm.link_lengths, arm.link_masses, arm.joint_torque_limits)\nend\n\n\"\"\"\nArmState3D(joint_angles, joint_velocities)\n\nStructure representing the state of a 3D robotic arm.\nEach joint has 2 angles (pitch and yaw).\n\"\"\"\nstruct ArmState3D\n    joint_angles::Vector{Float64}      # Angles of each joint (2 per joint: pitch, yaw)\n    joint_velocities::Vector{Float64}  # Angular velocities of each joint\nend\n\nfunction get_state(state::ArmState3D)\n    return (state.joint_angles, state.joint_velocities)\nend\n\nget_state (generic function with 1 method)","category":"section"},{"location":"categories/advanced_examples/robotic_arm/#Kinematics-and-Dynamics:-Working-Together","page":"Robotic Arm","title":"Kinematics and Dynamics: Working Together","text":"Robotic arm control requires three complementary mathematical tools:","category":"section"},{"location":"categories/advanced_examples/robotic_arm/#1.-Forward-Kinematics","page":"Robotic Arm","title":"1. Forward Kinematics","text":"Purpose: Maps joint angles to end effector position in Cartesian space\nInput: Joint angles (Œ∏‚ÇÅ, Œ∏‚ÇÇ, Œ∏‚ÇÉ, ...)\nOutput: End effector position (x, y, z)\nUse cases: Visualization, collision detection, workspace analysis\nMathematical nature: Pure geometric transformation (no physics)","category":"section"},{"location":"categories/advanced_examples/robotic_arm/#2.-Inverse-Kinematics","page":"Robotic Arm","title":"2. Inverse Kinematics","text":"Purpose: Maps desired end effector position to required joint angles\nInput: Target position (x, y, z)\nOutput: Joint angles (Œ∏‚ÇÅ, Œ∏‚ÇÇ, Œ∏‚ÇÉ, ...) that achieve this position\nUse cases: Goal specification, target translation, user interface\nMathematical nature: Solving geometric equations (often multiple solutions)","category":"section"},{"location":"categories/advanced_examples/robotic_arm/#3.-State-Transition-(Dynamics)","page":"Robotic Arm","title":"3. State Transition (Dynamics)","text":"Purpose: Models how the arm's state evolves over time when forces/torques are applied\nInput: Current state (angles, velocities) and control inputs (torques)\nOutput: Next state after a time step\nUse cases: Realistic motion simulation, control design, trajectory optimization\nMathematical nature: Physics-based differential equations (F=ma, œÑ=IŒ±)","category":"section"},{"location":"categories/advanced_examples/robotic_arm/#Why-We-Need-All-Three","page":"Robotic Arm","title":"Why We Need All Three","text":"These components work together in a complete robotic arm system:\n\nGoal Translation: Inverse kinematics translates task-space goals (x,y,z positions) into joint-space goals (angles)\nMotion Generation: State transition models how to apply torques to move between joint configurations\nFeedback: Forward kinematics verifies the actual position achieved\n\nThe inference process (probabilistic planning) uses these components to determine optimal control policies:\n\nIt uses the state transition to predict how controls affect future states\nIt uses inverse kinematics to define the target joint configuration\nIt uses forward kinematics to evaluate progress toward the goal\n\nWithout inverse kinematics, we couldn't translate Cartesian targets into joint angles. Without state transition, we couldn't model realistic physical motion with inertia, gravity, etc. Without forward kinematics, we couldn't visualize the arm or verify its position.\n\n\"\"\"\n    forward_kinematics_3d(arm, joint_angles)\n\nA direct geometric approach to forward kinematics for a 2-link arm.\nAngles are interpreted as:\n- joint_angles[1]: yaw angle of the first joint (rotation around Z axis)\n- joint_angles[2]: pitch angle of the first joint (rotation around new Y axis)\n- joint_angles[3]: bend angle of the second joint (in the local XZ plane)\n\"\"\"\nfunction forward_kinematics_3d(arm::RoboticArm3D{2}, joint_angles::Vector{Float64})\n    # Extract arm lengths\n    l1, l2 = arm.link_lengths\n    \n    # Extract angles\n    yaw = joint_angles[1]    # Base rotation around Z\n    pitch = joint_angles[2]  # Shoulder pitch\n    bend = joint_angles[3]   # Elbow bend\n    \n    # Initialize positions\n    positions = zeros(Float64, 3, 3)  # Base, shoulder, elbow\n    \n    # Base position\n    positions[:, 1] = [0.0, 0.0, 0.0]\n    \n    # First, calculate the shoulder position after yaw and pitch\n    # The first link points in direction [cos(yaw)*cos(pitch), sin(yaw)*cos(pitch), sin(pitch)]\n    shoulder_dir = [cos(yaw)*cos(pitch), sin(yaw)*cos(pitch), sin(pitch)]\n    positions[:, 2] = positions[:, 1] + l1 * shoulder_dir\n    \n    # For the elbow, we need to bend in the plane perpendicular to the yaw rotation\n    # Create a coordinate system at the shoulder\n    z_axis = shoulder_dir  # Direction of first link\n    y_axis = [-sin(yaw), cos(yaw), 0.0]  # Perpendicular to xz-plane\n    x_axis = cross(y_axis, z_axis)  # Complete right-handed system\n    \n    # Calculate direction of second link after bend\n    elbow_dir = cos(bend) * z_axis + sin(bend) * x_axis\n    positions[:, 3] = positions[:, 2] + l2 * elbow_dir\n    \n    return positions\nend\n\n\"\"\"\n    inverse_kinematics_3d(arm, target_position)\n\nA direct geometric inverse kinematics solver for a 2-link arm.\n\"\"\"\nfunction inverse_kinematics_3d(arm::RoboticArm3D{2}, target_position)\n    # Extract arm lengths\n    l1, l2 = arm.link_lengths\n    \n    # Extract target coordinates\n    x, y, z = target_position\n    \n    # Calculate distance to target\n    dist = norm(target_position)\n    \n    # Special case: if target is exactly at origin or too close to it\n    if dist < 0.1\n        # Return a safe default position slightly away from the origin\n        return [0.0, 0.3, 0.3, 0.0]  # Small angles that position arm in a safe configuration\n    end\n    \n    # Check if target is reachable\n    if dist > l1 + l2\n        @warn \"Target is out of reach, using closest possible solution\"\n        # Scale target to be at maximum reach\n        scale_factor = (l1 + l2 * 0.99) / dist\n        x *= scale_factor\n        y *= scale_factor\n        z *= scale_factor\n        # Recalculate distance\n        dist = norm([x, y, z])\n    elseif dist < abs(l1 - l2) + 0.05  # Added small margin to prevent numerical issues\n        @warn \"Target is too close, using closest possible solution\"\n        # Scale target to minimum reach\n        scale_factor = (abs(l1 - l2) * 1.05) / dist  # Increased margin\n        x *= scale_factor\n        y *= scale_factor\n        z *= scale_factor\n        # Recalculate distance\n        dist = norm([x, y, z])\n    end\n    \n    # Calculate yaw angle (rotation in the XY plane)\n    # Handle the case where both x and y are close to zero\n    if abs(x) < 1e-6 && abs(y) < 1e-6\n        yaw = 0.0  # Default yaw when target is directly above/below\n    else\n        yaw = atan(y, x)\n    end\n    \n    # Project the target onto the plane defined by the yaw angle\n    # This gives us the radial distance in the direction of the yaw\n    r = sqrt(x^2 + y^2)\n    \n    # Now we have a 2D problem in the RZ plane (where R is the radial distance)\n    # Apply the law of cosines to find the elbow angle\n    cos_elbow = (r^2 + z^2 - l1^2 - l2^2) / (2 * l1 * l2)\n    # Ensure the value is within valid range for acos\n    cos_elbow = clamp(cos_elbow, -1.0, 1.0)\n    elbow = acos(cos_elbow)\n    \n    # Find the angle between the first link and the line to the target\n    # Handle case where r is very small\n    if r < 1e-6\n        if z >= 0\n            # Target is directly above, point straight up\n            pitch = œÄ/2\n        else\n            # Target is directly below, point straight down\n            pitch = -œÄ/2\n        end\n    else\n        cos_alpha = (l1^2 + r^2 + z^2 - l2^2) / (2 * l1 * sqrt(r^2 + z^2))\n        cos_alpha = clamp(cos_alpha, -1.0, 1.0)\n        alpha = acos(cos_alpha)\n        \n        # Calculate pitch angle (elevation from XY plane)\n        # It's the sum of the angle to the target and alpha\n        pitch = atan(z, r) + alpha\n    end\n    \n    # Return the joint angles: [yaw, pitch, elbow]\n    return [yaw, pitch, elbow, 0.0]\nend\n\n\"\"\"\n    state_transition_3d(state, action, arm, environment, dt)\n\nState transition function for the 3D robotic arm, modeling the physics of motion.\n\"\"\"\nfunction state_transition_3d(state, action, arm, environment, dt)\n    # Extract state components (angles and velocities)\n    n = length(state) √∑ 2\n    Œ∏ = state[1:n]\n    œâ = state[n+1:end]\n    \n    # Extract physical parameters\n    g = get_gravity(environment)\n    num_links, link_lengths, link_masses, _ = get_properties(arm)\n    \n    # Initialize next state with current values\n    Œ∏_next = copy(Œ∏)\n    œâ_next = copy(œâ)\n    \n    # Apply simple physics for each joint\n    for i in 1:n\n        # Calculate acceleration: torque = I*Œ±, so Œ± = torque/I\n        # Using a simplified moment of inertia model\n        joint_idx = (i + 1) √∑ 2  # Convert to link index (1-indexed)\n        moment_of_inertia = link_masses[min(joint_idx, num_links)] * (link_lengths[min(joint_idx, num_links)]^2) / 3.0\n        \n        # Net torque = control torque - friction\n        # Gravity compensation is already in the action\n        friction = 0.1 * œâ[i]\n        net_torque = action[i] - friction\n        \n        # Calculate angular acceleration\n        Œ± = net_torque / moment_of_inertia\n        \n        # Update velocity and position using basic Euler integration\n        œâ_next[i] = œâ[i] + Œ± * dt\n        Œ∏_next[i] = Œ∏[i] + œâ_next[i] * dt\n    end\n    \n    # Combine angles and velocities\n    return vcat(Œ∏_next, œâ_next)\nend\n\nMain.var\"##WeaveSandBox#277\".state_transition_3d","category":"section"},{"location":"categories/advanced_examples/robotic_arm/#Visualization-Functions","page":"Robotic Arm","title":"Visualization Functions","text":"This is the most boring part, but it's necessary to visualize the arm and its motion. This is where forward kinematics and inverse kinematics become handy.\n\nfunction plot_arm_3d!(p, arm::RoboticArm3D{2}, joint_angles; color=:black)\n    # Calculate positions using the kinematics\n    positions = forward_kinematics_3d(arm, joint_angles)\n    \n    # Add a more substantial base platform\n    Œ∏ = range(0, 2œÄ, length=30)\n    base_radius = 0.25\n    base_height = 0.05\n    \n    # Base platform - top circle\n    base_x = base_radius .* cos.(Œ∏)\n    base_y = base_radius .* sin.(Œ∏)\n    base_z = zeros(length(Œ∏)) .+ base_height\n    plot!(p, base_x, base_y, base_z, linewidth=2, color=:darkgray, \n          fill=true, fillcolor=:darkgray, fillalpha=0.7, label=false)\n    \n    # Base platform - bottom circle\n    base_x_bottom = base_radius .* cos.(Œ∏)\n    base_y_bottom = base_radius .* sin.(Œ∏)\n    base_z_bottom = zeros(length(Œ∏))\n    plot!(p, base_x_bottom, base_y_bottom, base_z_bottom, linewidth=2, color=:darkgray, \n          fill=true, fillcolor=:darkgray, fillalpha=0.5, label=false)\n    \n    # Connect top and bottom circles to create cylinder\n    for i in 1:length(Œ∏)\n        plot!(p, [base_x[i], base_x[i]], [base_y[i], base_y[i]], [base_z[i], base_z_bottom[i]],\n              linewidth=1, color=:darkgray, label=false)\n    end\n    \n    # Plot each link of the arm with improved appearance\n    # Link 1: Base to shoulder - create a tapered cylinder effect\n    num_segments = 8\n    for i in 1:num_segments\n        t1 = (i-1)/num_segments\n        t2 = i/num_segments\n        \n        # Interpolate positions\n        x1 = positions[1, 1] * (1-t1) + positions[1, 2] * t1\n        y1 = positions[2, 1] * (1-t1) + positions[2, 2] * t1\n        z1 = positions[3, 1] * (1-t1) + positions[3, 2] * t1\n        \n        x2 = positions[1, 1] * (1-t2) + positions[1, 2] * t2\n        y2 = positions[2, 1] * (1-t2) + positions[2, 2] * t2\n        z2 = positions[3, 1] * (1-t2) + positions[3, 2] * t2\n        \n        # Taper the width from thick to thin\n        width1 = 10 - (i-1) * 0.5\n        width2 = 10 - i * 0.5\n        \n        # Gradient color from dark to light blue\n        color1 = RGB(0.1, 0.3 + t1*0.3, 0.6 + t1*0.3)\n        color2 = RGB(0.1, 0.3 + t2*0.3, 0.6 + t2*0.3)\n        \n        # Draw segment\n        plot!(p, [x1, x2], [y1, y2], [z1, z2],\n              linewidth=width1, color=color1, label=false,\n              seriestype=:path3d, alpha=0.9)\n    end\n    \n    # Link 2: Shoulder to end effector - create a tapered cylinder effect\n    for i in 1:num_segments\n        t1 = (i-1)/num_segments\n        t2 = i/num_segments\n        \n        # Interpolate positions\n        x1 = positions[1, 2] * (1-t1) + positions[1, 3] * t1\n        y1 = positions[2, 2] * (1-t1) + positions[2, 3] * t1\n        z1 = positions[3, 2] * (1-t1) + positions[3, 3] * t1\n        \n        x2 = positions[1, 2] * (1-t2) + positions[1, 3] * t2\n        y2 = positions[2, 2] * (1-t2) + positions[2, 3] * t2\n        z2 = positions[3, 2] * (1-t2) + positions[3, 3] * t2\n        \n        # Taper the width from thick to thin\n        width1 = 8 - (i-1) * 0.5\n        width2 = 8 - i * 0.5\n        \n        # Gradient color from medium to light blue\n        color1 = RGB(0.1, 0.4 + t1*0.4, 0.7 + t1*0.2)\n        color2 = RGB(0.1, 0.4 + t2*0.4, 0.7 + t2*0.2)\n        \n        # Draw segment\n        plot!(p, [x1, x2], [y1, y2], [z1, z2],\n              linewidth=width1, color=color1, label=false,\n              seriestype=:path3d, alpha=0.9)\n    end\n    \n    # Add joint spheres with metallic appearance\n    # Base joint\n    scatter!(p, [positions[1, 1]], [positions[2, 1]], [positions[3, 1]],\n            markersize=12, color=:darkgray, markerstrokewidth=1, \n            markerstrokecolor=:black, label=false)\n    \n    # Middle joint (shoulder) with highlight effect\n    scatter!(p, [positions[1, 2]], [positions[2, 2]], [positions[3, 2]],\n            markersize=10, color=:silver, markerstrokewidth=1, \n            markerstrokecolor=:black, label=false)\n    # Add highlight to middle joint\n    scatter!(p, [positions[1, 2] + 0.02], [positions[2, 2] + 0.02], [positions[3, 2] + 0.02],\n            markersize=3, color=:white, markerstrokewidth=0, \n            label=false)\n    \n    # Plot end effector with a more interesting shape\n    # Main part\n    scatter!(p, [positions[1, 3]], [positions[2, 3]], [positions[3, 3]],\n            markersize=12, markershape=:diamond, color=:crimson, \n            markerstrokewidth=1, markerstrokecolor=:black, label=\"End Effector\")\n    \n    # Add \"gripper\" effect to end effector\n    gripper_length = 0.1\n    gripper_angle1 = atan(positions[2, 3] - positions[2, 2], positions[1, 3] - positions[1, 2])\n    gripper_angle2 = gripper_angle1 + œÄ/2\n    \n    # Gripper part 1\n    plot!(p, [positions[1, 3], positions[1, 3] + gripper_length * cos(gripper_angle1 + œÄ/4)],\n          [positions[2, 3], positions[2, 3] + gripper_length * sin(gripper_angle1 + œÄ/4)],\n          [positions[3, 3], positions[3, 3]],\n          linewidth=3, color=:crimson, label=false)\n    \n    # Gripper part 2\n    plot!(p, [positions[1, 3], positions[1, 3] + gripper_length * cos(gripper_angle1 - œÄ/4)],\n          [positions[2, 3], positions[2, 3] + gripper_length * sin(gripper_angle1 - œÄ/4)],\n          [positions[3, 3], positions[3, 3]],\n          linewidth=3, color=:crimson, label=false)\n    \n    return p\nend\n\nfunction visualize_arm_and_target(arm::RoboticArm3D{N}, joint_angles, target_position) where {N}\n    # Calculate positions using forward kinematics\n    positions = forward_kinematics_3d(arm, joint_angles)\n    \n    # Create plot\n    p = plot(\n        title=\"3D Robotic Arm Visualization\",\n        xlabel=\"X\", ylabel=\"Y\", zlabel=\"Z\",\n        xlim=(-2, 2), ylim=(-2, 2), zlim=(-2, 2),\n        aspect_ratio=:equal,\n        legend=:topright\n    )\n    \n    # Plot the arm\n    for i in 1:arm.num_links\n        plot!(p, [positions[1, i], positions[1, i+1]], \n              [positions[2, i], positions[2, i+1]],\n              [positions[3, i], positions[3, i+1]],\n              linewidth=3, color=:blue, label=(i==1 ? \"Arm\" : false))\n        \n        scatter!(p, [positions[1, i]], [positions[2, i]], [positions[3, i]],\n                markersize=5, color=:black, label=(i==1 ? \"Joints\" : false))\n    end\n    \n    # Plot end effector\n    scatter!(p, [positions[1, end]], [positions[2, end]], [positions[3, end]],\n            markersize=6, color=:red, label=\"End Effector\")\n    \n    # Plot target\n    scatter!(p, [target_position[1]], [target_position[2]], [target_position[3]],\n            markersize=6, markershape=:star, color=:green, label=\"Target\")\n    \n    # Plot base\n    scatter!(p, [0], [0], [0], markersize=8, color=:black, label=\"Base\")\n    \n    # Calculate error\n    error = norm(positions[:, end] - target_position)\n    annotate!(p, 0, 0, 2, text(\"Error: $(round(error, digits=4))\", 10, :black))\n    \n    return p, positions, error\nend\n\n\"\"\"\n    animate_sequential_targets_3d(arm, all_states, all_targets)\n\nAnimate the arm's motion through a sequence of targets.\n\"\"\"\nfunction animate_sequential_targets_3d(arm::RoboticArm3D{N}, all_states::Vector, all_targets::Vector) where {N}\n    num_targets = length(all_targets)\n    \n    # Combine all trajectory segments into one continuous path\n    combined_states = hcat(all_states...)\n    total_frames = size(combined_states, 2)\n    \n    # Calculate the frame indices where we reach each target\n    target_reached_frames = zeros(Int, num_targets)\n    frame_count = 0\n    for i in 1:num_targets\n        frame_count += size(all_states[i], 2)\n        target_reached_frames[i] = frame_count\n    end\n    \n    animation = @animate for k in 1:total_frames\n        # Determine which target we're currently moving towards\n        current_target_idx = 1\n        for i in 1:num_targets\n            if k <= target_reached_frames[i]\n                current_target_idx = i\n                break\n            end\n        end\n        \n        # Get the current joint angles\n        joint_angles = combined_states[:, k]\n        \n        # Calculate camera angle that slowly rotates for better 3D perception\n        camera_angle_x = 30 + 20*sin(k/total_frames*2œÄ)\n        camera_angle_y = 20 + 10*cos(k/total_frames*2œÄ)\n        \n        # Calculate the current end effector position using the kinematics\n        positions = forward_kinematics_3d(arm, joint_angles)\n        current_pos = positions[:, 3]\n        \n        # Calculate distance to current target\n        distance = norm(current_pos - all_targets[current_target_idx])\n        \n        # Calculate overall progress\n        overall_progress = k / total_frames\n        \n        # Create a 3D plot with improved styling\n        p = plot(\n            xlabel=\"X\", ylabel=\"Y\", zlabel=\"Z\",\n            xlim=(-2, 2), ylim=(-2, 2), zlim=(0, 2),\n            title=\"Target: $current_target_idx/$num_targets | Progress: $(round(Int, overall_progress*100))% | Distance: $(round(distance, digits=2))\",\n            legend=:topright, size=(900, 700),\n            camera=(camera_angle_x, camera_angle_y),\n            grid=false,  # Remove grid for cleaner look\n            aspect_ratio=:equal,\n            background_color=:white,\n            foreground_color=:black,\n            guidefontsize=10,\n            titlefontsize=12\n        )\n        \n        # Add a more interesting ground plane with grid pattern\n        x_grid = range(-2, 2, length=20)\n        y_grid = range(-2, 2, length=20)\n        z_grid = zeros(length(x_grid), length(y_grid))\n        surface!(p, x_grid, y_grid, z_grid, color=:aliceblue, alpha=0.2, label=false)\n        \n        # Add grid lines on the ground for better depth perception\n        for x in range(-2, 2, step=0.5)\n            plot!(p, [x, x], [-2, 2], [0.01, 0.01], color=:lightgray, linewidth=1, label=false, alpha=0.3)\n        end\n        for y in range(-2, 2, step=0.5)\n            plot!(p, [-2, 2], [y, y], [0.01, 0.01], color=:lightgray, linewidth=1, label=false, alpha=0.3)\n        end\n        \n        # Plot targets with improved styling\n        for (i, target) in enumerate(all_targets)\n            if i < current_target_idx\n                # Completed targets - we've already reached these\n                scatter!(p, [target[1]], [target[2]], [target[3]],\n                        markersize=8, color=:darkgreen, markershape=:circle, \n                        label=(i==1 ? \"Completed\" : false))\n                \n                # Add a small vertical line connecting target to ground\n                plot!(p, [target[1], target[1]], [target[2], target[2]], [0, target[3]],\n                      linewidth=1, color=:darkgreen, linestyle=:dash, alpha=0.3, label=false)\n            elseif i == current_target_idx\n                # Current target with a glowing effect\n                scatter!(p, [target[1]], [target[2]], [target[3]],\n                        markersize=12, color=:green, markershape=:star, \n                        label=\"Current\")\n                \n                # Add a pulsing effect based on frame number\n                pulse_size = 6 + 3*sin(k/10)\n                scatter!(p, [target[1]], [target[2]], [target[3]],\n                        markersize=pulse_size, color=:green, markershape=:circle, \n                        alpha=0.3, label=false)\n                \n                # Add a vertical line connecting target to ground\n                plot!(p, [target[1], target[1]], [target[2], target[2]], [0, target[3]],\n                      linewidth=1, color=:green, linestyle=:dash, alpha=0.5, label=false)\n            elseif i == current_target_idx + 1\n                # Only show the next target\n                scatter!(p, [target[1]], [target[2]], [target[3]],\n                        markersize=8, color=:gray, markershape=:star, \n                        label=\"Next\")\n                \n                # Add a faint vertical line\n                plot!(p, [target[1], target[1]], [target[2], target[2]], [0, target[3]],\n                      linewidth=1, color=:gray, linestyle=:dash, alpha=0.2, label=false)\n            end\n        end\n        \n        # Add a trail of the end effector's path\n        if k > 1\n            # Get positions from previous frames to create a trail\n            trail_length = min(k-1, 15)  # Shorter trail for less clutter\n            trail_indices = max(1, k-trail_length):k-1\n            \n            # Extract end effector positions for each frame in the trail\n            trail_positions = []\n            for idx in trail_indices\n                trail_joint_angles = combined_states[:, idx]\n                trail_pos = forward_kinematics_3d(arm, trail_joint_angles)[:, 3]\n                push!(trail_positions, trail_pos)\n            end\n            \n            # Extract coordinates for the trail\n            trail_x = [pos[1] for pos in trail_positions]\n            trail_y = [pos[2] for pos in trail_positions]\n            trail_z = [pos[3] for pos in trail_positions]\n            \n            # Plot the trail with a gradient effect\n            if length(trail_x) > 1\n                for i in 1:length(trail_x)-1\n                    # Gradient color from orange to transparent\n                    alpha_val = 0.2 + 0.7 * i / length(trail_x)\n                    plot!(p, [trail_x[i], trail_x[i+1]], \n                          [trail_y[i], trail_y[i+1]],\n                          [trail_z[i], trail_z[i+1]],\n                          linewidth=2 + i/3, color=:orange, linestyle=:solid, \n                          label=false, alpha=alpha_val)\n                end\n            end\n        end\n        \n        # For visual reference, add a shadow of the arm on the XZ plane\n        for i in 1:size(positions, 2)-1\n            plot!(p, [positions[1, i], positions[1, i+1]], \n                  [0, 0],  # Fix Y coordinate to 0 (XZ plane)\n                  [positions[3, i], positions[3, i+1]],\n                  linewidth=2, color=:gray, linestyle=:dash, \n                  label=(i==1 ? \"Shadow\" : false), opacity=0.3)\n        end\n        \n        # Plot the arm with enhanced appearance\n        plot_arm_3d!(p, arm, joint_angles)\n    end\n    \n    gif(animation, \"sequential_targets_3d.gif\", fps=15, show_msg = false)\n    return nothing\nend\n\nMain.var\"##WeaveSandBox#277\".animate_sequential_targets_3d","category":"section"},{"location":"categories/advanced_examples/robotic_arm/#Model-specification","page":"Robotic Arm","title":"Model specification","text":"@model function robotic_arm_3d_model(arm, environment, initial_state, goal, horizon, dt)\n    # Extract properties\n    g = get_gravity(environment)\n    num_links, _, link_masses, _ = get_properties(arm)\n    \n    # Initial state prior\n    s[1] ~ MvNormal(mean = initial_state, covariance = 1e-5 * I)\n    \n    for i in 1:horizon\n        # Prior on torques - compensate for gravity at each joint\n        # For 3D arm: first joint (yaw) not affected by gravity, \n        # pitch joints affected based on angle\n        gravity_compensation = zeros(2*num_links)\n        for j in 1:num_links\n            if j > 1  # Skip first joint (base yaw)\n                gravity_compensation[2*j-1] = link_masses[j] * g * 0.5  # Pitch compensation\n            end\n        end\n        \n        u[i] ~ MvNormal(Œº = gravity_compensation, Œ£ = diageye(2*num_links))\n        \n        # State transition\n        s[i + 1] ~ MvNormal(\n            Œº = state_transition_3d(s[i], u[i], arm, environment, dt),\n            Œ£ = 1e-10 * I\n        )\n    end\n    \n    # Final state constraint\n    s[end] ~ MvNormal(mean = goal, covariance = 1e-5 * diageye(4*num_links))\nend\n\n\n@meta function robotic_arm_meta()\n    # Approximate the state transition\n    state_transition_3d() -> Unscented()\nend\n\nrobotic_arm_meta (generic function with 1 method)","category":"section"},{"location":"categories/advanced_examples/robotic_arm/#Integration-Possibilities","page":"Robotic Arm","title":"Integration Possibilities","text":"While this example keeps kinematics separate from the probabilistic model, it's theoretically possible to integrate them directly:\n\nEmbedded Forward Kinematics: The model could include forward kinematics as part of its structure, allowing direct optimization in Cartesian space\nEmbedded Inverse Kinematics: The inference process could solve inverse kinematics simultaneously with trajectory optimization\n\nFor example, we could define a model that directly optimizes for reaching a Cartesian target:\n\n@model function direct_cartesian_model(arm, environment, initial_state, target_position, horizon, dt)\n    # Initial state prior\n    s[1] ~ MvNormal(mean = initial_state, covariance = 1e-5 * I)\n    \n    for i in 1:horizon\n        # Control priors\n        u[i] ~ MvNormal(Œº = zeros(num_controls), Œ£ = diageye(num_controls))\n        \n        # State transition\n        s[i + 1] ~ MvNormal(\n            Œº = state_transition(s[i], u[i], arm, environment, dt),\n            Œ£ = 1e-10 * I\n        )\n        \n        # Calculate end effector position using forward kinematics\n        ee_pos[i] := forward_kinematics(arm, s[i][1:num_joints])\n    end\n    \n    # Final position constraint directly in Cartesian space\n    ee_pos[horizon] ~ MvNormal(mean = target_position, covariance = 1e-5 * I)\nend\n\nThis approach would eliminate the need for separate inverse kinematics calculations but would make the inference problem more complex. For clarity and computational efficiency, this example keeps these components separate.","category":"section"},{"location":"categories/advanced_examples/robotic_arm/#Motion-Planning","page":"Robotic Arm","title":"Motion Planning","text":"\"\"\"\n    move_to_target_3d(arm, env, start, target_position, horizon, dt)\n\nPlan motion to reach a target position in 3D space using the RxInfer model.\n\"\"\"\nfunction move_to_target_3d(arm::RoboticArm3D{N}, env::Environment, start::ArmState3D, target_position, horizon, dt) where {N}\n    # Convert ArmState3D to state vector\n    initial_state = vcat(start.joint_angles, start.joint_velocities)\n    \n    # Calculate target joint angles that would reach the target position\n    target_joint_angles = inverse_kinematics_3d(arm, target_position)\n    \n    # Create goal state (target angles and zero velocities)\n    goal_state = vcat(target_joint_angles, zeros(length(target_joint_angles)))\n        \n    # Create and run the inference using the correct API structure\n    results = infer(\n        model = robotic_arm_3d_model(\n            arm = arm,\n            environment = env,\n            horizon = horizon,\n            dt = dt\n        ),\n        data = (\n            initial_state = initial_state,\n            goal = goal_state,\n        ),\n        meta = robotic_arm_meta(),\n        returnvars = (s = KeepLast(), u = KeepLast())\n    )\n    \n    # Extract trajectories - FIXED to handle MvNormalWeightedMeanPrecision\n    states_distributions = results.posteriors[:s]\n    controls_distributions = results.posteriors[:u]\n    \n    # Extract means from the distributions\n    states = [mean(dist) for dist in states_distributions]\n    controls = [mean(dist) for dist in controls_distributions]\n    \n    # Convert to joint angles and velocities\n    n = length(states[1]) √∑ 2\n    joint_angles = [state[1:n] for state in states]\n    joint_velocities = [state[n+1:end] for state in states]\n    \n    return joint_angles, joint_velocities, controls\nend\n\n\n\n\"\"\"\n    run_3d_example()\n\nRun a complete example of 3D motion planning for a robotic arm.\n\"\"\"\nfunction run_3d_example()\n    # Create a 2-link 3D robotic arm\n    arm = RoboticArm3D{2}(\n        num_links = 2,                      # 2-link arm\n        link_lengths = [1.0, 0.8],          # Lengths of links\n        link_masses = [0.5, 0.3],           # Masses of links\n        joint_torque_limits = [5.0, 5.0, 3.0, 3.0]  # Maximum torques (2 per joint)\n    )\n    \n    # Create an environment\n    env = Environment(gravitational_constant = 9.81)\n    \n    # Define an expanded sequence of targets with more points\n    # Avoid the origin (0,0,0) which causes issues\n    targets = [\n        [1.5, 0.0, 0.3],     # Forward\n        [1.0, 1.0, 0.5],     # Forward-right and up\n        [0.0, 1.5, 0.3],     # Right\n        [-0.5, 1.0, 0.0],    # Back-right and down\n        [-1.0, 0.5, 0.8],    # Back and up\n        [-1.0, -0.5, 0.4],   # Back-left and mid-height\n        [-0.5, -1.0, 0.0],   # Back-left and down\n        [0.0, -1.5, 0.3],    # Left\n        [0.8, -0.8, 0.3],    # Forward-left\n        [0.5, 0.0, 1.5],     # Forward and up\n        [0.2, 0.2, 0.3]      # Near home position but not at origin\n    ]\n    \n    # Parameters for motion planning\n    horizon = 10   # Keep horizon at 10 as requested\n    dt = 0.1       # Time step\n    \n    # Initialize the arm state (all zeros)\n    initial_state = ArmState3D(\n        [0.0, 0.3, 0.3, 0.0],  # Start with a slight bend rather than all zeros\n        zeros(4)               # Joint velocities\n    )\n    \n    # Store the states, controls, and targets for later visualization\n    all_states = []\n    all_controls = []\n    current_state = initial_state\n    \n    # Plan motion for each target\n    for (i, target) in enumerate(targets)\n        println(\"\\nPlanning motion to target $i: $target\")\n        \n        # Plan motion to the target\n        Œ∏_trajectory, œâ_trajectory, u_trajectory = move_to_target_3d(arm, env, current_state, target, horizon, dt)\n        \n        # Combine all states into a single matrix for visualization\n        states_matrix = hcat(Œ∏_trajectory...)\n        \n        # Update the current state for the next target\n        current_state = ArmState3D(\n            Œ∏_trajectory[end],\n            œâ_trajectory[end]\n        )\n        \n        # Store the results\n        push!(all_states, states_matrix)\n        push!(all_controls, hcat(u_trajectory...))\n    end\n    \n    # Animate the motion through all targets\n    animation = animate_sequential_targets_3d(arm, all_states, targets)\n    \n    return arm, all_states, targets, all_controls\nend\n\nMain.var\"##WeaveSandBox#277\".run_3d_example\n\narm, states, targets, controls = run_3d_example();\n\nPlanning motion to target 1: [1.5, 0.0, 0.3]\n\nPlanning motion to target 2: [1.0, 1.0, 0.5]\n\nPlanning motion to target 3: [0.0, 1.5, 0.3]\n\nPlanning motion to target 4: [-0.5, 1.0, 0.0]\n\nPlanning motion to target 5: [-1.0, 0.5, 0.8]\n\nPlanning motion to target 6: [-1.0, -0.5, 0.4]\n\nPlanning motion to target 7: [-0.5, -1.0, 0.0]\n\nPlanning motion to target 8: [0.0, -1.5, 0.3]\n\nPlanning motion to target 9: [0.8, -0.8, 0.3]\n\nPlanning motion to target 10: [0.5, 0.0, 1.5]\n\nPlanning motion to target 11: [0.2, 0.2, 0.3]\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [90137ffa] StaticArrays v1.9.17\n\n\n","category":"section"},{"location":"categories/problem_specific/ising_model/","page":"Ising Model","title":"Ising Model","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/problem_specific/ising_model/#Recovering-a-hidden-temperature-field-from-hot/cold-readings","page":"Ising Model","title":"Recovering a hidden temperature field from hot/cold readings","text":"Imagine a 2D grid of true temperatures T[i, j] over a surface. The sensors we have are simple: they only tell us whether a location is ‚Äúhot‚Äù (1) or ‚Äúcold‚Äù (0) relative to a threshold. We do not see temperatures directly. Our goal is to reconstruct the continuous temperature field from these binary observations by exploiting the fact that real temperatures vary smoothly across space.","category":"section"},{"location":"categories/problem_specific/ising_model/#Generative-model-(intuition)","page":"Ising Model","title":"Generative model (intuition)","text":"Latent field: Continuous temperatures T[i, j] that are spatially smooth; neighbors tend to be similar.\nObservations: Binary hot/cold readings y[i, j] ‚àà {0,1} with noise, modeled as y[i, j] ~ Bernoulli(œÉ(T[i, j])), where œÉ is the logistic function. The threshold can be absorbed into the offset of T.\nSpatial prior: A pairwise coupling between neighbors that penalizes sharp jumps, encouraging smooth reconstructions unless data strongly suggests boundaries.\n\nIn this notebook, we implement the logistic observation via a custom Sigmoid node and enforce spatial smoothness using Gaussian couplings between neighboring cells (a Gaussian MRF‚Äìlike prior).","category":"section"},{"location":"categories/problem_specific/ising_model/#What-this-notebook-does","page":"Ising Model","title":"What this notebook does","text":"Simulates observations: Loads a smooth grayscale image as a proxy for T and produces noisy hot/cold readings via a logistic sensor.\nBuilds the model: Combines a logistic observation (Sigmoid) with a spatial prior coupling neighbors.\nPerforms inference: Uses variational message passing to approximate the posterior over T.\nVisualizes results: Compares the binary observations to the recovered continuous temperature field (normalized).","category":"section"},{"location":"categories/problem_specific/ising_model/#Setup","page":"Ising Model","title":"Setup","text":"Load the packages used for probabilistic modeling, image I/O, plotting, and numerical routines.\n\nusing Distributions, ExponentialFamilyProjection, Images, Plots, ReactiveMP, RxInfer, StableRNGs, StatsFuns","category":"section"},{"location":"categories/problem_specific/ising_model/#Custom-logistic-observation-factor","page":"Ising Model","title":"Custom logistic observation factor","text":"We introduce a Sigmoid factor that models the logistic link and provide variational rules needed by the optimizer. This lets us couple the binary observations to the continuous latent field.\n\nstruct Sigmoid end\n\n@node Sigmoid Stochastic [out, x]\n\n@rule Sigmoid(:x, Marginalisation) (q_out::PointMass,) = begin\n    y = mean(q_out)\n    y = float(mean(q_out))\n    sign = 1-2y\n    # Provide logpdf, gradient, and Hessian for 1D logistic-Bernoulli\n    _logpdf = (out, x) -> (out[] = -softplus(sign * x))\n    _grad = (out, x) -> (out[1] = y - logistic(x))\n    _hess = (out, x) -> (out[1, 1] = -logistic(x) * (1 - logistic(x)))\n    return ExponentialFamilyProjection.InplaceLogpdfGradHess(_logpdf, _grad, _hess)\nend\n\nfunction BayesBase.prod(::GenericProd, left::UnivariateGaussianDistributionsFamily, right::ExponentialFamilyProjection.InplaceLogpdfGradHess)\n    m = mean(left)\n    œÉ = var(left)\n    combined_logpdf! = (out, x) -> begin\n        right.logpdf!(out, x)\n        out[] = logpdf(left, x) + out[]\n    end\n    combined_gradhes! = (out_grad, out_hess, x) -> begin\n        out_grad, out_hess = right.grad_hess!(out_grad, out_hess, x)\n        out_grad .= out_grad .- ((x .- m) ./ œÉ)\n        out_hess .= out_hess .- 1 / œÉ\n        return out_grad, out_hess\n    end\n    return ExponentialFamilyProjection.InplaceLogpdfGradHess(combined_logpdf!, combined_gradhes!)\nend\n\nfunction BayesBase.prod(::GenericProd, left::ExponentialFamilyProjection.InplaceLogpdfGradHess, right::UnivariateGaussianDistributionsFamily)\n    return prod(GenericProd(), right, left)\nend","category":"section"},{"location":"categories/problem_specific/ising_model/#Data:-proxy-temperature-field-and-binary-observations","page":"Ising Model","title":"Data: proxy temperature field and binary observations","text":"We load a smooth grayscale image as a stand-in for the true temperature field, normalize it, and generate noisy hot/cold readings by sampling from mathrmBernoulli(sigma(T))\n\nrng = StableRNG(112)\nmnist_picture = load(\"mnist_picture.png\")\nmnist_picture\n\nsample_matrix = convert(Matrix{Float64}, mnist_picture);\nnormalized_matrix = (sample_matrix .- mean(sample_matrix))/std(sample_matrix)\n\nobservation_matrix = begin \n    o = zeros(28, 28)\n    for i in 1:28, j in 1:28\n        o[i, j] = rand(rng, Bernoulli(logistic(normalized_matrix[i, j])))\n    end\n    o\nend\n\nGray.(observation_matrix)\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/ising_model/#Model-and-first-inference-run","page":"Ising Model","title":"Model and first inference run","text":"The model places a Gaussian prior with neighbor couplings on the latent field xij and uses a logistic observation y sim mathrmBernoulli(sigma(x)) via the custom Sigmoid factor.\nWe run variational inference and visualize three panels: normalized proxy field, binary observations, and the reconstructed field.\n\n@model function sigmoid_ising(h, w, image, connection_force)\n    # x_extra_prior ~ NormalMeanVariance(0, 1)\n    local x\n    # as smaller variance as closer the estimates\n    var_used = 1.0/connection_force\n    prior ~ NormalMeanVariance(0, var_used)\n    for i in 1:h, j in 1:w\n        x[i, j] ~ NormalMeanVariance(prior, var_used)\n    end \n    for i in 1:h, j in 1:w\n        image[i, j] ~ Sigmoid(x[i, j]) \n        if i < h && j < w\n           x[i, j] ~ NormalMeanVariance(x[i+1, j], var_used)\n           x[i, j] ~ NormalMeanVariance(x[i, j+1], var_used)\n        end\n        if i < h\n            x[i, j] ~ NormalMeanVariance(x[i+1, j], var_used)\n        end\n        if j < w\n            x[i, j] ~ NormalMeanVariance(x[i, j+1], var_used)\n        end\n    end\nend\n\n# Streaming init & autoupdates\nsigmoid_init = @initialization begin\n    q(x) = NormalMeanVariance(0.0, 1.0)\n    q(prior) = NormalMeanVariance(0.5, 1)\nend\n\nbinary_constraints = @constraints begin\n    q(x) :: ProjectedTo(NormalMeanVariance, parameters = ProjectionParameters(\n        tolerance = 1e-8,\n        strategy = ExponentialFamilyProjection.GaussNewton(nsamples = 1), # deterministic\n    ))\n    q(x, prior) = q(x)q(prior)\n    q(x) = MeanField()\n    # q(x_prior, x, x_extra, x_extra_prior) = q(x_prior)q(x)q(x_extra, x_extra_prior)\nend\n\nresult = infer(\n    model          = sigmoid_ising(h=28, w=28, connection_force = 1), \n    data           = (image = observation_matrix,),\n    returnvars     = KeepEach(),\n    # options        = (limit_stack_depth = 100, ),\n    iterations     = 5,\n    initialization = sigmoid_init,\n    constraints    = binary_constraints,\n    showprogress   = true,\n);\n\nsigmoid_outputs = map(mean, result.posteriors[:x][5]);\nnormalize_sigmoid_outputs = (sigmoid_outputs .- mean(sigmoid_outputs))/std(sigmoid_outputs)\n\nl = @layout [\n    grid(1,3)\n]\nplot_obj = plot(layout=l)\nplot!(plot_obj, Gray.(normalized_matrix), subplot=1, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\nplot!(plot_obj, Gray.(observation_matrix), subplot=2, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\nplot!(plot_obj, Gray.(normalize_sigmoid_outputs), subplot=3, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/ising_model/#Introduce-missing-observations","page":"Ising Model","title":"Introduce missing observations","text":"We simulate missing data by randomly masking a fraction of binary readings. Masked locations will be rendered in yellow in the visualization.\n\nmask_probability = 0.25\nmasked_pattern = rand(rng, Bernoulli(mask_probability), size(observation_matrix)...) \n\n# Apply mask to observations as Union{Missing, Float64}\nmasked_observation_matrix = Matrix{Union{Missing, Float64}}(undef, size(observation_matrix)...)\n@inbounds for j in axes(observation_matrix, 2), i in axes(observation_matrix, 1)\n    masked_observation_matrix[i, j] = masked_pattern[i, j] ? missing : Float64(observation_matrix[i, j])\nend","category":"section"},{"location":"categories/problem_specific/ising_model/#Missing-binary-observations-and-the-Monte-Carlo-message","page":"Ising Model","title":"Missing binary observations and the Monte Carlo message","text":"When some binary outputs  y[i,j] in {0,1} are missing, we can still perform inference by passing an approximate message from the observation factor using the variational marginal over the latent field.\n\nFor the logistic observation model y | x ~ Bernoulli(œÉ(x)), the factor contribution is $ f(y \\mid x) = \\mathrm{Bernoulli}(y; \\sigma(x)) = \\sigma(x)^y (1-\\sigma(x))^{1-y}. $ The message needed by variational updates in many formulations is the expected log-factor under the current marginal q(x): $ \\mathbb{E}{q(x)}[\\log f(y \\mid x)] = y\\,\\mathbb{E}{q(x)}[\\log \\sigma(x)] + (1-y)\\,\\mathbb{E}_{q(x)}[\\log(1-\\sigma(x))] = \\mu y + C. $ Note that $ \\log \\sigma(x) - \\log(1-\\sigma(x)) = x.$","category":"section"},{"location":"categories/problem_specific/ising_model/#Implement-observation-message-for-missing-outputs","page":"Ising Model","title":"Implement observation message for missing outputs","text":"We add a simple rule for q(y) when needed: use the current mean of q(x) passed through the logistic to parameterize a Bernoulli. This provides a lightweight, consistent message for the missing-observation case.\n\n@rule Sigmoid(:out, Marginalisation) (q_x::NormalMeanVariance, ) = begin\n    return Bernoulli(logistic(mean(q_x)))\nend","category":"section"},{"location":"categories/problem_specific/ising_model/#Inference-with-missing-observations","page":"Ising Model","title":"Inference with missing observations","text":"We now run the same model on the masked data. The observation message (previous cell) lets inference proceed for locations where y is missing.\n\nresult_masked = infer(\n    model          = sigmoid_ising(h=28, w=28, connection_force=1), \n    data           = (image = masked_observation_matrix,),\n    returnvars     = KeepEach(),\n    # options        = (limit_stack_depth = 100, ),\n    iterations     = 5,\n    initialization = sigmoid_init,\n    constraints    = binary_constraints,\n    showprogress   = true,\n);","category":"section"},{"location":"categories/problem_specific/ising_model/#Visualize-masked-observations-and-reconstruction","page":"Ising Model","title":"Visualize masked observations and reconstruction","text":"Yellow pixels mark missing observations; gray pixels show observed hot/cold readings rendered as grayscale for context.\nWe compare the original normalized proxy field, the binary observations, the unmasked reconstruction, the masked observation map, and the masked reconstruction.\n\nsigmoid_outputs_masked = map(mean, result_masked.posteriors[:x][5]);\nnormalize_masked_sigmoid_outputs = (sigmoid_outputs_masked .- mean(sigmoid_outputs_masked))/std(sigmoid_outputs_masked)\n\nyellow = colorant\"yellow\"# Replace missings with 0 just to build the base gray image in RGB\nmasked_img = RGB.(Gray.(replace(masked_observation_matrix, missing => 0.0)))\nmasked_img[masked_pattern] .= yellow\n\n\nplot_obj_masked = plot(layout=@layout [\n    grid(1,5)\n])\nplot!(plot_obj_masked, Gray.(normalized_matrix), subplot=1, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\nplot!(plot_obj_masked, Gray.(observation_matrix), subplot=2, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\nplot!(plot_obj_masked, Gray.(normalize_sigmoid_outputs), subplot=3, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\nplot!(plot_obj_masked, masked_img, subplot=4, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\nplot!(plot_obj_masked, Gray.(normalize_masked_sigmoid_outputs), subplot=5, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/ising_model/#Sweep-over-connection_force-and-animate-results","page":"Ising Model","title":"Sweep over connection_force and animate results","text":"We will run inference for a range of connection_force values on both the original noised observations and the masked observations, and generate animations to visualize how the reconstruction changes.\n\nexponents = range(-10.0, 10.0, length=25)\nconnection_forces = 10.0 .^ exponents\niterations_anim = 5\n\nfunction run_reconstruction(image, connection_force; h=28, w=28, iterations=iterations_anim)\n    result = infer(\n        model          = sigmoid_ising(h=h, w=w, connection_force=connection_force),\n        data           = (image = image,),\n        returnvars     = KeepEach(),\n        iterations     = iterations,\n        initialization = sigmoid_init,\n        constraints    = binary_constraints,\n        showprogress   = false,\n    )\n    xs = map(mean, result.posteriors[:x][iterations])\n    return (xs .- mean(xs)) / std(xs)\nend\n# helper for animation\n\nrun_reconstruction (generic function with 1 method)\n\nanim_noised = @animate for (idx, cf) in enumerate(connection_forces)\n    k = exponents[idx]\n    recon = run_reconstruction(observation_matrix, cf)\n    l = @layout [grid(1,3)]\n    plt = plot(layout=l, size=(900, 300), title=\"c. force = $(round(10^k, sigdigits=2))\")\n    plot!(plt, Gray.(normalized_matrix), subplot=1, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\n    plot!(plt, Gray.(observation_matrix), subplot=2, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\n    plot!(plt, Gray.(recon), subplot=3, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\nend\n\ngif(anim_noised, \"ising_connection_force_noised.gif\", fps=5);\n\n(Image: )\n\nanim_masked = @animate for (idx, cf) in enumerate(connection_forces)\n    k = exponents[idx]\n    recon = run_reconstruction(masked_observation_matrix, cf)\n    l = @layout [grid(1,3)]\n    plt = plot(layout=l, size=(900, 300), title=\"c. force = $(round(10^k, sigdigits=2))\")\n    plot!(plt, Gray.(normalized_matrix), subplot=1, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\n    plot!(plt, masked_img, subplot=2, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\n    plot!(plt, Gray.(recon), subplot=3, legend=false, framestyle=:none, ticks=nothing, aspect_ratio=:equal)\nend\n\ngif(anim_masked, \"ising_connection_force_masked.gif\", fps=5);\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/ising_model/#Conclusion","page":"Ising Model","title":"Conclusion","text":"We reconstructed a smooth latent temperature field from binary hot/cold readings using a logistic observation model and a spatial (neighbor) prior.\nWith missing observations, adding an approximate observation message allows inference to proceed; the reconstruction remains coherent where data is absent.\nThe connection force is a very important hyperparameter in this model that controls the smoothing. If it's too small, no recovery is possible‚Äîthe model just follows the data. If it's too strong, it can overpower the data completely.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [31c24e10] Distributions v0.25.123\n‚åÉ [17f509fa] ExponentialFamilyProjection v3.1.1\n  [916415d5] Images v0.26.2\n  [91a5bcdd] Plots v1.41.6\n  [a194aa59] ReactiveMP v5.6.5\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [4c63d2b9] StatsFuns v1.5.2\nInfo Packages marked with ‚åÉ have new versions available and may be upgradable.\n\n\n","category":"section"},{"location":"autogenerated/list_of_examples/","page":"List of Examples","title":"List of Examples","text":"<style>\n    :root {\n        --tag-bg-color: #f3f6f9;\n        --tag-text-color: #476582;\n        --category-text-color: #2c3e50;\n        --card-border-color: #e9ecef;\n        --card-bg-color: transparent;\n        --text-color: inherit;\n        --resources-bg-color: #f8f9fa;\n        --text-muted-color: #666;\n        --description-text-color: #476582;\n    }\n    \n    .theme--documenter-dark {\n        --tag-bg-color: #2d2d2d;\n        --tag-text-color: #9ecbff;\n        --category-text-color: #e6e6e6;\n        --card-border-color: #404040;\n        --card-bg-color: #1f1f1f;\n        --text-color: #e6e6e6;\n        --resources-bg-color: #1f1f1f;\n        --text-muted-color: #999;\n        --description-text-color: #9ecbff;\n    }\n</style>","category":"section"},{"location":"autogenerated/list_of_examples/#List-of-Examples","page":"List of Examples","title":"List of Examples","text":"Welcome to our curated collection of RxInfer.jl examples! Here you'll find a comprehensive set of tutorials, demonstrations, and real-world applications that showcase the power and flexibility of RxInfer.jl.\n\nEach example comes with:\n\nA detailed description of concepts covered\nRelevant tags for easy filtering\nComplete source code and explanations\nVisualizations and results analysis\n\nnote: Contributing\nThis gallery is community-driven and automatically generated from our repository. We welcome your contributions!Report a bug\nSubmit a pull request\nRead contribution guide\nRxInfer.jl respository","category":"section"},{"location":"autogenerated/list_of_examples/#External-Resources","page":"List of Examples","title":"External Resources","text":"<div style=\"margin: 1.5em 0; padding: 1.2em; border-radius: 8px; \n    background-color: var(--resources-bg-color, #f8f9fa); \n    border: 1px solid var(--card-border-color, #e9ecef);\">\n    <h4 style=\"margin: 0 0 1em 0; color: var(--category-text-color, #333);\">Community Tutorials & Guides</h4>\n    <ul style=\"margin: 0; padding-left: 1.2em;\">\n        <li style=\"margin-bottom: 0.8em;\">\n            <strong>Active Inference with RxInfer.jl</strong><br/>\n            <span style=\"color: var(--text-muted-color, #666);\">An in-depth exploration of Active Inference principles guided by \n            <a href=\"https://www.linkedin.com/in/kobusesterhuysen/\">Kobus Esterhuysen</a> at \n            <a href=\"https://learnableloop.com/#category=RxInfer\">Learnable Loop</a>.</span>\n        </li>\n        <li style=\"margin-bottom: 0.8em;\">\n            <strong>Video Tutorial Series</strong><br/>\n            <span style=\"color: var(--text-muted-color, #666);\">Comprehensive video tutorials covering RxInfer.jl's core concepts and applications by \n            <a href=\"https://www.youtube.com/@doggodotjl/search?query=RxInfer\">@doggotodjl</a>.</span>\n        </li>\n        <li style=\"margin-bottom: 0.8em;\">\n            <strong>Victor Flores blogpost</strong><br/>\n            <span style=\"color: var(--text-muted-color, #666);\">A collection of projects and examples with RxInfer (but not limited to) at \n            <a href=\"https://vflores-io.github.io/\">vflores-io</a>.</span>\n        </li>\n    </ul>\n    \n    <h4 style=\"margin: 1.5em 0 1em 0; color: var(--category-text-color, #333);\">Python Integration & Server Infrastructure</h4>\n    <ul style=\"margin: 0; padding-left: 1.2em;\">\n        <li style=\"margin-bottom: 0.8em;\">\n            <strong>RxInferServer.jl</strong><br/>\n            <span style=\"color: var(--text-muted-color, #666);\">RESTful API service for deploying RxInfer models. \n            <a href=\"https://github.com/lazydynamics/RxInferServer\">GitHub Repository</a> | \n            <a href=\"https://server.rxinfer.com\">Documentation</a></span>\n        </li>\n        <li style=\"margin-bottom: 0.8em;\">\n            <strong>RxInferClient.py</strong><br/>\n            <span style=\"color: var(--text-muted-color, #666);\">Python SDK for interacting with RxInferServer. \n            <a href=\"https://github.com/lazydynamics/RxInferClient.py\">GitHub Repository</a> | \n            <a href=\"https://lazydynamics.github.io/RxInferClient.py/\">Documentation</a></span>\n        </li>\n    </ul>\n</div>\n\n<h2 style=\"margin-top: 2em; margin-bottom: 1em; color: var(--category-text-color, #2c3e50);\">\n    Basic Examples\n</h2>\n\n<div style=\"margin: -0.5em 0 2em 0; color: var(--description-text-color, #476582);\">\n    Fundamental concepts and introductory tutorials. Start here if you're new to RxInfer.jl.\nThese examples cover basic probabilistic models, inference techniques, and data processing.\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nBayesian Binomial Regression\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n            An introductory tutorial to Bayesian binomial regression with RxInfer. \n    Learn how to model binary outcomes using logistic regression with proper Bayesian inference.\n    The example demonstrates the use of Expectation Propagation (EP) algorithm and Polya-Gamma augmentation.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    basic examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    regression\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    multivariate\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    expectation propagation\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    polya-gamma\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nBayesian Linear Regression\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        An extensive tutorial on Bayesian linear regression with RxInfer with a lot of examples, including multivariate and hierarchical linear regression.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    basic examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    regression\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    tutorial\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    hierarchical model\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    multivariate\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nBayesian Multinomial Regression\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n            An introductory tutorial to Bayesian multinomial regression with RxInfer. \n    Learn how to model categorical outcomes using multinomial regression with proper Bayesian inference.\n    The example demonstrates the use of Expectation Propagation (EP) algorithm and Polya-Gamma augmentation.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    basic examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    regression\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    multivariate\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    expectation propagation\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    polya-gamma\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nBayesian Networks: The Sprinkler Model\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n            An introductory tutorial to Bayesian Networks with RxInfer using the classic sprinkler model.\n    Learn how to construct and perform inference in a simple Bayesian network given conditional probability tables.\n    The example demonstrates core concepts like conditional independence, belief propagation, and evidence-based inference.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    basic examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    bayesian networks\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    discrete bayesian networks\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    sprinkler model\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    conditional probability\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nCoin toss model (Beta-Bernoulli)\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        An example of Bayesian inference in Beta-Bernoulli model with IID observations.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    basic examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    conjugate model\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    iid observations\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    beta bernoulli\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nContextual Bandits\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This notebooks covers RxInfer usage for the Contextual Bandits problem.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    basic examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    contextual bandits\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nFeature Functions in Bayesian Regression\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        An example of Bayesian inference in a parametric Gaussian regression model.\nBased on \"Probabilistic Numerics: Computation as Machine Learning\" by Hennig, Osborne and Kersting.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    probabilistic numerics\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    regression\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    basis functions\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    parametric\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nForgetting Factors for Online Inference\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This example demonstrates online Bayesian inference using forgetting factors to adaptively adjust the observation noise precision over time. \nForgetting factors help the model gradually \"forget\" old data, allowing it to better track non-stationary processes and adapt to changing noise levels.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    online inference\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    forgetting factors\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    kalman filter\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nHow to train your Hidden Markov Model\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        An example of structured variational Bayesian inference in Hidden Markov Model with unknown transition and observational matrices.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    basic examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    hmm\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    structured inference\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    variational inference\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nIncomplete Data\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This notebooks covers RxInfer usage for the Incomplete Data problem.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    basic examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    incomplete data\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nKalman filtering and smoothing\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        In this demo, we are interested in Bayesian state estimation in different types of State-Space Models, including linear, nonlinear, and cases with missing observations\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    basic examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    state space model\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    kalman filter\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    missing data\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    nonlinear\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nPOMDP Control with Reactive Inference\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        An example demonstrating how to perform control in Partially Observable Markov Decision Processes (POMDPs) using reactive message passing and variational inference.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    basic examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    pomdp\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    control\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    structured inference\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    variational inference\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nPredicting Bike Rental Demand\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        An illustrative guide to implementing prediction mechanisms within RxInfer.jl, using bike rental demand forecasting as a contextual example.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    basic examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    prediction\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    time series\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    real data\n</span>\n\n</div>\n\n<h2 style=\"margin-top: 2em; margin-bottom: 1em; color: var(--category-text-color, #2c3e50);\">\n    Advanced Examples\n</h2>\n\n<div style=\"margin: -0.5em 0 2em 0; color: var(--description-text-color, #476582);\">\n    More complex applications and advanced inference techniques. These examples demonstrate\nsophisticated models, performance optimization, and integration with other Julia packages.\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nActive Inference Mountain car\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This notebooks covers RxInfer usage in the Active Inference setting for the simple mountain car problem.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    active inference\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    control\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    reinforcement learning\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nAdvanced Tutorial\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This notebook covers the fundamentals and advanced usage of the `RxInfer.jl` package.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    tutorial\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    fundamentals\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nAssessing People's Skills\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        The demo is inspired by the example from Chapter 2 of Bishop's Model-Based Machine Learning book. We are going to perform an exact inference to assess the skills of a student given the results of the test.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    exact inference\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    educational\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    skill assessment\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nBayesian Structured Time Series\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This notebooks covers RxInfer usage in the Bayesian Structured Time Series setting.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    bayesian\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    time series\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    structured\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nChance-Constrained Active Inference\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This notebook applies reactive message passing for active inference in the context of chance-constraints.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    active inference\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    constraints\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    control\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nConjugate-Computational Variational Message Passing (CVI)\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This example provides an extensive tutorial for the non-conjugate message-passing based inference by exploiting the local CVI approximation.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    cvi\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    non conjugate\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    variational inference\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    tutorial\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nDrone Dynamics\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This example shows how to use RxInfer.jl automated inference to simulate drone dynamics.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nSolve GP regression by SDE\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        In this notebook, we solve a GP regression problem by using 'Stochastic Differential Equation' (SDE). This method is well described in the dissertation 'Stochastic differential equation methods for spatio-temporal Gaussian process regression.' by Arno Solin and 'Sequential Inference for Latent Temporal Gaussian Process Models' by Jouni Hartikainen.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    gaussian process\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    sde\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    regression\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    state space model\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nInfinite Data Stream\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This example shows RxInfer capabilities of running inference for infinite time-series data.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    streaming\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    online inference\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    time series\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nIntegrating Neural Networks with Flux.jl\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This example shows how to use RxInfer.jl together with Flux.jl to incorporate neural networks into probabilistic models.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    neural networks\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    deep learning\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    integration\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    Flux.jl\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nLearning Dynamics with VAEs\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This example shows how to use RxInfer.jl automated inference to learn dynamics in latent space of a VAE.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    vae\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    dynamics\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nMulti-agent Trajectory Planning\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This example shows how to plan multi-agents' trajectories while avoiding obstacles and collisions between agents.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nNonlinear Sensor Fusion\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        Nonlinear object position identification using a sparse set of sensors\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    sensor fusion\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    nonlinear\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    sparse data\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nParameter Optimisation with Optim.jl\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This example shows how to use RxInfer.jl together with Optim.jl to perform parameter optimisation in probabilistic models.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    optimization\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    parameter estimation\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    integration\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    Optim.jl\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nRobotic Arm\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This example explores how RxInfer.jl's automated inference can be applied to path planning for a robotic arm and demonstrates how probabilistic inference enables smooth and efficient motion planning. Ideal for those interested in robotics, Bayesian inference, and intelligent control systems.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    advanced examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    robotics\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    probabilistic inference\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    path planning\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    Bayesian methods\n</span>\n\n</div>\n\n<h2 style=\"margin-top: 2em; margin-bottom: 1em; color: var(--category-text-color, #2c3e50);\">\n    Problem Specific\n</h2>\n\n<div style=\"margin: -0.5em 0 2em 0; color: var(--description-text-color, #476582);\">\n    Real-world applications and domain-specific models. These examples show how RxInfer.jl\ncan be applied to specific problems like time series analysis and signal processing.\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nAutoregressive Models\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        An example of Bayesian treatment of latent AR and ARMA models. Reference: [Albert Podusenko, Message Passing-Based Inference for Time-Varying Autoregressive Models](https://www.mdpi.com/1099-4300/23/6/683).\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    problem specific\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    time series\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    arma\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    latent variables\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nGamma Mixture Model\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This example implements one of the Gamma mixture experiments outlined in https://biaslab.github.io/publication/mp-based-inference-in-gmm/ .\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    problem specific\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    mixture model\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    gamma distribution\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    clustering\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nGaussian Mixture\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This example implements variational Bayesian inference in univariate and multivariate Gaussian mixture models with mean-field assumption.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    problem specific\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    mixture model\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    gaussian\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    mean field\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    clustering\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nHierarchical Gaussian Filter\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        An example of online inference procedure for Hierarchical Gaussian Filter with univariate noisy observations using Variational Message Passing algorithm. Reference: [Ismail Senoz, Online Message Passing-based Inference in the Hierarchical Gaussian Filter](https://ieeexplore.ieee.org/document/9173980).\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    problem specific\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    hierarchical model\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    online inference\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    filtering\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nInvertible neural networks: a tutorial\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        An example of variational Bayesian Inference with invertible neural networks. Reference: Bart van Erp, Hybrid Inference with Invertible Neural Networks in Factor Graphs.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    problem specific\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    neural networks\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    invertible networks\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    hybrid inference\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nIsing Model\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        Using Bayesian Inference and RxInfer to temperature over the grid with binary observations.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    problem specific\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    grid modeling\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    interaction modeling\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nLitter Model\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        Using Bayesian Inference and RxInfer to estimate daily litter events (adapted from https://learnableloop.com/posts/LitterModel_PORT.html)\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    problem specific\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    real data\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    time series\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    event modeling\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nODE Parameter Estimation\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        An example of solving Lotka Volterra ODE with RxInfer.jl. Reference: [Lotka Volterra ODE](https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations).\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    problem specific\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    ode\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    differential equations\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nProbit Model (EP)\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        In this demo we illustrate EP in the context of state-estimation in a linear state-space model that combines a Gaussian state-evolution model with a discrete observation model.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    problem specific\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    expectation propagation\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    probit\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    state space model\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nRTS vs BIFM Smoothing\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        This example performs BIFM Kalman smoother on a factor graph using message passing and compares it with the RTS implementation.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    problem specific\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    smoothing\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    kalman filter\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    comparison\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nSimple Nonlinear Node\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        In this example we create a non-conjugate model and use a nonlinear link function between variables. We show how to extend the functionality of `RxInfer` and to create a custom factor node with arbitrary message passing update rules.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    problem specific\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    nonlinear\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    custom node\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    message passing\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nStructural Dynamics with Augmented Kalman Filter\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        In this example, we estimate system states and unknown input forces for a simple **structural dynamical system** using the Augmented Kalman Filter (AKF) (https://www.sciencedirect.com/science/article/abs/pii/S0888327011003931) in **RxInfer**.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    problem specific\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    kalman filter\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    structural dynamics\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    state estimation\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nUniversal Mixtures\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n        Universal mixture modeling.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    problem specific\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    mixture model\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    universal approximation\n</span>\n\n</div>\n\n<h2 style=\"margin-top: 2em; margin-bottom: 1em; color: var(--category-text-color, #2c3e50);\">\n    Experimental Examples\n</h2>\n\n<div style=\"margin: -0.5em 0 2em 0; color: var(--description-text-color, #476582);\">\n    Experimental examples and proof-of-concepts. These examples are not yet ready for\nproduction use but are useful for research and development. They also usually require \nadditional patches to RxInfer.jl to work.\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nBayesian Trust Learning\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n            This is an experimental example of a Bayesian Trust Learning for LLM Routing.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    experimental examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    llm routing\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    bayesian trust learning\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    hierarchical bayesian models\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    custom nodes\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    custom rules\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    online learning cycles\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nLarge Language Models\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n            This is an experimental example of a Large Language Model (LLM) integration with RxInfer.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    experimental examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    large language models\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    llm\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nLatent Vector Autoregressive Model\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n            This is an experimental example of a Latent Vector Autoregressive Model (LVAR).\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    experimental examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    dynamical system\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    recurrent switching\n</span>\n\n</div>\n\n<div style=\"margin: 1.5em 0; padding: 1em 1.2em; border-radius: 8px; \n    border: 1px solid var(--card-border-color, #e9ecef);\n    background: var(--card-bg-color, transparent);\">\n    <h3 style=\"margin: 0 0 0.6em 0;\">\n\nRecurrent Switching Linear Dynamical System\n\n    </h3>\n    <p style=\"margin: 0 0 1em 0; line-height: 1.6; color: var(--text-color, inherit);\">\n            An experimental example of a Recurrent Switching Linear Dynamical System (RSLDS) model.\n\n    </p>\n    <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    experimental examples\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    dynamical system\n</span>\n <span style=\"display: inline-block; padding: 3px 7px; margin: 2px; \n    border-radius: 3px; font-size: 0.9em;\n    background: var(--tag-bg-color, #f3f6f9);\n    color: var(--tag-text-color, #476582);\">\n    recurrent switching\n</span>\n\n</div>\n\nnote: Contributing\nThis gallery is community-driven and automatically generated from our repository. We welcome your contributions!Report a bug\nSubmit a pull request\nRead contribution guide\nRxInfer.jl respository\n\n","category":"section"},{"location":"categories/basic_examples/contextual_bandits/","page":"Contextual Bandits","title":"Contextual Bandits","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/basic_examples/contextual_bandits/#Contextual-Bandits","page":"Contextual Bandits","title":"Contextual Bandits","text":"We will start this notebook with a motivating example.\n\nLet‚Äôs face it‚Äîads are annoying. But very often they‚Äôre also one of the few ways to keep the business running. Imagine a free-to-play game for example. The real question isn‚Äôt whether to show ads, but when and which kind to show, so that players don‚Äôt feel bombarded, leave the game frustrated, or stop spending altogether.\n\nIt‚Äôs a balancing act between monetization and player retention.\n\nIf you show ads too aggressively, players quit. If you show ads too cautiously, you leave money on the table. So, how do you decide what to do in each moment of a player‚Äôs session?","category":"section"},{"location":"categories/basic_examples/contextual_bandits/#Turning-Ad-Scheduling-Into-a-Learning-Problem","page":"Contextual Bandits","title":"Turning Ad Scheduling Into a Learning Problem","text":"Every player session is different. Some players are engaged, some are rushing through, some just made a purchase, some are one level away from quitting.\n\nAt every possible ad moment, you have choices like:\n\nShow a video ad (high revenue, high interruption)\nShow a banner ad (low revenue, low interruption)\nShow no ad (defer to later)\n\nAnd you have context‚Äîinformation about the session so far:\n\nPlayer‚Äôs level and progress\nTime since the last ad\nTime spent in the current session\nWhether the player just succeeded or failed at something\nRecent purchases or reward claims\n\nWhat you want is a system that learns from player behavior over time, figuring out which actions perform best in which contexts‚Äînot just maximizing clicks or ad revenue right now, but balancing that with keeping players happy and playing longer.","category":"section"},{"location":"categories/basic_examples/contextual_bandits/#Contextual-Multi-Armed-Bandits-to-the-Rescue","page":"Contextual Bandits","title":"Contextual Multi-Armed Bandits to the Rescue","text":"This is exactly where Contextual Multi-Armed Bandits (CMABs) come in.\n\nContextual‚ÄØMulti‚ÄëArmed‚ÄØBandits‚ÄØ(CMABs) extend the classic bandit setting by allowing the learner to observe a context‚Äîa feature vector that describes the current situation‚Äîbefore selecting an action (or arm). The learner‚Äôs aim is to maximise cumulative reward over time by repeatedly balancing:\n\nExploration ‚Äì trying arms whose pay‚Äëoffs are still uncertain in some contexts.\nExploitation ‚Äì choosing the arm with the highest estimated reward in the current context.\n\nCMABs sit between simple A/B tests and full reinforcement‚Äëlearning problems and are the work‚Äëhorse behind many personalisation engines.\n\nActing identically for every context wastes opportunity; CMABs formalise how to adapt decisions on‚Äëthe‚Äëfly.","category":"section"},{"location":"categories/basic_examples/contextual_bandits/#Implementing-CMABs-in-**RxInfer.jl**","page":"Contextual Bandits","title":"Implementing CMABs in RxInfer.jl","text":"In this notebook we will implement a CMAB in RxInfer.jl way. A way to tackle CMAB in RxInfer requires expressing the generative model as a hierarchical Bayesian linear‚Äëregression model and then message passing inference will do the rest.","category":"section"},{"location":"categories/basic_examples/contextual_bandits/#Generative-model-(consistent-notation)","page":"Contextual Bandits","title":"Generative model (consistent notation)","text":"Let\n\nK\n‚Äì number of arms.\nd\n‚Äì dimension of the context vector.\nc_tinmathbbR^d\n‚Äì context observed at round $t$.\na_tin1dotsK\n‚Äì arm selected at round $t$.\nr_tinmathbbR\n‚Äì realised reward.\n\nThe environment produces rewards according to:\n\nGlobal noise precision tausimmathcalG(alpha_tau beta_tau)\nArm‚Äëspecific regression parameters  k = 1dotsK theta_k sim mathcalN(m_0k V_0k) qquad  Lambda_k sim operatornameWishart(nu_0k W_0k)\nPer interaction latent coefficients  t = 1dotsT beta_t sim mathcalN(theta_a_t Lambda_a_t^-1)\nReward generation mu_t = c_t^top beta_t qquad  r_t sim mathcalN(mu_t tau^-1)\n\nInterpretation. Each arm owns a distribution of weight vectors (theta_k), capturing how the context maps to reward for that arm. On every play we draw a concrete weight vector beta_t, compute the expected reward mu_t, and then observe a noisy realisation r_t.","category":"section"},{"location":"categories/basic_examples/contextual_bandits/#Inference-and-decision‚Äëmaking","page":"Contextual Bandits","title":"Inference & decision‚Äëmaking","text":"With RxInfer we:\n\nDeclare the model above with the @model macro. (To make the example simpler, we'll have two models: one for parameters and one for predictions. A more complex scenario would be to have a single model for both.)\nStream incoming tuples (c_t a_t r_t).\nCall infer to update the posterior over (theta_k Lambda_k tau).\nCompute predictive distributions of rewards in a new context c_t+1 via infer on the predictive model:\nChoose the next arm based on sampled from the predictive distribution.\n\nBecause both learning and prediction are expressed as probabilistic inference, we keep all uncertainty in closed form‚Äîideal for principled exploration. The same pipeline generalises easily to non‚Äëlinear contexts (via feature maps) or non‚ÄëGaussian rewards by swapping likelihood terms.\n\nusing RxInfer, Distributions, LinearAlgebra, Plots, StatsPlots, ProgressMeter, StableRNGs, Random\n\nAt first let's generate synthetic data to simulate the CMAB problem.\n\nusing StableRNGs\n\n# Random number generator \nrng = StableRNG(42)\n\n# Data generation parameters\nn_train_samples = 300\nn_test_samples = 100\nn_total_samples = n_train_samples + n_test_samples\nn_arms = 10\nn_contexts = 50\ncontext_dim = 20\nnoise_sd = 0.1\n\n# Generate true arm parameters (Œ∏_k in the model description)\narms = [randn(rng, context_dim) for _ in 1:n_arms]\n\n# Generate context feature vectors with missing values\ncontexts = []\nfor i in 1:n_contexts\n    # Create a vector that can hold both Float64 and Missing values\n    context = Vector{Union{Float64,Missing}}(undef, context_dim)\n\n    # Fill with random values initially\n    for j in 1:context_dim\n        context[j] = randn(rng)\n    end\n\n    # Randomly introduce missing values in some contexts\n    if rand(rng) < 0.4  # 40% of contexts will have some missing values\n        n_missing = rand(rng, 1:2)  # 1-2 missing values per context\n\n        # Simple approach: randomly select indices for missing values\n        missing_indices = []\n        while length(missing_indices) < n_missing\n            idx = rand(rng, 1:context_dim)\n            if !(idx in missing_indices)\n                push!(missing_indices, idx)\n            end\n        end\n\n        for idx in missing_indices\n            context[idx] = missing\n        end\n    end\n\n    push!(contexts, context)\nend\n\n# Synthetic reward function (reusable)\nfunction compute_reward(arm_params, context_vec, noise_sd=0.0; rng=nothing)\n    \"\"\"\n    Compute reward for given arm parameters and context.\n\n    Args:\n        arm_params: Vector of arm parameters\n        context_vec: Context vector (may contain missing values)\n        noise_sd: Standard deviation of Gaussian noise to add\n        rng: Random number generator (optional, for reproducible noise)\n\n    Returns:\n        Scalar reward value\n    \"\"\"\n    # Calculate the deterministic part of the reward, handling missing values\n    mean_reward = 0.0\n    valid_dims = 0\n\n    for j in 1:length(context_vec)\n        if !ismissing(context_vec[j])\n            mean_reward += arm_params[j] * context_vec[j]\n            valid_dims += 1\n        end\n    end\n\n    # Normalize by the number of valid dimensions to maintain similar scale\n    if valid_dims > 0\n        mean_reward = mean_reward * (length(context_vec) / valid_dims)\n    end\n\n    # Add Gaussian noise if requested\n    if noise_sd > 0\n        if rng !== nothing\n            mean_reward += randn(rng) * noise_sd\n        else\n            mean_reward += randn() * noise_sd\n        end\n    end\n\n    return mean_reward\nend\n\n# Generate training and test data\nfunction generate_bandit_data(n_samples, arms, contexts, noise_sd; rng, start_idx=1)\n    \"\"\"\n    Generate bandit data for given number of samples.\n\n    Returns:\n        (arm_choices, context_choices, rewards)\n    \"\"\"\n    arm_choices = []\n    context_choices = []\n    rewards = []\n\n    for i in 1:n_samples\n        # Randomly select a context and an arm\n        push!(context_choices, rand(rng, 1:length(contexts)))\n        push!(arm_choices, rand(rng, 1:length(arms)))\n\n        # Get the selected context and arm\n        selected_context = contexts[context_choices[end]]\n        selected_arm = arms[arm_choices[end]]\n\n        # Compute reward using the synthetic reward function\n        reward = compute_reward(selected_arm, selected_context, noise_sd; rng=rng)\n        push!(rewards, reward)\n    end\n\n    return arm_choices, context_choices, rewards\nend\n\n# Generate training data\nprintln(\"Generating training data...\")\ntrain_arm_choices, train_context_choices, train_rewards = generate_bandit_data(\n    n_train_samples, arms, contexts, noise_sd; rng=rng\n)\n\n# Generate test data\nprintln(\"Generating test data...\")\ntest_arm_choices, test_context_choices, test_rewards = generate_bandit_data(\n    n_test_samples, arms, contexts, noise_sd; rng=rng\n)\n\n# Display information about the generated data\nprintln(\"\\nDataset Summary:\")\nprintln(\"Training samples: $n_train_samples\")\nprintln(\"Test samples: $n_test_samples\")\nprintln(\"Total contexts: $(length(contexts))\")\nprintln(\"Number of contexts with missing values: \", sum(any(ismissing, ctx) for ctx in contexts))\nprintln(\"Arms: $n_arms\")\nprintln(\"Context dimension: $context_dim\")\nprintln(\"Noise standard deviation: $noise_sd\")\n\n# Show examples of contexts with missing values\nprintln(\"\\nExamples of contexts with missing values:\")\ncount = 0\nfor (i, ctx) in enumerate(contexts)\n    if any(ismissing, ctx) && count < 3  # Show first 3 examples\n        println(\"Context $i: $ctx\")\n        global count += 1\n    end\nend\n\n# Show sample data\nprintln(\"\\nTraining data samples (first 5):\")\nfor i in 1:min(5, length(train_rewards))\n    println(\"Sample $i: Arm=$(train_arm_choices[i]), Context=$(train_context_choices[i]), Reward=$(round(train_rewards[i], digits=4))\")\nend\n\nprintln(\"\\nTest data samples (first 5):\")\nfor i in 1:min(5, length(test_rewards))\n    println(\"Sample $i: Arm=$(test_arm_choices[i]), Context=$(test_context_choices[i]), Reward=$(round(test_rewards[i], digits=4))\")\nend\n\n# Verify the reward function works correctly\nprintln(\"\\nTesting reward function:\")\ntest_context = contexts[1]\ntest_arm = arms[1]\ndeterministic_reward = compute_reward(test_arm, test_context, 0.0)  # No noise\nnoisy_reward = compute_reward(test_arm, test_context, noise_sd; rng=rng)  # With noise\nprintln(\"Deterministic reward: $(round(deterministic_reward, digits=4))\")\nprintln(\"Noisy reward: $(round(noisy_reward, digits=4))\")\n\nGenerating training data...\nGenerating test data...\n\nDataset Summary:\nTraining samples: 300\nTest samples: 100\nTotal contexts: 50\nNumber of contexts with missing values: 22\nArms: 10\nContext dimension: 20\nNoise standard deviation: 0.1\n\nExamples of contexts with missing values:\nContext 3: Union{Missing, Float64}[missing, -0.4741385118651381, -1.0989041\n9081401, -1.079288892379018, 0.8184199040107111, -0.30409464242950546, -0.6\n709508997562322, -0.7469592378369052, 0.21407501633089995, -0.6139813001136\n504, 2.8170273653049507, -1.4362435690909499, -0.30112508107598307, -0.3868\n83090487843, 0.6563571763621648, 1.401591444397142, 0.6193863742347839, 0.1\n2760715013378465, -0.2758495479700435, 1.8822768045661076]\nContext 8: Union{Missing, Float64}[-2.3650237776747054, -1.1739461025984783\n, 1.128284045692684, -0.8690689832066373, 0.4497591893001418, -0.2617237965\n612964, 0.07868265261314639, missing, 1.9119126287271901, 0.719828217704402\n8, -2.708690227134825, -2.645555311022844, -0.3202946667428825, 1.398258591\n17344, 0.06974735851443013, 1.1639494445584129, -0.36687387238833036, 0.506\n2972107773495, -1.3675557327045547, missing]\nContext 9: Union{Missing, Float64}[-0.7928407885849085, 0.5230893424666117,\n 0.21944291871653826, -0.2951043978830045, missing, 0.6739591611416778, 0.6\n091981160535558, 0.37661376790321904, -0.08201072963796563, 0.6762611326141\n408, -1.7998621684347569, 0.7079334064897562, -1.5082653360123872, 0.423324\n15672698104, 1.380447484940245, -3.325041477189219, 1.1893655835458625, 0.9\n25128468276957, -1.62673585658528, -0.667629748025382]\n\nTraining data samples (first 5):\nSample 1: Arm=6, Context=11, Reward=2.7556\nSample 2: Arm=2, Context=14, Reward=-3.911\nSample 3: Arm=8, Context=14, Reward=-2.0472\nSample 4: Arm=6, Context=36, Reward=9.6666\nSample 5: Arm=3, Context=21, Reward=-4.1496\n\nTest data samples (first 5):\nSample 1: Arm=1, Context=18, Reward=0.3271\nSample 2: Arm=2, Context=27, Reward=-3.2327\nSample 3: Arm=4, Context=4, Reward=-2.1027\nSample 4: Arm=1, Context=7, Reward=4.7518\nSample 5: Arm=8, Context=24, Reward=3.4953\n\nTesting reward function:\nDeterministic reward: -2.2755\nNoisy reward: -2.2613\n\nfunction create_bandit_plots(arm_choices, context_choices, rewards, title_prefix, color_scheme)\n    p1 = scatter(1:length(context_choices), context_choices,\n        label=\"Context Choices\",\n        title=\"$title_prefix: Context Selection\",\n        xlabel=\"Sample\", ylabel=\"Context ID\",\n        marker=:circle, markersize=6,\n        color=color_scheme[:context], alpha=0.7)\n\n    p2 = scatter(1:length(arm_choices), arm_choices,\n        label=\"Arm Choices\",\n        title=\"$title_prefix: Arm Selection\",\n        xlabel=\"Sample\", ylabel=\"Arm ID\",\n        marker=:diamond, markersize=6,\n        color=color_scheme[:arm], alpha=0.7)\n\n    p3 = plot(1:length(rewards), rewards,\n        label=\"Rewards\",\n        title=\"$title_prefix: Rewards\",\n        xlabel=\"Sample\", ylabel=\"Reward Value\",\n        linewidth=2, marker=:star, markersize=4,\n        color=color_scheme[:reward], alpha=0.8)\n\n    hline!(p3, [mean(rewards)], label=\"Mean Reward\",\n        linestyle=:dash, linewidth=2, color=:black)\n\n    return plot(p1, p2, p3, layout=(3, 1), size=(800, 600))\nend\n\n# Create training plots\ntrain_colors = Dict(:context => :blue, :arm => :red, :reward => :green)\ntrain_plot = create_bandit_plots(train_arm_choices, train_context_choices, train_rewards,\n    \"Training Data\", train_colors)\n\n# Create test plots  \ntest_colors = Dict(:context => :lightblue, :arm => :pink, :reward => :lightgreen)\ntest_plot = create_bandit_plots(test_arm_choices, test_context_choices, test_rewards,\n    \"Test Data\", test_colors)\n\n# Display both\nplot(train_plot, test_plot, layout=(1, 2), size=(1600, 600),\n    plot_title=\"Contextual Bandit Experiment: Training and Test Data\")\n\n(Image: )\n\n@model function conditional_regression(n_arms, priors, past_rewards, past_choices, past_contexts)\n    local Œ∏\n    local Œ≥\n    local œÑ\n\n    # Prior for each arm's parameters\n    for k in 1:n_arms\n        Œ∏[k] ~ priors[:Œ∏][k]\n        Œ≥[k] ~ priors[:Œ≥][k]\n    end\n\n    # Prior for the noise precision\n    œÑ ~ priors[:œÑ]\n\n    # Model for past observations\n    for n in eachindex(past_rewards)\n        arm_vals[n] ~ NormalMixture(switch=past_choices[n], m=Œ∏, p=Œ≥)\n        latent_context[n] ~ past_contexts[n]\n        past_rewards[n] ~ softdot(arm_vals[n], latent_context[n], œÑ)\n    end\nend\n\nLet's define the priors.\n\npriors_rng = StableRNG(42)\npriors = Dict(\n    :Œ∏ => [MvNormalMeanPrecision(randn(priors_rng, context_dim), diagm(ones(context_dim))) for _ in 1:n_arms],\n    :Œ≥ => [Wishart(context_dim + 1, diagm(ones(context_dim))) for _ in 1:n_arms],\n    :œÑ => GammaShapeRate(1.0, 1.0)\n)\n\nDict{Symbol, Any} with 3 entries:\n  :Œ≥ => Wishart{Float64, PDMat{Float64, Matrix{Float64}}, Int64}[Distributi\nons.‚Ä¶\n  :œÑ => ExponentialFamily.GammaShapeRate{Float64}(a=1.0, b=1.0)\n  :Œ∏ => MvNormalMeanPrecision{Float64, Vector{Float64}, Matrix{Float64}}[Mv\nNorm‚Ä¶\n\nAnd finally run the inference.\n\nfunction run_inference(; n_arms, priors, past_rewards, past_choices, past_contexts, iterations=50, free_energy=true)\n    init = @initialization begin\n        q(Œ∏) = priors[:Œ∏]\n        q(Œ≥) = priors[:Œ≥]\n        q(œÑ) = priors[:œÑ]\n        q(latent_context) = MvNormalMeanPrecision(zeros(context_dim), Diagonal(ones(context_dim)))\n    end\n\n    return infer(\n        model=conditional_regression(\n            n_arms=n_arms,\n            priors=priors,\n            past_contexts=past_contexts,\n        ),\n        data=(\n            past_rewards=past_rewards,\n            past_choices=past_choices,\n        ),\n        constraints=MeanField(),\n        initialization=init,\n        showprogress=true,\n        iterations=iterations,\n        free_energy=free_energy\n    )\n\nend\n\nrun_inference (generic function with 1 method)\n\n# Utility function to convert context with missing values to MvNormal distribution\nfunction context_to_mvnormal(context_vec; tiny_precision=1e-6, huge_precision=1e6)\n    \"\"\"\n    Convert a context vector (potentially with missing values) to MvNormal distribution.\n\n    Args:\n        context_vec: Vector that may contain missing values\n        tiny_v: Small variance for known values (high precision)\n        huge_var: Large variance for missing values (low precision)\n\n    Returns:\n        MvNormal distribution\n    \"\"\"\n    context_mean = Vector{Float64}(undef, length(context_vec))\n    context_precision = Vector{Float64}(undef, length(context_vec))\n\n    for j in 1:length(context_vec)\n        if ismissing(context_vec[j])\n            context_mean[j] = 0.0\n            context_precision[j] = tiny_precision\n        else\n            context_mean[j] = context_vec[j]\n            context_precision[j] = huge_precision\n        end\n    end\n\n    return MvNormalMeanPrecision(context_mean, Diagonal(context_precision))\nend\n\ncontext_to_mvnormal (generic function with 1 method)\n\n# Convert to the required types for the model (TRAINING DATA ONLY)\nrewards_data = Float64.(train_rewards)\n\n# Parameters for the covariance matrix\ntiny_precision = 1e-6   # Very high precision (small variance) for known values\nhuge_precision = 1e6  # Very low precision (large variance) for missing values\n\ncontexts_data = [\n    let context = contexts[idx]\n        context_to_mvnormal(context; tiny_precision=tiny_precision, huge_precision=huge_precision)\n    end\n    for idx in train_context_choices  # Use training context choices\n]\n\narm_choices_data = [[Float64(k == chosen_arm) for k in 1:n_arms] for chosen_arm in train_arm_choices];  # Use training arm choices\n\nresult = run_inference(\n    n_arms=n_arms,\n    priors=priors,\n    past_rewards=rewards_data,\n    past_choices=arm_choices_data,\n    past_contexts=contexts_data,\n    iterations=20,\n    free_energy=false\n)\n\nInference results:\n  Posteriors       | available for (Œ≥, arm_vals, œÑ, latent_context, Œ∏)\n\n# Diagnostics of inferred arms\n\n# 1. MSE of inferred arms coefficients\ninferred_arms = mean.(result.posteriors[:Œ∏][end])\nmse_arms = mean(mean((inferred_arms[i] .- arms[i]) .^ 2) for i in eachindex(arms))\nprintln(\"MSE of inferred arm coefficients: $mse_arms\")\n\nMSE of inferred arm coefficients: 0.005138753286482585\n\n# Function to compute predicted rewards using softdot rules\nfunction compute_predicted_rewards_with_variance(\n    arm_posteriors,\n    precision_posterior,\n    eval_arm_choices,\n    eval_context_choices,\n    eval_rewards\n)\n    predicted_rewards = []\n    reward_variances = []\n\n    for i in 1:length(eval_rewards)  # Evaluate on all samples in the evaluation set\n        arm_idx = eval_arm_choices[i]\n        ctx_idx = eval_context_choices[i]\n\n        # Get the posterior distributions\n        q_arm = arm_posteriors[arm_idx]  # Posterior over arm parameters\n        q_precision = precision_posterior  # Precision posterior\n\n        # Get the actual context and convert to MvNormal\n        actual_context = contexts[ctx_idx]\n        q_context = context_to_mvnormal(actual_context)\n\n        # Use softdot rule to compute predicted reward distribution\n        predicted_reward_dist = NormalMeanPrecision(\n            mean(q_arm)' * mean(q_context),\n            mean(q_precision)\n        )\n\n        push!(predicted_rewards, mean(predicted_reward_dist))\n        push!(reward_variances, var(predicted_reward_dist))\n    end\n\n    return predicted_rewards, reward_variances\nend\n\n# Function to display evaluation results\nfunction display_evaluation_results(predicted_rewards, reward_variances, actual_rewards,\n    arm_choices, context_choices, dataset_name)\n    println(\"\\n$dataset_name Evaluation Results:\")\n    println(\"Sample | Actual Reward | Predicted Mean | Predicted Std | Arm | Context\")\n    println(\"-------|---------------|----------------|---------------|-----|--------\")\n\n    for i in 1:min(10, length(predicted_rewards))\n        actual = actual_rewards[i]\n        pred_mean = predicted_rewards[i]\n        pred_std = sqrt(reward_variances[i])\n        arm_idx = arm_choices[i]\n        ctx_idx = context_choices[i]\n\n        println(\"$(lpad(i, 6)) | $(rpad(round(actual, digits=4), 13)) | $(rpad(round(pred_mean, digits=4), 14)) | $(rpad(round(pred_std, digits=4), 13)) | $(lpad(arm_idx, 3)) | $(lpad(ctx_idx, 7))\")\n    end\n\n    # Compute prediction metrics\n    prediction_mse = mean((predicted_rewards .- actual_rewards) .^ 2)\n    println(\"\\n$dataset_name Prediction MSE: $prediction_mse\")\n\n    # Compute log-likelihood of actual rewards under predicted distributions\n    log_likelihood = sum(\n        logpdf(Normal(predicted_rewards[i], sqrt(reward_variances[i])), actual_rewards[i])\n        for i in 1:length(predicted_rewards)\n    )\n    println(\"$dataset_name Average log-likelihood: $(log_likelihood / length(predicted_rewards))\")\n\n    return prediction_mse, log_likelihood / length(predicted_rewards)\nend\n\n# Evaluate on TRAINING data\nprintln(\"=== TRAINING DATA EVALUATION ===\")\ntrain_predicted_rewards, train_reward_variances = compute_predicted_rewards_with_variance(\n    result.posteriors[:Œ∏][end],  # Use full posteriors\n    result.posteriors[:œÑ][end],  # Precision posterior\n    train_arm_choices,\n    train_context_choices,\n    train_rewards\n)\n\ntrain_mse, train_ll = display_evaluation_results(\n    train_predicted_rewards,\n    train_reward_variances,\n    train_rewards,\n    train_arm_choices,\n    train_context_choices,\n    \"Training\"\n)\n\n# Evaluate on TEST data\nprintln(\"\\n=== TEST DATA EVALUATION ===\")\ntest_predicted_rewards, test_reward_variances = compute_predicted_rewards_with_variance(\n    result.posteriors[:Œ∏][end],  # Use full posteriors\n    result.posteriors[:œÑ][end],  # Precision posterior\n    test_arm_choices,\n    test_context_choices,\n    test_rewards\n)\n\ntest_mse, test_ll = display_evaluation_results(\n    test_predicted_rewards,\n    test_reward_variances,\n    test_rewards,\n    test_arm_choices,\n    test_context_choices,\n    \"Test\"\n)\n\n# Summary comparison\nprintln(\"\\n=== SUMMARY COMPARISON ===\")\nprintln(\"Dataset    | MSE      | Log-Likelihood\")\nprintln(\"-----------|----------|---------------\")\nprintln(\"Training   | $(rpad(round(train_mse, digits=4), 8)) | $(round(train_ll, digits=4))\")\nprintln(\"Test       | $(rpad(round(test_mse, digits=4), 8)) | $(round(test_ll, digits=4))\")\n\nif test_mse > train_mse * 1.2\n    println(\"\\nNote: Test MSE is significantly higher than training MSE - possible overfitting\")\nelseif test_mse < train_mse * 0.8\n    println(\"\\nNote: Test MSE is lower than training MSE - good generalization!\")\nelse\n    println(\"\\nNote: Test and training performance are similar - good generalization\")\nend\n\n=== TRAINING DATA EVALUATION ===\n\nTraining Evaluation Results:\nSample | Actual Reward | Predicted Mean | Predicted Std | Arm | Context\n-------|---------------|----------------|---------------|-----|--------\n     1 | 2.7556        | 2.7721         | 1.3082        |   6 |      11\n     2 | -3.911        | -3.535         | 1.3082        |   2 |      14\n     3 | -2.0472       | -1.8887        | 1.3082        |   8 |      14\n     4 | 9.6666        | 8.1026         | 1.3082        |   6 |      36\n     5 | -4.1496       | -3.8266        | 1.3082        |   3 |      21\n     6 | -4.7496       | -4.5237        | 1.3082        |   4 |      49\n     7 | -2.1116       | -2.1877        | 1.3082        |   5 |      34\n     8 | 0.3173        | 0.5183         | 1.3082        |   8 |      32\n     9 | -4.9155       | -4.1394        | 1.3082        |   8 |      49\n    10 | -3.0535       | -3.3429        | 1.3082        |   6 |      31\n\nTraining Prediction MSE: 0.16609598579011065\nTraining Average log-likelihood: -1.236149219320253\n\n=== TEST DATA EVALUATION ===\n\nTest Evaluation Results:\nSample | Actual Reward | Predicted Mean | Predicted Std | Arm | Context\n-------|---------------|----------------|---------------|-----|--------\n     1 | 0.3271        | 0.0431         | 1.3082        |   1 |      18\n     2 | -3.2327       | -2.6156        | 1.3082        |   2 |      27\n     3 | -2.1027       | -1.8232        | 1.3082        |   4 |       4\n     4 | 4.7518        | 4.465          | 1.3082        |   1 |       7\n     5 | 3.4953        | 2.9212         | 1.3082        |   8 |      24\n     6 | 1.0455        | 0.3028         | 1.3082        |   4 |      15\n     7 | -0.2608       | -0.2963        | 1.3082        |   9 |      38\n     8 | -6.0007       | -5.6078        | 1.3082        |   8 |       1\n     9 | -3.1662       | -2.8644        | 1.3082        |   7 |      36\n    10 | 0.9946        | 1.1453         | 1.3082        |  10 |      24\n\nTest Prediction MSE: 0.17808283508293526\nTest Average log-likelihood: -1.2396510580518532\n\n=== SUMMARY COMPARISON ===\nDataset    | MSE      | Log-Likelihood\n-----------|----------|---------------\nTraining   | 0.1661   | -1.2361\nTest       | 0.1781   | -1.2397\n\nNote: Test and training performance are similar - good generalization\n\n# Additional diagnostics\nprintln(\"\\n=== ADDITIONAL DIAGNOSTICS ===\")\n\n# Show precision/variance information\nprecision_posterior = result.posteriors[:œÑ][end]\nprintln(\"Inferred noise precision: mean=$(round(mean(precision_posterior), digits=4)), \" *\n        \"std=$(round(std(precision_posterior), digits=4))\")\nprintln(\"Inferred noise variance: $(round(1/mean(precision_posterior), digits=4))\")\nprintln(\"True noise variance: $(round(noise_sd^2, digits=4))\")\n\n# Show arm coefficient statistics\nprintln(\"\\nArm coefficient comparison:\")\nfor i in eachindex(arms)\n    true_arm = arms[i]\n    inferred_arm_posterior = result.posteriors[:Œ∏][end][i]\n    inferred_arm_mean = mean(inferred_arm_posterior)\n    println(\"Arm $i:\")\n    println(\"  True:     $(round.(true_arm, digits=3))\")\n    println(\"  Inferred: $(round.(inferred_arm_mean, digits=3))\")\n    println(\"  MSE:      $(round(mean((inferred_arm_mean .- true_arm).^2), digits=4))\")\nend\n\nprintln(\"\\nNumber of contexts with missing values: \", sum(any(ismissing, ctx) for ctx in contexts))\n\n=== ADDITIONAL DIAGNOSTICS ===\nInferred noise precision: mean=0.5843, std=0.0475\nInferred noise variance: 1.7115\nTrue noise variance: 0.01\n\nArm coefficient comparison:\nArm 1:\n  True:     [-0.67, 0.447, 1.374, 1.31, 0.126, 0.684, -1.019, -0.794, 1.775\n, 1.297, -1.644, 0.794, -1.31, -0.037, 1.072, -0.397, -0.239, -0.651, 1.134\n, -0.84]\n  Inferred: [-0.604, 0.429, 1.306, 1.212, 0.094, 0.665, -0.972, -0.744, 1.6\n85, 1.264, -1.578, 0.765, -1.279, -0.01, 1.043, -0.381, -0.209, -0.582, 1.0\n56, -0.76]\n  MSE:      0.003\nArm 2:\n  True:     [2.085, -1.801, 0.483, -0.57, -0.665, 2.243, -1.464, -1.012, -2\n.042, -0.787, 0.591, 0.642, 0.455, 0.054, 0.288, 0.587, -1.694, -0.696, -0.\n301, 2.101]\n  Inferred: [1.997, -1.708, 0.451, -0.542, -0.636, 2.161, -1.364, -0.965, -\n1.964, -0.754, 0.49, 0.614, 0.459, 0.044, 0.171, 0.557, -1.624, -0.59, -0.1\n67, 2.001]\n  MSE:      0.0057\nArm 3:\n  True:     [-0.69, -0.73, -1.417, -1.383, 1.201, 0.576, -0.987, 0.626, 0.1\n87, 0.239, -1.287, 0.147, -0.345, 1.909, 0.093, -0.643, 0.743, 0.725, 0.077\n, -0.008]\n  Inferred: [-0.655, -0.724, -1.353, -1.319, 1.132, 0.548, -0.898, 0.526, 0\n.194, 0.232, -1.263, 0.115, -0.257, 1.834, 0.068, -0.568, 0.703, 0.694, 0.0\n66, 0.001]\n  MSE:      0.0029\nArm 4:\n  True:     [-0.37, 0.888, -1.056, 1.242, 0.628, 1.161, -0.851, -0.428, 0.1\n09, -1.932, 0.105, 0.016, 0.105, 1.434, 0.141, 1.295, -0.931, 1.076, -1.799\n, -0.822]\n  Inferred: [-0.23, 0.849, -1.04, 1.172, 0.477, 1.134, -0.779, -0.355, 0.12\n8, -1.876, 0.097, 0.068, 0.037, 1.372, 0.124, 1.243, -0.905, 1.014, -1.727,\n -0.796]\n  MSE:      0.0044\nArm 5:\n  True:     [-0.217, 0.641, -1.566, -1.487, -0.45, -0.937, -0.59, 1.572, -0\n.229, 0.473, 2.148, -0.614, -0.451, -1.672, -0.224, 0.461, -0.093, 1.038, -\n1.827, 0.698]\n  Inferred: [-0.201, 0.628, -1.515, -1.422, -0.373, -0.907, -0.495, 1.468, \n-0.22, 0.476, 2.079, -0.564, -0.238, -1.613, -0.101, 0.433, -0.104, 0.973, \n-1.731, 0.634]\n  MSE:      0.0062\nArm 6:\n  True:     [0.403, 0.333, 1.549, 0.156, 1.816, -0.626, -1.275, 0.485, 1.23\n5, -1.121, -1.397, -0.658, -1.516, -0.712, -0.411, -1.254, 2.082, -0.53, -1\n.64, -0.769]\n  Inferred: [0.227, 0.312, 1.496, 0.107, 1.705, -0.594, -1.151, 0.383, 1.17\n4, -1.069, -1.351, -0.631, -1.445, -0.645, -0.4, -1.167, 2.001, -0.41, -1.5\n89, -0.716]\n  MSE:      0.0064\nArm 7:\n  True:     [1.528, 0.269, 1.215, 0.067, 0.84, 0.819, -1.459, 0.689, -1.067\n, 1.278, -0.364, -1.031, -0.452, -1.973, 0.266, 0.212, -0.424, -1.286, 0.57\n5, 0.72]\n  Inferred: [1.427, 0.271, 1.184, 0.041, 0.669, 0.79, -1.354, 0.645, -1.021\n, 1.246, -0.335, -0.992, -0.375, -1.893, 0.271, 0.224, -0.355, -1.19, 0.552\n, 0.696]\n  MSE:      0.0044\nArm 8:\n  True:     [-0.651, -1.01, -0.863, 1.512, 0.743, -1.477, -0.288, -0.288, -\n0.496, -0.151, 0.53, -0.429, -1.288, 0.95, 2.584, 0.719, -0.205, 1.232, -1.\n135, -0.626]\n  Inferred: [-0.581, -0.964, -0.852, 1.411, 0.673, -1.425, -0.219, -0.262, \n-0.466, -0.11, 0.486, -0.396, -1.228, 0.854, 2.469, 0.685, -0.191, 1.095, -\n1.062, -0.546]\n  MSE:      0.0047\nArm 9:\n  True:     [-1.049, 2.431, -0.434, 0.316, 1.271, -0.947, 0.131, 0.423, 0.1\n62, -1.648, -0.058, -0.573, 1.01, -0.237, 0.212, -0.347, 0.143, -1.574, 0.7\n96, 0.944]\n  Inferred: [-1.0, 2.341, -0.415, 0.143, 1.223, -0.91, 0.113, 0.439, 0.094,\n -1.557, -0.066, -0.531, 0.986, -0.146, 0.122, -0.118, 0.131, -1.518, 0.769\n, 0.869]\n  MSE:      0.0069\nArm 10:\n  True:     [0.447, -1.369, 0.6, 0.392, -0.449, 0.049, -0.558, -1.213, -0.2\n44, -0.289, 0.85, -0.834, 0.803, 1.531, -0.387, -1.258, -1.299, -1.05, -0.2\n37, 0.536]\n  Inferred: [0.368, -1.322, 0.586, 0.295, -0.191, 0.04, -0.502, -1.155, -0.\n24, -0.256, 0.813, -0.81, 0.782, 1.47, -0.29, -1.197, -1.278, -0.936, -0.14\n6, 0.505]\n  MSE:      0.0067\n\nNumber of contexts with missing values: 22","category":"section"},{"location":"categories/basic_examples/contextual_bandits/#Comparing-Different-Strategies-for-the-Contextual-Bandit-Problem","page":"Contextual Bandits","title":"Comparing Different Strategies for the Contextual Bandit Problem","text":"We'll implement and evaluate three different approaches:\n\nRandom Strategy - Selecting arms randomly without using context information\nVanilla Thompson Sampling - Sampling the reward distribution\nRxInfer Predictive Inference - Approximating the predictive posterior via message-passing\n\nfunction random_strategy(; rng, n_arms)\n    chosen_arm = rand(rng, 1:n_arms)\n    return chosen_arm\nend\n\nfunction thompson_strategy(; rng, n_arms, current_context, posteriors)\n    # Thompson Sampling: Sample parameter vectors and choose best arm\n    expected_rewards = zeros(n_arms)\n    for k in 1:n_arms\n        # Sample parameters from posterior\n        theta_sample = rand(rng, posteriors[:Œ∏][k])\n        # context might have missing values, so we use the mean of the context\n        augmented_context = mean(context_to_mvnormal(current_context))\n        expected_rewards[k] = dot(theta_sample, augmented_context)\n    end\n\n    # Choose best arm based on sampled parameters\n    chosen_arm = argmax(expected_rewards)\n\n    return chosen_arm\nend\n\nthompson_strategy (generic function with 1 method)\n\n@model function contextual_bandit_predictive(reward, priors, current_context)\n    local Œ∏\n    local Œ≥\n    local œÑ\n\n    # Prior for each arm's parameters\n    for k in 1:n_arms\n        Œ∏[k] ~ priors[:Œ∏][k]\n        Œ≥[k] ~ priors[:Œ≥][k]\n    end\n\n    œÑ ~ priors[:œÑ]\n\n    chosen_arm ~ Categorical(ones(n_arms) ./ n_arms)\n    arm_vals ~ NormalMixture(switch=chosen_arm, m=Œ∏, p=Œ≥)\n    latent_context ~ current_context\n    reward ~ softdot(arm_vals, latent_context, œÑ)\nend\n\nfunction predictive_strategy(; rng, n_arms, current_context, posteriors)\n\n    priors = Dict(\n        :Œ∏ => posteriors[:Œ∏],\n        :Œ≥ => posteriors[:Œ≥],\n        :œÑ => posteriors[:œÑ]\n    )\n\n    latent_context = context_to_mvnormal(current_context)\n\n    init = @initialization begin\n        q(Œ∏) = priors[:Œ∏]\n        q(œÑ) = priors[:œÑ]\n        q(Œ≥) = priors[:Œ≥]\n        q(latent_context) = latent_context\n        q(chosen_arm) = Categorical(ones(n_arms) ./ n_arms)\n    end\n\n    result = infer(\n        model=contextual_bandit_predictive(\n            priors=priors,\n            current_context=latent_context\n        ),\n        data=(reward=10maximum(train_rewards),),\n        constraints=MeanField(),\n        initialization=init,\n        showprogress=true,\n        iterations=20,\n    )\n\n    chosen_arm = argmax(probvec(result.posteriors[:chosen_arm][end]))\n\n    return chosen_arm\nend\n\npredictive_strategy (generic function with 1 method)\n\nAs we defined the strategies, we can proceed to defining the helper functions to run the simulation.\n\nWe will use the following flow:\n\nPLAN - Run different strategies\nACT - In this simulation, we're evaluating all strategies in parallel\nOBSERVE - Get rewards for all strategies\nLEARN - Update posteriors based on history\nKEEP HISTORY - Record all results\n\n# Helper functions\nfunction select_context(rng, n_contexts)\n    idx = rand(rng, 1:n_contexts)\n    return (index=idx, value=contexts[idx])\nend\n\nfunction plan(rng, n_arms, context, posteriors)\n    # Generate actions from different strategies\n    return Dict(\n        :random => random_strategy(rng=rng, n_arms=n_arms),\n        :thompson => thompson_strategy(rng=rng, n_arms=n_arms, current_context=context, posteriors=posteriors),\n        :predictive => predictive_strategy(rng=rng, n_arms=n_arms, current_context=context, posteriors=posteriors)\n    )\nend\n\nfunction act(rng, strategies)\n    # Here one would choose which strategy to actually follow\n    # For this simulation, we're evaluating all in parallel\n    # In a real scenario, one might return just one: return strategies[:thompson]\n    return strategies\nend\n\nfunction observe(rng, strategies, context, arms, noise_sd)\n    rewards = Dict()\n    for (strategy, arm_idx) in strategies\n        rewards[strategy] = compute_reward(arms[arm_idx], context, noise_sd)\n    end\n    return rewards\nend\n\nfunction learn(rng, n_arms, posteriors, past_rewards, past_choices, past_contexts)\n    # Note that we don't do any forgetting here which might be useful for long-term learning\n    # Prepare priors from current posteriors\n    priors = Dict(:Œ∏ => posteriors[:Œ∏], :œÑ => posteriors[:œÑ], :Œ≥ => posteriors[:Œ≥])\n\n    # Default initialization\n    init = @initialization begin\n        q(Œ∏) = priors[:Œ∏]\n        q(œÑ) = priors[:œÑ]\n        q(Œ≥) = priors[:Œ≥]\n        q(latent_context) = MvNormalMeanPrecision(zeros(context_dim), Diagonal(ones(context_dim)))\n    end\n\n    # Run inference\n    results = infer(\n        model=conditional_regression(\n            n_arms=n_arms,\n            priors=priors,\n            past_contexts=context_to_mvnormal.(past_contexts),\n        ),\n        data=(\n            past_rewards=past_rewards,\n            past_choices=past_choices,\n        ),\n        returnvars=KeepLast(),\n        constraints=MeanField(),\n        initialization=init,\n        iterations=20,\n        free_energy=false\n    )\n\n    return results.posteriors\nend\n\nfunction keep_history!(n_arms, history, strategies, rewards, context, posteriors)\n    # Update choices\n    for (strategy, arm_idx) in strategies\n        push!(history[:choices][strategy], [Float64(k == arm_idx) for k in 1:n_arms])\n    end\n\n    # Update rewards\n    for (strategy, reward) in rewards\n        push!(history[:rewards][strategy], reward)\n    end\n\n    # Update real history - using predictive strategy as the actual choice\n    push!(history[:real][:rewards], last(history[:rewards][:predictive]))\n    push!(history[:real][:choices], last(history[:choices][:predictive]))\n\n    # Update contexts\n    push!(history[:contexts][:values], context.value)\n    push!(history[:contexts][:indices], context.index)\n\n    # Update posteriors\n    push!(history[:posteriors], deepcopy(posteriors))\nend\n\nkeep_history! (generic function with 1 method)\n\nfunction run_bandit_simulation(n_epochs, window_length, n_arms, n_contexts, context_dim)\n    rng = StableRNG(42)\n\n    # Initialize histories with empty arrays, removing the references to undefined variables\n    history = Dict(\n        :rewards => Dict(:random => [], :thompson => [], :predictive => []),\n        :choices => Dict(:random => [], :thompson => [], :predictive => []),\n        :real => Dict(:rewards => [], :choices => []),\n        :contexts => Dict(:values => [], :indices => []),\n        :posteriors => []\n    )\n\n    # Initialize prior posterior as uninformative \n    posteriors = Dict(:Œ∏ => [MvNormalMeanPrecision(randn(rng, context_dim), diagm(ones(context_dim))) for _ in 1:n_arms],\n        :Œ≥ => [Wishart(context_dim + 1, diagm(ones(context_dim))) for _ in 1:n_arms],\n        :œÑ => GammaShapeRate(1.0, 1.0))\n\n    @showprogress for epoch in 1:n_epochs\n        # 1. PLAN - Run different strategies\n        current_context = select_context(rng, n_contexts)\n\n        strategies = plan(rng, n_arms, current_context.value, posteriors)\n\n        # 2. ACT - In this simulation, we're evaluating all strategies in parallel\n        # In a real scenario, you might choose one strategy here\n        chosen_arm = act(rng, strategies)\n\n        # 3. OBSERVE - Get rewards for all strategies\n        rewards = observe(rng, strategies, current_context.value, arms, noise_sd)\n\n        # 4. LEARN - Update posteriors based on history\n        # Only try to learn if we have collected data\n        if mod(epoch, window_length) == 0 && length(history[:real][:rewards]) > 0\n            data_idx = max(1, length(history[:real][:rewards]) - window_length + 1):length(history[:real][:rewards])\n\n            posteriors = learn(\n                rng,\n                n_arms,\n                posteriors,\n                history[:real][:rewards][data_idx],\n                history[:real][:choices][data_idx],\n                history[:contexts][:values][data_idx]\n            )\n\n        end\n\n        # 5. KEEP HISTORY - Record all results\n        keep_history!(n_arms, history, strategies, rewards, current_context, posteriors)\n    end\n\n    return history\nend\n\nrun_bandit_simulation (generic function with 1 method)\n\n# Run the simulation\nn_epochs = 5000\nwindow_length = 100\n\nhistory = run_bandit_simulation(n_epochs, window_length, n_arms, n_contexts, context_dim)\n\nDict{Symbol, Any} with 5 entries:\n  :choices    => Dict{Symbol, Vector{Any}}(:predictive=>[[1.0, 0.0, 0.0, 0.\n0, 0‚Ä¶\n  :contexts   => Dict{Symbol, Vector{Any}}(:values=>[Union{Missing, Float64\n}[0.‚Ä¶\n  :real       => Dict{Symbol, Vector{Any}}(:choices=>[[1.0, 0.0, 0.0, 0.0, \n0.0,‚Ä¶\n  :rewards    => Dict{Symbol, Vector{Any}}(:predictive=>[-1.63462, 6.77073,\n 6.7‚Ä¶\n  :posteriors => Any[Dict{Symbol, Any}(:Œ≥=>Wishart{Float64, PDMat{Float64, \nMatr‚Ä¶\n\nfunction print_summary_statistics(history, n_epochs)\n    # Additional summary statistics\n    println(\"Random strategy cumulative reward: $(sum(history[:rewards][:random]))\")\n    println(\"Thompson strategy cumulative reward: $(sum(history[:rewards][:thompson]))\")\n    println(\"Predictive strategy cumulative reward: $(sum(history[:rewards][:predictive]))\")\n\n    println(\"Results after $n_epochs epochs:\")\n    println(\"Random strategy average reward: $(mean(history[:rewards][:random]))\")\n    println(\"Thompson strategy average reward: $(mean(history[:rewards][:thompson]))\")\n    println(\"Predictive strategy average reward: $(mean(history[:rewards][:predictive]))\")\nend\n\n# Print the summary statistics\nprint_summary_statistics(history, n_epochs)\n\nRandom strategy cumulative reward: -597.5685457830007\nThompson strategy cumulative reward: 27929.30328927975\nPredictive strategy cumulative reward: 25936.93697970396\nResults after 5000 epochs:\nRandom strategy average reward: -0.11951370915660013\nThompson strategy average reward: 5.5858606578559495\nPredictive strategy average reward: 5.187387395940792\n\nfunction plot_arm_distribution(history, n_arms)\n    # Extract choices\n    random_choices = history[:choices][:random]\n    thompson_choices = history[:choices][:thompson]\n    predictive_choices = history[:choices][:predictive]\n\n    # Convert to arm indices\n    random_arms = [argmax(choice) for choice in random_choices]\n    thompson_arms = [argmax(choice) for choice in thompson_choices]\n    predictive_arms = [argmax(choice) for choice in predictive_choices]\n\n    # Count frequencies\n    arm_counts_random = zeros(Int, n_arms)\n    arm_counts_thompson = zeros(Int, n_arms)\n    arm_counts_predictive = zeros(Int, n_arms)\n\n    for arm in random_arms\n        arm_counts_random[arm] += 1\n    end\n\n    for arm in thompson_arms\n        arm_counts_thompson[arm] += 1\n    end\n\n    for arm in predictive_arms\n        arm_counts_predictive[arm] += 1\n    end\n\n    # Create grouped bar plot\n    bar_plot = groupedbar(\n        1:n_arms,\n        [arm_counts_random arm_counts_thompson arm_counts_predictive],\n        title=\"Arm Selection Distribution\",\n        xlabel=\"Arm Index\",\n        ylabel=\"Selection Count\",\n        bar_position=:dodge,\n        bar_width=0.8,\n        alpha=0.7,\n        legend=:topright,\n        labels=[\"Random\" \"Thompson\" \"Predictive\"]\n    )\n\n    return bar_plot\nend\n\n# Plot arm distribution\narm_distribution_plot = plot_arm_distribution(history, 10)\ndisplay(arm_distribution_plot)\n\n(Image: )\n\nfunction calculate_improvements(history)\n    # Get final average rewards\n    final_random_avg = mean(history[:rewards][:random])\n    final_thompson_avg = mean(history[:rewards][:thompson])\n    final_predictive_avg = mean(history[:rewards][:predictive])\n\n    # Improvements over random baseline\n    thompson_improvement = (final_thompson_avg - final_random_avg) / abs(final_random_avg) * 100\n    predictive_improvement = (final_predictive_avg - final_random_avg) / abs(final_random_avg) * 100\n\n    println(\"Thompson sampling improves over random by $(round(thompson_improvement, digits=2))%\")\n    println(\"Predictive strategy improves over random by $(round(predictive_improvement, digits=2))%\")\n\n    return Dict(\n        :thompson => thompson_improvement,\n        :predictive => predictive_improvement\n    )\nend\n\n# Calculate and display improvements\nimprovements = calculate_improvements(history)\n\nThompson sampling improves over random by 4773.82%\nPredictive strategy improves over random by 4440.41%\nDict{Symbol, Float64} with 2 entries:\n  :predictive => 4440.41\n  :thompson   => 4773.82\n\nfunction analyze_doubly_robust_uplift(history, target_strategy=:predictive, baseline_strategy=:random)\n    \"\"\"\n    Compute doubly robust uplift estimate from simulation history\n    \"\"\"\n    target_rewards = history[:rewards][target_strategy]\n    baseline_rewards = history[:rewards][baseline_strategy]\n\n    # Simple Direct Method - just difference in average rewards\n    direct_method = mean(target_rewards) - mean(baseline_rewards)\n\n    # For IPW, we use the fact that all strategies were evaluated on same contexts\n    # So propensity is uniform across arms for random, and we can estimate others\n    n_epochs = length(target_rewards)\n    n_arms = length(history[:choices][target_strategy][1])\n\n    # IPW correction (simplified since we have parallel evaluation)\n    ipw_correction = 0.0\n    for i in 1:n_epochs\n        # Get actual choice and reward (using predictive as \"real\" policy)\n        real_choice = history[:choices][:predictive][i]\n        real_reward = history[:rewards][:predictive][i]\n\n        target_choice = history[:choices][target_strategy][i]\n        baseline_choice = history[:choices][baseline_strategy][i]\n\n        # Simple propensity estimates\n        target_propensity = target_strategy == :random ? 1 / n_arms : 0.5  # rough estimate\n        baseline_propensity = baseline_strategy == :random ? 1 / n_arms : 0.5\n\n        # IPW terms (simplified)\n        if target_choice == real_choice\n            ipw_correction += real_reward / target_propensity\n        end\n        if baseline_choice == real_choice\n            ipw_correction -= real_reward / baseline_propensity\n        end\n    end\n    ipw_correction /= n_epochs\n\n    # Doubly robust = direct method + IPW correction\n    doubly_robust = direct_method + ipw_correction * 0.1  # damped correction\n\n    return Dict(\n        :direct_method => direct_method,\n        :doubly_robust => doubly_robust,\n        :target_mean => mean(target_rewards),\n        :baseline_mean => mean(baseline_rewards),\n        :uplift_percent => (direct_method / mean(baseline_rewards)) * 100\n    )\nend\n\nanalyze_doubly_robust_uplift (generic function with 3 methods)\n\n# Analyze uplift - no changes to existing code needed!\npredictive_vs_random = analyze_doubly_robust_uplift(history, :predictive, :random)\nthompson_vs_random = analyze_doubly_robust_uplift(history, :thompson, :random)\n\nprintln(\"Predictive vs Random:\")\nprintln(\"  Direct Method: $(round(predictive_vs_random[:direct_method], digits=4))\")\nprintln(\"  Doubly Robust: $(round(predictive_vs_random[:doubly_robust], digits=4))\")\nprintln(\"  Uplift: $(round(predictive_vs_random[:uplift_percent], digits=2))%\")\n\nprintln(\"\\nThompson vs Random:\")\nprintln(\"  Direct Method: $(round(thompson_vs_random[:direct_method], digits=4))\")\nprintln(\"  Doubly Robust: $(round(thompson_vs_random[:doubly_robust], digits=4))\")\nprintln(\"  Uplift: $(round(thompson_vs_random[:uplift_percent], digits=2))%\")\n\nPredictive vs Random:\n  Direct Method: 5.3069\n  Doubly Robust: 5.8598\n  Uplift: -4440.41%\n\nThompson vs Random:\n  Direct Method: 5.7054\n  Doubly Robust: 5.8848\n  Uplift: -4773.82%\n\nfunction plot_moving_averages(history, n_epochs, ma_window=20)\n    # Calculate moving average rewards\n    ma_rewards_random = [mean(history[:rewards][:random][max(1, i - ma_window + 1):i]) for i in 1:n_epochs]\n    ma_rewards_thompson = [mean(history[:rewards][:thompson][max(1, i - ma_window + 1):i]) for i in 1:n_epochs]\n    ma_rewards_predictive = [mean(history[:rewards][:predictive][max(1, i - ma_window + 1):i]) for i in 1:n_epochs]\n\n    # Plot moving average\n    plot(1:n_epochs, [ma_rewards_random, ma_rewards_thompson, ma_rewards_predictive],\n        label=[\"Random\" \"Thompson\" \"Predictive\"],\n        title=\"Moving Average Reward\",\n        xlabel=\"Epoch\", ylabel=\"Average Reward\",\n        lw=2)\nend\n\n# Plot moving averages\nplot_moving_averages(history, n_epochs)\n\n(Image: )\n\nfunction create_comprehensive_plots(history, window=100, k=10)\n      # Create a better color palette\n      colors = palette(:tab10)\n\n      # Plot 1: Arm choices comparison (every k-th point)\n      p1 = plot(title=\"Arm Choices Over Time\", xlabel=\"Epoch\", ylabel=\"Arm Index\",\n            legend=:outertopright, dpi=300)\n      plot!(p1, argmax.(history[:choices][:random][1:k:end]), label=\"Random\", color=colors[1],\n            markershape=:circle, markersize=3, alpha=0.5, linewidth=0)\n      plot!(p1, argmax.(history[:choices][:thompson][1:k:end]), label=\"Thompson\", color=colors[2],\n            markershape=:circle, markersize=3, alpha=0.5, linewidth=0)\n      plot!(p1, argmax.(history[:choices][:predictive][1:k:end]), label=\"Predictive\", color=colors[3],\n            markershape=:circle, markersize=3, alpha=0.5, linewidth=0)\n\n      # Plot 2: Context values (every k-th point)\n      p2 = plot(title=\"Context Changes\", xlabel=\"Epoch\", ylabel=\"Context Index\",\n            legend=false, dpi=300)\n      plot!(p2, history[:contexts][:indices][1:k:end], color=colors[4], linewidth=1.5)\n\n      # Plot 3: Reward comparison (every k-th point)\n      p3 = plot(title=\"Rewards by Strategy\", xlabel=\"Epoch\", ylabel=\"Reward Value\",\n            legend=:outertopright, dpi=300)\n      plot!(p3, history[:rewards][:random][1:k:end], label=\"Random\", color=colors[1], linewidth=1.5, alpha=0.7)\n      plot!(p3, history[:rewards][:thompson][1:k:end], label=\"Thompson\", color=colors[2], linewidth=1.5, alpha=0.7)\n      plot!(p3, history[:rewards][:predictive][1:k:end], label=\"Predictive\", color=colors[3], linewidth=1.5, alpha=0.7)\n\n      # Plot 4: Cumulative rewards (every k-th point)\n      cumul_random = cumsum(history[:rewards][:random])[1:k:end]\n      cumul_thompson = cumsum(history[:rewards][:thompson])[1:k:end]\n      cumul_predictive = cumsum(history[:rewards][:predictive])[1:k:end]\n\n      p4 = plot(title=\"Cumulative Rewards\", xlabel=\"Epoch\", ylabel=\"Cumulative Reward\",\n            legend=:outertopright, dpi=300)\n      plot!(p4, cumul_random, label=\"Random\", color=colors[1], linewidth=2)\n      plot!(p4, cumul_thompson, label=\"Thompson\", color=colors[2], linewidth=2)\n      plot!(p4, cumul_predictive, label=\"Predictive\", color=colors[3], linewidth=2)\n\n      # Plot 5: Moving average rewards (every k-th point)\n      ma_random = [mean(history[:rewards][:random][max(1, i - window + 1):i]) for i in 1:length(history[:rewards][:random])][1:k:end]\n      ma_thompson = [mean(history[:rewards][:thompson][max(1, i - window + 1):i]) for i in 1:length(history[:rewards][:thompson])][1:k:end]\n      ma_predictive = [mean(history[:rewards][:predictive][max(1, i - window + 1):i]) for i in 1:length(history[:rewards][:predictive])][1:k:end]\n\n      p5 = plot(title=\"$window-Epoch Moving Average Rewards\", xlabel=\"Epoch\", ylabel=\"Avg Reward\",\n            legend=:outertopright, dpi=300)\n      plot!(p5, ma_random, label=\"Random\", color=colors[1], linewidth=2)\n      plot!(p5, ma_thompson, label=\"Thompson\", color=colors[2], linewidth=2)\n      plot!(p5, ma_predictive, label=\"Predictive\", color=colors[3], linewidth=2)\n\n      # Combine all plots with a title\n      combined_plot = plot(p1, p2, p3, p4, p5,\n            layout=(5, 1),\n            size=(900, 900),\n            plot_title=\"Bandit Strategies Comparison (shows every $k th point)\",\n            plot_titlefontsize=14,\n            left_margin=10Plots.mm,\n            bottom_margin=10Plots.mm)\n\n      return combined_plot\nend\n\ncreate_comprehensive_plots(history, window_length, 10)  # Using k=10 for prettier plots\n\n(Image: )\n\nThompson and Predictive strategies both significantly outperform Random. Both intelligent strategies quickly adapt to changing contexts. The Predictive strategy shows a slight edge over Thompson sampling in final performance, demonstrating the effectiveness of Bayesian approaches in sequential decision-making under uncertainty.\n\nfunction plot_moving_averages(history, n_epochs, ma_window=20)\n    # Calculate moving average rewards\n    ma_rewards_random = [mean(history[:rewards][:random][max(1, i - ma_window + 1):i]) for i in 1:n_epochs]\n    ma_rewards_thompson = [mean(history[:rewards][:thompson][max(1, i - ma_window + 1):i]) for i in 1:n_epochs]\n    ma_rewards_predictive = [mean(history[:rewards][:predictive][max(1, i - ma_window + 1):i]) for i in 1:n_epochs]\n\n    # Plot moving average\n    plot(1:n_epochs, [ma_rewards_random, ma_rewards_thompson, ma_rewards_predictive],\n        label=[\"Random\" \"Thompson\" \"Predictive\"],\n        title=\"Moving Average Reward\",\n        xlabel=\"Epoch\", ylabel=\"Average Reward\",\n        lw=2)\nend\n\n# Plot moving averages\nplot_moving_averages(history, n_epochs)\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [31c24e10] Distributions v0.25.123\n  [91a5bcdd] Plots v1.41.6\n  [92933f4c] ProgressMeter v1.11.0\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [f3b207a7] StatsPlots v0.15.8\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#Advanced-Tutorial","page":"Advanced Tutorial","title":"Advanced Tutorial","text":"using RxInfer, Plots\n\nThis notebook covers the fundamentals and advanced usage of the RxInfer.jl package.","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#General-model-specification-syntax","page":"Advanced Tutorial","title":"General model specification syntax","text":"We use the @model macro from the GraphPPL.jl package to create a probabilistic model p(s y) and we also specify extra constraints on the variational family of distributions mathcalQ, used for approximating intractable posterior distributions. Below there is a simple example of the general syntax for model specification. In this tutorial we do not cover all possible ways to create models or advanced features of GraphPPL.jl.  Instead we refer the interested reader to the documentation for a more rigorous explanation and illustrative examples.\n\n# the `@model` macro accepts a regular Julia function\n@model function test_model1(s_mean, s_precision, y)\n    \n    # the `tilde` operator creates a functional dependency\n    # between variables in our model and can be read as \n    # `sampled from` or `is modeled by`\n    s ~ Normal(mean = s_mean, precision = s_precision)\n    y ~ Normal(mean = s, precision = 1.0)\n    \n    # It is possible to return something from the model specification (including variables and nodes)\n    return \"Hello world\"\nend\n\nThe @model macro creates a function with the same name and with the same set of input arguments as the original function (test_model1(s_mean, s_precision, y) in this example). The arguments are however converted to the keyword arguments. The @model macro does not support positional arguments.\n\nIt is also possible to use control flow statements such as if or for blocks in the model specification function. In general, any valid snippet of Julia code can be used inside the @model block. As an example consider the following (valid!) model:\n\n@model function test_model2(y)\n    \n    if length(y) <= 1\n        error(\"The `length` of `y` argument must be greater than one.\")\n    end\n    \n    s[1] ~ Normal(mean = 0.0, precision = 0.1)\n    y[1] ~ Normal(mean = s[1], precision = 1.0)\n    \n    for i in eachindex(y)\n        s[i] ~ Normal(mean = s[i - 1], precision = 1.0)\n        y[i] ~ Normal(mean = s[i], precision = 1.0)\n    end\n    \nend\n\nIt is also possible to use complex expressions inside the functional dependency expressions\n\ny ~ Normal(mean = 2.0 * (s + 1.0), precision = 1.0)\n\nThe ~ operator automatically creates a random variable if none was created before with the same name and throws an error if this name already exists\n\n# `~` creates random variables automatically\ns ~ Normal(mean = 0.0, precision1.0)","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#Probabilistic-inference-in-RxInfer.jl","page":"Advanced Tutorial","title":"Probabilistic inference in RxInfer.jl","text":"RxInfer.jl uses the Rocket.jl package API for inference routines. Rocket.jl is a reactive programming extension for Julia that is higly inspired by RxJS and similar libraries from the Rx ecosystem. It consists of observables, actors, subscriptions and operators. For more information and rigorous examples see Rocket.jl github page.","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#Observables","page":"Advanced Tutorial","title":"Observables","text":"Observables are lazy push-based collections and they deliver their values over time.\n\n# Timer that emits a new value every second and has an initial one second delay \nobservable = timer(300, 300)\n\nTimerObservable(300, 300)\n\nA subscription allows us to subscribe on future values of some observable, and actors specify what to do with these new values:\n\nactor = (value) -> println(value)\nsubscription1 = subscribe!(observable, actor)\n\nTimerSubscription()\n\n# We always need to unsubscribe from some observables\nunsubscribe!(subscription1)\n\n# We can modify our observables\nmodified = observable |> filter(d -> rem(d, 2) === 1) |> map(Int, d -> d ^ 2)\n\nProxyObservable(Int64, MapProxy(Int64))\n\nsubscription2 = subscribe!(modified, (value) -> println(value))\n\nTimerSubscription()\n\nunsubscribe!(subscription2)","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#Coin-Toss-Model","page":"Advanced Tutorial","title":"Coin Toss Model","text":"@model function coin_toss_model(y)\n    # We endow Œ∏ parameter of our model with some prior\n    Œ∏  ~ Beta(2.0, 7.0)\n    # We assume that the outcome of each coin flip \n    # is modeled by a Bernoulli distribution\n    y .~ Bernoulli(Œ∏)\nend\n\nWe can call the infer function to run inference in such model:\n\np = 0.75 # Bias of a coin\n\ndataset = float.(rand(Bernoulli(p), 500));\n\nresult = infer(\n    model = coin_toss_model(),\n    data  = (y = dataset, )\n)\n\nprintln(\"Inferred bias is \", mean(result.posteriors[:Œ∏]), \" with standard deviation is \", std(result.posteriors[:Œ∏]))\n\nInferred bias is 0.730844793713163 with standard deviation is 0.01963943018\n699018\n\nWe can see that the inferred bias is quite close to the actual value we used in the dataset generation with a low standard deviation.","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#Reactive-Online-Inference","page":"Advanced Tutorial","title":"Reactive Online Inference","text":"RxInfer.jl naturally supports reactive streams of data and it is possible to run reactive inference with some external datasource.\n\n@model function online_coin_toss_model(Œ∏_a, Œ∏_b, y)\n    Œ∏ ~ Beta(Œ∏_a, Œ∏_b)\n    y ~ Bernoulli(Œ∏)\nend\n\nautoupdates = @autoupdates begin \n    Œ∏_a, Œ∏_b = params(q(Œ∏))\nend\n\n@autoupdates begin\n    (Œ∏_a, Œ∏_b) = params(q(Œ∏))\nend\n\ninit = @initialization begin\n    q(Œ∏) = vague(Beta)\nend\n\nInitial state: \n  q(Œ∏) = Distributions.Beta{Float64}(Œ±=1.0, Œ≤=1.0)\n\nrxresult = infer(\n    model = online_coin_toss_model(),\n    data  = (y = dataset, ),\n    autoupdates = autoupdates,\n    historyvars = (Œ∏ = KeepLast(), ),\n    keephistory = length(dataset),\n    initialization = init,\n    autostart = true\n);\n\nanimation = @animate for i in 1:length(dataset)\n    plot(mean.(rxresult.history[:Œ∏][1:i]), ribbon = std.(rxresult.history[:Œ∏][1:i]), title = \"Online coin bias inference\", label = \"Inferred bias\", legend = :bottomright)\n    hline!([ p ], label = \"Real bias\", size = (600, 200))\nend\n\ngif(animation, \"online-coin-bias-inference.gif\", fps = 24, show_msg = false);\n\n(Image: )\n\nIn this example we used static dataset and the history field of the reactive inference result, but the rxinference function also supports any real-time reactive stream and can run indefinitely.\n\nThat was an example of exact Bayesian inference with Sum-Product (or Belief Propagation) algorithm. However, RxInfer is not limited to only the sum-product algorithm but it also supports variational message passing with Constrained Bethe Free Energy Minimisation.","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#Variational-inference","page":"Advanced Tutorial","title":"Variational inference","text":"On a very high-level, RxInfer is aimed to solve the Constrained Bethe Free Energy minimisation problem. For this task we approximate our exact posterior marginal distribution by some family of distributions q in mathcalQ. Often this involves assuming some factorization over q. \n\n@model function test_model6(y)\n    œÑ ~ Gamma(shape = 1.0, rate = 1.0) \n    Œº ~ Normal(mean = 0.0, variance = 100.0)\n    for i in eachindex(y)\n        y[i] ~ Normal(mean = Œº, precision = œÑ)\n    end\nend\n\nIn this example we want to specify extra constraints for q_a for Bethe factorisation:\n\nbeginaligned\nq(s) = prod_a in mathcalV q_a(s_a) prod_i in mathcalE q_i^-1(s_i)\nendaligned\n\nRxInfer.jl package exports @constraints macro to simplify factorisation and form constraints specification. Read more about @constraints macro in the corresponding documentation section, here we show a simple example of the same factorisation constraints specification, but with @constraints macro:\n\nconstraints6 = @constraints begin\n     q(Œº, œÑ) = q(Œº)q(œÑ) # Mean-Field over `Œº` and `œÑ`\nend\n\nConstraints: \n  q(Œº, œÑ) = q(Œº)q(œÑ)\n\ninit = @initialization begin\n    q(Œº) = vague(NormalMeanPrecision)\n    q(œÑ) = vague(GammaShapeRate)\nend\n\nInitial state: \n  q(Œº) = ExponentialFamily.NormalMeanPrecision{Float64}(Œº=0.0, w=1.0e-12)\n  q(œÑ) = ExponentialFamily.GammaShapeRate{Float64}(a=1.0, b=1.0e-12)","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#Inference","page":"Advanced Tutorial","title":"Inference","text":"To run inference in this model we again need to create a synthetic dataset and call the infer function.\n\ndataset = rand(Normal(-3.0, inv(sqrt(5.0))), 1000);\nresult = infer(\n    model          = test_model6(),\n    data           = (y = dataset, ),\n    constraints    = constraints6, \n    initialization = init,\n    returnvars     = (Œº = KeepLast(), œÑ = KeepLast()),\n    iterations     = 10,\n    free_energy    = true,\n    showprogress   = true\n)\n\nInference results:\n  Posteriors       | available for (Œº, œÑ)\n  Free Energy:     | Real[14763.3, 3276.02, 662.74, 621.834, 621.834, 621.8\n34, 621.834, 621.834, 621.834, 621.834]\n\nprintln(\"Œº: mean = \", mean(result.posteriors[:Œº]), \", std = \", std(result.posteriors[:Œº]))\n\nŒº: mean = -3.0085681853002453, std = 0.014141102648437598\n\nprintln(\"œÑ: mean = \", mean(result.posteriors[:œÑ]), \", std = \", std(result.posteriors[:œÑ]))\n\nœÑ: mean = 5.000720503870371, std = 0.22341571554336895","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#Form-constraints","page":"Advanced Tutorial","title":"Form constraints","text":"In order to support form constraints, the @constraints macro supports additional type specifications for posterior marginals.  For example, here how we can perform the EM algorithm with PointMass form constraint.\n\n(Image: )\n\n@model function test_model7(y)\n    œÑ ~ Gamma(shape = 1.0, rate = 1.0) \n    Œº ~ Normal(mean = 0.0, variance = 100.0)\n    for i in eachindex(y)\n        y[i] ~ Normal(mean = Œº, precision = œÑ)\n    end\nend\n\nAs in the previous example we can use @constraints macro to achieve the same goal with a nicer syntax:\n\nconstraints7 = @constraints begin \n    q(Œº) :: PointMassFormConstraint()\n    \n    q(Œº, œÑ) = q(Œº)q(œÑ) # Mean-Field over `Œº` and `œÑ`\nend\n\nConstraints: \n  q(Œº, œÑ) = q(Œº)q(œÑ)\n  q(Œº) :: PointMassFormConstraint()\n\ndataset = rand(Normal(-3.0, inv(sqrt(5.0))), 1000);\nresult = infer(\n    model          = test_model7(),\n    data           = (y = dataset, ),\n    constraints    = constraints7, \n    initialization = init,\n    returnvars     = (Œº = KeepLast(), œÑ = KeepLast()),\n    iterations     = 10,\n    free_energy    = true,\n    showprogress   = true\n)\n\nInference results:\n  Posteriors       | available for (Œº, œÑ)\n  Free Energy:     | Real[14766.5, 2051.94, 614.755, 614.755, 614.755, 614.\n755, 614.755, 614.755, 614.755, 614.755]\n\nprintln(\"Œº: mean = \", mean(result.posteriors[:Œº]), \", std = \", std(result.posteriors[:Œº]))\n\nŒº: mean = -3.018736475303153, std = 0.0\n\nprintln(\"œÑ: mean = \", mean(result.posteriors[:œÑ]), \", std = \", std(result.posteriors[:œÑ]))\n\nœÑ: mean = 5.043215606990412, std = 0.22531425673624408","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#Meta-data-specification","page":"Advanced Tutorial","title":"Meta data specification","text":"During model specification some functional dependencies may accept an optional meta object in the where { ... } clause. The purpose of the meta object is to adjust, modify or supply some extra information to the inference backend during the computations of the messages. The meta object for example may contain an approximation method that needs to be used during various approximations or it may specify the tradeoff between accuracy and performance:\n\n# In this example the `meta` object for the autoregressive `AR` node specifies the variate type of \n# the autoregressive process and its order. In addition it specifies that the message computation rules should\n# respect accuracy over speed with the `ARsafe()` strategy. In contrast, `ARunsafe()` strategy tries to speedup computations\n# by cost of possible numerical instabilities during an inference procedure\ns[i] ~ AR(s[i - 1], Œ∏, Œ≥) where { meta = ARMeta(Multivariate, order, ARsafe()) }\n...\ns[i] ~ AR(s[i - 1], Œ∏, Œ≥) where { meta = ARMeta(Univariate, order, ARunsafe()) }\n\nAnother example with GaussianControlledVariance, or simply GCV [see Hierarchical Gaussian Filter], node:\n\n# In this example we specify structured factorisation and flag meta with `GaussHermiteCubature` \n# method with `21` sigma points for approximation of non-lineariety between hierarchy layers\nxt ~ GCV(xt_min, zt, real_k, real_w) where { meta = GCVMetadata(GaussHermiteCubature(21)) }\n\nThe Meta object is useful to pass any extra information to a node that is not a random variable or constant model variable. It may include extra approximation methods, differentiation methods, optional non-linear functions, extra inference parameters etc.","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#GraphPPL.jl-@meta-macro","page":"Advanced Tutorial","title":"GraphPPL.jl @meta macro","text":"Users can use @meta macro from the GraphPPL.jl package to achieve the same goal. Read more about @meta macro in the corresponding documentation section. Here is a simple example of the same meta specification:\n\n@meta begin \n     AR(s, Œ∏, Œ≥) -> ARMeta(Multivariate, 5, ARsafe())\nend\n\nMeta: \n  ReactiveMP.AR(s, Œ∏, Œ≥) -> ReactiveMP.ARMeta{Distributions.Multivariate, R\neactiveMP.ARsafe}(5, ReactiveMP.ARsafe())","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#Creating-custom-nodes-and-message-computation-rules","page":"Advanced Tutorial","title":"Creating custom nodes and message computation rules","text":"","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#Custom-nodes","page":"Advanced Tutorial","title":"Custom nodes","text":"To create a custom functional form and to make it available during model specification the ReactiveMP inference engine exports the @node macro:\n\n# `@node` macro accepts a name of the functional form, its type, either `Stochastic` or `Deterministic` and an array of interfaces:\n@node NormalMeanVariance Stochastic [ out, Œº, v ]\n\n# Interfaces may have aliases for their names that might be convenient for factorisation constraints specification\n@node NormalMeanVariance Stochastic [ out, (Œº, aliases = [ mean ]), (v, aliases = [ var ]) ]\n\n# `NormalMeanVariance` structure declaration must exist, otherwise `@node` macro will throw an error\nstruct NormalMeanVariance end \n\n@node NormalMeanVariance Stochastic [ out, Œº, v ]\n\n# It is also possible to use function objects as a node functional form\nfunction dot end\n\n# Syntax for functions is a bit differet, as it is necesssary to use `typeof(...)` function for them \n# out = dot(x, a)\n@node typeof(dot) Deterministic [ out, x, a ]\n\nAfter that it is possible to use the newly created node during model specification:\n\n@model function test_model()\n    ...\n    y ~ dot(x, a)\n    ...\nend","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#Custom-messages-computation-rules","page":"Advanced Tutorial","title":"Custom messages computation rules","text":"RxInfer.jl exports the @rule macro to create custom message computation rules. For example let us create a simple + node to be available for usage in the model specification usage. We refer to A Factor Graph Approach to Signal Modelling , System Identification and Filtering [ Sascha Korl, 2005, page 32 ] for a rigorous explanation of the + node in factor graphs. According to Korl, assuming that inputs are Gaussian Sum-Product message computation rule for + node is the following:\n\nbeginaligned\nmu_z = mu_x + mu_y\nV_z = V_x + V_y\nendaligned\n\nTo specify this in RxInfer.jl we use the @node and @rule macros:\n\n@node typeof(+) Deterministic  [ z, x, y ]\n\n@rule typeof(+)(:z, Marginalisation) (m_x::UnivariateNormalDistributionsFamily, m_y::UnivariateNormalDistributionsFamily) = begin\n    x_mean, x_var = mean_var(m_x)\n    y_mean, y_var = mean_var(m_y)\n    return NormalMeanVariance(x_mean + y_mean, x_var + y_var)\nend\n\nIn this example, for the @rule macro, we specify a type of our functional form: typeof(+). Next, we specify an edge we are going to compute an outbound message for. Marginalisation indicates that the corresponding message respects the marginalisation constraint for posterior over corresponding edge:\n\nbeginaligned\nq(z) = int q(z x y) mathrmdxmathrmdy\nendaligned\n\nIf we look on difference between sum-product rules and variational rules with mean-field assumption we notice that they require different local information to compute an outgoing message:\n\n(Image: ) (Image: )\n\nbeginaligned\nmu(z) = int f(x y z)mu(x)mu(y)mathrmdxmathrmdy\nendaligned\n\nbeginaligned\nnu(z) = exp int log f(x y z)q(x)q(y)mathrmdxmathrmdy \nendaligned\n\nThe @rule macro supports both cases with special prefixes during rule specification:\n\nm_ prefix corresponds to the incoming message on a specific edge\nq_ prefix corresponds to the posterior marginal of a specific edge\n\nExample of a Sum-Product rule with m_ messages used:\n\n@rule NormalMeanPrecision(:Œº, Marginalisation) (m_out::UnivariateNormalDistributionsFamily, m_œÑ::PointMass) = begin \n    m_out_mean, m_out_cov = mean_cov(m_out)\n    return NormalMeanPrecision(m_out_mean, inv(m_out_cov + inv(mean(m_œÑ))))\nend\n\nExample of a Variational rule with Mean-Field assumption with q_ posteriors used:\n\n@rule NormalMeanPrecision(:Œº, Marginalisation) (q_out::Any, q_œÑ::Any) = begin \n    return NormalMeanPrecision(mean(q_out), mean(q_œÑ))\nend\n\nRxInfer.jl also supports structured rules. It is possible to obtain joint marginal over a set of edges:\n\n@rule NormalMeanPrecision(:œÑ, Marginalisation) (q_out_Œº::Any, ) = begin\n    m, V = mean_cov(q_out_Œº)\n    Œ∏ = 2 / (V[1,1] - V[1,2] - V[2,1] + V[2,2] + abs2(m[1] - m[2]))\n    Œ± = convert(typeof(Œ∏), 1.5)\n    return Gamma(Œ±, Œ∏)\nend\n\nNOTE: In the @rule specification the messages or marginals arguments must be in order with interfaces specification from @node macro:\n\n# Inference backend expects arguments in `@rule` macro to be in the same order\n@node NormalMeanPrecision Stochastic [ out, Œº, œÑ ]\n\nAny rule always has access to the meta information with hidden the meta::Any variable:\n\n@rule MyCustomNode(:out, Marginalisation) (m_in1::Any, m_in2::Any) = begin \n    ...\n    println(meta)\n    ...\nend\n\nIt is also possible to dispatch on a specific type of a meta object:\n\n@rule MyCustomNode(:out, Marginalisation) (m_in1::Any, m_in2::Any, meta::LaplaceApproximation) = begin \n    ...\nend\n\nor\n\n@rule MyCustomNode(:out, Marginalisation) (m_in1::Any, m_in2::Any, meta::GaussHermiteCubature) = begin \n    ...\nend","category":"section"},{"location":"categories/advanced_examples/advanced_tutorial/#Customizing-messages-computational-pipeline","page":"Advanced Tutorial","title":"Customizing messages computational pipeline","text":"In certain situations it might be convenient to customize the default message computational pipeline. RxInfer.jl supports the pipeline keyword in the where { ... } clause to add some extra steps after a message has been computed. A use case might be an extra approximation method to preserve conjugacy in the model, debugging or simple printing.\n\n(Image: )\n\n# Logs all outbound messages\ny[i] ~ Normal(mean = x[i], precision = 1.0) where { pipeline = LoggerPipelineStage() }\n# In principle, it is possible to approximate outbound messages with Laplace Approximation (this is not an implemented feature, but a concept)\ny[i] ~ Normal(mean = x[i], precision = 1.0) where { pipeline = LaplaceApproximation() }\n\nLet us return to the coin toss model, but this time we want to print flowing messages:\n\n@model function coin_toss_model_log(y)\n    Œ∏ ~ Beta(2.0, 7.0) where { pipeline = LoggerPipelineStage(\"Œ∏\") }\n    for i in eachindex(y)\n        y[i] ~ Bernoulli(Œ∏)  where { pipeline = LoggerPipelineStage(\"y[$i]\") }\n    end\nend\n\ndataset = float.(rand(Bernoulli(p), 5));\nresult = infer(\n    model = coin_toss_model_log(),\n    data  = (y = dataset, )\n)\n\n[Œ∏]: [Distributions.Beta][out]: DeferredMessage([ use `as_message` to compu\nte the message ])\n[y[1]]: [Distributions.Bernoulli][p]: DeferredMessage([ use `as_message` to\n compute the message ])\n[y[2]]: [Distributions.Bernoulli][p]: DeferredMessage([ use `as_message` to\n compute the message ])\n[y[3]]: [Distributions.Bernoulli][p]: DeferredMessage([ use `as_message` to\n compute the message ])\n[y[4]]: [Distributions.Bernoulli][p]: DeferredMessage([ use `as_message` to\n compute the message ])\n[y[5]]: [Distributions.Bernoulli][p]: DeferredMessage([ use `as_message` to\n compute the message ])\nInference results:\n  Posteriors       | available for (Œ∏)\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n\n\n","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/","page":"Multi-Agent Trajectory Planning","title":"Multi-Agent Trajectory Planning","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Multi-agent-Trajectory-Planning","page":"Multi-Agent Trajectory Planning","title":"Multi-agent Trajectory Planning","text":"These examples demonstrate the use of RxInfer for trajectory planning in multi-agent situations. The animations show the inferred trajectories from probabilistic inference. The examples shown in this notebook are based on https://github.com/biaslab/MultiAgentTrajectoryPlanning/blob/main/door.jl, prepared by Michi-Tsubaki, extended by bvdmitri. The original code is a part of the paper Multi-Agent Trajectory Planning with NUV Priors by Bart van Erp.","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Introduction","page":"Multi-Agent Trajectory Planning","title":"Introduction","text":"This notebook demonstrates multi-agent trajectory planning using probabilistic inference with RxInfer.jl. In this example, we model multiple agents navigating through an environment with obstacles while trying to reach their respective goals. The planning problem is formulated as Bayesian inference, where:\n\nAgent states evolve according to linear dynamics\nCollision avoidance between agents and obstacles is encoded as probabilistic constraints\nGoal-seeking behavior is represented as prior distributions\n\nBy performing inference on this probabilistic model, we can compute optimal trajectories that balance goal-reaching with collision avoidance. The visualization shows how agents coordinate their movements to navigate efficiently through the environment.\n\nusing LinearAlgebra, RxInfer, Plots, LogExpFunctions, StableRNGs","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Environment-setup","page":"Multi-Agent Trajectory Planning","title":"Environment setup","text":"To test our ideas, we need an environment to work with. We are going to create a simple environment consisting of a plane with boxes as obstacles. These boxes can be placed anywhere we want on the plane, allowing us to experiment with different configurations and scenarios. This flexible setup will help us evaluate how our multi-agent trajectory planning algorithms perform under various conditions and obstacle arrangements.\n\n# A simple struct to represent a rectangle, which is defined by its center (x, y) and size (width, height)\nBase.@kwdef struct Rectangle\n    center::Tuple{Float64, Float64}\n    size::Tuple{Float64, Float64}\nend\n\nfunction plot_rectangle!(p, rect::Rectangle)\n    # Calculate the x-coordinates of the four corners\n    x_coords = rect.center[1] .+ rect.size[1]/2 * [-1, 1, 1, -1, -1]\n    # Calculate the y-coordinates of the four corners\n    y_coords = rect.center[2] .+ rect.size[2]/2 * [-1, -1, 1, 1, -1]\n    \n    # Plot the rectangle with a black fill\n    plot!(p, Shape(x_coords, y_coords), \n          label = \"\", \n          color = :black, \n          alpha = 0.5,\n          linewidth = 1.5,\n          fillalpha = 0.3)\nend\n\n# A simple struct to represent an environment, which is defined by a list of obctales,\n# and in this demo the obstacles are just rectangles\nBase.@kwdef struct Environment\n    obstacles::Vector{Rectangle}\nend\n\nfunction plot_environment!(p, env::Environment)\n    for obstacle in env.obstacles\n        plot_rectangle!(p, obstacle)\n    end\n    return p\nend\n\nfunction plot_environment(env::Environment)\n    p = plot(size = (800, 400), xlims = (-20, 20), ylims = (-20, 20), aspect_ratio = :equal)\n    plot_environment!(p, env)\n    return p\nend\n\nplot_environment (generic function with 1 method)\n\nIn the code above, we've defined two key structures for our environment:\n\nRectangle: A simple structure representing rectangular obstacles, defined by:\ncenter: The (x,y) coordinates of the rectangle's center\nsize: The (width, height) of the rectangle\nEnvironment: A structure that contains a collection of obstacles (rectangles)\n\nWe've also defined several plotting functions:\n\nplot_rectangle!: Adds a rectangle to an existing plot\nplot_environment!: Adds all obstacles in an environment to an existing plot\nplot_environment: Creates a new plot and displays the environment\n\nThese structures and functions provide the foundation for visualizing our 2D environment where multi-agent trajectory planning will take place.\n\nLet's create a couple of different environments to demonstrate multi-agent trajectory planning. You can experiment with different obstacle configurations by modifying the rectangle positions, sizes, and quantities. This will allow you to test how the agents navigate around various obstacle arrangements and interact with each other in different scenarios.","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Door-environment","page":"Multi-Agent Trajectory Planning","title":"Door environment","text":"In this environment, we'll create a scenario resembling a doorway that agents must navigate through. The environment will consist of two wall-like obstacles with a narrow passage between them, simulating a door or gateway. This setup will test the agents' ability to coordinate when passing through a constrained space, which is a common challenge in multi-agent path planning. The narrow passage will force agents to negotiate the right-of-way and potentially wait for each other to pass through, demonstrating emergent cooperative behaviors.\n\ndoor_environment = Environment(obstacles = [\n    Rectangle(center = (-40, 0), size = (70, 5)),\n    Rectangle(center = (40, 0), size = (70, 5))\n])\n\nplot_environment(door_environment)\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Wall-environment","page":"Multi-Agent Trajectory Planning","title":"Wall environment","text":"In this environment, we'll create a scenario with a wall in the center that agents must navigate around. The environment will consist of a single elongated obstacle positioned in the middle of the space, forcing agents to choose whether to go above or below the wall. This setup will test the agents' ability to find efficient paths around obstacles and coordinate with each other to avoid congestion on either side of the wall. It represents a common scenario in multi-agent navigation where agents must make decisions about which route to take when faced with a barrier.\n\nwall_environment = Environment(obstacles = [\n    Rectangle(center = (0, 0), size = (10, 5))\n])\n\nplot_environment(wall_environment)\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Combined-environment","page":"Multi-Agent Trajectory Planning","title":"Combined environment","text":"In this environment, we'll combine the door and wall scenarios to create a more complex navigation challenge. This environment will feature both a narrow doorway that agents must pass through and a wall obstacle they need to navigate around. This combined setup will test the agents' ability to handle multiple types of obstacles in sequence, requiring more sophisticated path planning and coordination. Agents will need to negotiate the doorway and then decide which path to take around the wall, or vice versa depending on their starting and goal positions. This represents a more realistic scenario where environments often contain various types of obstacles that require different navigation strategies.\n\ncombined_environment = Environment(obstacles = [\n    Rectangle(center = (-50, 0), size = (70, 2)),\n    Rectangle(center = (50, -0), size = (70, 2)),\n    Rectangle(center = (5, -1), size = (3, 10))\n])\n\nplot_environment(combined_environment)\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Agent-state","page":"Multi-Agent Trajectory Planning","title":"Agent state","text":"In this section, we define states and goals for our agents. Each agent has a initial position and target end position. These states will be used to drive agent movement through the environment. The trajectory planning algorithm will use this information to generate paths from start to destination while avoiding obstacles. We start by first defining the necessary structures and functions for the goals.\n\n\n# Agent plan, encodes start and goal states\nBase.@kwdef struct Agent\n    radius::Float64\n    initial_position::Tuple{Float64, Float64}\n    target_position::Tuple{Float64, Float64}\nend\n\nfunction plot_marker_at_position!(p, radius, position; color=\"red\", markersize=10.0, alpha=1.0, label=\"\")\n    # Draw the agent as a circle with the given radius\n    Œ∏ = range(0, 2œÄ, 100)\n    \n    x_coords = position[1] .+ radius .* cos.(Œ∏)\n    y_coords = position[2] .+ radius .* sin.(Œ∏)\n    \n    plot!(p, Shape(x_coords, y_coords); color=color, label=label, alpha=alpha)\n    return p\nend\n\nplot_marker_at_position! (generic function with 1 method)\n\nLet see how does one of configurations for a single agent might look like in the first door environment. For this we will use two agents with different radius, as well as different initial and taget positions.\n\nfunction plot_agent_naive_plan!(p, agent; color = \"blue\")\n    plot_marker_at_position!(p, agent.radius, agent.initial_position, color = color)\n    plot_marker_at_position!(p, agent.radius, agent.target_position, color = color, alpha = 0.1)\n    quiver!(p, [ agent.initial_position[1] ], [ agent.initial_position[2] ], quiver = ([ agent.target_position[1] - agent.initial_position[1] ], [ agent.target_position[2] -  agent.initial_position[2] ]))\nend\n\nlet pe = plot_environment(door_environment)\n    agents = [ \n        Agent(radius = 2.5, initial_position = (-4, 10), target_position = (-10, -10)),\n        Agent(radius = 1.5, initial_position = (-10, 5), target_position = (10, -15)),\n        Agent(radius = 1.0, initial_position = (-15, -10), target_position = (10, 10)),\n        Agent(radius = 2.5, initial_position = (0, -10), target_position = (-10, 15))\n    ]\n    \n    colors = Plots.palette(:tab10)\n    \n    for (k, agent) in enumerate(agents)\n        plot_agent_naive_plan!(pe, agent, color = colors[k])\n    end\n    \n    pe\nend\n\n(Image: )\n\nThe plot above illustrates that naive trajectory from initial to target position will obviously not work and the agents will hit either the wall or each other while trying to execute their plan. Thus we need to come up with a better plan and simultaneously take into account multiple agents in the same environment.","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Next-Steps","page":"Multi-Agent Trajectory Planning","title":"Next Steps","text":"Now that we have set up our environment, defined our agents, and created utility functions, we are ready to build an RxInfer model to solve this multi-agent trajectory planning problem. In the following sections, we will:\n\nDefine a probabilistic model that captures the dynamics of our agents\nIncorporate collision avoidance constraints between agents and obstacles using NUV priors\nUse message passing to infer optimal trajectories\nVisualize the resulting paths\n\nThis will demonstrate how probabilistic programming with RxInfer can elegantly solve complex planning problems while handling uncertainty and constraints in a principled way.","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Half-space-prior-implementation","page":"Multi-Agent Trajectory Planning","title":"Half space prior implementation","text":"For our multi-agent trajectory planning model, we need to implement half-space priors to handle collision avoidance constraints. These priors allow us to model the requirement that agents must stay outside of obstacles and maintain safe distances from each other. The mathematical details and theoretical foundation of these half-space priors can be found in the paper referenced at the beginning of this notebook. The implementation below defines the necessary node and message-passing rules for incorporating these constraints into our probabilistic model.\n\n# Define the probabilistic model for obstacles using halfspace constraints\nstruct Halfspace end\n\n@node Halfspace Stochastic [out, a, œÉ2, Œ≥]\n\n# rule specification\n@rule Halfspace(:out, Marginalisation) (q_a::Any, q_œÉ2::Any, q_Œ≥::Any) = begin\n    return NormalMeanVariance(mean(q_a) + mean(q_Œ≥) * mean(q_œÉ2), mean(q_œÉ2))\nend\n\n@rule Halfspace(:œÉ2, Marginalisation) (q_out::Any, q_a::Any, q_Œ≥::Any, ) = begin\n    # `BayesBase.TerminalProdArgument` is used to ensure that the result of the posterior computation is equal to this value\n    return BayesBase.TerminalProdArgument(PointMass( 1 / mean(q_Œ≥) * sqrt(abs2(mean(q_out) - mean(q_a)) + var(q_out))))\nend","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Distance-functions-for-collision-avoidance","page":"Multi-Agent Trajectory Planning","title":"Distance functions for collision avoidance","text":"In addition to the halfspace priors, we need to implement distance functions to properly handle collision avoidance between agents and obstacles. These functions will calculate the distance between agents and obstacles, which is essential for determining when collision avoidance constraints should be activated. The distance functions will be used to ensure that agents maintain safe distances from each other and from obstacles in the environment. In the next section, we'll define utility functions that include these distance calculations for different geometric shapes like rectangles and circles.\n\nsoftmin(x; l=10) = -logsumexp(-l .* x) / l\n\n# state here is a 4-dimensional vector [x, y, vx, vy]\nfunction distance(r::Rectangle, state)\n    if abs(state[1] - r.center[1]) > r.size[1] / 2 || abs(state[2] - r.center[2]) > r.size[2] / 2\n        # outside of rectangle\n        dx = max(abs(state[1] - r.center[1]) - r.size[1] / 2, 0)\n        dy = max(abs(state[2] - r.center[2]) - r.size[2] / 2, 0)\n        return sqrt(dx^2 + dy^2)\n    else\n        # inside rectangle\n        return max(abs(state[1] - r.center[1]) - r.size[1] / 2, abs(state[2] - r.center[2]) - r.size[2] / 2)\n    end\nend\n\nfunction distance(env::Environment, state)\n    return softmin([distance(obstacle, state) for obstacle in env.obstacles])\nend\n\ndistance (generic function with 2 methods)\n\nWe use the softmin function to create a smooth approximation of the minimum distance between an agent and multiple obstacles. Unlike the regular min function which returns the exact minimum value, softmin produces a differentiable approximation that considers all distances with a weighted average, heavily biased toward the smallest values.\n\nThe parameter l controls the \"sharpness\" of the approximation - with larger values making the function behave more like the true minimum. This smoothness is particularly valuable in optimization contexts as it:\n\nAvoids discontinuities that could cause numerical issues during inference\nProvides gradient information from all obstacles, not just the closest one\nCreates a more stable optimization landscape for trajectory planning\n\nWhen calculating the distance between an agent and the environment, softmin helps create a continuous repulsive field around all obstacles, allowing for more natural avoidance behaviors.","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Model-specification","page":"Multi-Agent Trajectory Planning","title":"Model specification","text":"We use RxInfer's @model macro to specify the model. In the current example we fix our model to exactly 4 agents to simplify the model creation and construction. We also define auxiliary functions g and h which computes distance with agent's radius offset and minimum distance between all agents pairwise.\n\n# Helper function, distance with radius offset\nfunction g(environment, radius, state)\n    return distance(environment, state) - radius\nend\n\n# Helper function, finds minimum distances between agents pairwise\nfunction h(environment, radiuses, states...)\n    # Calculate pairwise distances between all agents\n    distances = Real[]\n    n = length(states)\n\n    for i in 1:n\n        for j in (i+1):n\n            push!(distances, norm(states[i] - states[j]) - radiuses[i] - radiuses[j])\n        end\n    end\n\n    return softmin(distances)\nend\n\nh (generic function with 1 method)\n\n# For more details about the model, please refer to the original paper\n@model function path_planning_model(environment, agents, goals, nr_steps)\n\n    # Model's parameters are fixed, refer to the original \n    # paper's implementation for more details about these parameters\n    local dt = 1\n    local A  = [1 dt 0 0; 0 1 0 0; 0 0 1 dt; 0 0 0 1]\n    local B  = [0 0; dt 0; 0 0; 0 dt]\n    local C  = [1 0 0 0; 0 0 1 0]\n    local Œ≥  = 1\n\n    local control\n    local state\n    local path   \n    \n    # Extract radiuses of each agent in a separate collection\n    local rs = map((a) -> a.radius, agents)\n\n    # Model is fixed for 4 agents\n    for k in 1:4\n\n        # Prior on state, the state structure is 4 dimensional, where\n        # [ x_position, x_velocity, y_position, y_velocity ]\n        state[k, 1] ~ MvNormal(mean = zeros(4), covariance = 1e2I)\n\n        for t in 1:nr_steps\n\n            # Prior on controls\n            control[k, t] ~ MvNormal(mean = zeros(2), covariance = 1e-1I)\n\n            # State transition\n            state[k, t+1] ~ A * state[k, t] + B * control[k, t]\n\n            # Path model, the path structure is 2 dimensional, where \n            # [ x_position, y_position ]\n            path[k, t] ~ C * state[k, t+1]\n\n            # Environmental distance\n            zœÉ2[k, t] ~ GammaShapeRate(3 / 2, Œ≥^2 / 2)\n            z[k, t]   ~ g(environment, rs[k], path[k, t])\n            \n            # Halfspase priors were defined previousle in this experiment\n            z[k, t] ~ Halfspace(0, zœÉ2[k, t], Œ≥)\n\n        end\n\n        # goal priors (indexing reverse due to definition)\n        goals[1, k] ~ MvNormal(mean = state[k, 1], covariance = 1e-5I)\n        goals[2, k] ~ MvNormal(mean = state[k, nr_steps+1], covariance = 1e-5I)\n\n    end\n\n    for t = 1:nr_steps\n\n        # observation constraint\n        dœÉ2[t] ~ GammaShapeRate(3 / 2, Œ≥^2 / 2)\n        d[t] ~ h(environment, rs, path[1, t], path[2, t], path[3, t], path[4, t])\n        d[t] ~ Halfspace(0, dœÉ2[t], Œ≥)\n\n    end\n\nend\n\n@constraints function path_planning_constraints()\n    # Mean-field variational constraints on the parameters\n    q(d, dœÉ2) = q(d)q(dœÉ2)\n    q(z, zœÉ2) = q(z)q(zœÉ2)\nend\n\npath_planning_constraints (generic function with 1 method)","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Constraint-specification","page":"Multi-Agent Trajectory Planning","title":"Constraint specification","text":"function path_planning(; environment, agents, nr_iterations = 350, nr_steps = 40, seed = 42)\n    # Fixed number of agents\n    nr_agents = 4\n\n    # Form goals compatible with the model\n    goals = hcat(\n        map(agents) do agent\n            return [\n                [ agent.initial_position[1], 0, agent.initial_position[2], 0 ],\n                [ agent.target_position[1], 0, agent.target_position[2], 0 ]\n            ]\n        end...\n    )\n    \n    rng = StableRNG(seed)\n    \n    # Initialize variables, more details about initialization \n    # can be found in the original paper\n    init = @initialization begin\n\n        q(dœÉ2) = repeat([PointMass(1)], nr_steps)\n        q(zœÉ2) = repeat([PointMass(1)], nr_agents, nr_steps)\n        q(control) = repeat([PointMass(0)], nr_steps)\n\n        Œº(state) = MvNormalMeanCovariance(randn(rng, 4), 100I)\n        Œº(path) = MvNormalMeanCovariance(randn(rng, 2), 100I)\n\n    end\n\n    # Define approximation methods for the non-linear functions used in the model\n    # `Linearization` is a simple and fast approximation method, but it is not\n    # the most accurate one. For more details about the approximation methods,\n    # please refer to the RxInfer documentation\n    door_meta = @meta begin \n        h() -> Linearization()\n        g() -> Linearization()\n    end\n\n    results = infer(\n        model \t\t\t= path_planning_model(environment = environment, agents = agents, nr_steps = nr_steps),\n        data  \t\t\t= (goals = goals, ),\n        initialization  = init,\n        constraints \t= path_planning_constraints(),\n        meta \t\t\t= door_meta,\n        iterations \t\t= nr_iterations,\n        returnvars \t\t= KeepLast(), \n        options         = (limit_stack_depth = 300, )\n    )\n\n    return results\nend\n\npath_planning (generic function with 1 method)\n\nfunction execute_and_save_animation(environment, agents; gifname = \"result.gif\", kwargs...)\n    result = path_planning(environment = environment, agents = agents; kwargs...)\n    paths  = mean.(result.posteriors[:path])\n    \n    nr_agents, nr_steps = size(paths)\n    colors = Plots.palette(:tab10)\n\n    animation = @animate for t in 1:nr_steps\n        frame = plot_environment(environment)\n    \n        for k in 1:nr_agents\n            position = paths[k, t]          \n            path = paths[k, 1:t]\n            \n            plot_marker_at_position!(frame, agents[k].radius, position, color = colors[k])\n            plot_marker_at_position!(frame, agents[k].radius, agents[k].target_position, color = colors[k], alpha = 0.2)\n            plot!(frame, getindex.(path, 1), getindex.(path, 2); linestyle=:dash, label=\"\", color=colors[k])\n        end\n\n        frame\n    end\n\n    # assign the path to save the image\n    gif(animation, gifname, fps=15, show_msg = false)\n    \n    return nothing\nend\n\nexecute_and_save_animation (generic function with 1 method)\n\n# These are the same agents as in the beginning of the notebook, but copy-pasted here \n# for easier experimentation, closer to the actual experiments\nagents = [\n    Agent(radius = 2.5, initial_position = (-4, 10), target_position = (-10, -10)),\n    Agent(radius = 1.5, initial_position = (-10, 5), target_position = (10, -15)),\n    Agent(radius = 1.0, initial_position = (-15, -10), target_position = (10, 10)),\n    Agent(radius = 2.5, initial_position = (0, -10), target_position = (-10, 15))\n]\n\n4-element Vector{Main.var\"##WeaveSandBox#277\".Agent}:\n Main.var\"##WeaveSandBox#277\".Agent(2.5, (-4.0, 10.0), (-10.0, -10.0))\n Main.var\"##WeaveSandBox#277\".Agent(1.5, (-10.0, 5.0), (10.0, -15.0))\n Main.var\"##WeaveSandBox#277\".Agent(1.0, (-15.0, -10.0), (10.0, 10.0))\n Main.var\"##WeaveSandBox#277\".Agent(2.5, (0.0, -10.0), (-10.0, 15.0))","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Experiments-and-visualizations","page":"Multi-Agent Trajectory Planning","title":"Experiments and visualizations","text":"The experiments and animations below demonstrate the power of probabilistic inference for multi-agent trajectory planning in different environments. Let's analyze what we can observe in each scenario:","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Door-environment-2","page":"Multi-Agent Trajectory Planning","title":"Door environment","text":"In the door environment, we see four agents with different sizes navigating through a narrow passage. The agents demonstrate several interesting behaviors:\n\nWhen multiple agents approach the doorway simultaneously, they naturally form a queue, with some agents waiting for others to pass through first\nAgents slow down or speed up based on the presence of other agents near the doorway\nLarger agents (with bigger radius) effectively have precedence in tight spaces, as smaller agents can more easily find alternative paths\n\nThe two different seeds (42 and 123) show how small changes in initialization can lead to different coordination patterns, highlighting the inherent variability in multi-agent systems.\n\nexecute_and_save_animation(door_environment, agents; seed = 42, gifname = \"door_42.gif\")\n\n(Image: )\n\nexecute_and_save_animation(door_environment, agents; seed = 123, gifname = \"door_123.gif\")\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Wall-environment-2","page":"Multi-Agent Trajectory Planning","title":"Wall environment","text":"The wall environment forces agents to choose whether to go above or below the obstacle and distribute themselves between the two possible paths to avoid congestion The choice of path (above or below) appears to be influenced by the agent's initial position.\n\nexecute_and_save_animation(wall_environment, agents; seed = 42, gifname = \"wall_42.gif\")\n\n(Image: )\n\nexecute_and_save_animation(wall_environment, agents; seed = 123, gifname = \"wall_123.gif\")\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Combined-environment-2","page":"Multi-Agent Trajectory Planning","title":"Combined environment","text":"The combined environment presents the most complex challenge, requiring agents to navigate both a doorway and a wall. This environment best showcases the power of the approach, as traditional reactive navigation methods would struggle with the compounding complexity of multiple obstacle types.\n\nexecute_and_save_animation(combined_environment, agents; seed = 42, gifname = \"combined_42.gif\")\n\n(Image: )\n\nexecute_and_save_animation(combined_environment, agents; seed = 123, gifname = \"combined_123.gif\")\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Practical-Applications-and-Potential-Improvements","page":"Multi-Agent Trajectory Planning","title":"Practical Applications and Potential Improvements","text":"The multi-agent trajectory planning approach demonstrated in this notebook has numerous real-world applications:\n\nWarehouse robotics: Coordinating multiple robots in fulfillment centers to avoid collisions while efficiently picking and delivering items\nTraffic management: Planning trajectories for autonomous vehicles at intersections or in congested areas\nCrowd simulation: Modeling realistic human movement patterns in architectural design or emergency evacuation planning\nDrone swarms: Coordinating groups of UAVs for tasks like search and rescue, surveillance, or package delivery\n\nFuture extensions to this work could include:\n\nHandling dynamic obstacles that move or change over time\nIncorporating uncertainty in agent dynamics and sensing\nScaling to much larger numbers of agents through more efficient inference algorithms\nAdding communication constraints between agents for more realistic modeling\nIncorporating heterogeneous agent types with different dynamics and capabilities","category":"section"},{"location":"categories/advanced_examples/multi-agent_trajectory_planning/#Conclusion","page":"Multi-Agent Trajectory Planning","title":"Conclusion","text":"This notebook has demonstrated how probabilistic inference can be used to solve the complex problem of multi-agent trajectory planning. By formulating the planning problem as Bayesian inference, we've shown how agents can coordinate their movements to navigate through various challenging environments while avoiding collisions with obstacles and each other.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [2ab3a3ac] LogExpFunctions v0.3.29\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [37e2e46d] LinearAlgebra v1.12.0\n\n\n","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/","page":"Bayesian Linear Regression","title":"Bayesian Linear Regression","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Bayesian-Linear-Regression-Tutorial","page":"Bayesian Linear Regression","title":"Bayesian Linear Regression Tutorial","text":"This notebook is an extensive tutorial on Bayesian linear regression with RxInfer and consists of two major parts:\n\nThe first part uses a regular Bayesian Linear Regression on a simple application of fuel consumption for a car with synthetic data.\nThe second part is an adaptation of a tutorial from NumPyro and uses Hierarchical Bayesian linear regression on the OSIC pulmonary fibrosis progression dataset from Kaggle.\n\nusing RxInfer, Random, Plots, StableRNGs, LinearAlgebra, StatsPlots, LaTeXStrings, DataFrames, CSV, GLM","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Part-1.-Bayesian-Linear-Regression","page":"Bayesian Linear Regression","title":"Part 1. Bayesian Linear Regression","text":"John recently purchased a new car and is interested in its fuel consumption rate. He believes that this rate has a linear relationship with speed, and as such, he wants to conduct tests by driving his car on different types of roads, recording both the fuel usage and speed. In order to determine the fuel consumption rate, John employs Bayesian linear regression.","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Univariate-regression-with-known-noise","page":"Bayesian Linear Regression","title":"Univariate regression with known noise","text":"First, he drives the car on a urban road. John enjoys driving on the well-built, wide, and flat urban roads. Urban roads also offer the advantage of precise fuel consumption measurement with minimal noise. Therefore John models the fuel consumption y_ninmathbbR as a normal distribution and treats x_n as a fixed hyperparameter:\n\nbeginaligned\np(y_n mid a b) = mathcalN(y_n mid a x_n + b  1)\nendaligned\n\nThe recorded speed is denoted as x_n in mathbbR and the recorded fuel consumption as y_n in mathbbR. Prior beliefs on a and b are informed by the vehicle manual.\n\nbeginaligned\n    p(a) = mathcalN(a mid m_a v_a) \n    p(b) = mathcalN(b mid m_b v_b) \nendaligned\n\nTogether they form the probabilistic model p(y a b) = p(a)p(b) prod_N=1^N p(y_n mid a b) where the goal is to infer the posterior distributions p(a mid y) and p(bmid y).\n\nHe records the speed and fuel consumption for the urban road which is the xdata and ydata.\n\nfunction generate_data(a, b, v, nr_samples; rng=StableRNG(1234))\n    x = float.(collect(1:nr_samples))\n    y = a .* x .+ b .+ randn(rng, nr_samples) .* sqrt(v)\n    return x, y\nend;\n\nx_data, y_data = generate_data(0.5, 25.0, 1.0, 250)\n\nscatter(x_data, y_data, title = \"Dataset (City road)\", legend=false)\nxlabel!(\"Speed\")\nylabel!(\"Fuel consumption\")\n\n(Image: )\n\nIn order to estimate the two parameters with the recorded data, he uses a RxInfer.jl to create the above described model.\n\n@model function linear_regression(x, y)\n    a ~ Normal(mean = 0.0, variance = 1.0)\n    b ~ Normal(mean = 0.0, variance = 100.0)    \n    y .~ Normal(mean = a .* x .+ b, variance = 1.0)\nend\n\nHe is delighted that he can utilize the inference function from this package, saving him the effort of starting from scratch and enabling him to obtain the desired results for this road. He does note that there is a loop in his model, namely all a and b variables are connected over all observations, therefore he needs to initialize one of the messages and run multiple iterations for the loopy belief propagation algorithm (see detailed explanation). It is worth noting that loopy belief propagation is not guaranteed to converge in general and might be highly influenced by the choice of the initial messages in the initialization argument. He is going to evaluate the convergency performance of the algorithm with the free_energy = true option:\n\nresults = infer(\n    model          = linear_regression(), \n    data           = (y = y_data, x = x_data), \n    initialization = @initialization(Œº(b) = NormalMeanVariance(0.0, 100.0)), \n    returnvars     = (a = KeepLast(), b = KeepLast()),\n    iterations     = 20,\n    free_energy    = true\n)\n\nInference results:\n  Posteriors       | available for (a, b)\n  Free Energy:     | Real[450.062, 8526.84, 4960.42, 2949.02, 1819.14, 1184\n.44, 827.897, 627.595, 515.064, 451.839, 416.313, 396.349, 385.129, 378.821\n, 375.274, 373.279, 372.156, 371.524, 371.167, 370.966]\n\nHe knows the theoretical coefficients and noise for this car from the manual. He is going to compare the experimental solution with theoretical results.\n\npra = plot(range(-3, 3, length = 1000), (x) -> pdf(NormalMeanVariance(0.0, 1.0), x), title=L\"Prior for $a$ parameter\", fillalpha=0.3, fillrange = 0, label=L\"$p(a)$\", c=1,)\npra = vline!(pra, [ 0.5 ], label=L\"True $a$\", c = 3)\npsa = plot(range(0.45, 0.55, length = 1000), (x) -> pdf(results.posteriors[:a], x), title=L\"Posterior for $a$ parameter\", fillalpha=0.3, fillrange = 0, label=L\"$p(a\\mid y)$\", c=2,)\npsa = vline!(psa, [ 0.5 ], label=L\"True $a$\", c = 3)\n\nplot(pra, psa, size = (1000, 200), xlabel=L\"$a$\", ylabel=L\"$p(a)$\", ylims=[0,Inf])\n\n(Image: )\n\nprb = plot(range(-40, 40, length = 1000), (x) -> pdf(NormalMeanVariance(0.0, 100.0), x), title=L\"Prior for $b$ parameter\", fillalpha=0.3, fillrange = 0, label=L\"p(b)\", c=1, legend = :topleft)\nprb = vline!(prb, [ 25 ], label=L\"True $b$\", c = 3)\npsb = plot(range(23, 28, length = 1000), (x) -> pdf(results.posteriors[:b], x), title=L\"Posterior for $b$ parameter\", fillalpha=0.3, fillrange = 0, label=L\"p(b\\mid y)\", c=2, legend = :topleft)\npsb = vline!(psb, [ 25 ], label=L\"True $b$\", c = 3)\n\nplot(prb, psb, size = (1000, 200), xlabel=L\"$b$\", ylabel=L\"$p(b)$\", ylims=[0, Inf])\n\n(Image: )\n\na = results.posteriors[:a]\nb = results.posteriors[:b]\n\nprintln(\"Real a: \", 0.5, \" | Estimated a: \", mean_var(a), \" | Error: \", abs(mean(a) - 0.5))\nprintln(\"Real b: \", 25.0, \" | Estimated b: \", mean_var(b), \" | Error: \", abs(mean(b) - 25.0))\n\nReal a: 0.5 | Estimated a: (0.501490188462706, 1.9162284531300301e-7) | Err\nor: 0.001490188462705988\nReal b: 25.0 | Estimated b: (24.81264210195605, 0.0040159675312827) | Error\n: 0.18735789804394898\n\nBased on the Bethe free energy below, John knows that the loopy belief propagation has actually converged after 20 iterations:\n\n# drop first iteration, which is influenced by the `initmessages`\nplot(2:20, results.free_energy[2:end], title=\"Free energy\", xlabel=\"Iteration\", ylabel=\"Free energy [nats]\", legend=false)\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Univariate-regression-with-unknown-noise","page":"Bayesian Linear Regression","title":"Univariate regression with unknown noise","text":"Afterwards, he plans to test the car on a mountain road. However, mountain roads are typically narrow and filled with small stones, which makes it more difficult to establish a clear relationship between fuel consumption and speed, leading to an unknown level of noise in the regression model. Therefore, he design a model with unknown Inverse-Gamma distribution on the variance. beginaligned p(y_n mid a b s) = mathcalN(y_n mid ax_n + b s)\np(s) = mathcalIG(smidalpha theta)\np(a) = mathcalN(a mid m_a v_a) \np(b) = mathcalN(b mid m_b v_b)  endaligned\n\n@model function linear_regression_unknown_noise(x, y)\n    a ~ Normal(mean = 0.0, variance = 1.0)\n    b ~ Normal(mean = 0.0, variance = 100.0)\n    s ~ InverseGamma(1.0, 1.0)\n    y .~ Normal(mean = a .* x .+ b, variance = s)\nend\n\nx_data_un, y_data_un = generate_data(0.5, 25.0, 400.0, 250)\n\nscatter(x_data_un, y_data_un, title = \"Dateset with unknown noise (mountain road)\", legend=false)\nxlabel!(\"Speed\")\nylabel!(\"Fuel consumption\")\n\n(Image: )\n\nTo solve this problem in closed-from we need to resort to a variational approximation. The procedure will be a combination of variational inference and loopy belief propagation. He chooses constraints = MeanField() as a global variational approximation and provides initial marginals with the initialization argument. He is, again, going to evaluate the convergency performance of the algorithm with the free_energy = true option:\n\ninit_unknown_noise = @initialization begin \n    Œº(b) = NormalMeanVariance(0.0, 100.0)\n    q(s) = vague(InverseGamma)\nend\n\nresults_unknown_noise = infer(\n    model           = linear_regression_unknown_noise(), \n    data            = (y = y_data_un, x = x_data_un), \n    initialization  = init_unknown_noise, \n    returnvars      = (a = KeepLast(), b = KeepLast(), s = KeepLast()), \n    iterations      = 20,\n    constraints     = MeanField(),\n    free_energy     = true\n)\n\nInference results:\n  Posteriors       | available for (a, b, s)\n  Free Energy:     | Real[1657.49, 1192.08, 1142.31, 1135.43, 1129.19, 1125\n.47, 1123.34, 1122.13, 1121.44, 1121.05, 1120.82, 1120.69, 1120.61, 1120.56\n, 1120.53, 1120.52, 1120.5, 1120.5, 1120.49, 1120.49]\n\nBased on the Bethe free energy below, John knows that his algorithm has converged after 20 iterations:\n\nplot(results_unknown_noise.free_energy, title=\"Free energy\", xlabel=\"Iteration\", ylabel=\"Free energy [nats]\", legend=false)\n\n(Image: )\n\nBelow he visualizes the obtained posterior distributions for parameters:\n\npra = plot(range(-3, 3, length = 1000), (x) -> pdf(NormalMeanVariance(0.0, 1.0), x), title=L\"Prior for $a$ parameter\", fillalpha=0.3, fillrange = 0, label=L\"$p(a)$\", c=1,)\npra = vline!(pra, [ 0.5 ], label=L\"True $a$\", c = 3)\npsa = plot(range(0.45, 0.55, length = 1000), (x) -> pdf(results_unknown_noise.posteriors[:a], x), title=L\"Posterior for $a$ parameter\", fillalpha=0.3, fillrange = 0, label=L\"$q(a)$\", c=2,)\npsa = vline!(psa, [ 0.5 ], label=L\"True $a$\", c = 3)\n\nplot(pra, psa, size = (1000, 200), xlabel=L\"$a$\", ylabel=L\"$p(a)$\", ylims=[0, Inf])\n\n(Image: )\n\nprb = plot(range(-40, 40, length = 1000), (x) -> pdf(NormalMeanVariance(0.0, 100.0), x), title=L\"Prior for $b$ parameter\", fillalpha=0.3, fillrange = 0, label=L\"$p(b)$\", c=1, legend = :topleft)\nprb = vline!(prb, [ 25.0 ], label=L\"True $b$\", c = 3)\npsb = plot(range(23, 28, length = 1000), (x) -> pdf(results_unknown_noise.posteriors[:b], x), title=L\"Posterior for $b$ parameter\", fillalpha=0.3, fillrange = 0, label=L\"$q(b)$\", c=2, legend = :topleft)\npsb = vline!(psb, [ 25.0 ], label=L\"True $b$\", c = 3)\n\nplot(prb, psb, size = (1000, 200), xlabel=L\"$b$\", ylabel=L\"$p(b)$\", ylims=[0, Inf])\n\n(Image: )\n\nprb = plot(range(0.001, 400, length = 1000), (x) -> pdf(InverseGamma(1.0, 1.0), x), title=L\"Prior for $s$ parameter\", fillalpha=0.3, fillrange = 0, label=L\"$p(s)$\", c=1, legend = :topleft)\nprb = vline!(prb, [ 200 ], label=L\"True $s$\", c = 3)\npsb = plot(range(0.001, 400, length = 1000), (x) -> pdf(results_unknown_noise.posteriors[:s], x), title=L\"Posterior for $s$ parameter\", fillalpha=0.3, fillrange = 0, label=L\"$q(s)$\", c=2, legend = :topleft)\npsb = vline!(psb, [ 200 ], label=L\"True $s$\", c = 3)\n\nplot(prb, psb, size = (1000, 200), xlabel=L\"$s$\", ylabel=L\"$p(s)$\", ylims=[0, Inf])\n\n(Image: )\n\nHe sees that in the presence of more noise the inference result is more uncertain about the actual values for a and b parameters.\n\nJohn samples a and b and plot many possible regression lines on the same plot:\n\nas = rand(results_unknown_noise.posteriors[:a], 100)\nbs = rand(results_unknown_noise.posteriors[:b], 100)\np = scatter(x_data_un, y_data_un, title = \"Linear regression with more noise\", legend=false)\nxlabel!(\"Speed\")\nylabel!(\"Fuel consumption\")\nfor (a, b) in zip(as, bs)\n    global p = plot!(p, x_data_un, a .* x_data_un .+ b, alpha = 0.05, color = :red)\nend\n\nplot(p, size = (900, 400))\n\n(Image: )\n\nFrom this plot John can see that many lines do fit the data well and there is no definite \"best\" answer to the regression coefficients. He realize that most of these lines, however, resemble a similar angle and shift.","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Multivariate-linear-regression","page":"Bayesian Linear Regression","title":"Multivariate linear regression","text":"In addition to fuel consumption, he is also interested in evaluating the car's power performance, braking performance, handling stability, smoothness, and other factors. To investigate the car's performance, he includes additional measurements. Essentially, this approach involves performing multiple linear regression tasks simultaneously, using multiple data vectors for x and y with different levels of noise. As in the previous example, he assumes the level of noise to be unknown.\n\n@model function linear_regression_multivariate(dim, x, y)\n    a ~ MvNormal(mean = zeros(dim), covariance = 100 * diageye(dim))\n    b ~ MvNormal(mean = ones(dim), covariance = 100 * diageye(dim))\n    W ~ InverseWishart(dim + 2, 100 * diageye(dim))\n    y .~ MvNormal(mean = x .* a .+ b, covariance = W)\nend\n\nAfter received all the measurement records, he plots the measurements and performance index:\n\ndim_mv = 6\nnr_samples_mv = 50\nrng_mv = StableRNG(42)\na_mv = randn(rng_mv, dim_mv)\nb_mv = 10 * randn(rng_mv, dim_mv)\nv_mv = 100 * rand(rng_mv, dim_mv)\n\nx_data_mv, y_data_mv = collect(zip(generate_data.(a_mv, b_mv, v_mv, nr_samples_mv)...));\n\np = plot(title = \"Multivariate linear regression\", legend = :topleft)\n\nplt = palette(:tab10)\n\ndata_set_label = [\"\"]\n\nfor k in 1:dim_mv\n    global p = scatter!(p, x_data_mv[k], y_data_mv[k], label = \"Measurement #$k\", ms = 2, color = plt[k])\nend\nxlabel!(L\"$x$\")\nylabel!(L\"$y$\")\np\n\n(Image: )\n\nBefore this data can be used to perform inference, John needs to change its format slightly.\n\nx_data_mv_processed = map(i -> Diagonal([getindex.(x_data_mv, i)...]), 1:nr_samples_mv)\ny_data_mv_processed = map(i -> [getindex.(y_data_mv, i)...], 1:nr_samples_mv);\n\ninit = @initialization begin \n    q(W) = InverseWishart(dim_mv + 2, 10 * diageye(dim_mv))\n    Œº(b) = MvNormalMeanCovariance(ones(dim_mv), 10 * diageye(dim_mv))\nend\n\nInitial state: \n  q(W) = Distributions.InverseWishart{Float64, PDMats.PDMat{Float64, Matrix\n{Float64}}}(\ndf: 8.0\nŒ®: [10.0 0.0 ‚Ä¶ 0.0 0.0; 0.0 10.0 ‚Ä¶ 0.0 0.0; ‚Ä¶ ; 0.0 0.0 ‚Ä¶ 10.0 0.0; 0.0 0.0\n ‚Ä¶ 0.0 10.0]\n)\n\n  Œº(b) = MvNormalMeanCovariance(\nŒº: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\nŒ£: [10.0 0.0 ‚Ä¶ 0.0 0.0; 0.0 10.0 ‚Ä¶ 0.0 0.0; ‚Ä¶ ; 0.0 0.0 ‚Ä¶ 10.0 0.0; 0.0 0.0\n ‚Ä¶ 0.0 10.0]\n)\n\nresults_mv = infer(\n    model           = linear_regression_multivariate(dim = dim_mv),\n    data            = (y = y_data_mv_processed, x = x_data_mv_processed),\n    initialization  = init,\n    returnvars      = (a = KeepLast(), b = KeepLast(), W = KeepLast()),\n    free_energy     = true,\n    iterations      = 50,\n    constraints     = MeanField()\n)\n\nInference results:\n  Posteriors       | available for (a, b, W)\n  Free Energy:     | Real[864.485, 789.026, 769.094, 750.865, 737.67, 724.7\n22, 712.341, 700.865, 690.782, 682.505  ‚Ä¶  664.434, 664.434, 664.434, 664.4\n34, 664.434, 664.434, 664.434, 664.434, 664.434, 664.434]\n\nAgain, the algorithm nicely converged, because the Bethe free energy reached a plateau. John also draws the results for the linear regression parameters and sees that the lines very nicely follow the provided data.\n\np = plot(title = \"Multivariate linear regression\", legend = :topleft, xlabel=L\"$x$\", ylabel=L\"$y$\")\n\n# how many lines to plot\nr = 50\n\ni_a = collect.(eachcol(rand(results_mv.posteriors[:a], r)))\ni_b = collect.(eachcol(rand(results_mv.posteriors[:b], r)))\n\nplt = palette(:tab10)\n\nfor k in 1:dim_mv\n    x_mv_k = x_data_mv[k]\n    y_mv_k = y_data_mv[k]\n\n    for i in 1:r\n        global p = plot!(p, x_mv_k, x_mv_k .* i_a[i][k] .+ i_b[i][k], label = nothing, alpha = 0.05, color = plt[k])\n    end\n\n    global p = scatter!(p, x_mv_k, y_mv_k, label = \"Measurement #$k\", ms = 2, color = plt[k])\nend\n\n# truncate the init step\nf = plot(results_mv.free_energy[2:end], title =\"Bethe free energy convergence\", label = nothing, xlabel = \"Iteration\", ylabel = \"Bethe free energy [nats]\") \n\nplot(p, f, size = (1000, 400))\n\n(Image: )\n\nHe needs more iterations to converge in comparison to the very first example, but that is expected since the problem became multivariate and, hence, more difficult.\n\ni_a_mv = results_mv.posteriors[:a]\n\nps_a = []\n\nfor k in 1:dim_mv\n    \n    local _p = plot(title = L\"Estimated $a_{%$k}$\", xlabel=L\"$a_{%$k}$\", ylabel=L\"$p(a_{%$k})$\", xlims = (-1.5,1.5), xticks=[-1.5, 0, 1.5], ylims=[0, Inf])\n\n    local m_a_mv_k = mean(i_a_mv)[k]\n    local v_a_mv_k = std(i_a_mv)[k, k]\n    \n    _p = plot!(_p, Normal(m_a_mv_k, v_a_mv_k), fillalpha=0.3, fillrange = 0, label=L\"$q(a_{%$k})$\", c=2,)\n    _p = vline!(_p, [ a_mv[k] ], label=L\"True $a_{%$k}$\", c = 3)\n           \n    push!(ps_a, _p)\nend\n\nplot(ps_a...)\n\n(Image: )\n\ni_b_mv = results_mv.posteriors[:b]\n\nps_b = []\n\nfor k in 1:dim_mv\n    \n    local _p = plot(title = L\"Estimated $b_{%$k}$\", xlabel=L\"$b_{%$k}$\", ylabel=L\"$p(b_{%$k})$\", xlims = (-20,20), xticks=[-20, 0, 20], ylims =[0, Inf])\n    local m_b_mv_k = mean(i_b_mv)[k]\n    local v_b_mv_k = std(i_b_mv)[k, k]\n\n    _p = plot!(_p, Normal(m_b_mv_k, v_b_mv_k), fillalpha=0.3, fillrange = 0, label=L\"$q(b_{%$k})$\", c=2,)\n    _p = vline!(_p, [ b_mv[k] ], label=L\"Real $b_{%$k}$\", c = 3)\n           \n    push!(ps_b, _p)\nend\n\nplot(ps_b...)\n\n(Image: )\n\nHe also checks the noise estimation procedure and sees that the noise variance are currently a bit underestimated. Note here that he neglects the covariance terms between the individual elements, which might result in this kind of behaviour.\n\nscatter(1:dim_mv, v_mv, ylims=(0, 100), label=L\"True $s_d$\")\nscatter!(1:dim_mv, diag(mean(results_mv.posteriors[:W])); yerror=sqrt.(diag(var(results_mv.posteriors[:W]))), label=L\"$\\mathrm{E}[s_d] \\pm \\sigma$\")\nplot!(; xlabel=L\"Dimension $d$\", ylabel=\"Variance\", title=\"Estimated variance of the noise\")\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Part-2.-Hierarchical-Bayesian-Linear-Regression","page":"Bayesian Linear Regression","title":"Part 2. Hierarchical Bayesian Linear Regression","text":"Disclaimer The tutorial below is an adaptation of the Bayesian Hierarchical Linear Regression tutorial implemented in NumPyro. \n\nThe original author in NumPyro is Carlos Souza. Updated by Chris Stoafer in NumPyro. Adapted to RxInfer by Dmitry Bagaev.\n\nProbabilistic Machine Learning models can not only make predictions about future data but also model uncertainty. In areas such as personalized medicine, there might be a large amount of data, but there is still a relatively small amount available for each patient. To customize predictions for each person, it becomes necessary to build a model for each individual ‚Äî considering its inherent uncertainties ‚Äî and then couple these models together in a hierarchy so that information can be borrowed from other similar individuals [1].\n\nThe purpose of this tutorial is to demonstrate how to implement a Bayesian Hierarchical Linear Regression model using RxInfer. To provide motivation for the tutorial, I will use the OSIC Pulmonary Fibrosis Progression competition, hosted on Kaggle.\n\n# https://www.machinelearningplus.com/linear-regression-in-julia/\n# https://nbviewer.org/github/pyro-ppl/numpyro/blob/master/notebooks/source/bayesian_hierarchical_linear_regression.ipynb","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Understanding-the-Task","page":"Bayesian Linear Regression","title":"Understanding the Task","text":"Pulmonary fibrosis is a disorder characterized by scarring of the lungs, and its cause and cure are currently unknown. In this competition, the objective was to predict the severity of decline in lung function for patients. Lung function is assessed based on the output from a spirometer, which measures the forced vital capacity (FVC), representing the volume of air exhaled.\n\nIn medical applications, it is valuable to evaluate a model's confidence in its decisions. As a result, the metric used to rank the teams was designed to reflect both the accuracy and certainty of each prediction. This metric is a modified version of the Laplace Log Likelihood (further details will be provided later).\n\nNow, let's explore the data and dig deeper into the problem involved.\n\ndataset = CSV.read(\"hbr/osic_pulmonary_fibrosis.csv\", DataFrame);\n\ndescribe(dataset)\n\n7√ó7 DataFrame\n Row ‚îÇ variable       mean     min                        median   max     \n    ‚ãØ\n     ‚îÇ Symbol         Union‚Ä¶   Any                        Union‚Ä¶   Any     \n    ‚ãØ\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ Patient                 ID00007637202177411956430           ID004266\n372 ‚ãØ\n   2 ‚îÇ Weeks          31.8618  -5                         28.0     133\n   3 ‚îÇ FVC            2690.48  827                        2641.0   6399\n   4 ‚îÇ Percent        77.6727  28.8776                    75.6769  153.145\n   5 ‚îÇ Age            67.1885  49                         68.0     88      \n    ‚ãØ\n   6 ‚îÇ Sex                     Female                              Male\n   7 ‚îÇ SmokingStatus           Currently smokes                    Never sm\noke\n                                                               3 columns om\nitted\n\nfirst(dataset, 5)\n\n5√ó7 DataFrame\n Row ‚îÇ Patient                    Weeks  FVC    Percent  Age    Sex      Sm\noki ‚ãØ\n     ‚îÇ String31                   Int64  Int64  Float64  Int64  String7  St\nrin ‚ãØ\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ ID00007637202177411956430     -4   2315  58.2536     79  Male     Ex\n-sm ‚ãØ\n   2 ‚îÇ ID00007637202177411956430      5   2214  55.7121     79  Male     Ex\n-sm\n   3 ‚îÇ ID00007637202177411956430      7   2061  51.8621     79  Male     Ex\n-sm\n   4 ‚îÇ ID00007637202177411956430      9   2144  53.9507     79  Male     Ex\n-sm\n   5 ‚îÇ ID00007637202177411956430     11   2069  52.0634     79  Male     Ex\n-sm ‚ãØ\n                                                                1 column om\nitted\n\nThe dataset provided us with a baseline chest CT scan and relevant clinical information for a group of patients. Each patient has an image taken at Week = 0, and they undergo numerous follow-up visits over approximately 1-2 years, during which their Forced Vital Capacity (FVC) is measured. For the purpose of this tutorial, we will only consider the Patient ID, the weeks, and the FVC measurements, discarding all other information. Restricting our analysis to these specific columns allowed our team to achieve a competitive score, highlighting the effectiveness of Bayesian hierarchical linear regression models, especially when dealing with uncertainty, which is a crucial aspect of the problem.\n\nSince this is real medical data, the relative timing of FVC measurements varies widely, as shown in the 3 sample patients below:\n\npatientinfo(dataset, patient_id) = filter(:Patient => ==(patient_id), dataset)\n\npatientinfo (generic function with 1 method)\n\nfunction patientchart(dataset, patient_id; line_kws = true)\n    info = patientinfo(dataset, patient_id)\n    x = info[!, \"Weeks\"]\n    y = info[!, \"FVC\"]\n\n    p = plot(tickfontsize = 10, margin = 1Plots.cm, size = (400, 400), titlefontsize = 11)\n    p = scatter!(p, x, y, title = patient_id, legend = false, xlabel = \"Weeks\", ylabel = \"FVC\")\n    \n    if line_kws\n        # Use the `GLM.jl` package to estimate linear regression\n        linearFormulae = @formula(FVC ~ Weeks)\n        linearRegressor = lm(linearFormulae, patientinfo(dataset, patient_id))\n        linearPredicted = predict(linearRegressor)\n        p = plot!(p, x, linearPredicted, color = :red, lw = 3)\n    end\n\n    return p\nend\n\npatientchart (generic function with 1 method)\n\np1 = patientchart(dataset, \"ID00007637202177411956430\")\np2 = patientchart(dataset, \"ID00009637202177434476278\")\np3 = patientchart(dataset, \"ID00010637202177584971671\")\n\nplot(p1, p2, p3, layout = @layout([ a b c ]), size = (1200, 400))\n\n(Image: )\n\nOn average, each of the 176 patients provided in the dataset had 9 visits during which their FVC was measured. These visits occurred at specific weeks within the interval [-12, 133]. The decline in lung capacity is evident, but it also varies significantly from one patient to another.\n\nOur task was to predict the FVC measurements for each patient at every possible week within the [-12, 133] interval, along with providing a confidence score for each prediction. In other words, we were required to fill a matrix, as shown below, with the predicted values and their corresponding confidence scores:\n\n(Image: )\n\nThe task was ideal for applying Bayesian inference. However, the vast majority of solutions shared within the Kaggle community utilized discriminative machine learning models, disregarding the fact that most discriminative methods struggle to provide realistic uncertainty estimates. This limitation stems from their typical training process, which aims to optimize parameters to minimize certain loss criteria (such as predictive error). As a result, these models do not inherently incorporate uncertainty into their parameters or subsequent predictions. While some methods may produce uncertainty estimates as a by-product or through post-processing steps, these are often heuristic-based and lack a statistically principled approach to estimate the target uncertainty distribution [2].","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Modelling:-Bayesian-Hierarchical-Linear-Regression-with-Partial-Pooling","page":"Bayesian Linear Regression","title":"Modelling: Bayesian Hierarchical Linear Regression with Partial Pooling","text":"In a basic linear regression, which is not hierarchical, the assumption is that all FVC decline curves share the same Œ± and Œ≤ values. This model is known as the \"pooled model.\" On the other extreme, we could assume a model where each patient has a personalized FVC decline curve, and these curves are entirely independent of one another. This model is referred to as the \"unpooled model,\" where each patient has completely separate regression lines.\n\nIn this analysis, we will adopt a middle ground approach known as \"Partial pooling.\" Specifically, we will assume that while Œ±'s and Œ≤'s are different for each patient, as in the unpooled case, these coefficients share some similarities. This partial pooling will be achieved by modeling each individual coefficient as being drawn from a common group distribution.:\n\nMathematically, the model is described by the following equations:\n\nbeginequation\n    beginaligned\n        mu_alpha sim mathcalN(mathrmmean = 00 mathrmvariance = 2500000) \n        sigma_alpha sim mathcalGamma(mathrmshape = 175 mathrmscale = 4554) \n        mu_beta sim mathcalN(mathrmmean = 00 mathrmvariance = 90) \n        sigma_beta sim mathcalGamma(mathrmshape = 175 mathrmscale = 136) \n        alpha_i sim mathcalN(mathrmmean = mu_alpha mathrmprecision = sigma_alpha) \n        beta sim mathcalN(mathrmmean = mu_beta mathrmprecision = sigma_beta) \n        sigma sim mathcalGamma(mathrmshape = 175 mathrmscale = 4554) \n        mathrmFVC_ij sim mathcalN(mathrmmean = alpha_i + t beta_i mathrmprecision = sigma)\n    endaligned\nendequation\n\nwhere t is the time in weeks. Those are very uninformative priors, but that's ok: our model will converge!\n\nImplementing this model in RxInfer is pretty straightforward:\n\n@model function partially_pooled(patient_codes, weeks, data)\n    Œº_Œ± ~ Normal(mean = 0.0, var = 250000.0) # Prior for the mean of Œ± (intercept)\n    Œº_Œ≤ ~ Normal(mean = 0.0, var = 9.0)      # Prior for the mean of Œ≤ (slope)\n    œÉ_Œ± ~ Gamma(shape = 1.75, scale = 45.54) # Prior for the precision of Œ± (intercept)\n    œÉ_Œ≤ ~ Gamma(shape = 1.75, scale = 1.36)  # Prior for the precision of Œ≤ (slope)\n\n    n_codes = length(patient_codes)            # Total number of data points\n    n_patients = length(unique(patient_codes)) # Number of unique patients in the data\n\n    local Œ± # Individual intercepts for each patient\n    local Œ≤ # Individual slopes for each patient\n\n    for i in 1:n_patients\n        Œ±[i] ~ Normal(mean = Œº_Œ±, precision = œÉ_Œ±) # Sample the intercept Œ± from a Normal distribution\n        Œ≤[i] ~ Normal(mean = Œº_Œ≤, precision = œÉ_Œ≤) # Sample the slope Œ≤ from a Normal distribution\n    end\n\n    œÉ ~ Gamma(shape = 1.75, scale = 45.54)   # Prior for the standard deviation of the error term\n    \n    local FVC_est\n\n    for i in 1:n_codes\n        FVC_est[i] ~ Œ±[patient_codes[i]] + Œ≤[patient_codes[i]] * weeks[i] # FVC estimation using patient-specific Œ± and Œ≤\n        data[i] ~ Normal(mean = FVC_est[i], precision = œÉ)                # Likelihood of the observed FVC data\n    end\nend\n\nVariational constraints are used in variational methods to restrict the set of functions or probability distributions that the method can explore during optimization. These constraints help guide the optimization process towards more meaningful and tractable solutions. We need variational constraints to ensure that the optimization converges to valid and interpretable solutions, avoiding solutions that might not be meaningful or appropriate for the given problem. By incorporating constraints, we can control the complexity and shape of the solutions, making them more useful for practical applications. We use the @constraints macro from RxInfer to define approriate variational constraints.\n\n@constraints function partially_pooled_constraints()\n    # Assume that `Œº_Œ±`, `œÉ_Œ±`, `Œº_Œ≤`, `œÉ_Œ≤` and `œÉ` are jointly independent\n    q(Œº_Œ±, œÉ_Œ±, Œº_Œ≤, œÉ_Œ≤, œÉ) = q(Œº_Œ±)q(œÉ_Œ±)q(Œº_Œ≤)q(œÉ_Œ≤)q(œÉ)\n    # Assume that `Œº_Œ±`, `œÉ_Œ±`, `Œ±` are jointly independent\n    q(Œº_Œ±, œÉ_Œ±, Œ±) = q(Œº_Œ±, Œ±)q(œÉ_Œ±)\n    # Assume that `Œº_Œ≤`, `œÉ_Œ≤`, `Œ≤` are jointly independent\n    q(Œº_Œ≤, œÉ_Œ≤, Œ≤) = q(Œº_Œ≤, Œ≤)q(œÉ_Œ≤)\n    # Assume that `FVC_est`, `œÉ` are jointly independent\n    q(FVC_est, œÉ) = q(FVC_est)q(œÉ) \nend\n\npartially_pooled_constraints (generic function with 1 method)\n\nThese @constraints assume some structural independencies in the resulting variational approximation. For simplicity we can also use constraints = MeanField() in the inference function below. That's all for modelling!","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Inference-in-the-model","page":"Bayesian Linear Regression","title":"Inference in the model","text":"A significant achievement of Probabilistic Programming Languages, like RxInfer, is the ability to separate model specification and inference. Once I define my generative model with priors, condition statements, and data likelihoods, I can delegate the challenging inference tasks to RxInfer's inference engine.\n\nCalling the inference engine only takes a few lines of code. Before proceeding, let's assign a numerical Patient ID to each patient code, a task that can be easily accomplished using label encoding.\n\npatient_ids          = dataset[!, \"Patient\"] # get the column of all patients\npatient_code_encoder = Dict(map(((id, patient), ) -> patient => id, enumerate(unique(patient_ids))));\npatient_code_column  = map(patient -> patient_code_encoder[patient], patient_ids)\n\ndataset[!, :PatientCode] = patient_code_column\n\nfirst(patient_code_encoder, 5)\n\n5-element Vector{Pair{InlineStrings.String31, Int64}}:\n \"ID00197637202246865691526\" => 85\n \"ID00388637202301028491611\" => 160\n \"ID00341637202287410878488\" => 142\n \"ID00020637202178344345685\" => 9\n \"ID00305637202281772703145\" => 127\n\nfunction partially_pooled_inference(dataset)\n\n    patient_codes = values(dataset[!, \"PatientCode\"])\n    weeks = values(dataset[!, \"Weeks\"])\n    FVC_obs = values(dataset[!, \"FVC\"]);\n\n    init = @initialization begin \n        Œº(Œ±) = vague(NormalMeanVariance)\n        Œº(Œ≤) = vague(NormalMeanVariance)\n        q(Œ±) = vague(NormalMeanVariance)\n        q(Œ≤) = vague(NormalMeanVariance)\n        q(œÉ) = vague(Gamma)\n        q(œÉ_Œ±) = vague(Gamma)\n        q(œÉ_Œ≤) = vague(Gamma)\n    end\n\n    results = infer(\n        model = partially_pooled(patient_codes = patient_codes, weeks = weeks),\n        data = (data = FVC_obs, ),\n        options = (limit_stack_depth = 500, ),\n        constraints = partially_pooled_constraints(),\n        initialization = init,\n        returnvars = KeepLast(),\n        iterations = 100\n    )\n    \nend\n\npartially_pooled_inference (generic function with 1 method)\n\nWe use a hybrid message passing approach combining exact and variational inference. In loopy models, where there are cycles or feedback loops in the graphical model, we need to initialize messages to kick-start the message passing process. Messages are passed between connected nodes in the model to exchange information and update beliefs iteratively. Initializing messages provides a starting point for the iterative process and ensures that the model converges to a meaningful solution.\n\nIn variational inference procedures, we need to initialize marginals because variational methods aim to approximate the true posterior distribution with a simpler, tractable distribution. Initializing marginals involves providing initial estimates for the parameters of this approximating distribution. These initial estimates serve as a starting point for the optimization process, allowing the algorithm to iteratively refine the approximation until it converges to a close approximation of the true posterior distribution. \n\npartially_pooled_inference_results = partially_pooled_inference(dataset)\n\nInference results:\n  Posteriors       | available for (Œ±, œÉ_Œ±, œÉ_Œ≤, œÉ, FVC_est, Œº_Œ≤, Œº_Œ±, Œ≤)","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Checking-the-model","page":"Bayesian Linear Regression","title":"Checking the model","text":"","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Inspecting-the-learned-parameters","page":"Bayesian Linear Regression","title":"Inspecting the learned parameters","text":"# Convert to `Normal` since it supports easy plotting with `StatsPlots`\nlet \n    local Œº_Œ± = Normal(mean_std(partially_pooled_inference_results.posteriors[:Œº_Œ±])...)\n    local Œº_Œ≤ = Normal(mean_std(partially_pooled_inference_results.posteriors[:Œº_Œ≤])...)\n    local Œ± = map(d -> Normal(mean_std(d)...), partially_pooled_inference_results.posteriors[:Œ±])\n    local Œ≤ = map(d -> Normal(mean_std(d)...), partially_pooled_inference_results.posteriors[:Œ≤])\n    \n    local p1 = plot(Œº_Œ±, title = \"q(Œº_Œ±)\", fill = 0, fillalpha = 0.2, label = false)\n    local p2 = plot(Œº_Œ≤, title = \"q(Œº_Œ≤)\", fill = 0, fillalpha = 0.2, label = false)\n    \n    local p3 = plot(title = \"q(Œ±)...\", legend = false)\n    local p4 = plot(title = \"q(Œ≤)...\", legend = false)\n    \n    foreach(d -> plot!(p3, d), Œ±) # Add each individual `Œ±` on plot `p3`\n    foreach(d -> plot!(p4, d), Œ≤) # Add each individual `Œ≤` on plot `p4`\n    \n    plot(p1, p2, p3, p4, size = (1200, 400), layout = @layout([ a b; c d ]))\nend\n\n(Image: )\n\nLooks like our model learned personalized alphas and betas for each patient!","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Visualizing-FVC-decline-curves-for-some-patients","page":"Bayesian Linear Regression","title":"Visualizing FVC decline curves for some patients","text":"Now, let's visually inspect the FVC decline curves predicted by our model. We will complete the FVC table by predicting all the missing values. To do this, we need to create a table to accommodate the predictions.\n\nfunction patientchart_bayesian(results, dataset, encoder, patient_id; kwargs...)\n    info            = patientinfo(dataset, patient_id)\n    patient_code_id = encoder[patient_id]\n\n    patient_Œ± = results.posteriors[:Œ±][patient_code_id]\n    patient_Œ≤ = results.posteriors[:Œ≤][patient_code_id]\n\n    estimated_œÉ = inv(mean(results.posteriors[:œÉ]))\n    \n    predict_weeks = range(-12, 134)\n\n    predicted = map(predict_weeks) do week\n        pm = mean(patient_Œ±) + mean(patient_Œ≤) * week\n        pv = var(patient_Œ±) + var(patient_Œ≤) * week ^ 2 + estimated_œÉ\n        return pm, sqrt(pv)\n    end\n    \n    p = patientchart(dataset, patient_id; kwargs...)\n    \n    return plot!(p, predict_weeks, getindex.(predicted, 1), ribbon = getindex.(predicted, 2), color = :orange)\nend\n\npatientchart_bayesian (generic function with 1 method)\n\np1 = patientchart_bayesian(partially_pooled_inference_results, dataset, patient_code_encoder, \"ID00007637202177411956430\")\np2 = patientchart_bayesian(partially_pooled_inference_results, dataset, patient_code_encoder, \"ID00009637202177434476278\")\np3 = patientchart_bayesian(partially_pooled_inference_results, dataset, patient_code_encoder, \"ID00011637202177653955184\")\n\nplot(p1, p2, p3, layout = @layout([ a b c ]), size = (1200, 400))\n\n(Image: )\n\nThe results match our expectations perfectly! Let's highlight the observations:\n\nThe model successfully learned Bayesian Linear Regressions! The orange line representing the learned predicted FVC mean closely aligns with the red line representing the deterministic linear regression. More importantly, the model effectively predicts uncertainty, demonstrated by the light orange region surrounding the mean FVC line.\nThe model predicts higher uncertainty in cases where the data points are more dispersed, such as in the 1st and 3rd patients. In contrast, when data points are closely grouped together, as seen in the 2nd patient, the model predicts higher confidence, resulting in a narrower light orange region.\nAdditionally, across all patients, we observe that the uncertainty increases as we look further into the future. The light orange region widens as the number of weeks increases, reflecting the growth of uncertainty over time.","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Computing-the-modified-Laplace-Log-Likelihood-and-RMSE","page":"Bayesian Linear Regression","title":"Computing the modified Laplace Log Likelihood and RMSE","text":"As mentioned earlier, the competition evaluated models using a modified version of the Laplace Log Likelihood, which takes into account both the accuracy and certainty of each prediction‚Äîa valuable feature in medical applications.\n\nTo compute the metric, we predicted both the FVC value and its associated confidence measure (standard deviation œÉ). The metric is given by the formula:\n\nbeginequation\n    beginaligned\n        sigma_mathrmclipped = max(sigma 70) \n        delta = min(vert mathrmFVC_mathrmtrue - mathrmFVC_mathrmpredvert 1000) \n        mathrmmetric = -fracsqrt2deltasigma_mathrmclipped - mathrmln(sqrt2sigma_mathrmclipped) \n    endaligned\nendequation\n\nTo prevent large errors from disproportionately penalizing results, errors were thresholded at 1000 ml. Additionally, confidence values were clipped at 70 ml to account for the approximate measurement uncertainty in FVC. The final score was determined by averaging the metric across all (Patient, Week) pairs. It is worth noting that metric values will be negative, and a higher score indicates better model performance.\n\nfunction FVC_predict(results)\n    return broadcast(results.posteriors[:FVC_est], Ref(results.posteriors[:œÉ])) do f, s\n        return @call_rule NormalMeanPrecision(:out, Marginalisation) (m_Œº = f, q_œÑ = s)\n    end\nend\n\nFVC_predict (generic function with 1 method)\n\nfunction compute_rmse(results, dataset)\n    FVC_predicted = FVC_predict(results)\n    return mean((dataset[!, \"FVC\"] .- mean.(FVC_predicted)) .^ 2) ^ (1/2)\nend\n\nfunction compute_laplace_log_likelihood(results, dataset)\n    FVC_predicted = FVC_predict(results)\n    sigma_c = std.(FVC_predicted)\n    sigma_c[sigma_c .< 70] .= 70\n    delta = abs.(mean.(FVC_predicted) .- dataset[!, \"FVC\"])\n    delta[delta .> 1000] .= 1000\n    return mean(-sqrt(2) .* delta ./ sigma_c .- log.(sqrt(2) .* sigma_c))\nend\n\ncompute_laplace_log_likelihood (generic function with 1 method)\n\nprintln(\"RMSE: $(compute_rmse(partially_pooled_inference_results, dataset))\")\nprintln(\"Laplace Log Likelihood: $(compute_laplace_log_likelihood(partially_pooled_inference_results, dataset))\")\n\nRMSE: 124.01306287551854\nLaplace Log Likelihood: -6.156795747473707\n\nWhat do these numbers signify? They indicate that adopting this approach would lead to outperforming the majority of public solutions in the competition. In several seconds of inference!\n\nInterestingly, most public solutions rely on a standard deterministic Neural Network and attempt to model uncertainty through a quantile loss, adhering to a frequentist approach. The importance of uncertainty in single predictions is growing in the field of machine learning, becoming a crucial requirement. Especially when the consequences of an inaccurate prediction are significant, knowing the probability distribution of individual predictions becomes essential.","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Add-layer-to-model-hierarchy:-Smoking-Status","page":"Bayesian Linear Regression","title":"Add layer to model hierarchy: Smoking Status","text":"We can enhance the model by incorporating the column \"SmokingStatus\" as a pooling level, where model parameters will be partially pooled within the groups \"Never smoked,\" \"Ex-smoker,\" and \"Currently smokes.\" To achieve this, we need to:\n\nEncode the \"SmokingStatus\" column. Map the patient encoding to the corresponding \"SmokingStatus\" encodings. Refine and retrain the model with the additional hierarchical structure.\n\ncombine(groupby(dataset, \"SmokingStatus\"), nrow)\n\n3√ó2 DataFrame\n Row ‚îÇ SmokingStatus     nrow\n     ‚îÇ String31          Int64\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ Ex-smoker          1038\n   2 ‚îÇ Never smoked        429\n   3 ‚îÇ Currently smokes     82\n\nsmoking_id_mapping   = Dict(map(((code, smoking_status), ) -> smoking_status => code, enumerate(unique(dataset[!, \"SmokingStatus\"]))))\nsmoking_code_encoder = Dict(map(unique(values(patient_ids))) do patient_id\n    smoking_status = first(unique(patientinfo(dataset, patient_id)[!, \"SmokingStatus\"]))\n    return patient_code_encoder[patient_id] => smoking_id_mapping[smoking_status]\nend)\n\nsmoking_status_patient_mapping = map(id -> smoking_code_encoder[id], 1:length(unique(patient_ids)));\n\n@model function partially_pooled_with_smoking(patient_codes, smoking_status_patient_mapping, weeks, data)\n    Œº_Œ±_global ~ Normal(mean = 0.0, var = 250000.0) # Prior for the mean of Œ± (intercept)\n    Œº_Œ≤_global ~ Normal(mean = 0.0, var = 250000.0) # Prior for the mean of Œ≤ (slope)\n    œÉ_Œ±_global ~ Gamma(shape = 1.75, scale = 45.54) # Corresponds to half-normal with scale 100.0\n    œÉ_Œ≤_global ~ Gamma(shape = 1.75, scale = 1.36)  # Corresponds to half-normal with scale 3.0\n\n    n_codes = length(patient_codes) # Total number of data points\n    n_smoking_statuses = length(unique(smoking_status_patient_mapping)) # Number of different smoking patterns\n    n_patients = length(unique(patient_codes)) # Number of unique patients in the data\n\n    local Œº_Œ±_smoking_status  # Individual intercepts for smoking pattern\n    local Œº_Œ≤_smoking_status  # Individual slopes for smoking pattern\n    \n    for i in 1:n_smoking_statuses\n        Œº_Œ±_smoking_status[i] ~ Normal(mean = Œº_Œ±_global, precision = œÉ_Œ±_global)\n        Œº_Œ≤_smoking_status[i] ~ Normal(mean = Œº_Œ≤_global, precision = œÉ_Œ≤_global)\n    end\n    \n    local Œ± # Individual intercepts for each patient\n    local Œ≤ # Individual slopes for each patient\n\n    for i in 1:n_patients\n        Œ±[i] ~ Normal(mean = Œº_Œ±_smoking_status[smoking_status_patient_mapping[i]], precision = œÉ_Œ±_global)\n        Œ≤[i] ~ Normal(mean = Œº_Œ≤_smoking_status[smoking_status_patient_mapping[i]], precision = œÉ_Œ≤_global)\n    end\n\n    œÉ ~ Gamma(shape = 1.75, scale = 45.54) # Corresponds to half-normal with scale 100.0\n\n    local FVC_est\n\n    for i in 1:n_codes\n        FVC_est[i] ~ Œ±[patient_codes[i]] + Œ≤[patient_codes[i]] * weeks[i] # FVC estimation using patient-specific Œ± and Œ≤\n        data[i] ~ Normal(mean = FVC_est[i], precision = œÉ)              # Likelihood of the observed FVC data\n    end\n    \nend\n\n@constraints function partially_pooled_with_smooking_constraints()\n    q(Œº_Œ±_global, œÉ_Œ±_global, Œº_Œ≤_global, œÉ_Œ≤_global) = q(Œº_Œ±_global)q(œÉ_Œ±_global)q(Œº_Œ≤_global)q(œÉ_Œ≤_global)\n    q(Œº_Œ±_smoking_status, Œº_Œ≤_smoking_status, œÉ_Œ±_global, œÉ_Œ≤_global) = q(Œº_Œ±_smoking_status)q(Œº_Œ≤_smoking_status)q(œÉ_Œ±_global)q(œÉ_Œ≤_global)\n    q(Œº_Œ±_global, œÉ_Œ±_global, Œº_Œ≤_global, œÉ_Œ≤_global, œÉ) = q(Œº_Œ±_global)q(œÉ_Œ±_global)q(Œº_Œ≤_global)q(œÉ_Œ≤_global)q(œÉ)\n    q(Œº_Œ±_global, œÉ_Œ±_global, Œ±) = q(Œº_Œ±_global, Œ±)q(œÉ_Œ±_global)\n    q(Œº_Œ≤_global, œÉ_Œ≤_global, Œ≤) = q(Œº_Œ≤_global, Œ≤)q(œÉ_Œ≤_global)\n    q(FVC_est, œÉ) = q(FVC_est)q(œÉ) \nend\n\npartially_pooled_with_smooking_constraints (generic function with 1 method)\n\nfunction partially_pooled_with_smoking(dataset, smoking_status_patient_mapping)\n    patient_codes = values(dataset[!, \"PatientCode\"])\n    weeks = values(dataset[!, \"Weeks\"])\n    FVC_obs = values(dataset[!, \"FVC\"]);\n\n    init = @initialization begin \n        Œº(Œ±) = vague(NormalMeanVariance)\n        Œº(Œ≤) = vague(NormalMeanVariance)\n        q(œÉ) = Gamma(1.75, 45.54)\n        q(œÉ_Œ±_global) = Gamma(1.75, 45.54)\n        q(œÉ_Œ≤_global) = Gamma(1.75, 1.36)\n    end\n    \n    return infer(\n        model = partially_pooled_with_smoking(\n            patient_codes = patient_codes, \n            smoking_status_patient_mapping = smoking_status_patient_mapping, \n            weeks = weeks\n        ),\n        data = (data = FVC_obs, ),\n        options = (limit_stack_depth = 500, ),\n        constraints = partially_pooled_with_smooking_constraints(),\n        initialization = init,\n        returnvars = KeepLast(),\n        iterations = 100,\n    )\nend\n\npartially_pooled_with_smoking (generic function with 3 methods)\n\npartially_pooled_with_smoking_inference_results = partially_pooled_with_smoking(dataset, smoking_status_patient_mapping);","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Inspect-the-learned-parameters","page":"Bayesian Linear Regression","title":"Inspect the learned parameters","text":"# Convert to `Normal` since it supports easy plotting with `StatsPlots`\nlet \n    local Œº_Œ± = Normal(mean_std(partially_pooled_with_smoking_inference_results.posteriors[:Œº_Œ±_global])...)\n    local Œº_Œ≤ = Normal(mean_std(partially_pooled_with_smoking_inference_results.posteriors[:Œº_Œ≤_global])...)\n    local Œ±smoking = map(d -> Normal(mean_std(d)...), partially_pooled_with_smoking_inference_results.posteriors[:Œº_Œ±_smoking_status])\n    local Œ≤smoking = map(d -> Normal(mean_std(d)...), partially_pooled_with_smoking_inference_results.posteriors[:Œº_Œ≤_smoking_status])\n    local Œ± = map(d -> Normal(mean_std(d)...), partially_pooled_with_smoking_inference_results.posteriors[:Œ±])\n    local Œ≤ = map(d -> Normal(mean_std(d)...), partially_pooled_with_smoking_inference_results.posteriors[:Œ≤])\n    \n    local p1 = plot(Œº_Œ±, title = \"q(Œº_Œ±_global)\", fill = 0, fillalpha = 0.2, label = false)\n    local p2 = plot(Œº_Œ≤, title = \"q(Œº_Œ≤_global)\", fill = 0, fillalpha = 0.2, label = false)\n    \n    local p3 = plot(title = \"q(Œ±)...\", legend = false)\n    local p4 = plot(title = \"q(Œ≤)...\", legend = false)\n    \n    foreach(d -> plot!(p3, d), Œ±) # Add each individual `Œ±` on plot `p3`\n    foreach(d -> plot!(p4, d), Œ≤) # Add each individual `Œ≤` on plot `p4`\n    \n    local p5 = plot(title = \"q(Œº_Œ±_smoking_status)...\", legend = false)\n    local p6 = plot(title = \"q(Œº_Œ≤_smoking_status)...\", legend = false)\n    \n    foreach(d -> plot!(p5, d, fill = 0, fillalpha = 0.2), Œ±smoking) \n    foreach(d -> plot!(p6, d, fill = 0, fillalpha = 0.2), Œ≤smoking)\n    \n    plot(p1, p2, p3, p4, p5, p6, size = (1200, 600), layout = @layout([ a b; c d; e f ]))\nend\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Interpret-smoking-status-model-parameters","page":"Bayesian Linear Regression","title":"Interpret smoking status model parameters","text":"The model parameters for each smoking status reveal intriguing findings, particularly concerning the trend, Œº_Œ≤_smoking_status. In the summary below, it is evident that the trend for current smokers has a positive mean, while the trend for ex-smokers and those who have never smoked is negative.\n\nsmoking_id_mapping\n\nDict{InlineStrings.String31, Int64} with 3 entries:\n  \"Currently smokes\" => 3\n  \"Ex-smoker\"        => 1\n  \"Never smoked\"     => 2\n\nposteriors_Œº_Œ≤_smoking_status = partially_pooled_with_smoking_inference_results.posteriors[:Œº_Œ≤_smoking_status]\n\nprintln(\"Trend for\")\nforeach(pairs(smoking_id_mapping)) do (key, id)\n    println(\"  $key: $(mean(posteriors_Œº_Œ≤_smoking_status[id]))\")\nend\n\nTrend for\n  Currently smokes: 1.8147143381168995\n  Ex-smoker: -4.572743474510769\n  Never smoked: -4.447769588035918\n\nLet's look at these curves for individual patients to help interpret these model results.\n\n# Never smoked\np1 = patientchart_bayesian(partially_pooled_with_smoking_inference_results, dataset, patient_code_encoder, \"ID00007637202177411956430\") \n# Ex-smoker\np2 = patientchart_bayesian(partially_pooled_with_smoking_inference_results, dataset, patient_code_encoder, \"ID00009637202177434476278\") \n# Currently smokes\np3 = patientchart_bayesian(partially_pooled_with_smoking_inference_results, dataset, patient_code_encoder, \"ID00011637202177653955184\") \n\nplot(p1, p2, p3, layout = @layout([ a b c ]), size = (1200, 400))\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Review-patients-that-currently-smoke","page":"Bayesian Linear Regression","title":"Review patients that currently smoke","text":"When plotting each patient with the smoking status \"Currently smokes,\" we observe different trends. Some patients show a clear positive trend, while others do not exhibit a clear trend or even have a negative trend. Compared to the unpooled trend lines, the trend lines with partial pooling are less prone to overfitting and display greater uncertainty in both slope and intercept.\n\nDepending on the purpose of the model, we can proceed in different ways:\n\nIf our goal is to gain insights into how different attributes relate to a patient's FVC over time, we can stop here and understand that current smokers might experience an increase in FVC over time when monitored for Pulmonary Fibrosis. We may then formulate hypotheses to explore the reasons behind this observation and design new experiments for further testing.\nHowever, if our aim is to develop a model for generating predictions to treat patients, it becomes crucial to ensure that the model does not overfit and can be trusted with new patients. To achieve this, we could adjust model parameters to shrink the \"Currently smokes\" group's parameters closer to the global parameters, or even consider merging the group with \"Ex-smokers.\" Additionally, collecting more data for current smokers could help in ensuring the model's robustness and preventing overfitting.\n\nlet \n    local plots = []\n\n    for (i, patient) in enumerate(unique(filter(:SmokingStatus => ==(\"Currently smokes\"), dataset)[!, \"Patient\"]))\n        push!(plots, patientchart_bayesian(partially_pooled_with_smoking_inference_results, dataset, patient_code_encoder, patient))\n    end\n\n    plot(plots..., size = (1200, 1200))\nend\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#Modified-Laplace-Log-Likelihood-and-RMSE-for-model-with-Smoking-Status-Level","page":"Bayesian Linear Regression","title":"Modified Laplace Log Likelihood and RMSE for model with Smoking Status Level","text":"We calculate the metrics for the updated model and compare to the original model.\n\nprintln(\"RMSE: $(compute_rmse(partially_pooled_with_smoking_inference_results, dataset))\")\nprintln(\"Laplace Log Likelihood: $(compute_laplace_log_likelihood(partially_pooled_with_smoking_inference_results, dataset))\")\n\nRMSE: 124.81042940540623\nLaplace Log Likelihood: -6.165660148605184\n\nBoth the Laplace Log Likelihood and RMSE indicate slightly worse performance for the smoking status model. Adding this hierarchy level as it is did not improve the model's performance significantly. However, we did discover some interesting results from the smoking status level that might warrant further investigation. Additionally, we could attempt to enhance model performance by adjusting priors or exploring different hierarchy levels, such as gender.","category":"section"},{"location":"categories/basic_examples/bayesian_linear_regression/#References","page":"Bayesian Linear Regression","title":"References","text":"[1] Ghahramani, Z. Probabilistic machine learning and artificial intelligence. Nature 521, 452‚Äì459 (2015). https://doi.org/10.1038/nature14541\n\n[2] Rainforth, Thomas William Gamlen. Automating Inference, Learning, and Design Using Probabilistic Programming. University of Oxford, 2017.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [336ed68f] CSV v0.10.16\n  [a93c6f00] DataFrames v1.8.1\n  [38e38edf] GLM v1.9.3\n  [b964fa9f] LaTeXStrings v1.4.0\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [f3b207a7] StatsPlots v0.15.8\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/problem_specific/invertible_neural_network_tutorial/","page":"Invertible Neural Network Tutorial","title":"Invertible Neural Network Tutorial","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/problem_specific/invertible_neural_network_tutorial/#Invertible-neural-networks:-a-tutorial","page":"Invertible Neural Network Tutorial","title":"Invertible neural networks: a tutorial","text":"Table of contents\n\nIntroduction\nModel specification\nModel compilation\nProbabilistic inference\nParameter estimation","category":"section"},{"location":"categories/problem_specific/invertible_neural_network_tutorial/#Introduction","page":"Invertible Neural Network Tutorial","title":"Introduction","text":"","category":"section"},{"location":"categories/problem_specific/invertible_neural_network_tutorial/#Load-required-packages","page":"Invertible Neural Network Tutorial","title":"Load required packages","text":"Before we can start, we need to import some packages:\n\nusing RxInfer\nusing Random\nusing StableRNGs\n\nusing ReactiveMP        # ReactiveMP is included in RxInfer, but we explicitly use some of its functionality\nusing LinearAlgebra     # only used for some matrix specifics\nusing Plots             # only used for visualisation\nusing Distributions     # only used for sampling from multivariate distributions\nusing Optim             # only used for parameter optimisation","category":"section"},{"location":"categories/problem_specific/invertible_neural_network_tutorial/#Model-specification","page":"Invertible Neural Network Tutorial","title":"Model specification","text":"Specifying an invertible neural network model is easy. The general recipe looks like follows: model = FlowModel(input_dim, (layer1(options), layer2(options), ...)). Here the first argument corresponds to the input dimension of the model and the second argument is a tuple of layers. An example model can be defined as \n\nmodel = FlowModel(2,\n    (\n        AdditiveCouplingLayer(PlanarFlow()),\n        AdditiveCouplingLayer(PlanarFlow(); permute=false)\n    )\n);\n\nAlternatively, the input_dim can also be passed as an InputLayer layer as \n\nmodel = FlowModel(\n    (\n        InputLayer(2),\n        AdditiveCouplingLayer(PlanarFlow()),\n        AdditiveCouplingLayer(PlanarFlow(); permute=false)\n    )\n);\n\nIn the above AdditiveCouplingLayer layers the input bfx = x_1 x_2 ldots x_N is partitioned into chunks of unit length. These partitions are additively coupled to an output bfy = y_1 y_2 ldots y_N as \n\nbeginaligned\n    y_1 = x_1 \n    y_2 = x_2 + f_1(x_1) \n    vdots \n    y_N = x_N + f_N-1(x_N-1)\nendaligned\n\nImportantly, this structure can easily be converted as \n\nbeginaligned\n    x_1 = y_1 \n    x_2 = y_2 - f_1(x_1) \n    vdots \n    x_N = y_N - f_N-1(x_N-1)\nendaligned\n\nf_n\n\nis an arbitrarily complex function, here chosen to be a PlanarFlow, but this can be interchanged for any function or neural network. The permute keyword argument (which defaults to true) specifies whether the output of this layer should be randomly permuted or shuffled. This makes sure that the first element is also transformed in consecutive layers.\n\nA permutation layer can also be added by itself as a PermutationLayer layer with a custom permutation matrix if desired.\n\nmodel = FlowModel(\n    (\n        InputLayer(2),\n        AdditiveCouplingLayer(PlanarFlow(); permute=false),\n        PermutationLayer(PermutationMatrix(2)),\n        AdditiveCouplingLayer(PlanarFlow(); permute=false)\n    )\n);","category":"section"},{"location":"categories/problem_specific/invertible_neural_network_tutorial/#Model-compilation","page":"Invertible Neural Network Tutorial","title":"Model compilation","text":"In the current models, the layers are setup to work with the passed input dimension. This means that the function f_n is repeated input_dim-1 times for each of the partitions. Furthermore the permutation layers are set up with proper permutation matrices. If we print the model we get\n\nmodel\n\nReactiveMP.FlowModel{3, Tuple{ReactiveMP.AdditiveCouplingLayerEmpty{Tuple{R\neactiveMP.PlanarFlowEmpty{1}}}, ReactiveMP.PermutationLayer{Int64}, Reactiv\neMP.AdditiveCouplingLayerEmpty{Tuple{ReactiveMP.PlanarFlowEmpty{1}}}}}(2, (\nReactiveMP.AdditiveCouplingLayerEmpty{Tuple{ReactiveMP.PlanarFlowEmpty{1}}}\n(2, (ReactiveMP.PlanarFlowEmpty{1}(),), 1), ReactiveMP.PermutationLayer{Int\n64}(2, [0 1; 1 0]), ReactiveMP.AdditiveCouplingLayerEmpty{Tuple{ReactiveMP.\nPlanarFlowEmpty{1}}}(2, (ReactiveMP.PlanarFlowEmpty{1}(),), 1)))\n\nThe text below describes the terms above. Please note the distinction in typing and elements, i.e. FlowModel{types}(elements):\n\nFlowModel - specifies that we are dealing with a flow model.\n3 - Number of layers.\nTuple{AdditiveCouplingLayerEmpty{...},PermutationLayer{Int64},AdditiveCouplingLayerEmpty{...}} - tuple of layer types.\nTuple{ReactiveMP.PlanarFlowEmpty{1},ReactiveMP.PlanarFlowEmpty{1}} - tuple of functions f_n.\nPermutationLayer{Int64}(2, [0 1; 1 0]) - permutation layer with input dimension 2 and permutation matrix [0 1; 1 0].\n\nFrom inspection we can see that the AdditiveCouplingLayerEmpty and PlanarFlowEmpty objects are different than before. They are initialized for the correct dimension, but they do not have any parameters registered to them. This is by design to allow for separating the model specification from potential optimization procedures. Before we perform inference in this model, the parameters should be initialized. We can randomly initialize the parameters as\n\ncompiled_model = compile(model)\n\nReactiveMP.CompiledFlowModel{3, Tuple{ReactiveMP.AdditiveCouplingLayer{Tupl\ne{ReactiveMP.PlanarFlow{Float64, Float64}}}, ReactiveMP.PermutationLayer{In\nt64}, ReactiveMP.AdditiveCouplingLayer{Tuple{ReactiveMP.PlanarFlow{Float64,\n Float64}}}}}(2, (ReactiveMP.AdditiveCouplingLayer{Tuple{ReactiveMP.PlanarF\nlow{Float64, Float64}}}(2, (ReactiveMP.PlanarFlow{Float64, Float64}(0.67804\n65831593375, 1.0096745605146764, 2.2552532185305205),), 1), ReactiveMP.Perm\nutationLayer{Int64}(2, [0 1; 1 0]), ReactiveMP.AdditiveCouplingLayer{Tuple{\nReactiveMP.PlanarFlow{Float64, Float64}}}(2, (ReactiveMP.PlanarFlow{Float64\n, Float64}(-0.44297044541553116, 1.1188624133846627, 0.8047371709989919),),\n 1)))\n\nNow we can see that random parameters have been assigned to the individual functions inside of our model. Alternatively if we would like to pass our own parameters, then this is also possible. You can easily find the required number of parameters using the nr_params(model) function.\n\ncompiled_model = compile(model, randn(StableRNG(321), nr_params(model)))\n\nReactiveMP.CompiledFlowModel{3, Tuple{ReactiveMP.AdditiveCouplingLayer{Tupl\ne{ReactiveMP.PlanarFlow{Float64, Float64}}}, ReactiveMP.PermutationLayer{In\nt64}, ReactiveMP.AdditiveCouplingLayer{Tuple{ReactiveMP.PlanarFlow{Float64,\n Float64}}}}}(2, (ReactiveMP.AdditiveCouplingLayer{Tuple{ReactiveMP.PlanarF\nlow{Float64, Float64}}}(2, (ReactiveMP.PlanarFlow{Float64, Float64}(0.72964\n12319250487, -0.9767336128037319, -0.4749869451771002),), 1), ReactiveMP.Pe\nrmutationLayer{Int64}(2, [0 1; 1 0]), ReactiveMP.AdditiveCouplingLayer{Tupl\ne{ReactiveMP.PlanarFlow{Float64, Float64}}}(2, (ReactiveMP.PlanarFlow{Float\n64, Float64}(0.3490911082645933, -0.8184067956921087, -1.4578214732352386),\n), 1)))","category":"section"},{"location":"categories/problem_specific/invertible_neural_network_tutorial/#Probabilistic-inference","page":"Invertible Neural Network Tutorial","title":"Probabilistic inference","text":"We can perform inference in our compiled model through standard usage of RxInfer and its underlying ReactiveMP inference engine. Let's first generate some random 2D data which has been sampled from a standard normal distribution and is consecutively passed through an invertible neural network. Using the forward(model, data) function we can propagate data in the forward direction.\n\nfunction generate_data(nr_samples::Int64, model::CompiledFlowModel; seed = 123)\n\n    rng = StableRNG(seed)\n    \n    # specify latent sampling distribution\n    dist = MvNormal([1.5, 0.5], I)\n\n    # sample from the latent distribution\n    x = rand(rng, dist, nr_samples)\n\n    # transform data\n    y = zeros(Float64, size(x))\n    for k = 1:nr_samples\n        y[:,k] .= ReactiveMP.forward(model, x[:,k])\n    end\n\n    # return data\n    return y, x\n\nend;\n\n# generate data\ny, x = generate_data(1000, compiled_model)\n\n# plot generated data\np1 = scatter(x[1,:], x[2,:], alpha=0.3, title=\"Original data\", size=(800,400))\np2 = scatter(y[1,:], y[2,:], alpha=0.3, title=\"Transformed data\", size=(800,400))\nplot(p1, p2, legend = false)\n\n(Image: )\n\nThe probabilistic model for doing inference can be described as \n\n@model function invertible_neural_network(y)\n\n    # specify prior\n    z_Œº ~ MvNormalMeanCovariance(zeros(2), huge*diagm(ones(2)))\n    z_Œõ ~ Wishart(2.0, tiny*diagm(ones(2)))\n\n    # specify observations\n    for k in eachindex(y)\n\n        # specify latent state\n        x[k] ~ MvNormalMeanPrecision(z_Œº, z_Œõ)\n\n        # specify transformed latent value\n        y_lat[k] ~ Flow(x[k])\n\n        # specify observations\n        y[k] ~ MvNormalMeanCovariance(y_lat[k], tiny*diagm(ones(2)))\n\n    end\n\nend;\n\nHere the model is passed inside a meta data object of the flow node. Inference then resorts to\n\nobservations = [y[:,k] for k=1:size(y,2)]\n\nfmodel         = invertible_neural_network()\ndata           = (y = observations, )\ninitialization = @initialization begin \n    q(z_Œº) = MvNormalMeanCovariance(zeros(2), huge*diagm(ones(2)))\n    q(z_Œõ) = Wishart(2.0, tiny*diagm(ones(2)))\nend\nreturnvars     = (z_Œº = KeepLast(), z_Œõ = KeepLast(), x = KeepLast(), y_lat = KeepLast())\n\nconstraints = @constraints begin\n    q(z_Œº, x, z_Œõ) = q(z_Œº)q(z_Œõ)q(x)\nend\n\n@meta function fmeta(model)\n    compiled_model = compile(model, randn(StableRNG(321), nr_params(model)))\n    Flow(y_lat, x) -> FlowMeta(compiled_model) # defaults to FlowMeta(compiled_model; approximation=Linearization()). \n                                               # other approximation methods can be e.g. FlowMeta(compiled_model; approximation=Unscented(input_dim))\nend\n\n# First execution is slow due to Julia's initial compilation \nresult = infer(\n    model          = fmodel, \n    data           = data,\n    constraints    = constraints,\n    meta           = fmeta(model),\n    initialization = initialization,\n    returnvars     = returnvars,\n    free_energy    = true,\n    iterations     = 10, \n    showprogress   = false\n)\n\nInference results:\n  Posteriors       | available for (z_Œº, z_Œõ, y_lat, x)\n  Free Energy:     | Real[29485.3, 23762.9, 23570.6, 23570.6, 23570.6, 2357\n0.6, 23570.6, 23570.6, 23570.6, 23570.6]\n\nfe_flow = result.free_energy\nzŒº_flow = result.posteriors[:z_Œº]\nzŒõ_flow = result.posteriors[:z_Œõ]\nx_flow  = result.posteriors[:x]\ny_flow  = result.posteriors[:y_lat];\n\nAs we can see, the variational free energy decreases inside of our model.\n\nplot(1:10, fe_flow/size(y,2), xlabel=\"iteration\", ylabel=\"normalized variational free energy [nats/sample]\", legend=false)\n\n(Image: )\n\nIf we plot a random noisy observation and its approximated transformed uncertainty we obtain:\n\n# pick a random observation\nid = rand(StableRNG(321), 1:size(y,2))\nrand_observation = MvNormal(y[:,id], 5e-1*diagm(ones(2)))\nwarped_observation = MvNormal(ReactiveMP.backward(compiled_model, y[:,id]), ReactiveMP.inv_jacobian(compiled_model, y[:,id])*5e-1*diagm(ones(2))*ReactiveMP.inv_jacobian(compiled_model, y[:,id])');\n\np1 = scatter(x[1,:], x[2,:], alpha=0.1, title=\"Latent distribution\", size=(1200,500), label=\"generated data\")\ncontour!(-5:0.1:5, -5:0.1:5, (x, y) -> pdf(MvNormal([1.5, 0.5], I), [x, y]), c=:viridis, colorbar=false, linewidth=2)\nscatter!([mean(zŒº_flow)[1]], [mean(zŒº_flow)[2]], color=\"red\", markershape=:x, markersize=5, label=\"inferred mean\")\ncontour!(-5:0.01:5, -5:0.01:5, (x, y) -> pdf(warped_observation, [x, y]), colors=\"red\", levels=1, linewidth=2, colorbar=false)\nscatter!([mean(warped_observation)[1]], [mean(warped_observation)[2]], color=\"red\", label=\"transformed noisy observation\")\np2 = scatter(y[1,:], y[2,:], alpha=0.1, label=\"generated data\")\nscatter!([ReactiveMP.forward(compiled_model, mean(zŒº_flow))[1]], [ReactiveMP.forward(compiled_model, mean(zŒº_flow))[2]], color=\"red\", marker=:x, label=\"inferred mean\")\ncontour!(-10:0.1:10, -10:0.1:10, (x, y) -> pdf(MvNormal([1.5, 0.5], I), ReactiveMP.backward(compiled_model, [x, y])), c=:viridis, colorbar=false, linewidth=2)\ncontour!(-10:0.1:10, -10:0.1:10, (x, y) -> pdf(rand_observation, [x, y]), colors=\"red\", levels=1, linewidth=2, label=\"random noisy observation\", colorba=false)\nscatter!([mean(rand_observation)[1]], [mean(rand_observation)[2]], color=\"red\", label=\"random noisy observation\")\nplot(p1, p2, legend = true)\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/invertible_neural_network_tutorial/#Parameter-estimation","page":"Invertible Neural Network Tutorial","title":"Parameter estimation","text":"The flow model is often used to learn unknown probabilistic mappings. Here we will demonstrate it as follows for a binary classification task with the following data:\n\nfunction generate_data(nr_samples::Int64; seed = 123)\n    \n    rng = StableRNG(seed)\n\n    # sample weights\n    w = rand(rng, nr_samples, 2)\n\n    # sample appraisal\n    y = zeros(Float64, nr_samples)\n    for k = 1:nr_samples\n        y[k] = 1.0*(w[k,1] > 0.5)*(w[k,2] < 0.5)\n    end\n\n    # return data\n    return y, w\n\nend;\n\ndata_y, data_x = generate_data(50);\nscatter(data_x[:,1], data_x[:,2], marker_z=data_y, xlabel=\"w1\", ylabel=\"w2\", colorbar=false, legend=false)\n\n(Image: )\n\nWe will then specify a possible model as\n\n# specify flow model\nmodel = FlowModel(2,\n    (\n        AdditiveCouplingLayer(PlanarFlow()), # defaults to AdditiveCouplingLayer(PlanarFlow(); permute=true)\n        AdditiveCouplingLayer(PlanarFlow()),\n        AdditiveCouplingLayer(PlanarFlow()),\n        AdditiveCouplingLayer(PlanarFlow(); permute=false)\n    )\n);\n\nThe corresponding probabilistic model for the binary classification task can be created as\n\n@model function invertible_neural_network_classifier(x, y)\n\n    # specify observations\n    for k in eachindex(x)\n\n        # specify latent state\n        x_lat[k] ~ MvNormalMeanPrecision(x[k], 1e3*diagm(ones(2)))\n\n        # specify transformed latent value\n        y_lat1[k] ~ Flow(x_lat[k])\n        y_lat2[k] ~ dot(y_lat1[k], [1, 1])\n\n        # specify observations\n        y[k] ~ Probit(y_lat2[k]) # default: where { pipeline = RequireMessage(in = NormalMeanPrecision(0, 1.0)) }\n\n    end\n\nend;\n\nfcmodel       = invertible_neural_network_classifier()\ndata          = (y = data_y, x = [data_x[k,:] for k=1:size(data_x,1)], )\n\n@meta function fmeta(model, params)\n    compiled_model = compile(model, params)\n    Flow(y_lat1, x_lat) -> FlowMeta(compiled_model)\nend\n\nfmeta (generic function with 2 methods)\n\nHere we see that the compilation occurs inside of our probabilistic model. As a result we can pass parameters (and a model) to this function which we wish to opmize for some criterium, such as the variational free energy. Inference can be described as\n\nFor the optimization procedure, we will simplify our inference loop, such that it only accepts parameters as an argument (which is wishes to optimize) and outputs a performance metric.\n\nfunction f(params)\n    Random.seed!(123) # Flow uses random permutation matrices, which is not good for the optimisation procedure\n    result = infer(\n        model                   = fcmodel, \n        data                    = data,\n        meta                    = fmeta(model, params),\n        free_energy             = true,\n        free_energy_diagnostics = nothing, # Free Energy can be set to NaN due to optimization procedure\n        iterations              = 10, \n        showprogress            = false\n    );\n    \n    result.free_energy[end]\nend;\n\nOptimization can be performed using the Optim package. Alternatively, other (custom) optimizers can be implemented, such as:\n\nres = optimize(f, randn(StableRNG(42), nr_params(model)), GradientDescent(), Optim.Options(store_trace = true, show_trace = true, show_every = 50), autodiff=:forward)\n\nuses finitediff and is slower/less accurate.\n\nor\n\n# create gradient function\ng = (x) -> ForwardDiff.gradient(f, x);\n\n# specify initial params\nparams = randn(nr_params(model))\n\n# create custom optimizer (here Adam)\noptimizer = Adam(params; Œª=1e-1)\n\n# allocate space for gradient\n‚àá = zeros(nr_params(model))\n\n# perform optimization\nfor it = 1:10000\n\n    # backward pass\n    ‚àá .= ForwardDiff.gradient(f, optimizer.x)\n\n    # gradient update\n    ReactiveMP.update!(optimizer, ‚àá)\n\nend\n\n\nres = optimize(f, randn(StableRNG(42), nr_params(model)), GradientDescent(), Optim.Options(f_tol = 1e-3, store_trace = true, show_trace = true, show_every = 100), autodiff=:forward)\n\nIter     Function value   Gradient norm \n     0     5.927695e+02     8.826085e+02\n * time: 0.04076194763183594\n * Status: success\n\n * Candidate solution\n    Final objective value:     5.579987e+01\n\n * Found with\n    Algorithm:     Gradient Descent\n\n * Convergence measures\n    |x - x'|               = 0.00e+00 ‚â§ 0.0e+00\n    |x - x'|/|x'|          = 0.00e+00 ‚â§ 0.0e+00\n    |f(x) - f(x')|         = 0.00e+00 ‚â§ 0.0e+00\n    |f(x) - f(x')|/|f(x')| = 0.00e+00 ‚â§ 1.0e-03\n    |g(x)|                 = 2.22e+01 ‚â∞ 1.0e-08\n\n * Work counters\n    Seconds run:   17  (vs limit Inf)\n    Iterations:    5\n    f(x) calls:    211\n    ‚àáf(x) calls:   211\n\noptimization results are then given as\n\nparams = Optim.minimizer(res)\ninferred_model = compile(model, params)\ntrans_data_x_1 = hcat(map((x) -> ReactiveMP.forward(inferred_model, x), [data_x[k,:] for k=1:size(data_x,1)])...)'\ntrans_data_x_2 = map((x) -> dot([1, 1], x), [trans_data_x_1[k,:] for k=1:size(data_x,1)])\ntrans_data_x_2_split = [trans_data_x_2[data_y .== 1.0], trans_data_x_2[data_y .== 0.0]]\np1 = scatter(data_x[:,1], data_x[:,2], marker_z = data_y, size=(1200,400), c=:viridis, colorbar=false, title=\"original data\")\np2 = scatter(trans_data_x_1[:,1], trans_data_x_1[:,2], marker_z = data_y, c=:viridis, size=(1200,400), colorbar=false, title=\"|> warp\")\np3 = histogram(trans_data_x_2_split; stacked=true, bins=50, size=(1200,400), title=\"|> dot\")\nplot(p1, p2, p3, layout=(1,3), legend=false)\n\n(Image: )\n\nusing StatsFuns: normcdf\np1 = scatter(data_x[:,1], data_x[:,2], marker_z = data_y, title=\"original labels\", xlabel=\"weight 1\", ylabel=\"weight 2\", size=(1200,400), c=:viridis)\np2 = scatter(data_x[:,1], data_x[:,2], marker_z = normcdf.(trans_data_x_2), title=\"predicted labels\", xlabel=\"weight 1\", ylabel=\"weight 2\", size=(1200,400), c=:viridis)\np3 = contour(0:0.01:1, 0:0.01:1, (x, y) -> normcdf(dot([1,1], ReactiveMP.forward(inferred_model, [x,y]))), title=\"Classification map\", xlabel=\"weight 1\", ylabel=\"weight 2\", size=(1200,400), c=:viridis)\nplot(p1, p2, p3, layout=(1,3), legend=false)\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [31c24e10] Distributions v0.25.123\n‚åÖ [429524aa] Optim v1.13.3\n  [91a5bcdd] Plots v1.41.6\n  [a194aa59] ReactiveMP v5.6.5\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [4c63d2b9] StatsFuns v1.5.2\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\nInfo Packages marked with ‚åÖ have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated`\n\n\n","category":"section"},{"location":"categories/problem_specific/simple_nonlinear_node/","page":"Simple Nonlinear Node","title":"Simple Nonlinear Node","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/problem_specific/simple_nonlinear_node/#Simple-Nonlinear-Node","page":"Simple Nonlinear Node","title":"Simple Nonlinear Node","text":"using RxInfer, Random, StableRNGs\n\nHere is an example of creating custom node with nonlinear function approximation with samplelist.","category":"section"},{"location":"categories/problem_specific/simple_nonlinear_node/#Custom-node-creation","page":"Simple Nonlinear Node","title":"Custom node creation","text":"struct NonlinearNode end # Dummy structure just to make Julia happy\n\nstruct NonlinearMeta{R, F}\n    rng      :: R\n    fn       :: F   # Nonlinear function, we assume 1 float input - 1 float output\n    nsamples :: Int # Number of samples used in approximation\nend\n\n@node NonlinearNode Deterministic [ out, in ]\n\nWe need to define two Sum-product message computation rules for our new custom node\n\nRule for outbound message on out edge given inbound message on in edge\nRule for outbound message on in edge given inbound message on out edge\nBoth rules accept optional meta object\n\n# Rule for outbound message on `out` edge given inbound message on `in` edge\n@rule NonlinearNode(:out, Marginalisation) (m_in::NormalMeanVariance, meta::NonlinearMeta) = begin \n    samples = rand(meta.rng, m_in, meta.nsamples)\n    return SampleList(map(meta.fn, samples))\nend\n\n# Rule for outbound message on `in` edge given inbound message on `out` edge\n@rule NonlinearNode(:in, Marginalisation) (m_out::Gamma, meta::NonlinearMeta) = begin     \n    return ContinuousUnivariateLogPdf((x) -> logpdf(m_out, meta.fn(x)))\nend","category":"section"},{"location":"categories/problem_specific/simple_nonlinear_node/#Model-specification","page":"Simple Nonlinear Node","title":"Model specification","text":"After we have defined our custom node with custom rules we may proceed with a model specification:\n\nbeginaligned\np(theta) = mathcalN(thetamu_theta sigma_theta)\np(m) = mathcalN(thetamu_m sigma_m)\np(w) = f(theta)\np(y_im w) = mathcalN(y_im w)\nendaligned\n\nGiven this IID model, we aim to estimate the precision of a Gaussian distribution. We pass a random variable theta through a non-linear transformation f to make it positive and suitable for a precision parameter of a Gaussian distribution. We, later on, will estimate the posterior of theta. \n\n@model function nonlinear_estimation(y, Œ∏_Œº, m_Œº, Œ∏_œÉ, m_œÉ)\n    \n    # define a distribution for the two variables\n    Œ∏ ~ Normal(mean = Œ∏_Œº, variance = Œ∏_œÉ)\n    m ~ Normal(mean = m_Œº, variance = m_œÉ)\n\n    # define a nonlinear node\n    w ~ NonlinearNode(Œ∏)\n\n    # We consider the outcome to be normally distributed\n    for i in eachindex(y)\n        y[i] ~ Normal(mean = m, precision = w)\n    end\n    \nend\n\n@constraints function nconstsraints(nsamples)\n    q(Œ∏) :: SampleListFormConstraint(nsamples, LeftProposal())\n    q(w) :: SampleListFormConstraint(nsamples, RightProposal())\n    \n    q(Œ∏, w, m) = q(Œ∏)q(m)q(w)\nend\n\nnconstsraints (generic function with 1 method)\n\n@meta function nmeta(fn, nsamples)\n    NonlinearNode(Œ∏, w) -> NonlinearMeta(StableRNG(123), fn, nsamples)\nend\n\nnmeta (generic function with 1 method)\n\n@initialization function ninit()\n    q(m) = vague(NormalMeanPrecision)\n    q(w) = vague(Gamma)\nend\n\nninit (generic function with 1 method)\n\nHere we generate some data\n\nnonlinear_fn(x) = abs(exp(x) * sin(x))\n\nnonlinear_fn (generic function with 1 method)\n\nseed = 123\nrng  = StableRNG(seed)\n\nniters   = 15 # Number of VMP iterations\nnsamples = 5_000 # Number of samples in approximation\n\nn = 500 # Number of IID samples\nŒº = -10.0\nŒ∏ = -1.0\nw = nonlinear_fn(Œ∏)\n\ndata = rand(rng, NormalMeanPrecision(Œº, w), n);\n\nnow that synthetic data/constriants/model is defined, lets infer:\n\nresult = infer(\n    model = nonlinear_estimation(Œ∏_Œº = 0.0, m_Œº = 0.0, Œ∏_œÉ=100.0, m_œÉ=1.0),\n    meta =  nmeta(nonlinear_fn, nsamples),\n    constraints = nconstsraints(nsamples),\n    data = (y = data, ), \n    initialization = ninit(),\n    returnvars = (Œ∏ = KeepLast(), ),\n    iterations = niters,  \n    showprogress = true\n)\n\nInference results:\n  Posteriors       | available for (Œ∏)\n\nwe can check the posterior now\n\nŒ∏posterior = result.posteriors[:Œ∏]\n\nSampleList(Univariate, 5000)\n\nLet's us visualise the results\n\nusing Plots, StatsPlots\n\nestimated = Normal(mean_std(Œ∏posterior)...)\n\nplot(estimated, title=\"Posterior for Œ∏\", label = \"Estimated\", legend = :bottomright, fill = true, fillopacity = 0.2, xlim = (-3, 3), ylim = (0, 2))\nvline!([ Œ∏ ], label = \"Real value of Œ∏\")\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [f3b207a7] StatsPlots v0.15.8\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/advanced_examples/learning_dynamics_with_vaes/","page":"Learning Dynamics With Vaes","title":"Learning Dynamics With Vaes","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/learning_dynamics_with_vaes/#Learning-Dynamics-with-VAEs","page":"Learning Dynamics With Vaes","title":"Learning Dynamics with VAEs","text":"Bayesian inference often struggles in high-dimensional spaces (not with RxInfer.jl, it actually happens rarely) - a challenge known as the \"curse of dimensionality.\" \n\nThe curse of dimensionality refers to various phenomena that arise when analyzing data in high-dimensional spaces that do not occur in low-dimensional settings. In Bayesian inference context, the curse of dimensionality refers to the exponential increase in computational difficulty and statistical challenges as the number of parameters (dimensions) in a model increases.\n\nThere are several approaches to tackle this problem, among them:\n\nHierarchical models - Breaking down complex problems into nested, simpler components\n\"Compromise\" approaches - Being \"partially Bayesian\" by combining Bayesian and non-fully Bayesian methods\n\nIn this notebook, we explore the compromise approach. We'll use a Variational Autoencoder (VAE) to learn a low-dimensional latent representation of MNIST digits, and then perform Bayesian inference on the dynamics of rotating digits in this latent space.\n\nVariational Autoencoder (VAE): A type of neural network architecture that learns to encode data into a compressed latent representation and then decode it back to the original form. Unlike traditional autoencoders, VAEs encode data as probability distributions rather than fixed points, making them generative models capable of creating new data samples.Latent representation: A compressed, lower-dimensional encoding of data that captures its essential features. Think of it as finding the most important aspects of complex data while discarding noise and redundancy.MNIST digits: A standard dataset in machine learning consisting of 28√ó28 pixel grayscale images of handwritten digits (0-9), commonly used for training image processing systems.\n\nNote: This is a simple example with simplified data that serves as a template for more interesting applications.Throughout this demonstration we will use CPU for computation; however, the model is fully GPU compatible. See AutoEncoderToolkit.jl for more details.\n\nThis demonstrates how we can leverage the strengths of both worlds:\n\nVAEs for efficient dimensionality reduction (non-fully Bayesian)\nBayesian inference for modeling dynamics in the reduced space\n\nDimensionality reduction: The process of reducing the number of variables under consideration by obtaining a set of principal variables that still preserves the essential information in the data.\n\nDynamics: In this context, refers to how the latent representations change over time or with certain transformations (like rotation of digits).\n\nimport AutoEncoderToolkit\nimport Flux\nusing MLDatasets: MNIST\nimport JLD2\nusing Plots\nusing Statistics\nusing RxInfer, ReactiveMP, LinearAlgebra","category":"section"},{"location":"categories/advanced_examples/learning_dynamics_with_vaes/#Part-1:-Creating-a-Dataset-of-Rotating-Digits","page":"Learning Dynamics With Vaes","title":"Part 1: Creating a Dataset of Rotating Digits","text":"First, we need data to work with. Instead of using static MNIST digits, we'll create a dataset of rotating digits. This will give us a clear transformation to model in the latent space.\n\nWe'll select a few examples of digits 0 and 1, then generate multiple rotated versions of each. This will create a dataset where we know exactly how the images are related to each other through the rotation transformation.\n\n\"\"\"\n    generate_rotated_sequence(image, n_frames=36, max_angle=360)\n\nGenerate a sequence of rotated versions of an input image.\nReturns the sequence of rotated images.\n\"\"\"\nfunction generate_rotated_sequence(image, n_frames=36, max_angle=360)\n    img_2d = image[:, :, 1, 1]\n    \n    # Get image dimensions\n    height, width = size(img_2d)\n    \n    # Create array to store rotated images\n    rotated_images = []\n    \n    for i in 1:n_frames\n        # Calculate rotation angle for this frame\n        angle = (i-1) * max_angle / n_frames\n        \n        # Create rotation matrix\n        rotation = [cosd(angle) -sind(angle); sind(angle) cosd(angle)]\n        \n        # Create empty image for the rotated result\n        rotated = zeros(Float32, height, width)\n        \n        # Center of the image\n        center_y, center_x = (height+1)/2, (width+1)/2\n        \n        # Apply rotation to each pixel\n        for y in 1:height, x in 1:width\n            # Convert to coordinates relative to center\n            y_centered = y - center_y\n            x_centered = x - center_x\n            \n            # Apply rotation\n            new_coords = rotation * [x_centered, y_centered]\n            \n            # Convert back to image coordinates\n            new_x = round(Int, new_coords[1] + center_x)\n            new_y = round(Int, new_coords[2] + center_y)\n            \n            # Check if the new coordinates are within bounds\n            if 1 <= new_x <= width && 1 <= new_y <= height\n                rotated[y, x] = img_2d[new_y, new_x]\n            end\n        end\n        \n        # Store the rotated image\n        push!(rotated_images, rotated)\n    end\n    \n    return rotated_images\nend\n\nMain.var\"##WeaveSandBox#277\".generate_rotated_sequence\n\nIn order to download datasets without having to manually confirm the download, we can set to true the DATADEPS_ALWAYS_ACCEPT environmental variable. Read more about MLDatasets.jl here.\n\nENV[\"DATADEPS_ALWAYS_ACCEPT\"] = true\n\ntrue\n\n\"\"\"\n    create_rotated_mnist_dataset(n_samples_per_digit=10, n_rotations=36)\n\nCreate a dataset of rotated MNIST digits (0s and 1s).\nReturns the dataset and labels.\n\"\"\"\nfunction create_rotated_mnist_dataset(n_samples_per_digit=10, n_rotations=36)\n    # Load MNIST data\n    train_dataset = MNIST(split=:train)\n    \n    # Find indices of 0s and 1s\n    indices_0 = findall(x -> x == 0, train_dataset.targets)\n    indices_1 = findall(x -> x == 1, train_dataset.targets)\n    \n    # Select a subset of each digit\n    selected_indices_0 = indices_0[1:n_samples_per_digit]\n    selected_indices_1 = indices_1[1:n_samples_per_digit]\n    \n    # Combine indices\n    selected_indices = vcat(selected_indices_0, selected_indices_1)\n    \n    # Create arrays to store rotated images and labels\n    rotated_images = []\n    rotated_labels = []\n    \n    # For each selected digit\n    for (i, idx) in enumerate(selected_indices)\n        # Get the original image\n        original = Float32.(reshape(train_dataset.features[:, :, idx], 28, 28))\n        \n        # Get the label\n        label = train_dataset.targets[idx]\n        \n        # Generate rotated versions\n        rotations = generate_rotated_sequence(original, n_rotations)\n        \n        # Add to dataset\n        for rotated in rotations\n            push!(rotated_images, rotated)\n            push!(rotated_labels, label)\n        end\n    end\n    \n    # Convert to arrays\n    X = zeros(Float32, 28, 28, 1, length(rotated_images))\n    for i in 1:length(rotated_images)\n        X[:, :, 1, i] = rotated_images[i]\n    end\n    \n    y = rotated_labels\n    \n    # we will use a binarized version of the MNIST datase\n    threshold = 0.5 * maximum(X)\n    X = Float32.(X .> threshold)\n    \n    return X, y\nend\n\nMain.var\"##WeaveSandBox#277\".create_rotated_mnist_dataset\n\n# Create rotated MNIST dataset\nprintln(\"Creating rotated MNIST dataset...\")\nn_samples_per_digit = 10  # Number of original digits to use\nn_rotations = 36  # Number of rotations per digit\n\nrotated_train_data, rotated_train_labels = create_rotated_mnist_dataset(n_samples_per_digit, n_rotations)\nprintln(\"Rotated dataset created with $(size(rotated_train_data, 4)) images\")\n\n# Create an animation of sample rotated digits\nsample_indices = rand(1:n_samples_per_digit*2, 5)  # 5 random digits from our dataset\nsample_animation = @animate for angle_idx in 1:n_rotations\n    # Create a plot with 5 random digits at the same rotation angle\n    p = plot(layout=(1, 5), size=(1000, 200))\n    for (i, digit_idx) in enumerate(sample_indices)\n        # Calculate the index in the full dataset\n        idx = (digit_idx-1) * n_rotations + angle_idx\n        # Use binary colors (white background, black digits)\n        heatmap!(p, rotated_train_data[:, :, 1, idx], \n                color=[:black, :white], \n                colorbar=false,\n                title=\"Digit: $(rotated_train_labels[idx])\", \n                subplot=i, axis=false)\n    end\n    plot!(p, title=\"Rotation: $(round((angle_idx-1)*360/n_rotations, digits=1))¬∞\")\nend\n\n# Save as GIF with 10 frames per second\ngif(sample_animation, \"rotated_digits_samples.gif\", fps=10, show_msg=false);\n\nCreating rotated MNIST dataset...\nRotated dataset created with 720 images\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/learning_dynamics_with_vaes/#Part-2:-Building-the-VAE-Model","page":"Learning Dynamics With Vaes","title":"Part 2: Building the VAE Model","text":"Now we'll define our Variational Autoencoder. The VAE will learn to compress the high-dimensional image data (28√ó28 = 784 dimensions) into a much lower-dimensional latent space (just 2 dimensions in this example).\n\nVariational Autoencoder (VAE) architecture: A VAE consists of two main components:An encoder network that compresses input data into a probability distribution in latent space\nA decoder network that reconstructs the original data from samples in the latent spaceUnlike traditional autoencoders, VAEs don't encode to exact points but to probability distributions, making them generative models.Latent space regularization: VAEs use a special loss function that includes both reconstruction error and a regularization term (KL divergence) that encourages the latent space to be well-structured and continuous, making it suitable for interpolation and generation.\n\nThis is the \"non-Bayesian\" part of our approach - we're using a neural network for dimensionality reduction rather than a fully Bayesian model, which can be computationally intractable for high-dimensional image data.\n\nComputational intractability: A fully Bayesian approach would require modeling the joint probability distribution of all 784 pixels, which would involve an enormous number of parameters and complex dependencies. This becomes computationally prohibitive as the dimensionality increases - a manifestation of the \"curse of dimensionality\" mentioned earlier.\n\ngraph LR\n    A[Input 784d] --> B\n    subgraph Encoder\n    B[Neural Network]\n    end\n    B --> C[Latent Space 2d]\n    C --> D\n    subgraph Decoder\n    D[Neural Network]\n    end\n    D --> E[Output 784d]\n\n\"\"\"\n    create_vae(n_latent=2, n_channels_init=32)\n\nCreate a VAE model with convolutional encoder and decoder.\nReturns the VAE model with a 2D latent space by default.\n\"\"\"\nfunction create_vae(n_latent=2, n_channels_init=32)\n    # Define convolutional layers for encoder\n    conv_layers = Flux.Chain(\n        Flux.Conv((4, 4), 1 => n_channels_init, Flux.relu; stride=2, pad=1),\n        Flux.Conv((4, 4), n_channels_init => n_channels_init * 2, Flux.relu; stride=2, pad=1),\n        AutoEncoderToolkit.Flatten(),\n        Flux.Dense(n_channels_init * 2 * 7 * 7 => 256, Flux.relu),\n        Flux.Dense(256 => 256, Flux.relu),\n    )\n\n    # Define layers for Œº and log(œÉ)\n    Œº_layer = Flux.Dense(256, n_latent, Flux.identity)\n    logœÉ_layer = Flux.Dense(256, n_latent, Flux.identity, bias=fill(-1.0f0, n_latent))\n\n    # Build encoder\n    encoder = AutoEncoderToolkit.JointGaussianLogEncoder(conv_layers, Œº_layer, logœÉ_layer)\n\n    # Define deconvolutional layers for decoder\n    deconv_layers = Flux.Chain(\n        Flux.Dense(n_latent => 256, Flux.identity),\n        Flux.Dense(256 => 256, Flux.relu),\n        Flux.Dense(256 => n_channels_init * 2 * 7 * 7, Flux.relu),\n        AutoEncoderToolkit.Reshape(7, 7, n_channels_init * 2, :),\n        Flux.ConvTranspose((4, 4), n_channels_init * 2 => n_channels_init, Flux.relu; stride=2, pad=1),\n        Flux.ConvTranspose((4, 4), n_channels_init => 1, x -> Flux.sigmoid_fast(x * 5.0); stride=2, pad=1),\n    )\n\n    # Define decoder - use BernoulliDecoder for binarized data\n    decoder = AutoEncoderToolkit.BernoulliDecoder(deconv_layers)\n\n    # Define VAE model\n    vae = encoder * decoder |> Flux.cpu\n    \n    return vae\nend;","category":"section"},{"location":"categories/advanced_examples/learning_dynamics_with_vaes/#Part-3:-Training-the-VAE","page":"Learning Dynamics With Vaes","title":"Part 3: Training the VAE","text":"Now we'll train the VAE on our rotated digit dataset. The VAE learns to:\n\nEncode images into a 2D latent space (encoder)\nDecode points from the latent space back to images (decoder)\n\nThe training process and function implementation used here are adapted from the AutoEncoderToolkit.jl documentation, which provides comprehensive examples for implementing various autoencoder architectures in Julia.\n\n\"\"\"\n    train_vae(vae, train_data; n_epoch=50, batch_size=64, learning_rate=1e-3)\n\nTrain a VAE model on the provided data.\nReturns the trained model and training metrics.\n\"\"\"\nfunction train_vae(vae, train_data; n_epoch=50, batch_size=64, learning_rate=1e-3)\n    # Create data loader\n    train_loader = Flux.DataLoader(train_data, batchsize=batch_size, shuffle=true)\n    \n    # Setup optimizer\n    opt_vae = Flux.Train.setup(Flux.Optimisers.Adam(learning_rate), vae)\n    \n    # Initialize arrays to save metrics\n    train_losses = Array{Float32}(undef, n_epoch)\n    \n    # Loop through epochs\n    for epoch in 1:n_epoch\n        batch_losses = Float32[]\n        \n        # Calculate Œ≤ value with annealing scheme\n        Œ≤_value = epoch <= 15 ? 0.1f0 + (epoch - 1) / 15 * 0.9f0 : 1.0f0\n        \n        # Loop through batches\n        for (i, x) in enumerate(train_loader)\n            # Train VAE with current Œ≤ value (doesn't return a value)\n            AutoEncoderToolkit.VAEs.train!(vae, x, opt_vae; loss_kwargs=(Œ≤=Œ≤_value,))\n            \n            # Calculate loss separately\n            batch_loss = AutoEncoderToolkit.VAEs.loss(vae, x; Œ≤=Œ≤_value)\n            push!(batch_losses, batch_loss)\n            \n            # Print progress for every 10 batches\n            if i % 10 == 0\n                println(\"Epoch: $epoch/$n_epoch | Batch: $i/$(length(train_loader)) | Loss: $(round(mean(batch_losses), digits=4))\")\n            end\n        end\n        \n        # Record average loss for epoch\n        train_losses[epoch] = mean(batch_losses)\n        \n        # Print epoch summary\n        println(\"Epoch $epoch/$n_epoch completed | Avg Loss: $(round(train_losses[epoch], digits=4))\")\n    end\n    \n    return vae, train_losses\nend\n\nMain.var\"##WeaveSandBox#277\".train_vae\n\n# # Create and train the VAE model on the rotated dataset\n# # We will skip the training step within the notebook and will load the pre-trained model instead, feel free to uncomment the following lines to train the model yourself.\n# println(\"Creating VAE model...\")\n# vae = create_vae()\n\n# println(\"Training VAE on rotated MNIST dataset...\")\n# vae, losses = train_vae(vae, rotated_train_data, n_epoch=100)\n\n# # Save the trained model parameters\n# model_params = Dict()\n# for (i, p) in enumerate(Flux.params(vae))\n#     model_params[\"param_$i\"] = Flux.cpu(p)  # Move to CPU before saving\n# end\n\n# # Save the parameters dictionary\n# JLD2.save(\"rotated_mnist_vae_params.jld2\", model_params)\n# println(\"Model parameters saved to: rotated_mnist_vae_params.jld2\")\n\n# # Plot training loss\n# loss_plot = plot(losses, title=\"VAE Training Loss (Rotated MNIST)\", xlabel=\"Epoch\", ylabel=\"Loss\", \n#                  legend=false, linewidth=2, color=:blue)\n\n# Create an empty VAE with the same architecture as the one you saved\nfunction load_vae(filepath; n_latent=2, n_channels_init=32)\n    # Create a new VAE with the same architecture\n    vae = create_vae(n_latent, n_channels_init)\n    \n    # Load the saved parameters\n    model_params = JLD2.load(filepath)\n    \n    # Get the parameters of the current model\n    ps = Flux.params(vae)\n    \n    # Replace the parameters with the loaded ones\n    for (i, p) in enumerate(ps)\n        param_key = \"param_$i\"\n        if haskey(model_params, param_key)\n            # Copy values from saved parameters to the model\n            copyto!(p, model_params[param_key])\n        else\n            @warn \"Parameter $param_key not found in saved model\"\n        end\n    end\n    \n    return vae\nend\n\nvae = load_vae(\"rotated_mnist_vae_params.jld2\");\n\n# Display original and reconstructed images\nimg = rotated_train_data[:, :, :, 42]\np1 = heatmap(img[:, :, 1, 1] |> Flux.cpu, color=[:black, :white], colorbar=false, title=\"Original Image\")\n# Reshape to add channel dimension (H√óW ‚Üí H√óW√óC) for network input\nencoded_img = vae.encoder(reshape(img, size(img)..., 1))\n# p represents pixel-wise probabilities (Bernoulli parameters) since we're using binarized images\ndecoded_img = vae.decoder(encoded_img.Œº)\np2 = heatmap(decoded_img.p[:, :, 1, 1], color=:grays, title=\"Reconstructed Image\")\ndisplay(plot(p1, p2, layout=(1, 2), size=(800, 400)))\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/learning_dynamics_with_vaes/#Part-4:-Integrating-VAE-with-RxInfer-for-Bayesian-Inference","page":"Learning Dynamics With Vaes","title":"Part 4: Integrating VAE with RxInfer for Bayesian Inference","text":"Now we'll explore the Bayesian component of our approach. Using RxInfer, we'll perform probabilistic inference on the latent space dynamics of rotating digits, enabling us to simultaneously model the underlying rotation process and generate predictions of future images.\n\nFirst, we need to create a custom node that connects our VAE to the RxInfer framework. This is really simple, we just need to define a node and a couple of rules. \n\nWe will create a VAENode with input and output interfaces. Nodes in RxInfer require messages to be passed between them during inference. In this case, we have the luxury of not needing to solve any tough integrals:\n\nWe'll use the encoder as our message passing function toward the input interface (from images to latent space)\nThe forward message for the output interface will be our decoder (from latent space to images)\n\n# Create a VAE wrapper to help with RxInfer integration\nstruct VAENode end\n\n# Meta struct to store the VAE model for use in message passing rules\nstruct VAEMeta{F}\n    vae::F\nend\n\n# Define a custom VAE node for RxInfer\n@node VAENode Stochastic [out, x]\n\n# Define the backward message passing rule (z ‚Üê out)\n@rule VAENode(:x, Marginalisation) (q_out::PointMass, meta::VAEMeta) = begin\n    # Get the value from the output message\n    x_val = mean(q_out)\n    \n    # Pass through encoder to get latent distribution\n    # Need to reshape x_val to match expected input shape\n    x_reshaped = reshape(x_val, 28, 28, 1, 1)\n    encoded = meta.vae.encoder(x_reshaped)\n    \n    z_mean = vec(encoded.Œº) |> Flux.cpu\n    z_var = exp.(vec(encoded.logœÉ)) .^ 2 |> Flux.cpu\n    \n    # Return multivariate normal distribution\n    return MvNormalMeanCovariance(z_mean, Diagonal(z_var))\nend\n\n@rule VAENode(:out, Marginalisation) (q_x::MultivariateNormalDistributionsFamily, meta::VAEMeta) = begin \n    # from the latent distribution, sample a value\n    z_val = mean(q_x)\n    # Convert to Float32 to match the decoder's parameter type\n    z_val = Float32.(z_val)\n    # pass through decoder to get image distribution\n    decoder_output = meta.vae.decoder(z_val)\n    \n    # return the image distribution\n    return decoder_output.p\nend\n\n# DONE!\n\nNow we'll define a state space model to capture the dynamics of rotation in the latent space. This model assumes:\n\nThe latent state evolves according to a linear dynamical system with unknown transition matrix and noise\nThe observed images are generated from the latent states through the VAE\n\n# Define the state space model using the VAE node\n@model function ssm_vae(y)\n    Œõ‚Çõ ~ Wishart(4, diageye(2)) # Precision matrix for the transition matrix\n    H‚Çõ ~ MvNormal(Œº = zeros(4), Œõ = diageye(4)) # Vectorized 2√ó2 transition matrix prior\n\n    # Initial state\n    x[1] ~ MvNormal(Œº = zeros(2), Œ£ = diageye(2)) \n    y[1] ~ VAENode(x[1])\n\n    # State space model evolution\n    for t in 2:length(y)\n        x[t] ~ ContinuousTransition(x[t-1], H‚Çõ, Œõ‚Çõ)  # equivalent to x[t] := H‚Çõ * x[t-1] + œµ[t]\n        y[t] ~ VAENode(x[t])\n    end\nend\n\nAfter specifying our model, we need to set up several components that will guide the inference process:\n\nConstraints: We'll specify factorization constraints on the approximate posterior distribution, assuming independence between variables transition matrix and precision matrix, q(x, H‚Çõ, Œõ‚Çõ) = q(x)q(H‚Çõ)q(Œõ‚Çõ).\nTransition function: This reshapes our vector representation of the transition matrix into the 2√ó2 matrix form needed for the state equation.\nMetadata: We provide RxInfer with information about our custom VAE node and continuous transition function.\nInitial marginals: Starting distributions for our unknown parameters (transition matrix and precision matrix).\n\nThese components define how our inference algorithm will learn the dynamics of rotation in the latent space.\n\n# Define constraints for inference\nconstraints = @constraints begin\n    q(x, H‚Çõ, Œõ‚Çõ) = q(x)q(H‚Çõ)q(Œõ‚Çõ)\nend\n\n# Define transition function\ntransition(h) = reshape(h, (2, 2))\n\n# Define metadata for inference\nmeta = @meta begin\n    ContinuousTransition() ->  CTMeta(transition)\n    VAENode() -> VAEMeta(vae)\nend\n\n# Define initial marginals\ninitmarginals = @initialization begin\n    q(H‚Çõ) = MvNormalMeanCovariance(zeros(4), 1e2diagm(ones(4)))\n    q(Œõ‚Çõ) = Wishart(4, diageye(2))\nend\n\n# Create model\nssm_vae_model = ssm_vae();\n\nLet's generate a sequence of rotated images to use for inference.\n\n# Select a sample image from the dataset (e.g., the first digit 1)\nprintln(\"Generating rotated image sequence...\")\ndigit_indices = findall(rotated_train_labels .== 1)\nsample_image = rotated_train_data[:, :, :, digit_indices[1]]\n\n# Generate and display the rotation sequence\nrotation_anim = generate_rotated_sequence(sample_image, 100, 360)\n\n# Create an animation of the rotating sequence used for learning dynamics\nprintln(\"Creating rotation animation for learning dynamics...\")\nrotation_animation = @animate for i in 1:length(rotation_anim)\n    heatmap(rotation_anim[i], color=[:black, :white], colorbar=false, \n            title=\"Observed Rotations $(round((i-1)*360/length(rotation_anim), digits=1))¬∞\",\n            axis=false, aspect_ratio=:equal, size=(400, 400))\nend\n\n# Save as GIF with 10 frames per second\ngif(rotation_animation, \"rotation_learning_animation.gif\", fps=10, show_msg=false);\n\nGenerating rotated image sequence...\nCreating rotation animation for learning dynamics...\n\n(Image: )\n\nNow, we are going to do something cool here. We will not only pass 100 images to our model to infer the dynamics, but we will also have RxInfer predict the next 100 images. This means we'll simultaneously learn the dynamics and generate predictions for future images.\n\n# Prepare rotated sequence for inference\n# Convert the rotated images to the format expected by the VAE node\nrotated_data = []\nfor img in rotation_anim\n    img_4d = reshape(img, size(img)..., 1, 1)\n    push!(rotated_data, img_4d)\nend\nn_obs = length(rotated_data);\nn_pred = 100;\n# Create data structure for inference\ndata = (y = [rotated_data; repeat([missing], n_pred)],);\n\nprintln(\"Running inference...\")\nresult = infer(\n    model = ssm_vae_model, \n    meta = meta, \n    initialization = initmarginals, \n    data = data, \n    constraints = constraints, \n    iterations = 50, \n    showprogress = true, \n    free_energy = false, \n    free_energy_diagnostics = nothing, \n    options = (limit_stack_depth = 100,)\n)\n\nRunning inference...\nInference results:\n  Posteriors       | available for (x, Œõ‚Çõ, H‚Çõ)\n  Predictions      | available for (y)\n\n# Create an animation that distinguishes between observations and predictions\ny_pred = result.predictions[:y][end];\nprintln(\"Creating observation-prediction animation...\")\ncontinuation_animation = @animate for i in 1:length(y_pred)\n    if i == 1\n        # First frame gets a more descriptive title\n        heatmap(y_pred[i][:, :, 1, 1], color=:grays, \n                title=\"Rotating Digit: $n_obs observations ‚Üí $n_pred predictions\",\n                axis=false, aspect_ratio=:equal, size=(400, 400))\n    elseif i <= n_obs\n        # Rest of observations\n        heatmap(y_pred[i][:, :, 1, 1], color=:grays, \n                title=\"Observation #$i of $n_obs\",\n                axis=false, colorbar=false, aspect_ratio=:equal, size=(400, 400))\n    else\n        # Predictions - with red title text\n        heatmap(y_pred[i][:, :, 1, 1], color=:inferno, \n                title=(\"Prediction #$(i-n_obs) of $n_pred ahead\"),\n                title_location=:center, titlefontcolor=:red,\n                axis=false, aspect_ratio=:equal, size=(400, 400),\n                border=:red, colorbar=false, borderwidth=3)\n    end\nend\n\n# Save as GIF with 10 frames per second\ngif(continuation_animation, \"observation_prediction_animation.gif\", fps=24, show_msg=false);\n\nCreating observation-prediction animation...\n\n(Image: )\n\nLet's visualize the observations and predictions side by side.\n\nfunction create_digit_strips_with_titles(y_pred, n_obs=100, n_pred_to_show=50)\n    # Get image dimensions\n    img_height, img_width = size(y_pred[1][:,:,1,1])\n    \n    # Create a single large image for observations (top row)\n    obs_strip = zeros(img_height, img_width * n_obs)\n    for i in 1:n_obs\n        obs_strip[:, ((i-1)*img_width+1):(i*img_width)] = y_pred[i][:,:,1,1]\n    end\n    \n    # For predictions, use the first 50 predictions (101-150)\n    pred_indices = (n_obs+1):(n_obs+n_pred_to_show)\n    \n    # Create a single large image for predictions (bottom row)\n    # Make each prediction twice as wide to fill the same space\n    pred_strip = zeros(img_height, img_width * n_pred_to_show * 2)\n    for i in 1:n_pred_to_show\n        # Fill a 2x wider space for each prediction\n        start_col = ((i-1)*img_width*2+1)\n        end_col = (i*img_width*2)\n        \n        # Repeat each column to double the width\n        for j in 1:img_width\n            pred_strip[:, start_col+2*(j-1):start_col+2*(j-1)+1] .= y_pred[pred_indices[i]][:, j, 1, 1]\n        end\n    end\n    \n    # Create tick positions and labels\n    obs_tick_pos = range(1, img_width*n_obs, length=11)\n    obs_tick_labels = string.(range(1, n_obs, length=11))\n    \n    # For predictions, show ticks from 101 to 150\n    pred_tick_pos = range(1, img_width*n_pred_to_show*2, length=6)\n    pred_tick_labels = string.(range(n_obs+1, n_obs+n_pred_to_show, length=6))\n    \n    # Plot observations (1-100)\n    p1 = heatmap(\n        obs_strip,\n        color=:grays, \n        colorbar=false,\n        yticks=false,\n        xticks=(obs_tick_pos, obs_tick_labels),\n        framestyle=:box,\n        title=\"Observation Sequence\",\n        titlefontsize=12,\n        titlefontcolor=:blue,\n        size=(1000, 100)\n    )\n    \n    # Plot predictions (101-150)\n    p2 = heatmap(\n        pred_strip,\n        color=:inferno, \n        colorbar=false,\n        yticks=false,\n        xticks=(pred_tick_pos, pred_tick_labels),\n        framestyle=:box,\n        title=\"Prediction Sequence\",\n        titlefontsize=12,\n        titlefontcolor=:red,\n        size=(1000, 150)  # Make this row taller\n    )\n    \n    # Create a small plot for the simultaneous learning message\n    message_plot = plot(\n        grid=false,\n        showaxis=false,\n        ticks=false,\n        framestyle=:none,\n        size=(1000, 30),\n        margin=0Plots.mm,\n        bottom_margin=-5Plots.mm,\n        top_margin=-5Plots.mm\n    )\n    \n    # Combine the plots\n    p = plot(\n        p1, message_plot, p2,\n        layout=grid(3, 1, heights=[0.35, 0.1, 0.55]),\n        size=(1000, 280),\n        margin=5Plots.mm\n    )\n    \n    return p\nend\n\n# Create the strips with titles and message\nprintln(\"Creating digit strips with titles...\")\nn_obs = 100  # Number of observations\nn_pred_to_show = 50  # Number of predictions to show (101-150)\n\nfinal_strips = create_digit_strips_with_titles(\n    result.predictions[:y][end], n_obs, n_pred_to_show\n)\ndisplay(final_strips)\n\nCreating digit strips with titles...\n\n(Image: )\n\nLet's also plot the predicted trajectories with uncertainty ribbons.\n\n# Extract the real latent trajectories from the data\nreal_latent_dim1 = first.(first.(vae.encoder.(rotated_data)))\nreal_latent_dim2 = last.(first.(vae.encoder.(rotated_data)))\n\n# Create improved plots with both inferred and real trajectories\np1 = plot(1:length(mean.(result.posteriors[:x][end])), \n          first.(mean.(result.posteriors[:x][end])), \n          ribbon=first.(std.(result.posteriors[:x][end])), \n          xlabel=\"Time Step\", ylabel=\"Latent Dimension 1\", \n          label=\"Predicted\", \n          linewidth=2, alpha=0.7)\n\n# Add the real trajectory to dimension 1 plot\nplot!(p1, 1:length(real_latent_dim1), real_latent_dim1, \n      label=\"Real trajectory\", \n      linewidth=2, linestyle=:dash, color=:red)\n\n# Create dimension 2 plot\np2 = plot(1:length(mean.(result.posteriors[:x][end])), \n          last.(mean.(result.posteriors[:x][end])), \n          ribbon=last.(std.(result.posteriors[:x][end])),\n          xlabel=\"Time Step\", ylabel=\"Latent Dimension 2\", \n          label=\"Predicted\", \n          linewidth=2, alpha=0.7)\n\n# Add the real trajectory to dimension 2 plot\nplot!(p2, 1:length(real_latent_dim2), real_latent_dim2, \n      label=\"Real trajectory\", \n      linewidth=2, linestyle=:dash, color=:red)\n\n# Combine the plots\nplot(p1, p2, layout=(1,2), size=(1000, 300), \n     title=\"Latent Space Trajectory\")\n\n(Image: )\n\nLastly, let's analyze the learned rotation matrix.\n\n# Analyze the learned rotation matrix\nH_matrix = reshape(mean(result.posteriors[:H‚Çõ][end]), (2, 2))\nprintln(\"Learned rotation matrix:\")\ndisplay(H_matrix)\n\n# Calculate eigenvalues and eigenvectors\neigen_vals, eigen_vecs = eigen(H_matrix)\n\n# Calculate the rotation angle from the matrix\nrotation_angle = atan(H_matrix[2,1], H_matrix[1,1]) * 180 / œÄ\n\n# Calculate the determinant (should be close to 1 for a rotation)\ndet_H = det(H_matrix)\n\n# Calculate the matrix norm (measure of scaling)\nnorm_H = norm(H_matrix)\n\n# Print analysis results\nprintln(\"\\n=== Rotation Matrix Analysis ===\")\nprintln(\"Determinant: $(round(det_H, digits=5)) (ideal for pure rotation: 1.0)\")\nprintln(\"Matrix norm: $(round(norm_H, digits=5))\")\nprintln(\"Eigenvalues: $(round.(abs.(eigen_vals), digits=5)) ‚à† $(round.(angle.(eigen_vals) .* 180/œÄ, digits=2))¬∞\")\nprintln(\"Estimated rotation angle per step: $(round(rotation_angle, digits=2))¬∞\")\nprintln(\"Expected rotation angle per step: $(round(360/100, digits=2))¬∞\")\n\n# Check if it's close to a pure rotation\nis_pure_rotation = isapprox(det_H, 1.0, atol=0.05) && \n                   all(isapprox.(abs.(eigen_vals), 1.0, atol=0.05))\n\nprintln(\"\\n=== Interpretation ===\")\nif is_pure_rotation\n    println(\"‚úì The matrix is very close to a pure rotation matrix.\")\nelse\n    println(\"‚ö† The matrix includes some scaling or shearing in addition to rotation.\")\nend\n\n# Check if eigenvalues are complex conjugates (as expected for rotation)\nif all(isapprox.(real(eigen_vals[1]), real(eigen_vals[2]), atol=1e-10)) && \n   isapprox(imag(eigen_vals[1]), -imag(eigen_vals[2]), atol=1e-10)\n    println(\"‚úì Eigenvalues form a complex conjugate pair, as expected for rotation.\")\nelse\n    println(\"‚ö† Eigenvalues don't form a perfect complex conjugate pair.\")\nend\n\n# Check if the rotation angle matches expectation\nangle_error = abs(rotation_angle - 360/100)\nif angle_error < 1.0\n    println(\"‚úì Rotation angle matches expected value very closely (error < 1¬∞).\")\nelseif angle_error < 2.0\n    println(\"‚úì Rotation angle is reasonably close to expected value (error < 2¬∞).\")\nelse\n    println(\"‚ö† Rotation angle differs from expected value by $(round(angle_error, digits=2))¬∞.\")\nend\n\n# Overall assessment\nprintln(\"\\n=== Overall Assessment ===\")\nif is_pure_rotation && angle_error < 2.0\n    println(\"The learned matrix is an excellent approximation of the expected rotation.\")\nelseif angle_error < 5.0\n    println(\"The learned matrix captures the rotation well, with some minor deviations.\")\nelse\n    println(\"The learned matrix approximates the rotation, but has significant deviations.\")\nend\n\nLearned rotation matrix:\n2√ó2 Matrix{Float64}:\n 0.985487   -0.048242\n 0.0721243   0.97395\n\n=== Rotation Matrix Analysis ===\nDeterminant: 0.96329 (ideal for pure rotation: 1.0)\nMatrix norm: 1.38827\nEigenvalues: [0.98148, 0.98148] ‚à† [-3.43, 3.43]¬∞\nEstimated rotation angle per step: 4.19¬∞\nExpected rotation angle per step: 3.6¬∞\n\n=== Interpretation ===\n‚úì The matrix is very close to a pure rotation matrix.\n‚úì Eigenvalues form a complex conjugate pair, as expected for rotation.\n‚úì Rotation angle matches expected value very closely (error < 1¬∞).\n\n=== Overall Assessment ===\nThe learned matrix is an excellent approximation of the expected rotation.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [1575904b] AutoEncoderToolkit v0.1.2\n‚åÖ [587475ba] Flux v0.14.25\n  [033835bb] JLD2 v0.6.3\n  [eb30cadb] MLDatasets v0.7.20\n  [91a5bcdd] Plots v1.41.6\n  [a194aa59] ReactiveMP v5.6.5\n  [86711068] RxInfer v4.7.0\n  [10745b16] Statistics v1.11.1\nInfo Packages marked with ‚åÖ have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated`\n\n\n","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/","page":"Structural Dynamics With Augmented Kalman Filter","title":"Structural Dynamics With Augmented Kalman Filter","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#Structural-Dynamics-with-Augmented-Kalman-Filter","page":"Structural Dynamics With Augmented Kalman Filter","title":"Structural Dynamics with Augmented Kalman Filter","text":"This example demonstrates state and input force estimation for structural dynamical systems with Augmented Kalman Filter (AKF) implemented in RxInfer.\n\nNOTE: This example was originally featured in this blog post. Check it out for additional insights! The notebook has been prepared by V√≠ctor Flores and adapted by Dmitry Bagaev.","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#State-and-Input-Estimation","page":"Structural Dynamics With Augmented Kalman Filter","title":"State and Input Estimation","text":"State-space models are fundamental tools in control theory and signal processing that allow us to analyze complex dynamical systems by breaking them down into first-order differential equations. They are particularly important for structural dynamics problems because they can capture both the internal states (like position and velocity) and external influences (like forces) in a unified mathematical framework. A typical state-space model formulation might look like this:\n\nxk+1 sim mathcalN(A xk + B pk Q)\n\nyk sim mathcalN(G xk + J pk R)\n\nwhere:\n\nxk\nrepresents the system states at time-step k\npk\nrepresents the unknown input forces at time-step k\nyk\nrepresents our noisy measurements at time-step k\nA\nis the state transition matrix that describes how the system evolves from one time step to the next\nB\nis the input matrix that maps the external forces to their effects on the states\nQ\nis the process noise covariance matrix that captures uncertainties in the system dynamics\nR\nis the measurement noise covariance matrix that represents uncertainties in sensor measurements","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#4-floor-shear-building-model","page":"Structural Dynamics With Augmented Kalman Filter","title":"4-floor shear building model","text":"For this example, we consider a simplified 4-floor shear building model with 4 degrees of freedom (DOF). This system is depicted below:\n\n(Image: )\n\nIn this example, the dynamics of a structural system are governed by its mass (M), stiffness (K), and damping (C) matrices, leading to the equation of motion:\n\nM ddotx(t) + C dotx(t) + K x(t) = p(t)\n\nwhere x(t) represents the displacements at each degree of freedom, and p(t) is the external force applied to the system.\n\nThis model captures the essential dynamics of a multi-story structure while remaining computationally manageable. The system matrices are defined as follows:\n\nM\nis the diagonal mass matrix representing the lumped masses at each floor,  \nK\nis the stiffness matrix representing inter-floor lateral stiffness, and  \nC\nis the proportional damping matrix reflecting energy dissipation.\n\nLets begin the experiment! To start, we import the necessary packages.\n\nusing LinearAlgebra, Statistics, Random, Plots\n\nTo keep our analysis organized, we'll use a custom StructuralModelData data structure. This structure serves as a central repository for model parameters, simulation settings, system matrices, results, and outputs.\n\n# define a data structure for the structural model environment\nstruct StructuralModelData\n    t::Union{Nothing,Any}\n    ndof::Union{Nothing,Int64}\n    nf::Union{Nothing,Int64}\n    N_data::Union{Nothing,Int64}\n    y_meas::Union{Nothing,Vector{Vector{Float64}}}\n    A_aug::Union{Nothing,Matrix{Float64}}\n    G_aug::Union{Nothing,Matrix{Float64}}\n    G_aug_fullfield::Union{Nothing,Matrix{Float64}}\n    Q_akf::Union{Nothing,Matrix{Float64}}\n    R::Union{Nothing,LinearAlgebra.Diagonal{Float64,Vector{Float64}}}\n    x_real::Union{Nothing,Matrix{Float64}}\n    y_real::Union{Nothing,Matrix{Float64}}\n    p_real::Union{Nothing,Matrix{Float64}}\nend\n\nWe also define a structure for the system matrices.\n\n# define the structural system matrices\nstruct StructuralMatrices\n    M::Union{Nothing,Matrix{Float64}}\n    K::Union{Nothing,Matrix{Float64}}\n    C::Union{Nothing,Matrix{Float64}}\nend\n\n\nM = I(4)\n\n\nK = [\n    2 -1 0 0;\n    -1 2 -1 0;\n    0 -1 2 -1;\n    0 0 -1 1\n] * 1e3\n\nC = [\n    2 -1 0 0;\n    -1 2 -1 0;\n    0 -1 2 -1;\n    0 0 -1 1\n]\n\nStructuralModel = StructuralMatrices(M, K, C);","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#Constructing-the-State-Space-Model","page":"Structural Dynamics With Augmented Kalman Filter","title":"Constructing the State-Space Model","text":"We convert the structural system into its discrete-time state-space form for numerical simulation. Starting from the equation of motion:\n\nM ddotx(t) + C dotx(t) + K x(t) = F(t)\n\nwe introduce the state variable:\n\nz(t) = beginbmatrix x(t)  dotx(t) endbmatrix\n\nwhich allows us to express the system as:\n\ndotz(t) = A_textc z(t) + B_textc p(t)\n\nwhere:\n\nA_textc = beginbmatrix 0  I  -(M^-1 K)  -(M^-1 C) endbmatrix\nB_textc = beginbmatrix 0  M^-1 S_p endbmatrix\nS_p\nis the input selection matrix that determines where the external forces p(t) are applied.\n\nTo perform simulations, the system is discretized using a time step Delta t as:\n\nzk+1 = A zk + B pk\n\nwhere:\n\nA = e^A_textc Delta t\nis the state transition matrix.\nB = (A - I) A_textc^-1 B_textc\nis the input matrix, obtained by integrating the continuous-time system.\n\nThis state-space representation forms the basis for propagating the system states during simulation.\n\n# function to construct the state space model\nfunction construct_ssm(StructuralModel, dt, ndof, nf)\n    # unpack the structural model\n    M = StructuralModel.M\n    K = StructuralModel.K\n    C = StructuralModel.C\n\n\n    Sp = zeros(ndof, nf)\n    Sp[4, 1] = 1\n\n    Z = zeros(ndof, ndof)\n    Id = I(ndof)\n\n    A_continuous = [Z Id;\n        -(M \\ K) -(M \\ C)]\n    B_continuous = [Z; Id \\ M] * Sp\n\n    A = exp(dt * A_continuous)\n    B = (A - I(2 * ndof)) * A_continuous \\ B_continuous\n\n    return A, B, Sp\nend\n\nconstruct_ssm (generic function with 1 method)","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#Generating-Input-Forces","page":"Structural Dynamics With Augmented Kalman Filter","title":"Generating Input Forces","text":"External forces pk acting on the system are modeled as Gaussian white noise:\n\npk sim mathcalN(mu sigma^2)\n\nwhere mu is the mean and sigma controls the intensity of the force.\n\nIn this example, the inputs are generated independently at each time step k and across input channels to simulate random excitations, such as wind or seismic forces.\n\n# function to generate random input noise\nfunction generate_input(N_data::Int, nf::Int; input_mu::Float64, input_std::Float64)\n    Random.seed!(42)\n    p_real = input_mu .+ randn(N_data, nf) .* input_std\n    return p_real\nend\n\ngenerate_input (generic function with 1 method)","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#Observation-Model","page":"Structural Dynamics With Augmented Kalman Filter","title":"Observation Model","text":"System responses, such as accelerations, are often measured at specific locations using sensors. The measurements are simulated using the equation:\n\nyk = G xk + J pk + vk\n\nwhere:\n\nG\nmaps the system states xk to measured outputs.\nJ\nmaps the input forces pk to the measurements.\nvk sim mathcalN(0 sigma_y^2 I)\nis Gaussian noise representing sensor inaccuracies.\n\nThe noise variance sigma_y^2 is chosen as a fraction of the true system response variance for realism.\n\nIn this example, accelerations are measured at selected degrees of freedom (e.g., nodes 1 and 4).\n\n# function to generate the measurements and noise\nfunction generate_measurements(ndof, na, nv, nd, N_data, x_real, y_real, p_real, StructuralModel, Sp)\n    # unpack the structural model\n    M = StructuralModel.M\n    K = StructuralModel.K\n    C = StructuralModel.C\n\n    Sa = zeros(na, ndof)            # selection matrix\n    Sa[1, 1] = 1                    # acceleration at node 1\n    Sa[2, 4] = 1                    # acceleration at node 4\n    G = Sa * [-(M \\ K) -(M \\ C)]\n    J = Sa * (I \\ M) * Sp\n\n    ry = Statistics.var(y_real[2*ndof+1, :],) * (0.1^2)        # simulate noise as 1% RMS of the noise-free acceleration response\n\n    nm = na + nv + nd\n\n    R = I(nm) .* ry\n\n    y_meas = zeros(nm, N_data)\n    y_noise = sqrt(ry) .* randn(nm, N_data)\n\n    # reconstruct the measurements\n    y_meas = Vector{Vector{Float64}}(undef, N_data)\n    for i in 1:N_data\n        y_meas[i] = G * x_real[:, i] + J * p_real[i, :] + y_noise[:, i]\n    end\n\n    return y_meas, G, J, R\nend\n\ngenerate_measurements (generic function with 1 method)","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#Simulating-the-Structural-Response","page":"Structural Dynamics With Augmented Kalman Filter","title":"Simulating the Structural Response","text":"The structural response under applied forces is governed by the state-space equations:\n\nbeginaligned\nxk+1  = A xk + B pk \nyk    = G_textfull xk + J_textfull pk\nendaligned\n\nwhere xk are the system states, pk are the input forces, and yk are the full-field responses, i.e., the response at every degree of freedom in our structure.\n\nThe function below returns:\n\nTrue States: x_textreal, propagated using $ A $ and $ B $.\nFull-Field Responses: y_textreal, incorporating both states and inputs.\nInput Forces: p_textreal, generated as stochastic excitations.\nResponse Matrices: G_textfull (state-to-response) and J_textfull (input-to-response).\n\nThese outputs simulate the physical behavior of the system and serve as the basis for inference. We keep the matrices because they will be used later when analyzing our results.\n\n# function to simulate the structural response\nfunction simulate_response(A, B, StructuralModel, Sp, nf, ndof, N_data)\n    # unpack the structural model\n    M = StructuralModel.M\n    K = StructuralModel.K\n    C = StructuralModel.C\n\n    p_real = generate_input(N_data, nf, input_mu=0.0, input_std=0.05)\n\n    Z = zeros(ndof, ndof)\n    Id = I(ndof)\n\n    G_full = [\n        Id Z;\n        Z Id;\n        -(M \\ K) -(M \\ C)\n    ]\n\n    J_full = [\n        Z;\n        Z;\n        Id \\ M\n    ] * Sp\n\n    # preallocate matrices\n    x_real = zeros(2 * ndof, N_data)\n    y_real = zeros(3 * ndof, N_data)\n\n    for i in 2:N_data\n        x_real[:, i] = A * x_real[:, i-1] + B * p_real[i-1, :]\n        y_real[:, i] = G_full * x_real[:, i-1] + J_full * p_real[i-1, :]\n    end\n\n    return x_real, y_real, p_real, G_full, J_full\nend\n\nsimulate_response (generic function with 1 method)","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#Augmented-State-Space-Model","page":"Structural Dynamics With Augmented Kalman Filter","title":"Augmented State-Space Model","text":"In structural health monitoring, external input forces pk acting on a structure, such as environmental loads or unknown excitations, are often not directly measurable. To estimate both the system states xk and these unknown input forces, we augment the state vector as follows:\n\ntildexk = \nbeginbmatrix\nxk \npk\nendbmatrix\n\nThis approach allows us to simultaneously infer the internal system states (e.g., displacements and velocities) and the unknown inputs using available measurements.\n\nThe augmented system dynamics are then expressed as:\n\nbeginaligned\ntildexk+1  = A_textaug tildexk + wk \nyk  = G_textaug tildexk + vk\nendaligned\n\nwhere:\n\nA_textaug\n: Augmented state transition matrix.  \nG_textaug\n: Augmented measurement matrix.  \nQ_textakf\n: Augmented process noise covariance, capturing uncertainties in both states and inputs.  \nwk\n, vk: Process and measurement noise.  ","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#Full-Field-vs.-Measurement-Space","page":"Structural Dynamics With Augmented Kalman Filter","title":"Full-Field vs. Measurement Space","text":"To avoid confusion, we define two augmented measurement matrices:  \n\nG_textaug\n: Projects the augmented state vector tildexk to the observed sensor measurements (e.g., accelerations at specific nodes).  \nG^*\n: The augmented full-field measurement matrix, which projects the augmented state vector to the full-field system response. This includes all degrees of freedom (displacements, velocities, and accelerations).  \n\nThe distinction is critical:\n\nG_textaug\nis used directly in the smoother to estimate states and inputs from limited measurements.  \nG^*\nis used later to reconstruct the full response field for visualization and validation.\n\nFor clarity, we will refer to the augmented full-field matrix as G^* throughout the rest of this example, whereas, in the code, this will be the G_aug_fullfield object.","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#Noise-Covariances","page":"Structural Dynamics With Augmented Kalman Filter","title":"Noise Covariances","text":"In this step, the process and measurement noise covariances are assumed to be known or pre-calibrated. For example:\n\nThe input force uncertainty Q_p is set to reflect significant variability.  \nState noise covariance Q_x is chosen to reflect uncertainty in the model.  \n\nThe augmented noise covariance matrix Q_textakf combines these quantities:\n\nQ_textakf =\nbeginaligned\nbeginbmatrix\nQ_x  0 \n0  Q_p\nendbmatrix\nendaligned\n\n# function to construct the augmented model\nfunction construct_augmented_model(A, B, G, J, G_full, J_full, nf, ndof)\n    Z_aug = zeros(nf, 2 * ndof)\n    A_aug = [\n        A B;\n        Z_aug I(nf)\n    ]\n    G_aug = [G J]\n\n    G_aug_fullfield = [G_full J_full]                               # full-field augmented matrix\n\n    Qp_aug = I(nf) * 1e-2                                           # assumed known or pre-callibrated\n\n    # The `Q` matrix here has zero entries on the diagonal, which in turn \n    # leads to a non-symmetric matrices in the computation. \n    # This is acceptable for this example\n    ENV[\"JULIA_FASTCHOLESKY_NO_WARN_NON_SYMMETRIC\"] = \"1\"\n    if haskey(ENV, \"JULIA_FASTCHOLESKY_THROW_ERROR_NON_SYMMETRIC\")\n        delete!(ENV, \"JULIA_FASTCHOLESKY_THROW_ERROR_NON_SYMMETRIC\")\n    end\n\n    Qx_aug = zeros(2 * ndof, 2 * ndof)\n    Qx_aug[(ndof+1):end, (ndof+1):end] = I(ndof) * 1e-1             # assumed known or pre-callibrated\n\n    Q_akf = [\n        Qx_aug Z_aug';\n        Z_aug Qp_aug\n    ]\n\n    return A_aug, G_aug, Q_akf, G_aug_fullfield\nend\n\nconstruct_augmented_model (generic function with 1 method)\n\nFinally, we combine all the key steps into a single workflow to generate the system dynamics, responses, measurements, and the augmented state-space model.\n\nThe results are stored in a StructuralModelData object for convenient access:\n\nfunction get_structural_model(StructuralModel, simulation_time, dt)\n\n    # intialize\n    ndof = size(StructuralModel.M)[1]                               # number of degrees of freedom\n    nf = 1                                                          # number of inputs\n    na, nv, nd = 2, 0, 0                                            # number of oberved accelerations, velocities, and displacements\n    N_data = Int(simulation_time / dt) + 1\n    t = range(0, stop=simulation_time, length=N_data)\n\n    # construct state-space model from structural matrices\n    A, B, Sp = construct_ssm(StructuralModel, dt, ndof, nf)\n\n    # Generate input and simulate response\n    x_real, y_real, p_real, G_full, J_full = simulate_response(A, B, StructuralModel, Sp, nf, ndof, N_data)\n\n    # Generate measurements\n    y_meas, G, J, R = generate_measurements(ndof, na, nv, nd, N_data, x_real, y_real, p_real, StructuralModel, Sp)\n\n    # Construct augmented model\n    A_aug, G_aug, Q_akf, G_aug_fullfield = construct_augmented_model(A, B, G, J, G_full, J_full, nf, ndof)\n\n    return StructuralModelData(t, ndof, nf, N_data, y_meas, A_aug, G_aug, G_aug_fullfield, Q_akf, R, x_real, y_real, p_real)\nend\n\nget_structural_model (generic function with 1 method)\n\nWe define the simulation time and time step, then run the workflow to generate the structural model:\n\nsimulation_time = 5.0\ndt = 0.001\n\nmodel_data = get_structural_model(StructuralModel, simulation_time, dt);","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#State-and-Input-Estimation-with-RxInfer","page":"Structural Dynamics With Augmented Kalman Filter","title":"State and Input Estimation with RxInfer","text":"In this section, we use RxInfer to estimate the system states and unknown input forces from the simulated noisy measurements using the Augmented State Space Model discussed.\n\nusing RxInfer","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#Defining-the-AKF-Smoother-Model","page":"Structural Dynamics With Augmented Kalman Filter","title":"Defining the AKF Smoother Model","text":"Here, we define our Augmented Kalman Filter (AKF) smoother using RxInfer. This probabilistic model estimates the system states and unknown input forces based on the measurements.\n\nState Prior: We start with a prior belief about the initial state, x0.  \nState Transition: At each time step, the system state evolves based on the transition matrix A and process noise covariance Q: xk sim mathcalN(A xk-1 Q)\nMeasurements: The observations (sensor data) are modeled as noisy measurements of the states: yk sim mathcalN(G xk R) where G maps the states to the measurements, and R is the measurement noise covariance.\n\n@model function smoother_model(y, x0, A, G, Q, R)\n\n    x_prior ~ x0\n    x_prev = x_prior  # initialize previous state with x_prior\n\n    for i in 1:length(y)\n        x[i] ~ MvNormal(mean=A * x_prev, cov=Q)\n        y[i] ~ MvNormal(mean=G * x[i], cov=R)\n        x_prev = x[i]\n    end\n\nend","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#Running-the-AKF-Smoother","page":"Structural Dynamics With Augmented Kalman Filter","title":"Running the AKF Smoother","text":"Now that we have our system set up, it's time to estimate the system states and unknown input forces using RxInfer. We'll run the Augmented Kalman Filter (AKF) smoother to make sense of the noisy measurements.\n\nHere‚Äôs the game plan:\n\nUnpack the Data:   We grab everything we need from the model_data object ‚Äì time, matrices, measurements, and noise covariances.\nSet the Initial State:   We start with a prior belief about the first state, assuming it's zero with some process noise:   x_0 sim mathcalN(0 Q_textakf)\nRun the Smoother:   We define a helper function to keep things tidy. This function calls RxInfer‚Äôs infer method, which does the heavy lifting for us.\nExtract and Reconstruct:  \nRxInfer gives us state marginals, which are the posterior estimates of the states.  \nUsing a helper function, we reconstruct the full-field responses (displacements, velocities, and accelerations).  \nWe also extract the estimated input forces, which are part of the augmented state.\n\nThat‚Äôs it! With just a few lines of code, RxInfer takes care of the math behind the scenes and delivers smooth, reliable estimates of what‚Äôs happening inside the system.\n\n# RxInfer returns the result in its own structure. \n# Here we wrap the results in a different struct for the example's convenience\nstruct InferenceResults\n    state_marginals\n    y_full_means\n    y_full_stds\n    p_means\n    p_stds\nend\n\nfunction run_smoother(model_data)\n    # unpack the model data\n    t = model_data.t\n    N_data = model_data.N_data\n    A_aug = model_data.A_aug\n    G_aug = model_data.G_aug\n    G_aug_fullfield = model_data.G_aug_fullfield\n    Q_akf = model_data.Q_akf\n    R = model_data.R\n    y_meas = model_data.y_meas\n\n    # initialize the state - required when doing smoothing\n    x0 = MvNormalMeanCovariance(zeros(size(A_aug, 1)), Q_akf)\n\n    # define the smoother engine\n    function smoother_engine(y_meas, A, G, Q, R)\n        # run the akf smoother\n        result_smoother = infer(\n            model=smoother_model(x0=x0, A=A, G=G, Q=Q, R=R),\n            data=(y=y_meas,),\n            options=(limit_stack_depth=500,) # This setting is required for large models\n        )\n\n        # return posteriors as this inference task returns the results as posteriors\n        # because inference is done over the full graph\n        return result_smoother.posteriors[:x]\n    end\n\n    # get the marginals of x\n    state_marginals = smoother_engine(y_meas, A_aug, G_aug, Q_akf, R)\n\n    # reconstructing the full-field response:\n    # use helper function to reconstruct the full-field response\n    y_full_means, y_full_stds = reconstruct_full_field(state_marginals, G_aug_fullfield, N_data)\n\n    # extract the estimated input (input modeled as an augmentation state)\n    p_results_means = getindex.(mean.(state_marginals), length(state_marginals[1]))\n    p_results_stds = getindex.(std.(state_marginals), length(state_marginals[1]))\n\n    return InferenceResults(state_marginals, y_full_means, y_full_stds, p_results_means, p_results_stds)\nend\n\nrun_smoother (generic function with 1 method)","category":"section"},{"location":"categories/problem_specific/structural_dynamics_with_augmented_kalman_filter/#Mapping-States-to-Full-Field-Responses","page":"Structural Dynamics With Augmented Kalman Filter","title":"Mapping States to Full-Field Responses","text":"In the run_smoother function, we used a helper function to map the state estimates from the AKF smoother back to the full-field responses (e.g., displacements, velocities, and accelerations).  \n\nWhy is this important?\n\nWhile the smoother estimates the system states, we often care about physical quantities like accelerations or displacements across the entire structure.\n\nUsing the augmented full-field matrix G^*, we compute:\n\nResponse means from state means:   mu_yi = G^* mu_xi  \nResponse uncertainties from state covariances:   sigma_yi = sqrttextdiag(G^* Sigma_xi G^*^top)  \n\nThis gives us both the expected responses and their uncertainties at each time step.  \n\nIn other words, this function connects the smoother‚Äôs internal state estimates to meaningful, physical quantities, making it easy to visualize the system‚Äôs behavior.  \n\n# helper function to reconstruct the full field response from the state posteriors\nfunction reconstruct_full_field(\n    x_marginals,\n    G_aug_fullfield,\n    N_data::Int\n)\n\n    # preallocate the full field response\n    y_means = Vector{Vector{Float64}}(undef, N_data)        # vector of vectors\n    y_stds = Vector{Vector{Float64}}(undef, N_data)\n\n    # reconstruct the full-field response using G_aug_fullfield\n    for i in 1:N_data\n        # extract the mean and covariance of the state posterior\n        state_mean = mean(x_marginals[i])       # each index is a vector\n        state_cov = cov(x_marginals[i])\n\n        # project mean and covariance onto the full-field response space\n        y_means[i] = G_aug_fullfield * state_mean\n        y_stds[i] = sqrt.(diag(G_aug_fullfield * state_cov * G_aug_fullfield'))\n    end\n\n    return y_means, y_stds\n\nend\n\nreconstruct_full_field (generic function with 1 method)\n\nWe now run the AKF smoother using the structural model data to estimate the system states, reconstruct the full-field responses, and extract the input forces along with their uncertainties.\n\nLet‚Äôs fire up that RxInfer!\n\n# run the smoother\nsmoother_results = run_smoother(model_data);\n\nWe first write a helper function and then plot the true states, full-field response, input, their estimates, and the associated uncertainty:\n\n# helper function\nfunction plot_with_uncertainty(\n    t,\n    true_values,\n    estimated_means,\n    estimated_uncertainties,\n    ylabel_text,\n    title_text,\n    label_suffix=\"\";\n    plot_size=(700, 300),)\n    # plot true values\n    plt = plot(\n        t,\n        true_values,\n        label=\"true ($label_suffix)\",\n        lw=2,\n        color=:blue,\n        size=plot_size,\n        left_margin=5Plots.mm,\n        top_margin=5Plots.mm,\n        bottom_margin=5Plots.mm\n    )\n\n    # plot estimated values with uncertainty ribbon\n    plot!(\n        plt,\n        t,\n        estimated_means,\n        ribbon=estimated_uncertainties,\n        fillalpha=0.3,\n        label=\"estimated ($label_suffix)\",\n        lw=2,\n        color=:orange,\n        linestyle=:dash\n    )\n\n    # add labels and title\n    xlabel!(\"time (s)\")\n    ylabel!(ylabel_text)\n    title!(title_text)\n\n    return plt\nend\n\nplot_with_uncertainty (generic function with 2 methods)\n\n# select some DOFs to plot\nndof = size(StructuralModel.M)[1]\n\ndisplay_state_dof = 4                # dof 1:4 displacements, dof 5:8 velocities\ndisplay_response_dof = 2 * ndof + 1       # dof 1:4 displacements, dof 5:8 velocities, dof 9:12 accelerations\ndisplay_input_dof = 1                # the only one really\n\n# plot the states\nstate_plot = plot_with_uncertainty(\n    model_data.t,\n    model_data.x_real[display_state_dof, :],\n    getindex.(mean.(smoother_results.state_marginals), display_state_dof),\n    getindex.(std.(smoother_results.state_marginals), display_state_dof),\n    \"state value\",\n    \"state estimate (dof $(display_state_dof))\",\n    \"state dof $(display_state_dof)\"\n);\n\n# plot the responses\nresponse_plot = plot_with_uncertainty(\n    model_data.t,\n    model_data.y_real[display_response_dof, :],\n    getindex.(smoother_results.y_full_means, display_response_dof),\n    getindex.(smoother_results.y_full_stds, display_response_dof),\n    \"response value\",\n    \"reconstructed response (dof $(display_response_dof))\",\n    \"response dof $(display_response_dof)\"\n);\n\n# plot the inputs\ninput_plot = plot_with_uncertainty(\n    model_data.t,\n    model_data.p_real[:, display_input_dof],\n    smoother_results.p_means,\n    smoother_results.p_stds,\n    \"force value\",\n    \"input estimate (applied at dof $(display_input_dof))\",\n    \"input force $(display_input_dof)\"\n);\n\ndisplay(state_plot)\ndisplay(response_plot)\ndisplay(input_plot)\n\n(Image: ) (Image: ) (Image: )\n\nLet's quickly go over these results now:\n\nState estimation: The true state and the estimated state show excellent agreement, demonstrating the accuracy of the smoother model implemented via RxInfer. The uncertainty bounds around the estimated states are noticeable, especially early in the domain. This reflects the natural uncertainty in state estimation since only accelerations are observed, whereas displacements and velocities are inferred through integration.\nReconstructed response: the real response and the reconstructed response align well across the domain, confirming that the filter captures the dynamics quite nicely. The uncertainty bounds here are narrower, showing that the confidence improves as the filter incorporates observations of these quantities of interest (i.e. accelerations).\nInput force reconstruction: The input force and its reconstructed counterpart show significant high frequency variations with very narrow uncertainty bounds. This is expected because accelerations, being the directly observed quantities, are estimated with higher confidence. Plus, we gave ourselves a small advantage by using a well-calibrated prior on this quantity of interest (Q_p).\n\nThe results demonstrate how well the smoother model, implemented with RxInfer, performs in capturing the system dynamics and reconstructing hidden states and inputs. Notably, setting up the probabilistic model was straightforward and intuitive‚Äîmuch easier than dealing with the rest of the structural modeling! This highlights the power of RxInfer for quickly building and solving complex inference problems while keeping the implementation clean and efficient.\n\nWith just a few lines of code, we were able to estimate states, reconstruct responses, and confidently quantify uncertainties‚Äîa win for both accuracy and usability. üöÄ\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [10745b16] Statistics v1.11.1\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/problem_specific/gaussian_mixture/","page":"Gaussian Mixture","title":"Gaussian Mixture","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/problem_specific/gaussian_mixture/#Gaussian-Mixture","page":"Gaussian Mixture","title":"Gaussian Mixture","text":"This notebook illustrates how to use the NormalMixture node in RxInfer.jl for both univariate and multivariate observations.","category":"section"},{"location":"categories/problem_specific/gaussian_mixture/#Load-packages","page":"Gaussian Mixture","title":"Load packages","text":"using RxInfer, Plots, Random, LinearAlgebra, StableRNGs, LaTeXStrings","category":"section"},{"location":"categories/problem_specific/gaussian_mixture/#Univariate-Gaussian-Mixture-Model","page":"Gaussian Mixture","title":"Univariate Gaussian Mixture Model","text":"Consider the data set of length N observed below.\n\nfunction generate_univariate_data(nr_samples; rng = MersenneTwister(123))\n\n    # data generating parameters\n    class        = [1/3, 2/3]\n    mean1, mean2 = -10, 10\n    precision    = 1.777\n\n    # generate data\n    z = rand(rng, Categorical(class), nr_samples)\n    y = zeros(nr_samples)\n    for k in 1:nr_samples\n        y[k] = rand(rng, Normal(z[k] == 1 ? mean1 : mean2, 1/sqrt(precision)))\n    end\n\n    return y\n\nend;\n\ndata_univariate = generate_univariate_data(100)\nhistogram(data_univariate, bins=50, label=\"data\", normed=true)\nxlims!(minimum(data_univariate), maximum(data_univariate))\nylims!(0, Inf)\nylabel!(\"relative occurrence [%]\")\nxlabel!(\"y\")\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/gaussian_mixture/#Model-specification","page":"Gaussian Mixture","title":"Model specification","text":"The goal here is to create a model for the data set above. In this case a Gaussian mixture model with K components seems to suite the situation well. We specify the factorized model as  p(y z s m w) = prod_n=1^N bigg(p(y_n mid m w z_n) p(z_n mid s) bigg)prod_k=1^K bigg(p(m_k) p(w_k) bigg) p(s) where the individual terms are specified as beginaligned     p(s)                    = mathrmBeta(s mid alpha_s beta_s) \n    p(m_k)                = mathcalN(m_k mid mu_k sigma_k^2)          p(w_k)                = Gamma(w_k mid alpha_k beta_k) \n    p(z_n mid s)           = mathrmBer(z_n mid s) \n    p(y_n mid m w z_n)   = prod_k=1^K mathcalNleft(y_n mid m_k w_kright)^z_nk endaligned\n\nThe set of observations y = y_1 y_2 ldots y_N is modeled by a mixture of Gaussian distributions, parameterized by means m = m_1 m_2 ldots m_K and precisions w =  w_1 w_2 ldots w_K, where k denotes the component index. This component is selected per observation by the indicator variable z_n, which is a one-of-K encoded vector satisfying sum_k=1^K z_nk = 1 and z_nk in 0 1 forall k. We put a hyperprior on these variables, termed s, which represents the relative occurrence of the different realizations of z_n.\n\nHere we implement the following model with uninformative values for the hyperparameters as\n\n@model function univariate_gaussian_mixture_model(y)\n    \n    s ~ Beta(1.0, 1.0)\n\n    m[1] ~ Normal(mean = -2.0, variance = 1e3)\n    w[1] ~ Gamma(shape = 0.01, rate = 0.01)\n\n    m[2] ~ Normal(mean = 2.0, variance = 1e3)\n    w[2] ~ Gamma(shape = 0.01, rate = 0.01)\n\n    for i in eachindex(y)\n        z[i] ~ Bernoulli(s)\n        y[i] ~ NormalMixture(switch = z[i], m = m, p = w)\n    end\n    \nend","category":"section"},{"location":"categories/problem_specific/gaussian_mixture/#Probabilistic-inference","page":"Gaussian Mixture","title":"Probabilistic inference","text":"In order to fit the model to the data, we are interested in computing the posterior distribution p(z s m w mid y) However, computation of this term is intractable. Therefore, it is approximated by a naive mean-field approximation, specified as  p(z s m w mid y) approx prod_n=1^N q(z_n) prod_k=1^K bigg(q(m_k) q(w_k)bigg) q(s) with the functional forms beginaligned     q(s)   = mathrmBeta(s mid hatalpha_s hatbeta_s) \n    q(m_k) = mathcalN(m_k mid hatmu_k hatsigma^2_k) \n    q(w_k) = Gamma (w_k mid hatalpha_k hatbeta_k) \n    q(z_n) = mathrmBer(z_n mid hatp_n) endaligned In order to get the inference procedure started, these marginal distribution need to be initialized.\n\nn_iterations = 10\n\ninit = @initialization begin\n    q(s) = vague(Beta)\n    q(m) = [NormalMeanVariance(-2.0, 1e3), NormalMeanVariance(2.0, 1e3)]\n    q(w) = [vague(GammaShapeRate), vague(GammaShapeRate)]\nend\n\nresults_univariate = infer(\n    model = univariate_gaussian_mixture_model(), \n    constraints = MeanField(),\n    data  = (y = data_univariate,), \n    initialization = init, \n    iterations  = n_iterations, \n    free_energy = true\n)\n\nInference results:\n  Posteriors       | available for (m, w, s, z)\n  Free Energy:     | Real[262.985, 206.795, 183.824, 140.402, 138.188, 138.\n184, 138.184, 138.184, 138.184, 138.184]","category":"section"},{"location":"categories/problem_specific/gaussian_mixture/#Results","page":"Gaussian Mixture","title":"Results","text":"Below the inference results can be seen as a function of the iterations\n\nm1 = [results_univariate.posteriors[:m][i][1] for i in 1:n_iterations]\nm2 = [results_univariate.posteriors[:m][i][2] for i in 1:n_iterations]\nw1 = [results_univariate.posteriors[:w][i][1] for i in 1:n_iterations]\nw2 = [results_univariate.posteriors[:w][i][2] for i in 1:n_iterations];\n\nmp = plot(mean.(m1), ribbon = std.(m1) .|> sqrt, label = L\"posterior $m_1$\")\nmp = plot!(mean.(m2), ribbon = std.(m2) .|> sqrt, label = L\"posterior $m_2$\")\nmp = plot!(mp, [ -10 ], seriestype = :hline, label = L\"true $m_1$\")\nmp = plot!(mp, [ 10 ], seriestype = :hline, label = L\"true $m_2$\")\n\nwp = plot(mean.(w1), ribbon = std.(w1) .|> sqrt, label = L\"posterior $w_1$\", legend = :bottomright, ylim = (-1, 3))\nwp = plot!(wp, mean.(w2), ribbon = std.(w2) .|> sqrt, label = L\"posterior $w_2$\")\nwp = plot!(wp, [ 1.777 ], seriestype = :hline, label = L\"true $w_1$\")\nwp = plot!(wp, [ 1.777 ], seriestype = :hline, label = L\"true $w_2$\")\n\nswp = plot(mean.(results_univariate.posteriors[:s]), ribbon = std.(results_univariate.posteriors[:s]) .|> sqrt, label = L\"posterior $s$\")\nswp = plot!(swp, [ 2/3 ], seriestype = :hline, label = L\"true $s$\")\n\nfep = plot(results_univariate.free_energy, label = \"Free Energy\", legend = :topright)\n\nplot(mp, wp, swp, fep, layout = @layout([ a b; c d ]), size = (800, 400))\nxlabel!(\"iteration\")\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/gaussian_mixture/#Multivariate-Gaussian-Mixture-Model","page":"Gaussian Mixture","title":"Multivariate Gaussian Mixture Model","text":"The above example can also be extended to the multivariate case. Consider the data set below\n\nfunction generate_multivariate_data(nr_samples; rng = MersenneTwister(123))\n\n    L         = 50.0\n    nr_mixtures = 6\n\n    probvec = normalize!(ones(nr_mixtures), 1)\n\n    switch = Categorical(probvec)\n\n    gaussians = map(1:nr_mixtures) do index\n        angle      = 2œÄ / nr_mixtures * (index - 1)\n        basis_v    = L * [ 1.0, 0.0 ]\n        R          = [ cos(angle) -sin(angle); sin(angle) cos(angle) ]\n        mean       = R * basis_v \n        covariance = Matrix(Hermitian(R * [ 10.0 0.0; 0.0 20.0 ] * transpose(R)))\n        return MvNormal(mean, covariance)\n    end\n\n    z = rand(rng, switch, nr_samples)\n    y = Vector{Vector{Float64}}(undef, nr_samples)\n\n    for n in 1:nr_samples\n        y[n] = rand(rng, gaussians[z[n]])\n    end\n\n    return y\n\nend;\n\ndata_multivariate = generate_multivariate_data(500)\n\nsdim(n) = (a) -> map(d -> d[n], a) # helper function\nscatter(data_multivariate |> sdim(1), data_multivariate |> sdim(2), ms = 2, alpha = 0.4, size = (600, 400), legend=false)\nxlabel!(L\"y_1\")\nylabel!(L\"y_2\")\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/gaussian_mixture/#Model-specification-2","page":"Gaussian Mixture","title":"Model specification","text":"The goal here is to create a model for the data set above. In this case a Gaussian mixture model with K components seems to suite the situation well. We specify the factorized model as  p(y z s m w) = prod_n=1^N bigg(p(y_n mid m W z_n) p(z_n mid s) bigg)prod_k=1^K bigg(p(m_k) p(W_k) bigg) p(s) where the individual terms are specified as beginaligned     p(s)                    = mathrmDir(s mid alpha_s) \n    p(m_k)                = mathcalN(m_k mid mu_k Sigma_k)          p(W_k)                = mathcalW(W_k mid V_k nu_k) \n    p(z_n mid s)           = mathrmCat(z_n mid s) \n    p(y_n mid m W z_n)   = prod_k=1^K mathcalNleft(y_n mid m_k W_kright)^z_nk endaligned\n\nThe set of observations y = y_1 y_2 ldots y_N is modeled by a mixture of Gaussian distributions, parameterized by means m = m_1 m_2 ldots m_K and precisions W =  W_1 W_2 ldots W_K, where k denotes the component index. This component is selected per observation by the indicator variable z_n, which is a one-of-K encoded vector satisfying sum_k=1^K z_nk = 1 and z_nk in 0 1 forall k. We put a hyperprior on these variables, termed s, which represents the relative occurrence of the different realizations of z_n.\n\n@model function multivariate_gaussian_mixture_model(nr_mixtures, priors, y)\n    local m\n    local w\n\n    for k in 1:nr_mixtures        \n        m[k] ~ priors[k]\n        w[k] ~ Wishart(3, 1e2*diagm(ones(2)))\n    end\n    \n    s ~ Dirichlet(ones(nr_mixtures))\n    \n    for n in eachindex(y)\n        z[n] ~ Categorical(s) \n        y[n] ~ NormalMixture(switch = z[n], m = m, p = w)\n    end\n    \nend","category":"section"},{"location":"categories/problem_specific/gaussian_mixture/#Probabilistic-inference-2","page":"Gaussian Mixture","title":"Probabilistic inference","text":"In order to fit the model to the data, we are interested in computing the posterior distribution p(z s m W mid y) However, computation of this term is intractable. Therefore, it is approximated by a naive mean-field approximation, specified as  p(z s m W mid y) approx prod_n=1^N q(z_n) prod_k=1^K bigg(q(m_k) q(W_k)bigg) q(s) with the functional forms beginaligned     q(s)   = mathrmDir(s mid hatalpha_s) \n    q(m_k) = mathcalN(m_k mid hatmu_k hatSigma_k) \n    q(w_k) = mathcalW(W_k mid hatV_k hatnu_k) \n    q(z_n) = mathrmCat(z_n mid hatp_n) endaligned In order to get the inference procedure started, these marginal distribution need to be initialized.\n\nrng = MersenneTwister(121)\npriors = [MvNormal([cos(k*2œÄ/6), sin(k*2œÄ/6)], diagm(1e2 * ones(2))) for k in 1:6]\ninit = @initialization begin\n    q(s) = vague(Dirichlet, 6)\n    q(m) = priors\n    q(w) = Wishart(3, diagm(1e2 * ones(2)))\nend\n\nresults_multivariate = infer(\n    model = multivariate_gaussian_mixture_model(\n        nr_mixtures = 6, \n        priors = priors,\n    ), \n    data  = (y = data_multivariate,), \n    constraints   = MeanField(),\n    initialization = init, \n    iterations  = 50, \n    free_energy = true\n)\n\nInference results:\n  Posteriors       | available for (w, m, s, z)\n  Free Energy:     | Real[3927.95, 3884.37, 3884.37, 3884.37, 3884.37, 3884\n.37, 3884.37, 3884.37, 3884.37, 3884.37  ‚Ä¶  3884.37, 3884.37, 3884.37, 3884\n.37, 3884.37, 3884.37, 3884.37, 3884.37, 3884.37, 3884.37]","category":"section"},{"location":"categories/problem_specific/gaussian_mixture/#Results-2","page":"Gaussian Mixture","title":"Results","text":"Below the inference results can be seen\n\np_data = scatter(data_multivariate |> sdim(1), data_multivariate |> sdim(2), ms = 2, alpha = 0.4, legend=false, title=\"Data\", xlims=(-75, 75), ylims=(-75, 75))\np_result = plot(xlims = (-75, 75), ylims = (-75, 75), title=\"Inference result\", legend=false, colorbar = false)\nfor (e_m, e_w) in zip(results_multivariate.posteriors[:m][end], results_multivariate.posteriors[:w][end])\n    gaussian = MvNormal(mean(e_m), Matrix(Hermitian(mean(inv, e_w))))\n    global p_result = contour!(p_result, range(-75, 75, step = 0.25), range(-75, 75, step = 0.25), (x, y) -> pdf(gaussian, [ x, y ]), title=\"Inference result\", legend=false, levels = 7, colorbar = false)\nend\np_fe = plot(results_multivariate.free_energy, label = \"Free Energy\")\n\nplot(p_data, p_result, p_fe, layout = @layout([ a b; c ]))\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [b964fa9f] LaTeXStrings v1.4.0\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/problem_specific/hierarchical_gaussian_filter/","page":"Hierarchical Gaussian Filter","title":"Hierarchical Gaussian Filter","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/problem_specific/hierarchical_gaussian_filter/#Hierarchical-Gaussian-Filter","page":"Hierarchical Gaussian Filter","title":"Hierarchical Gaussian Filter","text":"In this demo the goal is to perform approximate variational Bayesian Inference for Univariate Hierarchical Gaussian Filter (HGF).\n\nSimple HGF model can be defined as:\n\nbeginaligned\n  x^(j)_k  sim  mathcalN(x^(j)_k - 1 f_k(x^(j - 1)_k)) \n  y_k  sim  mathcalN(x^(j)_k tau_k)\nendaligned\n\nwhere j is an index of layer in hierarchy, k is a time step and f_k is a variance activation function. RxInfer.jl export Gaussian Controlled Variance (GCV) node with f_k = exp(kappa x + omega) variance activation function. By default the node uses Gauss-Hermite cubature with a prespecified number of approximation points in the cubature. In this demo we also show how we can change the hyperparameters in different approximation methods (iin this case Gauss-Hermite cubature) with the help of metadata structures. Here how our model will look like with the GCV node:\n\nbeginaligned\n  z_k  sim  mathcalN(z_k - 1 mathcaltau_z) \n  x_k  sim  mathcalN(x_k - 1 exp(kappa z_k + omega)) \n  y_k  sim  mathcalN(x_k mathcaltau_y)\nendaligned\n\nIn this experiment we will create a single time step of the graph and perform variational message passing filtering alrogithm to estimate hidden states of the system. For a more rigorous introduction to Hierarchical Gaussian Filter we refer to Ismail Senoz, Online Message Passing-based Inference in the Hierarchical Gaussian Filter paper.\n\nFor simplicity we will consider tau_z, tau_y, kappa and omega known and fixed, but there are no principled limitations to make them random variables too.\n\nTo model this process in RxInfer, first, we start with importing all needed packages:\n\nusing RxInfer, BenchmarkTools, Random, Plots, StableRNGs\n\nNext step, is to generate some synthetic data:\n\nfunction generate_data(rng, n, k, w, zv, yv)\n    z_prev = 0.0\n    x_prev = 0.0\n\n    z = Vector{Float64}(undef, n)\n    v = Vector{Float64}(undef, n)\n    x = Vector{Float64}(undef, n)\n    y = Vector{Float64}(undef, n)\n\n    for i in 1:n\n        z[i] = rand(rng, Normal(z_prev, sqrt(zv)))\n        v[i] = exp(k * z[i] + w)\n        x[i] = rand(rng, Normal(x_prev, sqrt(v[i])))\n        y[i] = rand(rng, Normal(x[i], sqrt(yv)))\n\n        z_prev = z[i]\n        x_prev = x[i]\n    end \n    \n    return z, x, y\nend\n\ngenerate_data (generic function with 1 method)\n\n# Seed for reproducibility\nseed = 42\n\nrng = StableRNG(seed)\n\n# Parameters of HGF process\nreal_k = 1.0\nreal_w = 0.0\nz_variance = abs2(0.2)\ny_variance = abs2(0.1)\n\n# Number of observations\nn = 300\n\nz, x, y = generate_data(rng, n, real_k, real_w, z_variance, y_variance);\n\nLet's plot our synthetic dataset. Lines represent our hidden states we want to estimate using noisy observations.\n\nlet \n    pz = plot(title = \"Hidden States Z\")\n    px = plot(title = \"Hidden States X\")\n    \n    plot!(pz, 1:n, z, label = \"z_i\", color = :orange)\n    plot!(px, 1:n, x, label = \"x_i\", color = :green)\n    scatter!(px, 1:n, y, label = \"y_i\", color = :red, ms = 2, alpha = 0.2)\n    \n    plot(pz, px, layout = @layout([ a; b ]))\nend\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/hierarchical_gaussian_filter/#Online-learning-(Filtering)","page":"Hierarchical Gaussian Filter","title":"Online learning (Filtering)","text":"To create a model we use the @model macro:\n\n# We create a single-time step of corresponding state-space process to\n# perform online learning (filtering)\n@model function hgf(y, Œ∫, œâ, z_variance, y_variance, z_prev_mean, z_prev_var, x_prev_mean, x_prev_var)\n\n    z_prev ~ Normal(mean = z_prev_mean, variance = z_prev_var)\n    x_prev ~ Normal(mean = x_prev_mean, variance = x_prev_var)\n\n    # Higher layer is modelled as a random walk \n    z_next ~ Normal(mean = z_prev, variance = z_variance)\n    \n    # Lower layer is modelled with `GCV` node\n    x_next ~ GCV(x_prev, z_next, Œ∫, œâ)\n    \n    # Noisy observations \n    y ~ Normal(mean = x_next, variance = y_variance)\nend\n\n@constraints function hgfconstraints() \n    # Mean-field factorization constraints\n    q(x_next, x_prev, z_next) = q(x_next)q(x_prev)q(z_next)\nend\n\n@meta function hgfmeta()\n    # Lets use 31 approximation points in the Gauss Hermite cubature approximation method\n    GCV() -> GCVMetadata(GaussHermiteCubature(31)) \nend\n\nhgfmeta (generic function with 1 method)\n\nThe code below uses the infer function from RxInfer to generate the message passing algorithm given the model and constraints specification.  We also specify the @autoupdates in order to set new priors for the next observation based on posteriors.\n\nfunction run_inference(data, real_k, real_w, z_variance, y_variance)\n\n    autoupdates   = @autoupdates begin\n        # The posterior becomes the prior for the next time step\n        z_prev_mean, z_prev_var = mean_var(q(z_next))\n        x_prev_mean, x_prev_var = mean_var(q(x_next))\n    end\n\n    init = @initialization begin\n        q(x_next) = NormalMeanVariance(0.0, 5.0)\n        q(z_next) = NormalMeanVariance(0.0, 5.0)\n    end\n\n    return infer(\n        model          = hgf(Œ∫ = real_k, œâ = real_w, z_variance = z_variance, y_variance = y_variance),\n        constraints    = hgfconstraints(),\n        meta           = hgfmeta(),\n        data           = (y = data, ),\n        autoupdates    = autoupdates,\n        keephistory    = length(data),\n        historyvars    = (\n            x_next = KeepLast(),\n            z_next = KeepLast()\n        ),\n        initialization = init,\n        iterations     = 5,\n        free_energy    = true,\n    )\nend\n\nrun_inference (generic function with 1 method)\n\nEverything is ready to run the algorithm. We used the online version of the algorithm, thus we need to fetch the history of the posterior estimation instead of the actual posteriors.\n\nresult = run_inference(y, real_k, real_w, z_variance, y_variance);\n\nmz = result.history[:z_next];\nmx = result.history[:x_next];\n\nlet \n    pz = plot(title = \"Hidden States Z\")\n    px = plot(title = \"Hidden States X\")\n    \n    plot!(pz, 1:n, z, label = \"z_i\", color = :orange)\n    plot!(pz, 1:n, mean.(mz), ribbon = std.(mz), label = \"estimated z_i\", color = :teal)\n    \n    plot!(px, 1:n, x, label = \"x_i\", color = :green)\n    plot!(px, 1:n, mean.(mx), ribbon = std.(mx), label = \"estimated x_i\", color = :violet)\n    \n    plot(pz, px, layout = @layout([ a; b ]))\nend\n\n(Image: )\n\nAs we can see from our plot, estimated signal resembles closely to the real hidden states with small variance. We maybe also interested in the values for Bethe Free Energy functional:\n\nplot(result.free_energy_history, label = \"Bethe Free Energy\")\n\n(Image: )\n\nAs we can see BetheFreeEnergy converges nicely to a stable point. ","category":"section"},{"location":"categories/problem_specific/hierarchical_gaussian_filter/#Offline-learning-(Smoothing)","page":"Hierarchical Gaussian Filter","title":"Offline learning (Smoothing)","text":"Aside from online learning, we can also perform offline learning (smoothing) with the HGF model to learn the parameters in case we have collected all the data. In this offline setting, we treat the parameters kappa and omega as random variables and place a prior over them. These parameters will be updated along with latent states during the inference. First, let's define the HGF model for offline learning\n\n#Model for offline learning (smoothing)\n\n@model function hgf_smoothing(y, z_variance, y_variance)\n    # Initial states \n    z_prev ~ Normal(mean = 0., variance = 5.0)\n    x_prev ~ Normal(mean = 0., variance = 5.0)\n\n    # Priors on Œ∫ and œâ\n    Œ∫ ~ Normal(mean = 1.5, variance = 1.0)\n    œâ ~ Normal(mean = 0.0, variance = 0.05)\n\n    for i in eachindex(y)\n        # Higher layer \n        z[i] ~ Normal(mean = z_prev, variance = z_variance)\n\n        # Lower layer \n        x[i] ~ GCV(x_prev, z[i], Œ∫, œâ)\n\n        # Noisy observations \n        y[i] ~ Normal(mean = x[i], variance = y_variance)\n\n        # Update last/previous hidden states\n        z_prev = z[i]\n        x_prev = x[i]\n    end\nend\n\n@constraints function hgfconstraints_smoothing() \n    #Structured mean-field factorization constraints\n    q(x_prev,x, z,Œ∫,œâ) = q(x_prev,x)q(z)q(Œ∫)q(œâ)\nend\n\n@meta function hgfmeta_smoothing()\n    # Lets use 31 approximation points in the Gauss Hermite cubature approximation method\n    GCV() -> GCVMetadata(GaussHermiteCubature(31)) \nend\n\nhgfmeta_smoothing (generic function with 1 method)\n\nSimilar to the filtering case, we use the infer function from RxInfer to implement inference. \n\nfunction run_inference_smoothing(data, z_variance, y_variance)\n    @initialization function hgf_init_smoothing()\n        q(x) = NormalMeanVariance(0.0,5.0)\n        q(z) = NormalMeanVariance(0.0,5.0)\n        q(Œ∫) = NormalMeanVariance(1.5,1.0)\n        q(œâ) = NormalMeanVariance(0.0,0.05)\n    end\n\n    #Let's do inference with 20 iterations \n    return infer(\n        model = hgf_smoothing(z_variance = z_variance, y_variance = y_variance,),\n        data = (y = data,),\n        meta = hgfmeta_smoothing(),\n        constraints = hgfconstraints_smoothing(),\n        initialization = hgf_init_smoothing(),\n        iterations = 20,\n        options = (limit_stack_depth = 100, ), \n        returnvars = (x = KeepLast(), z = KeepLast(),œâ=KeepLast(),Œ∫=KeepLast(),),\n        free_energy = true \n    )\nend\n\nrun_inference_smoothing (generic function with 1 method)\n\nNow we can get the result.\n\nresult_smoothing = run_inference_smoothing(y, z_variance, y_variance);\nmz_smoothing = result_smoothing.posteriors[:z];\nmx_smoothing = result_smoothing.posteriors[:x];\n\nlet \n    pz = plot(title = \"Hidden States Z\")\n    px = plot(title = \"Hidden States X\")\n    \n    plot!(pz, 1:n, z, label = \"z_i\", color = :orange)\n    plot!(pz, 1:n, mean.(mz_smoothing), ribbon = std.(mz_smoothing), label = \"estimated z_i\", color = :teal)\n    \n    plot!(px, 1:n, x, label = \"x_i\", color = :green)\n    plot!(px, 1:n, mean.(mx_smoothing), ribbon = std.(mx_smoothing), label = \"estimated x_i\", color = :violet)\n    \n    plot(pz, px, layout = @layout([ a; b ]))\nend\n\n(Image: )\n\nAs we can see from our plot, estimated signal resembles to the real hidden states and appears \"smoother\" compared to the filtering case. We may be also interested in the values for Bethe Free Energy functional:\n\nplot(result_smoothing.free_energy, label = \"Bethe Free Energy\")\n\n(Image: )\n\nFinally, we can also extract the marginals q(kappa) and q(omega) to get the appropximation of these parameters.\n\nq_Œ∫ = result_smoothing.posteriors[:Œ∫]\nq_œâ = result_smoothing.posteriors[:œâ]\n\nprintln(\"Approximate value of Œ∫: \", mean(q_Œ∫))\nprintln(\"Approximate value of œâ: \", mean(q_œâ))\n\nApproximate value of Œ∫: 0.7543386579898821\nApproximate value of œâ: -0.18164892866626792\n\nLet's visualize their marginal distributions.\n\nrange_w = range(-1,0.5,length = 1000)\nrange_k = range(0,2,length = 1000)\nlet \n    pw = plot(title = \"Marginal q(w)\")\n    pk = plot(title = \"Marginal q(k)\")\n    \n    plot!(pw, range_w, (x) -> pdf(q_œâ, x), fillalpha=0.3, fillrange = 0, label=\"Posterior q(w)\", c=3, legend_position=(0.1,0.95),legendfontsize=9)\n    vline!([real_w], label=\"Real w\")\n    xlabel!(\"w\")\n    \n    \n    plot!(pk, range_k, (x) -> pdf(q_Œ∫, x), fillalpha=0.3, fillrange = 0, label=\"Posterior q(k)\", c=3, legend_position=(0.1,0.95),legendfontsize=9)\n    vline!([real_k], label=\"Real k\")\n    xlabel!(\"k\")\n    \n    plot(pk, pw, layout = @layout([ a; b ]))\nend\n\n(Image: )\n\nAs we can see, both the marginals q(kappa) and q(omega) are not quite off from the true values. Specifically, the means of q(kappa) and q(omega) are approximately 075 and -018, respectively, which are quite close to their true values. \n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/","page":"Feature Functions In Bayesian Regression","title":"Feature Functions In Bayesian Regression","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Feature-Functions-in-Bayesian-Regression","page":"Feature Functions In Bayesian Regression","title":"Feature Functions in Bayesian Regression","text":"This notebook demonstrates how we can use probabilistic methods to learn and predict continuous functions from noisy data.\n\nThis example is inspired by Chapter 4.1 Regression from the excellent book Probabilistic Numerics by Phillip Hennig, Michael A. Osborn, and Hans P. Kersting. We'll take their theoretical foundations and bring them to life with practical code examples.\n\nThe code and narrative in this notebook is written by Dmitry Bagaev (GitHub, LinkedIn). While some explanations draw from the book's content, we'll focus on building intuition through interactive examples and visualizations.\n\nBy the end of this notebook, you'll understand:\n\nThe power of linear regression with basis functions\nHow to handle uncertainty in your predictions\nPractical implementation using Julia and RxInfer.jl\n\nWe start by importing all required packages for this example, the primary of which is of course RxInfer!\n\nusing RxInfer, StableRNGs, LinearAlgebra, Plots, DataFrames\n\nGaussian distributions (multivariate) assign probability density to vectors of real numbers - think of them as sophisticated probability maps for multiple variables at once. In numerical applications, we often encounter real-valued functions f  mathbbX rightarrow R over some input domain mathbbX (imagine predicting house prices based on features like size and location).\n\nA interesting way to use the Gaussian inference framework is to assume that f can be written as a weighted sum over a finite number F of feature functions phi_i  mathbbX rightarrow mathbbR_i=1F (much like how a house price might be a weighted combination of its features, e.g. size, number of floors, number of rooms, etc..):\n\nbeginalign\nf(x) = sum_i=1^F phi_i(x)omega_i = Phi^T_x omega  mathrmwhere  omega in mathbbR^F\nendalign\n\nAs discussed in the Probabilistic Numerics book, uncertainty is a fundamental aspect of numerical computations. When we perform regression, we are essentially solving an inverse problem - trying to infer the underlying function from noisy observations. This inherently involves uncertainty for several reasons:\n\nOur observations usually contain noise and measurement errors\nWe have a finite number of samples, leaving gaps in our knowledge\nThe true function may be more complex than our model can capture\n\nBy modeling uncertainty explicitly through a Gaussian distribution over the weights omega, we can:\n\nQuantify our confidence in predictions\nMake more robust decisions by accounting for uncertainty\nDetect when we're extrapolating beyond our data\nPropagate uncertainty on the next step in our Machine Learning pipeline\n\nMathematically, we express this uncertainty as:\n\nbeginalign\np(omega) = mathcalN(omega vert mu Sigma)\nendalign\n\nWhere mu represents our best estimate of the weights and Sigma captures our uncertainty about them.","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Dataset:-Noisy-Observations-in-the-Real-World","page":"Feature Functions In Bayesian Regression","title":"Dataset: Noisy Observations in the Real World","text":"In real-world scenarios, we rarely have access to perfect measurements. Instead, we collect observations Y = y_1 cdots  y_N  in mathbbR that are corrupted by Gaussian noise - a common and mathematically convenient way to model measurement uncertainty. These noisy samples of our target function f are taken at specific input locations X, with the noise characterized by a covariance matrix Lambda  mathbbR^NN. This setup mirrors many practical applications, from sensor measurements to experimental data collection.\n\nLet's assume we have collected noisy measurenets Y at locations X:\n\nN = 40\nŒõ = I\nX = range(-8, 8, length=N)\n\nrng = StableRNG(42)\n\n# Arbitrary non-linear function, which is hidden\nf(x) = -((-x / 3)^3 - (-x / 2)^2 + x + 10) \n\nY = rand(rng, MvNormalMeanCovariance(f.(X), Œõ))\n\n# Can be loaded from a file or a database\ndf = DataFrame(X = X, Y = Y)\n\n40√ó2 DataFrame\n Row ‚îÇ X         Y\n     ‚îÇ Float64   Float64\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ -8.0      -5.63321\n   2 ‚îÇ -7.58974  -3.75472\n   3 ‚îÇ -7.17949  -2.26681\n   4 ‚îÇ -6.76923  -1.95387\n   5 ‚îÇ -6.35897  -2.92934\n   6 ‚îÇ -5.94872  -2.31714\n   7 ‚îÇ -5.53846  -4.10432\n   8 ‚îÇ -5.12821  -4.08565\n  ‚ãÆ  ‚îÇ    ‚ãÆ         ‚ãÆ\n  34 ‚îÇ  5.53846  -1.5234\n  35 ‚îÇ  5.94872   0.98319\n  36 ‚îÇ  6.35897   3.86051\n  37 ‚îÇ  6.76923   4.48039\n  38 ‚îÇ  7.17949   8.71697\n  39 ‚îÇ  7.58974  12.703\n  40 ‚îÇ  8.0      19.0635\n           25 rows omitted","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Train-and-Test-Dataset-Configurations","page":"Feature Functions In Bayesian Regression","title":"Train & Test Dataset Configurations","text":"To thoroughly evaluate our model's performance and robustness, we'll create three distinct train-test splits of our data. This approach helps us understand how well our model generalizes to different regions of the input space and whether it can effectively capture the underlying patterns regardless of which portions of the data it learns from.\n\nWe'll explore the following configurations:\n\nForward Split: Uses the first half for training and second half for testing, evaluating the model's ability to extrapolate to higher x-values\nReverse Split: Uses the first half for testing and second half for training, testing extrapolation to lower x-values\nInterleaved Split: Uses first and last quarters for training and middle portion for testing, assessing interpolation capabilities\n\nThese diverse splits will help reveal any biases in our model and ensure it performs consistently across different regions of the input space. They also allow us to evaluate both interpolation (predicting within the training range) and extrapolation (predicting outside the training range) capabilities.\n\n# Split data into train/test sets\n# Forward split - first half train, second half test\ndataset_1 = let mid = N √∑ 2\n    (\n        y_train = Y[1:mid], x_train = X[1:mid],\n        y_test = Y[mid+1:end], x_test = X[mid+1:end]\n    )\nend\n\n# Reverse split - first half test, second half train  \ndataset_2 = let mid = N √∑ 2\n    (\n        y_test = Y[1:mid], x_test = X[1:mid],\n        y_train = Y[mid+1:end], x_train = X[mid+1:end]\n    )\nend\n\n# Interleaved split - first/last quarters train, middle half test\ndataset_3 = let q1 = N √∑ 4, q3 = 3N √∑ 4\n    (\n        y_train = [Y[1:q1]..., Y[q3+1:end]...],\n        x_train = [X[1:q1]..., X[q3+1:end]...],\n        y_test = Y[q1+1:q3],\n        x_test = X[q1+1:q3]\n    )\nend\n\ndatasets = [dataset_1, dataset_2, dataset_3]\n\n# Create visualization for each dataset split\nps = map(enumerate(datasets)) do (i, dataset)\n    p = plot(\n        xlim = (-10, 10), \n        ylim = (-30, 30),\n        title = \"Dataset $i\",\n        xlabel = \"x\",\n        ylabel = \"y\"\n    )\n    scatter!(p, \n        dataset[:x_train], dataset[:y_train],\n        yerror = Œõ,\n        label = \"Train dataset\",\n        color = :blue,\n        markersize = 4\n    )\n    scatter!(p,\n        dataset[:x_test], dataset[:y_test], \n        yerror = Œõ,\n        label = \"Test dataset\",\n        color = :red,\n        markersize = 4\n    )\n    return p\nend\n\nplot(ps..., size = (1200, 400), layout = @layout([a b c]))\n\n(Image: )\n\nThe datasets above provide nonlinear data with independent and identically distributed (i.i.d.) Gaussian observation noise, where we set the noise covariance Œõ = I (identity matrix).","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Bayesian-Inference-with-RxInfer","page":"Feature Functions In Bayesian Regression","title":"Bayesian Inference with RxInfer","text":"Our exciting challenge is to uncover the probability distribution over the parameter vector omega, given our basis functions phi and observed data points (XY). To tackle this, we'll harness the power of probabilistic programming by constructing an elegant generative model using RxInfer's @model macro. The beauty of this approach lies in its simplicity - we can express our entire model in just a few lines of code:\n\n@model function parametric_regression(œïs, x, y, Œº, Œ£, Œõ)\n    # Prior distribution over parameters œâ\n    œâ ~ MvNormal(mean = Œº, covariance = Œ£)\n    \n    # Design matrix Œ¶‚Çì where each element is œï·µ¢(x‚±º)\n    Œ¶‚Çì = [œï(x·µ¢) for x·µ¢ in x, œï in œïs]\n    \n    # Likelihood of observations y given parameters œâ\n    y ~ MvNormal(mean = Œ¶‚Çì * œâ, covariance = Œõ)\nend\n\nLet's break down the key components of our probabilistic model:\n\nphimathrms\ncontains our basis functions phi_i - these are the building blocks of our model\nx\nholds the input locations X where we've made observations. Think of these as the points along the x-axis where we've collected data, like timestamps or spatial coordinates.\ny\ncontains our noisy measurements at each location in X.\nmu\ndefines our prior beliefs about the average values of the parameters omega. Setting mu = 0 indicates we believe the parameters are centered around zero before seeing any data.\nSigma\nencodes our uncertainty about omega before seeing data. A larger Sigma means we're more uncertain, while smaller values indicate stronger prior beliefs.\nLambda\nrepresents the noise in our observations. For example, Lambda = 01I suggests our measurements have small, independent Gaussian noise, while larger values indicate noisier data.\n\nTo put this model to work, we'll use RxInfer's powerful infer function. Here's how:\n\nfunction infer_œâ(; œïs, x, y)\n    # Create probabilistic model, \n    # RxInfer will construct the graph of this model auutomatically\n    model = parametric_regression(\n        œïs = œïs, \n        Œº  = zeros(length(œïs)),\n        Œ£  = I,\n        Œõ  = I,\n        x  = x\n    )\n\n    # Let RxInfer do all the math for you\n    result = infer(\n        model = model, \n        data  = (y = y,)\n    )\n\n    # Return posterior over œâ\n    return result.posteriors[:œâ]\nend\n\ninfer_œâ (generic function with 1 method)","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#How-to-choose-basis-functions?","page":"Feature Functions In Bayesian Regression","title":"How to choose basis functions?","text":"Just like how choosing between pizza toppings can make or break your dinner, the choice of basis functions phi_i  can dramatically impact our results! Think of basis functions as the building blocks of our mathematical LEGO set -  pick the wrong pieces and your model might end up looking more like abstract art than a useful predictor.\n\nWhy does this matter? Because these functions are the \"vocabulary\" our model uses to describe the patterns in our data. Choose a too-simple vocabulary and your model will sound like a caveman (\"data go up, data go down\"). Choose one that's  too complex and it might start speaking mathematical gibberish!\n\nLet's embark on a thrilling journey through different datasets with various basis function choices. We'll create a  handy function that will:\n\nTake our basis functions for a test drive üöó\nRun inference on multiple datasets defined above\nCreate beautiful plots that would make any statistician swoon\n\n(RxInfer makes it so easy to perform Bayesian inference so I have more time to make beautiful plots!)\n\nfunction plot_inference_results_for(; œïs, datasets, title = \"\", rng = StableRNG(42))\n    # Create main plot showing basis functions\n    p1 = plot(\n        title = \"Basis functions: $(title)\", \n        xlabel = \"x\",\n        ylabel = \"y\",\n        xlim = (-5, 5), \n        ylim = (-10, 10),\n        legend = :outertopleft,\n        grid = true,\n        fontfamily = \"Computer Modern\"\n    )\n\n    # Plot basis functions in gray\n    plot_œï!(p1, œïs, color = :gray, alpha = 0.5, \n            labels = [\"œï$i\" for _ in 1:1, i in 1:length(œïs)])\n    \n    # Add examples with random œâ values\n    plot_œï!(p1, œïs, randn(rng, length(œïs), 3), \n            linewidth = 2)\n\n    # Create subplot for each dataset\n    ps = map(enumerate(datasets)) do (i, dataset)\n        p2 = plot(\n            title = \"Dataset #$(i): $(title)\",\n            xlabel = \"x\",\n            ylabel = \"y\", \n            xlim = (-10, 10),\n            ylim = (-25, 25),\n            grid = true,\n            fontfamily = \"Computer Modern\"\n        )\n\n        # Infer posterior over œâ\n        œâs = infer_œâ(\n            œïs = œïs, \n            x = dataset[:x_train], \n            y = dataset[:y_train]\n        )\n\n        # Plot posterior mean\n        plot_œï!(p2, œïs, mean(œâs),\n                linewidth = 3,\n                color = :green,\n                labels = \"Posterior mean\")\n\n        # Plot posterior samples\n        plot_œï!(p2, œïs, rand(œâs, 15),\n                linewidth = 1,\n                color = :gray,\n                alpha = 0.4,\n                labels = nothing)\n\n        # Add data points\n        scatter!(p2, dataset[:x_train], dataset[:y_train],\n                yerror = Œõ,\n                label = \"Training data\",\n                color = :royalblue,\n                markersize = 4)\n        scatter!(p2, dataset[:x_test], dataset[:y_test],\n                yerror = Œõ,\n                label = \"Test data\", \n                color = :crimson,\n                markersize = 4)\n\n        return p2\n    end\n\n    # Combine all plots\n    plot(p1, ps..., \n         size = (1000, 800),\n         margin = 5Plots.mm,\n         layout = (2,2))\nend\n\n# Helper function to plot basis functions\nfunction plot_œï!(p, œïs; rl = -10, rr = 10, kwargs...)\n    xs = range(rl, rr, length = 200)\n    ys = [œï(x) for x in xs, œï in œïs]\n    plot!(p, xs, ys; kwargs...)\nend\n\n# Helper function to plot function with given weights\nfunction plot_œï!(p, œïs, œâs; rl = -10, rr = 10, kwargs...)\n    xs = range(rl, rr, length = 200)\n    ys = [œï(x) for x in xs, œï in œïs]\n    yr = ys * œâs\n    labels = [\"Sample $i\" for _ in 1:1, i in 1:size(œâs,2)]\n    plot!(p, xs, yr, labels = labels; kwargs...)\nend\n\nplot_œï! (generic function with 2 methods)\n\nPhew! We've finally escaped the plotting purgatory - you know it's bad when the visualization code is longer than the actual inference code! But fear not, dear reader, for we're about to dive into the juicy stuff. Grab your statistical popcorn, because the real fun is about to begin!","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Polynomials:-The-Building-Blocks-of-Function-Approximation","page":"Feature Functions In Bayesian Regression","title":"Polynomials: The Building Blocks of Function Approximation","text":"Let's start our exploration with one of the most fundamental and elegant choices for basis functions: polynomials. These simple yet powerful functions form the backbone of many approximation techniques in mathematics and machine learning.\n\nFor our polynomial basis functions phi_i, we'll use the classic form:\n\nbeginalign\nphi_i(x) = x^i\nendalign\n\nwhere i represents the degree of each polynomial term. This gives us a sequence of increasingly complex functions: constant (x^0 = 1), linear (x^1), quadratic (x^2), cubic (x^3), and so on. When combined with appropriate weights omega, these basis functions can approximate a wide variety of smooth functions - a result famously known as the Weierstrass approximation theorem.\n\nLet's witness the magic of RxInfer as it efficiently infers the posterior distribution over the weights omega using these polynomial basis functions. The beauty of this approach lies in how it automatically determines the contribution of each polynomial term to fit our data.\n\nplot_inference_results_for(\n    title    = \"polynomials\",\n    datasets = datasets,\n    œïs       = [ (x) -> x ^ i for i in 0:5 ], \n)\n\n(Image: )\n\nLet's break down what we're seeing in these fascinating plots! The first plot (in gray) reveals our polynomial basis functions in their raw form - from constant to quintic terms. Overlaid on these are some example functions generated by combining these basis functions with random weights œâ, giving us a glimpse of the expressive power of polynomial approximation.\n\nThe subsequent plots demonstrate how our model performs inference on different datasets. Notice how the posterior distribution (shown by the shaded region) adapts to capture the uncertainty in different regions of the input space. It's particularly interesting to observe how the model's predictions change when faced with different training and test sets - a beautiful illustration of how the learning process is influenced by the data we feed it.\n\nWhile polynomials have served us well here, they're just one tool in our mathematical toolbox. Ready to explore some alternative basis functions that might capture different aspects of our target function? Let's dive into some exciting alternatives!","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Trigonometric-Functions:-Catch-Some-Waves","page":"Feature Functions In Bayesian Regression","title":"Trigonometric Functions: Catch Some Waves","text":"While polynomials are great (and we love them dearly), sometimes life isn't just about going up and down in straight-ish lines. Sometimes, we need to embrace our inner surfer and catch some waves! Enter trigonometric functions - the mathematical world's answer to the question \"What if everything just went round and round?\"\n\nTrigonometric functions, particularly sin and cos, have been the backbone of mathematical analysis since ancient times. From describing planetary motions to analyzing sound waves, these periodic functions have a special place in the mathematician's heart. Their ability to represent cyclic patterns makes them particularly powerful for approximating periodic phenomena - something our polynomial friends from earlier might struggle with (imagine a polynomial trying to do the wave at a sports event - awkward!).\n\nFor our basis functions, we'll use scaled versions of sine and cosine:\n\nbeginalign\nphi_i(x) = mathrmsin(fracxi) \nendalign\n\nbeginalign\nphi_i(x) = mathrmcos(fracxi)\nendalign\n\nwhere i acts as a frequency scaling factor. As i increases, our waves become more stretched out, giving us different frequencies to work with. Think of it as having an orchestra where each instrument plays the same tune but at different tempos!\n\nLet's start by riding the sine wave alone (no cosine jealousy please!) for i = 15. Will these wavy functions give our polynomial predecessors a run for their money? Let's find out!\n\nplot_inference_results_for(\n    title    = \"trigonometric sin\",\n    datasets = datasets,\n    œïs       = [ (x) -> sin(x / i) for i in 1:8 ], \n)\n\n(Image: )\n\nNow let's examine the results using cosine basis functions\n\nplot_inference_results_for(\n    title    = \"trigonometric cos\",\n    datasets = datasets,\n    œïs       = [ (x) -> cos(x / i) for i in 1:8 ], \n)\n\n(Image: )\n\nAnd for our grand finale, let's combine both sin and cos - because two waves are better than one! (Just don't tell that to particle-wave duality...)\n\nplot_inference_results_for(\n    title    = \"trigonometric sin & cos\",\n    datasets = datasets,\n    œïs       = [\n        [ (x) -> sin(x / i) for i in 1:4 ]...,\n        [ (x) -> cos(x / i) for i in 1:4 ]...,\n    ], \n)\n\n(Image: )\n\nIncredible! RxInfer proved to be quite the adaptable fellow - it handled these different basis functions without missing a beat. The results speak for themselves: our sine and cosine tag team performed remarkably well for this example. I guess you could say they really found their wavelength!","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Comparing-Model-Performance-via-Log-Evidence","page":"Feature Functions In Bayesian Regression","title":"Comparing Model Performance via Log-Evidence","text":"Now that we've explored different basis functions, let's quantitatively evaluate their performance using Free Energy, also known as negative log-evidence or negative Evidence Lower BOund (ELBO). RxInfer can compute Free Energy values when requested, which serve as a principled way to compare different models.\n\nFree Energy has several important properties:\n\nIt acts as a proxy for negative log model evidence P(y|model)\nLower values indicate better model fit, balancing complexity and data fit\nIt automatically implements Occam's Razor by penalizing overly complex models\n\nFor example, if we have:\n\nModel A: Free Energy = 100\nModel B: Free Energy = 50\n\nThen Model B provides a better explanation of the data, as exp(-50) > exp(-100).\n\nLet's analyze the Free Energy values for our polynomial and trigonometric basis functions to determine which model class provides the best explanation of our data. We'll check:\n\nPure sine basis functions\nPure cosine basis functions  \nCombined sine and cosine basis functions\n\nThis will help us quantitatively validate our earlier visual assessments.\n\n# Combine the function definition with the usage\nfunction infer_œâ_but_return_free_energy(; œïs, x, y)\n    result = infer(\n        model = parametric_regression(\n            œïs = œïs, \n            Œº  = zeros(length(œïs)),\n            Œ£  = I,\n            Œõ  = I,\n            x  = x\n        ), \n        data  = (y = y,),\n        free_energy = true\n    )\n    return first(result.free_energy)\nend\n\ndfs = map(enumerate(datasets)) do (i, dataset)\n    # Generate basis functions\n    sin_bases = [(x) -> sin(x / i) for i in 1:8]\n    cos_bases = [(x) -> cos(x / i) for i in 1:8]\n    combined_bases = [\n        [(x) -> sin(x / i) for i in 1:4]...,\n        [(x) -> cos(x / i) for i in 1:4]...\n    ]\n\n    # Calculate free energy for each basis\n    energies = [\n        infer_œâ_but_return_free_energy(œïs=sin_bases, x=dataset[:x_train], y=dataset[:y_train]),\n        infer_œâ_but_return_free_energy(œïs=cos_bases, x=dataset[:x_train], y=dataset[:y_train]),\n        infer_œâ_but_return_free_energy(œïs=combined_bases, x=dataset[:x_train], y=dataset[:y_train])\n    ]\n\n    # Create DataFrame row\n    DataFrame(\n        dataset = fill(i, 3),\n        fns = [:sin, :cos, :sin_cos],\n        free_energy = energies\n    )\nend\n\nvcat(dfs...)\n\n9√ó3 DataFrame\n Row ‚îÇ dataset  fns      free_energy\n     ‚îÇ Int64    Symbol   Float64\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ       1  sin          74.6271\n   2 ‚îÇ       1  cos          44.3858\n   3 ‚îÇ       1  sin_cos      49.3385\n   4 ‚îÇ       2  sin         943.507\n   5 ‚îÇ       2  cos         107.092\n   6 ‚îÇ       2  sin_cos      93.3269\n   7 ‚îÇ       3  sin          83.0291\n   8 ‚îÇ       3  cos          53.7804\n   9 ‚îÇ       3  sin_cos      70.1097\n\nThe results demonstrate that the choice of basis functions plays a significant role, as evidenced by the varying values of the Free Energy function. For dataset 1, cosine-based basis functions perform better than both sine-based and combined sine-cosine basis functions. Meanwhile, for dataset 3, the combination of sine and cosine basis functions yields superior results.\n\nHowever, why limit ourselves to polynomials and trigonometric functions? Let's explore other possibilities!","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Switch-Functions:-A-Binary-Approach-to-Basis-Functions","page":"Feature Functions In Bayesian Regression","title":"Switch Functions: A Binary Approach to Basis Functions","text":"Let's explore an intriguing and perhaps unconventional choice for basis functions: the switch functions. These functions, despite their simplicity, can be remarkably effective in certain scenarios.\n\nA switch function essentially divides the input space into two regions, outputting either +1 or -1 based on which side of a threshold the input falls. Mathematically, we define it as:\n\nbeginalign\nphi_i(x) = mathrmsign(x - i)\nendalign\n\nwhere i serves as the threshold point. The function returns +1 when x  i and -1 when x  i. This creates a sharp \"switch\" at x = i, hence the name.\n\nWhat makes these functions particularly interesting is their ability to capture discontinuities and sharp transitions in the data. By combining multiple switch functions with different threshold points, we can approximate complex patterns through a series of binary decisions.\n\nLet's see how these switch functions perform on our datasets!\n\nplot_inference_results_for(\n    title    = \"switches\",\n    datasets = datasets,\n    œïs       = [ (x) -> sign(x - i) for i in -8:8 ], \n)\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Step-Functions:-A-Binary-Leap-Forward","page":"Feature Functions In Bayesian Regression","title":"Step Functions: A Binary Leap Forward","text":"Let's explore another fascinating class of basis functions: step functions. Also known as Heaviside functions, these elegant mathematical constructs make a dramatic jump from 0 to 1 at a specific threshold point.\n\nMathematically, we define our step basis functions as:\n\nbeginalign\nphi_i(x) = mathbbI(x - i  0)\nendalign\n\nwhere mathbbI is the indicator function that equals 1 when its argument is true and 0 otherwise. Unlike the switch functions we saw earlier, step functions provide a unidirectional transition, making them particularly useful for modeling data with distinct regimes or threshold effects.\n\nplot_inference_results_for(\n    title    = \"steps\",\n    datasets = datasets,\n    œïs       = [ (x) -> ifelse(x - i > 0, 1.0, 0.0) for i in -8:8 ], \n)\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Linear-Basis-Functions:-A-Classic-Twist","page":"Feature Functions In Bayesian Regression","title":"Linear Basis Functions: A Classic Twist","text":"Here's an intriguing proposition: what if we used linear functions as our basis functions in linear regression? While it might sound redundant at first, this approach offers a fascinating perspective. By centering linear functions at different points, we create a rich set of features that can capture both local and global trends in our data.\n\nThe basis functions take the form:\n\nbeginalign\nphi_i(x) = vert x - i vert\nendalign\n\nwhere each function measures the absolute distance from a reference point i. This creates a V-shaped function centered at each point, allowing us to model both increasing and decreasing trends with remarkable flexibility.\n\nplot_inference_results_for(\n    title    = \"linears\",\n    datasets = datasets,\n    œïs       = [ (x) -> abs(x - i) for i in -8:8 ], \n)\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Absolute-Exponential-Functions:-Elegantly-Decaying-Distance","page":"Feature Functions In Bayesian Regression","title":"Absolute Exponential Functions: Elegantly Decaying Distance","text":"Let's venture into the realm of absolute exponential functions, a fascinating class of basis functions that elegantly capture the notion of distance-based influence. These functions, also known as Laplace kernels in some contexts, decay exponentially with the absolute distance from their center points.\n\nThe mathematical formulation reveals their elegant simplicity:\n\nbeginalign\nphi_i(x) = e^-vert x - i vert\nendalign\n\nThis expression creates a peaked function that reaches its maximum of 1 at x = i and smoothly decays in both directions, providing a natural way to model localized influences that diminish with distance.\n\nplot_inference_results_for(\n    title    = \"abs exps\",\n    datasets = datasets,\n    œïs       = [ (x) -> exp(-abs(x - i)) for i in -8:8 ], \n)\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Squared-Exponential-Functions:-The-Gaussian-Bell-Curves","page":"Feature Functions In Bayesian Regression","title":"Squared Exponential Functions: The Gaussian Bell Curves","text":"Let's explore another one of the most elegant and widely-used basis functions in machine learning - the squared exponential, also known as the Gaussian or radial basis function. These functions create perfect bell curves that smoothly decay in all directions from their centers.\n\nThe mathematical form reveals their graceful symmetry:\n\nbeginalign\nphi_i(x) = e^-(x - i)^2\nendalign\n\nThese functions have remarkable properties - they're infinitely differentiable and create ultra-smooth interpolations between points. Their rapid decay also provides natural localization, making them excellent choices for capturing both local and global patterns in data.\n\nplot_inference_results_for(\n    title    = \"sqrt exps\",\n    datasets = datasets,\n    œïs       = [ (x) -> exp(-(x - i) ^ 2) for i in -8:8 ], \n)\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Sigmoid-Functions:-The-Neural-Network's-Activation","page":"Feature Functions In Bayesian Regression","title":"Sigmoid Functions: The Neural Network's Activation","text":"The sigmoid function, a cornerstone of neural network architectures, offers another fascinating basis for our exploration. This S-shaped curve elegantly transitions between two asymptotic values, creating a smooth, differentiable \"step\" that's invaluable in modeling transitions and decision boundaries.\n\nThe mathematical elegance of the sigmoid reveals itself in its formula:\n\nbeginalign\nphi_i(x) = frac11 + e^-3(x - 1)\nendalign\n\nThis function's graceful transition from 0 to 1 makes it particularly well-suited for capturing threshold phenomena and modeling probability-like quantities. Its bounded nature also provides natural regularization, preventing the explosive growth that can plague polynomial bases.\n\nplot_inference_results_for(\n    title    = \"sigmoids\",\n    datasets = datasets,\n    œïs       = [ (x) -> 1 / (1 + exp(-3 * (x - i))) for i in -8:8 ], \n)\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#The-Power-of-Combination:-Using-Different-Classes-of-Basis-Functions-Together","page":"Feature Functions In Bayesian Regression","title":"The Power of Combination: Using Different Classes of Basis Functions Together","text":"What if we could harness the unique strengths of different basis functions we've explored? By combining polynomials, trigonometric functions, squared exponentials, and sigmoids, we can create an incredibly flexible and expressive basis that captures both global trends and local patterns. The polynomials can handle overall growth patterns, trigonometric functions can capture periodic behavior, squared exponentials can provide smooth local interpolation, and sigmoids can model sharp transitions. This combined approach leverages the best of each basis function family, potentially leading to more robust and accurate predictions. And here how easy it is to do so!\n\n# Combine all basis functions we've explored into one powerful basis\ncombined_basis = vcat(\n    # Polynomials (from first example)\n    [ (x) -> x ^ i for i in 0:5 ],\n    \n    # Trigonometric functions (from second example) \n    [ (x) -> sin(i*x) for i in 1:3 ],\n    [ (x) -> cos(i*x) for i in 1:3 ],\n    \n    # Squared exponentials (from seventh example)\n    [ (x) -> exp(-(x - i)^2) for i in -8:8 ],\n    \n    # Sigmoids (from eighth example)\n    [ (x) -> 1 / (1 + exp(-3 * (x - i))) for i in -8:8 ]\n)\n\nplot_inference_results_for(\n    title    = \"combined\",\n    datasets = datasets,\n    œïs       = combined_basis, \n)\n\n(Image: )\n\nNow that we've combined these different basis functions, it's interesting to explore how this powerful ensemble performs on our complete dataset. By visualizing the posterior distribution over functions induced by this combined basis, we can see how it leverages the unique characteristics of each basis type - the global trends captured by polynomials, the periodic patterns from trigonometric functions, the local smoothness from squared exponentials, and the sharp transitions enabled by sigmoids. Let's plot the results to see this rich expressiveness in action.\n\ncombined_basis_œâs_all_data = infer_œâ(œïs = combined_basis, x = X, y = Y)\n\n# Left plot - local region\np1 = plot(\n    title = \"Local region\",\n    xlabel = \"x\",\n    ylabel = \"y\",\n    xlim = (-10, 10),\n    ylim = (-20, 20),\n    grid = true\n)\n\n# Plot posterior mean\nplot_œï!(p1, combined_basis, mean(combined_basis_œâs_all_data),\n    rl = -10,\n    rr = 10,\n    linewidth = 3,\n    color     = :green,\n    labels    = \"Posterior mean\"\n)\n\n# Plot posterior samples (in gray)\nplot_œï!(p1, combined_basis, rand(combined_basis_œâs_all_data, 50),\n    rl = -10,\n    rr = 10,\n    linewidth = 1,\n    color     = :gray,\n    alpha     = 0.4,\n    labels    = nothing\n)\n\n# Plot data points\nscatter!(p1, X, Y,\n    yerror     = Œõ,\n    label      = \"Data\",\n    color      = :royalblue,\n    markersize = 4\n)\n\n# Right plot - bigger region\np2 = plot(\n    title = \"Extended region\",\n    xlabel = \"x\",\n    ylabel = \"y\",\n    xlim = (-30, 30),\n    ylim = (-75, 75),\n    grid = true\n)\n\n# Plot posterior mean\nplot_œï!(p2, combined_basis, mean(combined_basis_œâs_all_data),\n    rl = -30,\n    rr = 30,\n    linewidth = 3,\n    color     = :green,\n    labels    = \"Posterior mean\"\n)\n\n# Plot posterior samples (in gray)\nplot_œï!(p2, combined_basis, rand(combined_basis_œâs_all_data, 50),\n    rl = -30,\n    rr = 30,\n    linewidth = 1,\n    color     = :gray,\n    alpha     = 0.4,\n    labels    = nothing\n)\n\n# Plot data points\nscatter!(p2, X, Y,\n    label      = \"Data\", \n    color      = :royalblue,\n    markersize = 2\n)\n\np = plot(p1, p2, layout=(1,2), size=(1000,400), fontfamily = \"Computer Modern\")\n\n(Image: )\n\nThe plot above beautifully demonstrates the expressive power of combining multiple basis functions. The posterior mean (shown in green) captures both the global trend and local variations in the data with remarkable accuracy. The gray lines, representing samples from the posterior distribution, illustrate the model's uncertainty - tighter in regions with more data points and wider in sparse regions. This combined basis approach leverages the strengths of each basis type: polynomials handle the overall trend, trigonometric functions capture periodic components, and localized basis functions manage fine details. The result is a flexible and robust model that adapts well to the complex patterns in our dataset.","category":"section"},{"location":"categories/basic_examples/feature_functions_in_bayesian_regression/#Performance:-The-Need-for-Speed!","page":"Feature Functions In Bayesian Regression","title":"Performance: The Need for Speed! üèéÔ∏è","text":"Alright, we've been having a blast playing with different basis functions, and RxInfer has been crunching those posterior calculations faster than you can say \"Bayesian inference\". But just how zippy is it really? Let's put our mathematical hot rod through its paces with our trusty polynomial basis functions and see what kind of speed records we can break! üèÅ\n\nusing BenchmarkTools\n\nIn Julia, benchmarking is made easy with the BenchmarkTools package. The @benchmark macro runs the given expression multiple times to get statistically meaningful results. It provides detailed statistics about execution time, memory allocations, and garbage collection overhead. The output shows minimum, maximum, median and mean execution times, along with a nice histogram visualization of the timing distribution.\n\n@benchmark infer_œâ(œïs = $([ (x) -> x ^ i for i in 0:5 ]), x = $(datasets[1][:x_train]), y = $(datasets[1][:y_train]))\n\nBenchmarkTools.Trial: 10000 samples with 1 evaluation per sample.\n Range (min ‚Ä¶ max):  263.633 Œºs ‚Ä¶  35.417 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 98.\n05%\n Time  (median):     343.676 Œºs               ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   362.987 Œºs ¬± 512.769 Œºs  ‚îä GC (mean ¬± œÉ):  1.81% ¬±  1.\n38%\n\n    ‚ñÅ‚ñÑ‚ñÉ  ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñá‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÅ                                     \n  ‚ñÉ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ ‚ñÖ\n  264 Œºs           Histogram: frequency by time          550 Œºs <\n\n Memory estimate: 85.09 KiB, allocs estimate: 1494.\n\nLet's benchmark inference on a larger dataset with 10,000 datapoints to test scalability.\n\nN_benchmark = 10_000\nX_benchmark = range(-8, 8, length=N_benchmark)\nY_benchmark = rand(rng, MvNormalMeanCovariance(f.(X_benchmark), Œõ));\n\n@benchmark infer_œâ(œïs = $([ (x) -> x ^ i for i in 0:5 ]), x = $(X_benchmark), y = $(Y_benchmark))\n\nBenchmarkTools.Trial: 8 samples with 1 evaluation per sample.\n Range (min ‚Ä¶ max):  629.052 ms ‚Ä¶ 709.425 ms  ‚îä GC (min ‚Ä¶ max): 0.00% ‚Ä¶ 0.0\n0%\n Time  (median):     635.556 ms               ‚îä GC (median):    0.00%\n Time  (mean ¬± œÉ):   644.265 ms ¬±  26.574 ms  ‚îä GC (mean ¬± œÉ):  0.00% ¬± 0.0\n0%\n\n  ‚ñÅ‚ñÅ ‚ñÅ‚ñà  ‚ñÅ‚ñÅ                                                   ‚ñÅ  \n  ‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà ‚ñÅ\n  629 ms           Histogram: frequency by time          709 ms <\n\n Memory estimate: 1.15 MiB, allocs estimate: 1498.\n\nAnd that's a wrap! From exploring different basis functions (polynomials, trigonometric functions, and even those fancy sigmoids) to performing lightning-fast Bayesian inference, we've seen how RxInfer handles parametric Gaussian regression with style. The benchmarks don't lie - processing 10,000 datapoints in a blast while keeping memory usage lean? That's not just fast, that's \"blink and you'll miss it\" fast! \n\nThroughout this notebook, we've gone from basic data generation to sophisticated model inference, all while keeping things both mathematically rigorous and computationally efficient. Whether you're a Bayesian enthusiast or just someone who appreciates elegant mathematical machinery, this journey through parametric Gaussian regression shows that probabilistic programming doesn't have to be slow or memory-hungry.\n\nThanks again to the authors of \"Probabilistic Numerics: Computation as Machine Learning\" for providing the theoretical foundations and inspiration for this notebook!\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [a93c6f00] DataFrames v1.8.1\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/advanced_examples/chance_constraints/","page":"Chance Constraints","title":"Chance Constraints","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/chance_constraints/#Chance-Constrained-Active-Inference","page":"Chance Constraints","title":"Chance-Constrained Active Inference","text":"This notebook applies reactive message passing for active inference in the context of chance-constraints. The implementation is based on (van de Laar et al., 2021, \"Chance-constrained active inference\") and discussion with John Boik.\n\nWe consider a 1-D agent that tries to elevate itself above ground level. Instead of a goal prior, we impose a chance constraint on future states, such that the agent prefers to avoid the ground with a preset probability (chance) level. \n\nusing Plots, Distributions, StatsFuns, RxInfer","category":"section"},{"location":"categories/advanced_examples/chance_constraints/#Chance-Constraint-Node-Definition","page":"Chance Constraints","title":"Chance-Constraint Node Definition","text":"A chance-constraint is meant to constraint a marginal distribution to abide by certain properties. In this case, a (posterior) probability distribution should not \"overflow\" a given region by more than a certain probability mass. This constraint then affects adjacent beliefs and ultimately the controls to (hopefully) account for the imposed constraint.\n\nIn order to enforce this constraint on a marginal distribution, an auxiliary chance-constraint node is included in the graphical model. This node then sends messages that enforce the marginal to abide by the preset conditions. In other words, the (chance) constraint on the (posterior) marginal, is converted to a prior constraint on the generative model that sends an adaptive message. We start by defining this chance-constraint node and its message.\n\nstruct ChanceConstraint end  \n\n# Node definition with safe region limits (lo, hi), overflow chance epsilon and tolerance atol\n@node ChanceConstraint Stochastic [out, lo, hi, epsilon, atol]\n\n# Function to compute normalizing constant and central moments of a truncated Gaussian distribution\nfunction truncatedGaussianMoments(m::Float64, V::Float64, a::Float64, b::Float64)\n    V = clamp(V, tiny, huge)\n    StdG = Distributions.Normal(m, sqrt(V))\n    TrG = Distributions.Truncated(StdG, a, b)\n    \n    Z = Distributions.cdf(StdG, b) - Distributions.cdf(StdG, a)  # safe mass for standard Gaussian\n    \n    if Z < tiny\n        # Invalid region; return undefined mean and variance of truncated distribution\n        Z    = 0.0\n        m_tr = 0.0\n        V_tr = 0.0\n    else\n        m_tr = Distributions.mean(TrG)\n        V_tr = Distributions.var(TrG)\n    end\n    \n    return (Z, m_tr, V_tr)\nend;\n\n@rule ChanceConstraint(:out, Marginalisation) (\n    m_out::UnivariateNormalDistributionsFamily, # Require inbound message\n    q_lo::PointMass, \n    q_hi::PointMass, \n    q_epsilon::PointMass, \n    q_atol::PointMass) = begin \n\n    # Extract parameters\n    lo = mean(q_lo)\n    hi = mean(q_hi)\n    epsilon = mean(q_epsilon)\n    atol = mean(q_atol)\n    \n    (m_bw, V_bw) = mean_var(m_out)\n    (xi_bw, W_bw) = (m_bw, 1. /V_bw)  # check division by  zero\n    (m_tilde, V_tilde) = (m_bw, V_bw)\n    \n    # Compute statistics (and normalizing constant) of q in safe region G\n    # Phi_G is called the \"safe mass\" \n    (Phi_G, m_G, V_G) = truncatedGaussianMoments(m_bw, V_bw, lo, hi)\n\n    xi_fw = xi_bw\n    W_fw  = W_bw\n    if epsilon <= 1.0 - Phi_G # If constraint is active\n        # Initialize statistics of uncorrected belief\n        m_tilde = m_bw\n        V_tilde = V_bw\n        for i = 1:100 # Iterate at most this many times\n            (Phi_lG, m_lG, V_lG) = truncatedGaussianMoments(m_tilde, V_tilde, -Inf, lo) # Statistics for q in region left of G\n            (Phi_rG, m_rG, V_rG) = truncatedGaussianMoments(m_tilde, V_tilde, hi, Inf) # Statistics for q in region right of G\n\n            # Compute moments of non-G region as a mixture of left and right truncations\n            Phi_nG = Phi_lG + Phi_rG\n            m_nG = Phi_lG / Phi_nG * m_lG + Phi_rG / Phi_nG * m_rG\n            V_nG = Phi_lG / Phi_nG * (V_lG + m_lG^2) + Phi_rG/Phi_nG * (V_rG + m_rG^2) - m_nG^2\n\n            # Compute moments of corrected belief as a mixture of G and non-G regions\n            m_tilde = (1.0 - epsilon) * m_G + epsilon * m_nG\n            V_tilde = (1.0 - epsilon) * (V_G + m_G^2) + epsilon * (V_nG + m_nG^2) - m_tilde^2\n            # Re-compute statistics (and normalizing constant) of corrected belief\n            (Phi_G, m_G, V_G) = truncatedGaussianMoments(m_tilde, V_tilde, lo, hi)\n            if (1.0 - Phi_G) < (1.0 + atol)*epsilon\n                break # Break the loop if the belief is sufficiently corrected\n            end\n        end\n        \n        # Convert moments of corrected belief to canonical form\n        W_tilde = inv(V_tilde)\n        xi_tilde = W_tilde * m_tilde\n\n        # Compute canonical parameters of forward message\n        xi_fw = xi_tilde - xi_bw\n        W_fw  = W_tilde - W_bw\n    end\n\n    return NormalWeightedMeanPrecision(xi_fw, W_fw)\nend","category":"section"},{"location":"categories/advanced_examples/chance_constraints/#Definition-of-the-Environment","page":"Chance Constraints","title":"Definition of the Environment","text":"We consider an environment where the agent has an elevation level, and where the agent directly controls its vertical velocity. After some time, an unexpected and sudden gust of wind tries to push the agent to the ground.\n\nwind(t::Int64) = -0.1*(60 <= t < 100) # Time-dependent wind profile\n\nfunction initializeWorld()\n    x_0 = 0.0 # Initial elevation\n    \n    x_t_last = x_0\n    function execute(t::Int64, a_t::Float64)\n        x_t = x_t_last + a_t + wind(t) # Update elevation\n    \n        x_t_last = x_t # Reset state\n                \n        return x_t\n    end\n\n    x_t = x_0 # Predefine outcome variable\n    observe() = x_t # State is fully observed\n\n    return (execute, observe)\nend;","category":"section"},{"location":"categories/advanced_examples/chance_constraints/#Generative-Model-for-Regulator","page":"Chance Constraints","title":"Generative Model for Regulator","text":"We consider a fully observed Markov decision process, where the agent directly observes the true state (elevation) of the world. In this case we only need to define a chance-constrained generative model of future states. Inference for controls on this model then derives our controller.\n\n# m_u ::Vector{Float64}, ,   Control prior means\n# v_u = datavar(Float64, T)  Control prior variances\n# x_t ::Float64              Fully observed state\n\n@model function regulator_model(T, m_u, v_u, x_t, lo, hi, epsilon, atol)\n    \n    # Loop over horizon\n    x_k_last = x_t\n    for k = 1:T\n        u[k] ~ NormalMeanVariance(m_u[k], v_u[k]) # Control prior\n        x[k] ~ x_k_last + u[k] # Transition model\n        x[k] ~ ChanceConstraint(lo, hi, epsilon, atol) where { # Simultaneous constraint on state\n            dependencies = RequireMessageFunctionalDependencies(out = NormalWeightedMeanPrecision(0, 0.01))} # Predefine inbound message to break circular dependency\n        x_k_last = x[k]\n    end\n \nend","category":"section"},{"location":"categories/advanced_examples/chance_constraints/#Reactive-Agent-Definition","page":"Chance Constraints","title":"Reactive Agent Definition","text":"function initializeAgent()\n    # Set control prior statistics\n    m_u = zeros(T)\n    v_u = lambda^(-1)*ones(T)\n    \n    function compute(x_t::Float64)\n        model_t = regulator_model(;T=T, lo=lo, hi=hi, epsilon=epsilon, atol=atol)\n        data_t = (m_u = m_u, v_u = v_u, x_t = x_t)\n\n        result = infer(\n            model = model_t,\n            data = data_t,\n            iterations = n_its)\n\n        # Extract policy from inference results\n        pol = mode.(result.posteriors[:u][end])\n\n        return pol\n    end\n\n    pol = zeros(T) # Predefine policy variable\n    act() = pol[1]\n\n    return (compute, act)\nend;","category":"section"},{"location":"categories/advanced_examples/chance_constraints/#Action-Perception-Cycle","page":"Chance Constraints","title":"Action-Perception Cycle","text":"Next we define and execute the action-perception cycle. Because the state is fully observed, these is no slide (estimator) step in the cycle. \n\n# Simulation parameters\nN = 160 # Total simulation time\nT = 1 # Lookahead time horizon\nlambda = 1.0 # Control prior precision\nlo = 1.0 # Chance region lower bound\nhi = Inf # Chance region upper bound\nepsilon = 0.01 # Allowed chance violation\natol = 0.01 # Convergence tolerance for chance constraints\nn_its = 10;  # Number of inference iterations\n\n(execute, observe) = initializeWorld() # Let there be a world\n(compute, act) = initializeAgent() # Let there be an agent\n\na = Vector{Float64}(undef, N) # Actions\nx = Vector{Float64}(undef, N) # States\nfor t = 1:N\n    a[t] = act()\n           execute(t, a[t])\n    x[t] = observe()\n           compute(x[t])\nend","category":"section"},{"location":"categories/advanced_examples/chance_constraints/#Results","page":"Chance Constraints","title":"Results","text":"Results show that the agent does not allow the wind to push it all the way to the ground.\n\np1 = plot(1:N, wind.(1:N), color=\"blue\", label=\"Wind\", ylabel=\"Velocity\", lw=2)\nplot!(p1, 1:N, a, color=\"red\", label=\"Control\", lw=2)\np2 = plot(1:N, x, color=\"black\", lw=2, label=\"Agent\", ylabel=\"Elevation\")\nplot(p1, p2, layout=(2,1))\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [31c24e10] Distributions v0.25.123\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [4c63d2b9] StatsFuns v1.5.2\n\n\n","category":"section"},{"location":"categories/experimental_examples/large_language_models/","page":"Large Language Models","title":"Large Language Models","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/experimental_examples/large_language_models/#Large-Language-Models","page":"Large Language Models","title":"Large Language Models","text":"","category":"section"},{"location":"categories/experimental_examples/large_language_models/#Warning:-Maximum-Unprincipledness-Ahead","page":"Large Language Models","title":"‚ö†Ô∏è Warning: Maximum Unprincipledness Ahead ‚ö†Ô∏è","text":"","category":"section"},{"location":"categories/experimental_examples/large_language_models/#The-speed-of-RxInfer-will-be-bottlenecked-by-the-speed-of-the-LLM-calls","page":"Large Language Models","title":"‚ö†Ô∏è The speed of RxInfer will be bottlenecked by the speed of the LLM calls ‚ö†Ô∏è","text":"using RxInfer, OpenAI, JSON\n\n# Your OpenAI API key should be set in the environment variables\nsecret_key = ENV[\"OPENAI_KEY\"];\nllm_model = \"gpt-4o-mini-2024-07-18\";\n\nDisclaimer: This is probably one of the most unprincipled notebooks in the RxInferExamples repository. We're about to hook Large Language Models directly into Bayesian inference using nothing but good vibes and questionable life choices. If you're looking for rigorous mathematical foundations, you might want to slowly back away from this notebook.\n\nThat said, if you've ever wondered \"what happens if I treat LLMs' outputs like a probability distribution?\", you've come to the right place. We'll start with a gentle introduction to RxInfer for two reasons: first, we need to justify this madness of integrating LLMs with probabilistic models, and second, we want to explain what RxInfer is to newcomers in a single notebook with as few external references as possible. Think of this as \"Bayesian Inference for People Who Just Want to See the Cool Stuff.\"","category":"section"},{"location":"categories/experimental_examples/large_language_models/#What-is-RxInfer?-(The-Gentle-Introduction)","page":"Large Language Models","title":"What is RxInfer? (The Gentle Introduction)","text":"Before we commit crimes against Bayesian inference (by the way we use the word inference to mean \"Bayesian inference\", not the forward pass of a neural network), let's understand what RxInfer actually is and why it accidentally makes LLM integration possible.\n\nRxInfer is a Julia package for Bayesian inference that takes a rather unusual approach: instead of treating your probabilistic model as one big mathematical beast that needs to be slayed with MCMC or variational inference, it breaks everything down into small, local conversations between probability distributions.\n\nImagine your probabilistic model as a social network where probability distributions are people, and they're all gossiping about what they think the true parameters might be. RxInfer organizes this gossip into an efficient message-passing protocol on something called a factor graph.","category":"section"},{"location":"categories/experimental_examples/large_language_models/#Factor-Graphs:-The-Social-Network-of-Probability","page":"Large Language Models","title":"Factor Graphs: The Social Network of Probability","text":"A factor graph is just a visual way to represent how different parts of your probabilistic model talk to each other. Think of it like this:\n\nRound nodes (variables): These represent the things you want to learn about\nSquare nodes (factors): These represent relationships or constraints between variables  \nEdges: These are the communication channels where probability distributions flow as \"messages\"\n\nFor example, if you want to model coin flips:\n\ngraph LR\n    %% Variable nodes (circles)\n    theta[\"Œ∏<br/>(coin fairness)\"]\n    x1[\"x‚ÇÅ<br/>(flip 1)\"]\n    x2[\"x‚ÇÇ<br/>(flip 2)\"]\n    x3[\"x‚ÇÉ<br/>(flip 3)\"]\n    \n    %% Factor nodes (squares)\n    prior[\"Beta<br/>Prior\"]\n    flip1[\"Bernoulli<br/>Flip\"]\n    flip2[\"Bernoulli<br/>Flip\"] \n    flip3[\"Bernoulli<br/>Flip\"]\n    \n    %% Connections\n    prior --- theta\n    theta --- flip1\n    theta --- flip2\n    theta --- flip3\n    flip1 --- x1\n    flip2 --- x2\n    flip3 --- x3\n    \n    %% Styling\n    classDef variable fill:#e1f5fe,stroke:#01579b,stroke-width:2px\n    classDef factor fill:#fff3e0,stroke:#e65100,stroke-width:2px\n    \n    class theta,x1,x2,x3 variable\n    class prior,flip1,flip2,flip3 factor\n\nIn this graph:\n\nBlue squares are variables (things we want to learn about)\nOrange squares are factors (probability distributions or relationships)\nLines are the communication channels where messages flow back and forth\n\nThe magic happens when messages flow along these edges, updating beliefs as new information comes in.","category":"section"},{"location":"categories/experimental_examples/large_language_models/#The-Philosophy:-Local-Conversations,-Global-Intelligence","page":"Large Language Models","title":"The Philosophy: Local Conversations, Global Intelligence","text":"Here's what makes RxInfer special: instead of solving your entire probabilistic model in one giant computation, it breaks everything down into local conversations. \n\nEach node only needs to:\n\nListen to messages from its neighbors\nUpdate its local beliefs\nSend updated messages to its neighbors\n\nRepeat this process, and eventually the entire network converges to the exact or approximate posterior distributions. It's like crowd-sourced intelligence, but with math.\n\nThis approach has some nice properties:\n\nModular: You can swap out parts of your model without affecting others\nParallel: Different parts can update simultaneously  \nInterpretable: You can inspect what each part of your model \"thinks\"\nExtensible: You can add new types of nodes... like LLMs üëÄ","category":"section"},{"location":"categories/experimental_examples/large_language_models/#The-Beautiful-Accident:-RxInfer-Doesn't-Care-What-You-Pass","page":"Large Language Models","title":"The Beautiful Accident: RxInfer Doesn't Care What You Pass","text":"Here's where things get interesting (and unprincipled). \n\nRxInfer was designed for passing probability distributions along those edges. But here's the thing: the framework doesn't actually care what you pass. It just needs to know how to:\n\nCompute outgoing messages from incoming ones\nUpdate local beliefs (marginals)\nCalculate free energy contributions (we will skip this for now)\n\nAs long as you can define these two (three) things, you can plug in literally anything as a node. A matrix multiplication? Sure. A neural network? Why not (see examples within the repository). A Large Language Model? Hold my coffee...","category":"section"},{"location":"categories/experimental_examples/large_language_models/#The-Moment-of-Questionable-Judgment","page":"Large Language Models","title":"The Moment of Questionable Judgment","text":"So here we were, understanding that RxInfer is basically a message-passing system that doesn't care what you pass, when someone (probably me) had a thought:\n\n\"What if we just... asked ChatGPT to be a probability distribution?\"\n\nNow, any reasonable person would immediately recognize this as a terrible idea. Probability distributions have well-defined mathematical properties. They integrate to 1. They have moments. They follow laws. Jaynes would be rolling in his grave.\n\nLarge Language Models, on the other hand, are... vibes-based. They generate text that sounds plausible. They hallucinate. They change their mind if you ask the same question twice.\n\nBut here's the thing about terrible ideas: sometimes they work.","category":"section"},{"location":"categories/experimental_examples/large_language_models/#The-Great-LLM-Bayesian-Integration-Experiment","page":"Large Language Models","title":"The Great LLM-Bayesian Integration Experiment","text":"The plan was simple (and deeply unscientific):\n\nCreate LLM nodes that can participate in message passing\nTeach LLMs to speak probability through prompting\nLet them gossip with real probability distributions and see what happens\nHope nothing catches fire\n\nSurprisingly, steps 1-3 worked. Step 4 is still ongoing.","category":"section"},{"location":"categories/experimental_examples/large_language_models/#The-Problem:-Can-We-Cluster-Text-Using-Bayesian-Inference?","page":"Large Language Models","title":"The Problem: Can We Cluster Text Using Bayesian Inference?","text":"Before we dive into the implementation, let's define a concrete problem that will motivate our LLM integration. We want to:\n\nCluster text snippets by sentiment, but with proper uncertainty quantification.\n\nHere's our dataset - 5 text snippets about RxInfer.jl:\n\nobservations = [\n    \"RxInfer.jl is confusing and frustrating to use. I wouldn't recommend it.\",\n    \"RxInfer.jl made my Bayesian modeling workflow much easier and more efficient!\",\n    \"Absolutely love RxInfer.jl! It's revolutionized my approach to probabilistic programming.\",\n    \"I gave RxInfer.jl a try, but it just doesn't work for my needs at all.\",\n    \"I prefer apples over oranges.\"  # üçé Wait, this one's different...\n];\n\nThe challenges:\n\nTwo sentiment clusters: Positive and negative opinions about RxInfer.jl\nUnrelated text: The last one isn't about RxInfer.jl at all\nUncertainty: We want to know how confident we are about each classification\n\nTraditional clustering would give us hard assignments. We want probabilistic clustering with uncertainty.","category":"section"},{"location":"categories/experimental_examples/large_language_models/#The-Model:-Mixing-Traditional-Bayesian-with-LLM-Magic","page":"Large Language Models","title":"The Model: Mixing Traditional Bayesian with LLM Magic","text":"Here's our probabilistic model for sentiment clustering (this will be the final model we will use):\n\n@model function language_mixture_model(c, context‚ÇÅ, context‚ÇÇ, task‚ÇÅ, task‚ÇÇ, likelihood_task)\n    # Mixture probability (how much of each sentiment type)\n    s ~ Beta(1.0, 1.0)\n    \n    # Two sentiment clusters with LLM-generated priors\n    m[1] ~ LLMPrior(context‚ÇÅ, task‚ÇÅ)  # Negative sentiment prior\n    w[1] ~ Gamma(shape = 0.01, rate = 0.01)\n    \n    m[2] ~ LLMPrior(context‚ÇÇ, task‚ÇÇ)  # Positive sentiment prior  \n    w[2] ~ Gamma(shape = 0.01, rate = 0.01)\n    \n    for i in eachindex(c)\n        z[i] ~ Bernoulli(s)  # Cluster assignment (0=negative, 1=positive)\n        y[i] ~ NormalMixture(switch = z[i], m = m, p = w)  # Latent sentiment score\n        c[i] ~ LLMObservation(y[i], likelihood_task)  # Observed text\n    end\nend","category":"section"},{"location":"categories/experimental_examples/large_language_models/#What-This-Model-Does","page":"Large Language Models","title":"What This Model Does","text":"Let's break this down:\n\ns ~ Beta(1,1): Overall mixture proportion (how much positive vs negative sentiment in our dataset)\nm[1] ~ LLMPrior(context‚ÇÅ, task‚ÇÅ): \nAsk an LLM: \"Given that RxInfer.jl is terrible, what satisfaction score distribution would you expect?\"\nLLM response becomes our prior for negative sentiment\nm[2] ~ LLMPrior(context‚ÇÇ, task‚ÇÇ): \nAsk an LLM: \"Given that RxInfer.jl is great, what satisfaction score distribution would you expect?\"\nLLM response becomes our prior for positive sentiment\nz[i] ~ Bernoulli(s): Each text snippet gets assigned to positive or negative cluster\ny[i] ~ NormalMixture(...): Each snippet has a latent \"satisfaction score\" based on its cluster\nc[i] ~ LLMObservation(y[i], likelihood_task): \nAsk an LLM: \"What sentiment score would generate this text?\"\nThis connects our observed text to the latent satisfaction scores","category":"section"},{"location":"categories/experimental_examples/large_language_models/#The-Insight:-LLMs-as-Probabilistic-Components","page":"Large Language Models","title":"The Insight: LLMs as Probabilistic Components","text":"The brilliant (and possibly insane) insight is that we're using LLMs as:\n\nLLMPrior: A way to generate informed priors based on contextual knowledge\nLLMObservation: A likelihood function that connects text to latent numerical variables\n\nThis means the LLMs aren't just doing classification - they're participating in full Bayesian inference!","category":"section"},{"location":"categories/experimental_examples/large_language_models/#Creating-the-LLM-Nodes","page":"Large Language Models","title":"Creating the LLM Nodes","text":"Now that we understand why we need these nodes, let's see how to build them. Creating a custom node in RxInfer requires 4 steps (but we will skip the last two):\n\nCreate the node structure using the @node macro\nDefine message passing rules with the @rule macro  \nSpecify marginal computations with the @marginalrule macro (skipped)\nImplement free energy computation with the @average_energy macro (skipped)\n\nThe beauty is in the message passing protocol. Each node only needs to know how to:\n\nProcess incoming messages from neighbors\nSend outgoing messages to neighbors  \nMaintain local beliefs\n\nLet's look at the actual implementation:","category":"section"},{"location":"categories/experimental_examples/large_language_models/#LLMPrior-Node","page":"Large Language Models","title":"LLMPrior Node","text":"First, the node definition:\n\n\"\"\"\n    LLMPrior\n\nNode that represents an LLM's prior beliefs about latent variables based on contextual information.\nThe LLM interprets the context and task to produce a probability distribution as a prior.\n\n# Interfaces\n- `belief` (b): Output distribution representing the LLM's prior belief\n- `context` (c): Input text providing context for the prior\n- `task` (t): Input text describing what distribution to generate\n\"\"\"\nstruct LLMPrior end\n\n@node LLMPrior Stochastic [ (b, aliases = [belief]), (c, aliases = [context]), (t, aliases = [task]) ]\n\nNow here's the actual message passing rule that does the magic. This is going to be a forward rule that will provide a prior for the sentiment of the text. We understand that the syntax for the rule is a bit weird, so we refer the curious reader to the documentation.\n\n@rule LLMPrior(:b, Marginalisation) (q_c::PointMass{<:String}, q_t::PointMass{<:String}) = begin\n    # Build the conversation with the LLM\n    messages = [\n        Dict(\"role\" => \"system\",\n             \"content\" => \"\"\"\n                 You are an expert analyst who maps contextual cues to a\n                 Normal(mean, variance) distribution.\n\n                 ‚Ä¢ Think step-by-step internally.\n                 ‚Ä¢ **Only** output a JSON object that conforms to the schema below.\n                 ‚Ä¢ Do not wrap the JSON in markdown fences or add extra keys.\n             \"\"\"),\n\n        Dict(\"role\" => \"assistant\",\n             \"content\" => \"\"\"\n                 ## CONTEXT\n                 $(q_c.point)\n             \"\"\"),\n\n        Dict(\"role\" => \"user\",\n             \"content\" => \"\"\"\n                 ## TASK\n                 $(q_t.point)\n\n                 Using the context above, infer a Normal distribution and return:\n                   \"analysis\"  ‚Äì brief rationale (‚â§ 100 words)\n                   \"mean\"      ‚Äì number in [0, 10]\n                   \"variance\"  ‚Äì number in [1, 100]\n             \"\"\")\n    ]\n\n    # Define strict JSON schema for consistent responses\n    response_schema = Dict(\n        \"type\" => \"json_schema\",\n        \"json_schema\" => Dict(\n            \"name\"   => \"normal_estimate\",\n            \"schema\" => Dict(\n                \"type\"       => \"object\",\n                \"properties\" => Dict(\n                    \"analysis\" => Dict(\"type\" => \"string\"),\n                    \"mean\"     => Dict(\"type\" => \"number\", \"minimum\" => 0, \"maximum\" => 10),\n                    \"variance\" => Dict(\"type\" => \"number\", \"minimum\" => 1, \"maximum\" => 100)\n                ),\n                \"required\" => [\"analysis\", \"mean\", \"variance\"],\n                \"additionalProperties\" => false\n            )\n        )\n    )\n\n    # Call the LLM and parse the response\n    r = create_chat(secret_key, llm_model, messages; response_format = response_schema)\n    obj = JSON.parse(r.response[:choices][1][:message][:content])\n\n    return NormalMeanVariance(obj[\"mean\"], obj[\"variance\"])\nend","category":"section"},{"location":"categories/experimental_examples/large_language_models/#LLMObservation-Node","page":"Large Language Models","title":"LLMObservation Node","text":"The node definition:\n\n\"\"\"\n    LLMObservation\n\nNode that represents an LLM's observation of data based on a latent belief and task description.\nThe LLM takes a latent belief and task description to produce corresponding observed data.\n\n# Interfaces\n- `out`: Output observation data generated by the LLM\n- `belief` (b): Input latent variable/distribution that influences the observation\n- `task` (t): Input text describing how to generate observations from beliefs\n\"\"\"\nstruct LLMObservation end\n\n@node LLMObservation Stochastic [ out, (b, aliases = [belief]), (t, aliases = [task]) ]\n\nNow we need to define the rule. Normally, we would have to define the rules for each interface (edge) of the node, but here we will skip this part and define only a backward rule from observations to a belief.\n\n@rule LLMObservation(:b, Marginalisation) (q_out::PointMass{<:String}, q_t::PointMass{<:String}) = begin\n    messages = [\n        Dict(\"role\" => \"system\",\n             \"content\" => \"\"\"\n                 You are **LLMObservation**, a senior evaluator who maps a text to\n                 a Normal(mean, variance) distribution.\n\n                 ‚Ä¢ Think step-by-step internally, but **only** output a JSON object\n                   that conforms to the provided schema.\n                 ‚Ä¢ Do not wrap the JSON in markdown fences or add extra keys.\n             \"\"\"),\n\n        Dict(\"role\" => \"assistant\",\n             \"content\" => \"\"\"\n                 ## TEXT\n                 $(q_out.point)\n             \"\"\"),\n\n        Dict(\"role\" => \"user\",\n             \"content\" => \"\"\"\n                 ## TASK\n                 $(q_t.point)\n\n                 Using the text above, infer a Gaussian distribution.\n                 Return a JSON object with keys:\n                   \"analysis\"  ‚Äì ‚â§ 100 words explaining your reasoning\n                   \"mean\"      ‚Äì number in [0, 10]\n                   \"variance\"  ‚Äì number in [0.1, 100]\n             \"\"\")\n    ]\n\n    response_schema = Dict(\n        \"type\" => \"json_schema\",\n        \"json_schema\" => Dict(\n            \"name\"   => \"normal_estimate\",\n            \"schema\" => Dict(\n                \"type\"       => \"object\",\n                \"properties\" => Dict(\n                    \"analysis\" => Dict(\"type\" => \"string\"),\n                    \"mean\"     => Dict(\"type\" => \"number\", \"minimum\" => 0, \"maximum\" => 10),\n                    \"variance\" => Dict(\"type\" => \"number\", \"minimum\" => 0.1, \"maximum\" => 100)\n                ),\n                \"required\" => [\"analysis\", \"mean\", \"variance\"],\n                \"additionalProperties\" => false\n            )\n        )\n    )\n\n    r = create_chat(secret_key, llm_model, messages; response_format = response_schema)\n    obj = JSON.parse(r.response[:choices][1][:message][:content])\n\n    return NormalMeanVariance(obj[\"mean\"], obj[\"variance\"])\nend\n\n# Priors\ncontext‚ÇÅ = \"RxInfer.jl is absolutely terrible.\"\ncontext‚ÇÇ = \"RxInfer.jl is a great tool for Bayesian Inference.\"\n\nprior_task = \"\"\"\nProvide a distribution of the statement.\n- **Mean**: Most likely satisfaction score (0-10 scale)  \n- **Variance**: Uncertainty in your interpretation\n    - Low variance (2.0-4.0): Very clear sentiment\n    - Medium variance (4.1-6.0): Some ambiguity\n    - High variance (6.0-10.0): Unclear or mixed signals\n\"\"\"\n\n# Likelihood  \nlikelihood_task = \"\"\"\nEvaluation of sentiment about RxInfer.jl and provide satisfaction score distribution.\nIf expression is not related to RxInfer.jl, return distribution with mean 5 and high variance of 100.\n- **Mean**: Most likely satisfaction score (0-10 scale)\n- **Variance**: Uncertainty in interpretation  \n    - Low variance (0.1-1.0): Very clear sentiment, confident interpretation\n    - Medium variance (1.1-5.0): Some ambiguity in the text\n    - High variance (5.1-10.0): Unclear/mixed signals, or not related to RxInfer.jl\n\"\"\";","category":"section"},{"location":"categories/experimental_examples/large_language_models/#What-Happens-During-Inference","page":"Large Language Models","title":"What Happens During Inference","text":"LLM Priors Generate Initial Beliefs:\nNegative context ‚Üí Low satisfaction score (‚âà Gaussians with mean some mean between 0 and 5 and (perhaps) high variance) \nPositive context ‚Üí High satisfaction score (‚âà Gaussians with mean some mean between 5 and 10 and (perhaps) high variance)\nLLM Observations Process Text:\n\"RxInfer.jl is confusing...\" ‚Üí Low score, low uncertainty\n\"Absolutely love RxInfer.jl...\" ‚Üí High score, low uncertainty  \n\"I prefer apples over oranges\" ‚Üí Medium score, HIGH uncertainty (not related!)\nMessage Passing Updates Beliefs:\nTraditional Bayesian update rules combine LLM outputs\nCluster assignments emerge from the mixture model\nUncertainty propagates through the network\nFinal Result: Clean clustering with proper uncertainty quantification\n\n# Some shennenigans to make inference work\nn_iterations = 5 # number of variational iterations to run\n\n# initial values for the variational distributions, we use uninformative distributions\n# If this looks weird to you, please refer to the documentation for the @initialization macro\ninit = @initialization begin\n    q(s) = vague(Beta)\n    q(m) = [NormalMeanVariance(0.0, 1e2), NormalMeanVariance(10.0, 1e2)]\n    q(y) = NormalMeanVariance(5.0, 1e2) # centered initialization with broad uncertainty\n    q(w) = [GammaShapeRate(0.01, 0.01), GammaShapeRate(0.01, 0.01)]\nend\n\nInitial state: \n  q(s) = Distributions.Beta{Float64}(Œ±=1.0, Œ≤=1.0)\n  q(m) = ExponentialFamily.NormalMeanVariance{Float64}[ExponentialFamily.No\nrmalMeanVariance{Float64}(Œº=0.0, v=100.0), ExponentialFamily.NormalMeanVari\nance{Float64}(Œº=10.0, v=100.0)]\n  q(y) = ExponentialFamily.NormalMeanVariance{Float64}(Œº=5.0, v=100.0)\n  q(w) = ExponentialFamily.GammaShapeRate{Float64}[ExponentialFamily.GammaS\nhapeRate{Float64}(a=0.01, b=0.01), ExponentialFamily.GammaShapeRate{Float64\n}(a=0.01, b=0.01)]\n\nimport ReactiveMP: rule_nm_switch_k, softmax!\n\n# Run Bayesian inference \n# Again, RxInfer is fast, LLMs are not, bare with inference\nresults_language = infer(\n    model=language_mixture_model(context‚ÇÅ=context‚ÇÅ, context‚ÇÇ=context‚ÇÇ, task‚ÇÅ=prior_task, task‚ÇÇ=prior_task, likelihood_task=likelihood_task),\n    constraints=MeanField(), # This is needed for the mixture node\n    data=(c=observations,),\n    initialization=init,\n    iterations=n_iterations,\n    free_energy=false,\n    showprogress=true\n)\n\nInference results:\n  Posteriors       | available for (w, m, s, y, z)\n\nusing Plots\n\n# Create the animation object\nanimation = @animate for i in 1:n_iterations\n\n    # Get the data for visualization\n    initial_means = [0.0, 10.0]\n    initial_vars = [1e2, 1e2]\n    posterior_means = [mean.(results_language.posteriors[:m][i])...]\n    posterior_vars = inv.([mean.(results_language.posteriors[:w][i])...])\n\n    x = -10:0.01:20\n\n    plt = plot(\n        title=\"RxLLM: Sentiment Clustering\",\n        xlabel=\"Sentiment Spectrum\",\n        ylabel=\"Density\",\n        size=(800, 500),\n        dpi=300,\n        background_color=:white,\n        titlefontsize=14,\n        legendfontsize=11\n    )\n\n    # Plot posteriors with fill\n    plot!(plt, x, pdf.(Normal(posterior_means[1], sqrt(posterior_vars[1])), x),\n        fillalpha=0.4, fillrange=0, fillcolor=:red,\n        linewidth=3, linecolor=:darkred,\n        label=\"Negative Sentiment\")\n\n    plot!(plt, x, pdf.(Normal(posterior_means[2], sqrt(posterior_vars[2])), x),\n        fillalpha=0.4, fillrange=0, fillcolor=:blue,\n        linewidth=3, linecolor=:darkblue,\n        label=\"Positive Sentiment\")\n\n    # Plot priors as lighter background\n    plot!(plt, x, pdf.(Normal(initial_means[1], sqrt(initial_vars[1])), x),\n        linewidth=1, linestyle=:dash, linecolor=:gray, alpha=0.6,\n        label=\"Initial Prior\")\n\n    plot!(plt, x, pdf.(Normal(initial_means[2], sqrt(initial_vars[2])), x),\n        linewidth=1, linestyle=:dash, linecolor=:gray, alpha=0.6,\n        label=\"\")\n\n    # Simple cluster probabilities visualization\n    cluster_probs = probvec.(results_language.posteriors[:z][i])\n    plt2 = bar(1:length(cluster_probs), [p[1] for p in cluster_probs],\n        title=\"Positive Sentiment Probability\", ylabel=\"P(Positive)\", xlabel=\"Data Point\")\n\n    plot(plt, plt2)\n\nend\n\n# Now you can save the animation\ngif(animation, \"inference_process.gif\", fps=1, show_msg=false);\n\n(Image: )\n\nThe model successfully:\n\nClusters related text into positive/negative sentiment\nIdentifies unrelated text through high uncertainty\nQuantifies confidence in each assignment\nUpdates beliefs through proper Bayesian inference\n\nMost importantly, the LLMs aren't just doing text classification - they're participating in a full probabilistic reasoning process where their outputs are combined with traditional statistical models.","category":"section"},{"location":"categories/experimental_examples/large_language_models/#Why-This-Matters:-Beyond-Prompt-Chains","page":"Large Language Models","title":"Why This Matters: Beyond Prompt Chains","text":"This approach opens up possibilities that go far beyond traditional LLM applications:\n\nUncertainty-Aware LLM Agents\n\nInstead of binary decisions, agents can maintain probability distributions over their beliefs and actions.\n\nRigorous Decision-Making Frameworks  \n\nLLM outputs become part of formal decision theory with some uncertainty quantification.\n\nCompositional Reasoning\n\nComplex problems can be decomposed into smaller LLM nodes that communicate through message passing.\n\nContinual Learning\n\nAs new data arrives, beliefs update through established Bayesian mechanisms rather than retraining.\n\nExplainable AI\n\nThe factor graph structure makes the reasoning process transparent and interpretable.","category":"section"},{"location":"categories/experimental_examples/large_language_models/#Lessons-Learned-and-Future-Directions","page":"Large Language Models","title":"Lessons Learned and Future Directions","text":"","category":"section"},{"location":"categories/experimental_examples/large_language_models/#What-Worked-Well","page":"Large Language Models","title":"What Worked Well","text":"Natural integration: LLMs fit surprisingly well into message passing\nUncertainty handling: LLMs can express uncertainty when prompted correctly\nCompositionality: Multiple LLM nodes can work together in complex models","category":"section"},{"location":"categories/experimental_examples/large_language_models/#Current-Limitations","page":"Large Language Models","title":"Current Limitations","text":"Prompt engineering: Requires prompt design for consistent distribution formats\nComputational cost: LLM queries are expensive compared to traditional operations\nReliability: LLM responses need robust parsing and error handling","category":"section"},{"location":"categories/experimental_examples/large_language_models/#Future-Opportunities","page":"Large Language Models","title":"Future Opportunities","text":"Multimodal integration: Extend to vision/audio LLMs\nOnline learning: Update LLM beliefs through experience\nHierarchical models: Use LLMs at different abstraction levels\nMeta-learning: Learn better prompting strategies through inference","category":"section"},{"location":"categories/experimental_examples/large_language_models/#What's-Missing:-Current-Limitations","page":"Large Language Models","title":"What's Missing: Current Limitations","text":"While our LLM-Bayesian integration works, this is very much a proof-of-concept with several important limitations that need to be addressed:","category":"section"},{"location":"categories/experimental_examples/large_language_models/#1.-Fixed-Functional-Forms","page":"Large Language Models","title":"1. Fixed Functional Forms","text":"Currently, our LLM nodes are hardcoded to output Normal distributions with specific parameter ranges. This isn't very flexible:\n\n# Current: Always returns Normal(mean, variance)\nreturn NormalMeanVariance(obj[\"mean\"], obj[\"variance\"])\n\nThe issue: What if we want LLMs to output other distributions? Gamma? Beta? Categorical? Or even mixture distributions?\n\nEasy extension: The nodes should be generic and allow the user to specify the desired output distribution family through the task description.","category":"section"},{"location":"categories/experimental_examples/large_language_models/#2.-Message-Products-Not-Addressed","page":"Large Language Models","title":"2. Message Products Not Addressed","text":"In real factor graphs, you often need to combine multiple incoming messages before processing them. Our current implementation only handles single messages:\n\n# Current: Only handles one message at a time\n@rule LLMPrior(:b, Marginalisation) (q_c::PointMass{<:String}, q_t::PointMass{<:String})\n\nThe issue: What happens when multiple messages arrive at an LLM node? How do we combine them before sending to the LLM?\n\nMissing: Rules for message products and handling multiple incoming probability distributions simultaneously.","category":"section"},{"location":"categories/experimental_examples/large_language_models/#3.-The-Uncertainty-Quantification-Problem","page":"Large Language Models","title":"3. The Uncertainty Quantification Problem","text":"Perhaps the most philosophically questionable aspect of our approach is how we handle uncertainty. We're essentially asking LLMs:\n\n\"What do you think about your own confidence?\"\n\nThis is arguably unprincipled for several reasons:\n\nText-to-Text Uncertainty: When we prompt an LLM to express uncertainty about its own output, we're asking it to introspect about its own reasoning process. But LLMs don't actually have access to their internal uncertainty - they're just generating text that sounds like uncertainty based on their training.\n\n# This is basically what we're doing:\n\"I think this text expresses positive sentiment with variance 0.8\"\n# vs\n\"I think this text expresses positive sentiment with variance 2.5\"\n\nThe LLM is pattern-matching to training examples where humans expressed different levels of confidence, but it's not performing genuine uncertainty quantification.\n\nLog-Probability Limitations: An alternative approach might be to use the LLM's token log-probabilities as uncertainty proxies:\n\n# Instead of asking the LLM about uncertainty, use its output probabilities\ntoken_probs = model.logprobs(response)\nuncertainty = -sum(token_probs)  # Entropy-based uncertainty\n\nBut this is also problematic because:\n\nConfidence ‚â† Correctness: An LLM can be very confident (high probability) about completely wrong outputs\nSequence-level vs Token-level: High token probabilities don't necessarily mean the overall semantic content is reliable\nDistribution Mismatch: Token probabilities reflect linguistic patterns, not epistemic uncertainty about the underlying task\nTraining Artifacts: LLM confidence is heavily influenced by training data patterns rather than true knowledge uncertainty\n\nWhy We Do It Anyway: Despite being unprincipled, this approach can be useful in the absence of other information. When you have no other source of uncertainty quantification, asking an LLM to express its confidence can provide a rough proxy that's better than no uncertainty at all.\n\nIt's a bit like asking someone \"how sure are you?\" - not perfect, but often practically useful.\n\nThe Better Path: True uncertainty quantification would require:\n\nExplicit modeling of different uncertainty sources (aleatoric vs epistemic)\nIntegration with proper Bayesian model uncertainty\nIntegration of subjective logic frameworks\n\nBut for a proof-of-concept showing LLMs can participate in message passing? Text-based uncertainty estimation gets the job done.","category":"section"},{"location":"categories/experimental_examples/large_language_models/#Grounding-Agentic-Systems-in-Bayesian-Reasoning","page":"Large Language Models","title":"Grounding Agentic Systems in Bayesian Reasoning","text":"Beyond fixing current limitations, we're thinking through something much more ambitious: simultaneous integration of agents and Bayesian models working together across trust networks.\n\nThe vision is agentic systems where:\n\n# Agent submodel with trust and capability\n@model function agent(capability, trust_prior, task)\n    trust ~ Beta(trust_prior...)\n    performance := capability * trust * exp(-task)\nend\n\n# Main ecosystem using nested models\n@model function networked_agent_ecosystem(tasks, trust_priors, capabilities)\n    for i in eachindex(tasks)\n        # GraphPPL interpolates performance for each agent\n        agent_perf[i] ~ agent(\n            capability = capabilities[i], \n            trust_prior = trust_priors[i],\n            task = tasks[i]\n        )\n    end\nend","category":"section"},{"location":"categories/experimental_examples/large_language_models/#The-Trust-Layer","page":"Large Language Models","title":"The Trust Layer","text":"Traditional agentic systems lack principled uncertainty about which agent to trust for what task. One can imagine a system where:\n\nTrust becomes a probabilistic belief that updates through Bayesian mechanisms\nAgent capabilities are distributions over competency domains  \nTask allocation emerges from probabilistic reasoning about trust and capability\nCross-validation happens naturally through message passing between agents","category":"section"},{"location":"categories/experimental_examples/large_language_models/#Grounded-Agentic-Reasoning","page":"Large Language Models","title":"Grounded Agentic Reasoning","text":"The most principled path forward is grounding LLMs in Bayesian reasoning. Instead of heuristic agent coordination, we get:\n\nPrincipled uncertainty about agent outputs and capabilities\nTrust propagation through established probabilistic mechanisms  \nEmergent collaboration from agents reasoning about each other's uncertainty\nRobust coordination that degrades gracefully under failure\n\nThis isn't just multi-agent systems‚Äîit's probabilistic agent networks where trust, capability, and task execution all become part of one coherent Bayesian model.\n\nThe goal: agentic systems that can reason about their own reasoning, trust each other appropriately, and coordinate complex tasks through principled uncertainty quantification.","category":"section"},{"location":"categories/experimental_examples/large_language_models/#Conclusion:-The-Weird-Idea-That-Worked","page":"Large Language Models","title":"Conclusion: The Weird Idea That Worked","text":"What started as a lunch conversation about reactive systems turned into a working prototype that treats LLMs as first-class citizens in Bayesian inference.\n\nThe key insight wasn't just technical‚Äîit was philosophical. Instead of trying to make LLMs more like traditional ML models, we asked: what if we make traditional Bayesian inference more like natural reasoning?\n\nBy hooking LLMs into RxInfer's message passing framework, we've created a bridge between LLMs and Bayesian inference.\n\nThis opens a path toward agentic systems grounded in principled uncertainty‚Äîwhere trust networks, capability reasoning, and task coordination all emerge from coherent Bayesian models.\n\nSometimes the best discoveries happen when you stop overthinking and just try the crazy idea.\n\nAnd it all started with the realization that RxInfer doesn't care what you pass through those edges.\n\nAs long as you can define the rules, you can pass anything and be reactive about it.","category":"section"},{"location":"categories/experimental_examples/large_language_models/#A-few-caveats-about-NormalMixture-node","page":"Large Language Models","title":"A few caveats about NormalMixture node","text":"There few known issues with NormalMixture node:\n\nIterations matter: with VMP, more iterations can materially change posteriors; too many iterations can lead to overconfident or wrong clusters.\nMixture limitation: NormalMixture under meanfield tends to collapse to a single Normal on its output edge, losing multi‚Äëmodality and corrupting downstream beliefs.\nPrefer gating/mixtures: use a gating/expert setup (rSLDS‚Äëstyle see rSLDS.jl) that propagates the full mixture (preserve z‚Äìy dependence) instead of moment‚Äëmatching to one Normal.\nIf keeping this model: increase iterations and use stronger priors/initialization; but for robust results, favor gating or explicit mixture propagation.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n‚åÖ [682c06a0] JSON v0.21.4\n  [e9f21f70] OpenAI v0.12.0\n  [91a5bcdd] Plots v1.41.6\n  [a194aa59] ReactiveMP v5.6.5\n  [86711068] RxInfer v4.7.0\nInfo Packages marked with ‚åÖ have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated`\n\n\n","category":"section"},{"location":"categories/advanced_examples/drone_dynamics/","page":"Drone Dynamics","title":"Drone Dynamics","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/drone_dynamics/#Drone-Dynamics","page":"Drone Dynamics","title":"Drone Dynamics","text":"Note: These examples demonstrate the use of RxInfer for motion planning. The animations show the inferred trajectories from probabilistic inference, rather than simulated executions. For more realistic simulations, especially in the 3D drone example, the model would need to be extended with a reactive environment that responds to the drone's actions during plan execution. If you're interested in collaborating on a more realistic implementation, please open a discussion and let's work on it together!\n\nusing RxInfer, LinearAlgebra","category":"section"},{"location":"categories/advanced_examples/drone_dynamics/#Defining-structures","page":"Drone Dynamics","title":"Defining structures","text":"\"\"\"\n    Environment(; gravitational_constant::Float64 = 9.81)\n\nThis structure contains the properties of the environment.\n\"\"\"\nBase.@kwdef struct Environment\n    gravitational_constant::Float64 = 9.81\nend\nget_gravity(env::Environment) = env.gravitational_constant\n\nget_gravity (generic function with 1 method)\n\n\"\"\"\n    Drone(mass, inertia, radius, force_limit)\n\nThis structure contains the properties of the drone.\n\"\"\"\nBase.@kwdef struct Drone\n    mass::Float64\n    inertia::Float64\n    radius::Float64\n    force_limit::Float64\nend\nget_mass(drone::Drone) = drone.mass\nget_properties(drone::Drone) = (drone.mass, drone.inertia, drone.radius, drone.force_limit)\n\nget_properties (generic function with 1 method)\n\n\"\"\"\n    State(x, y, vx, vy, ùúÉ, ùúî)\n\nThis structure contains the state of the drone. It contains the position, velocity, and orientation of the drone.\n\"\"\"\nstruct State\n    x::Float64\n    y::Float64\n    vx::Float64\n    vy::Float64\n    ùúÉ::Float64\n    ùúî::Float64\nend\nget_state(state::State) = (state.x, state.y, state.vx, state.vy, state.ùúÉ, state.ùúî)\n\nget_state (generic function with 1 method)","category":"section"},{"location":"categories/advanced_examples/drone_dynamics/#Model-specification","page":"Drone Dynamics","title":"Model specification","text":"\"\"\"\n    state_transition(state, actions, drone, environment, dt)\n\nThis function computes the next state of the drone given the current state, the actions, the drone properties and the environment properties.\n\"\"\"\nfunction state_transition(state, actions, drone::Drone, environment::Environment, dt)\n\n    # extract drone properties\n    m, I, r, limit  = get_properties(drone)\n\n    # extract environment properties\n    g = get_gravity(environment)\n\n    # extract feasible actions\n    Fl, Fr   = clamp.(actions, 0, limit)\n        \n    # extract state properties\n    x, y, vx, vy, Œ∏, œâ = state\n\n    # compute forces and torques\n    Fg = m * g\n    Fy = (Fl + Fr) * cos(Œ∏) - Fg\n    Fx = (Fl + Fr) * sin(Œ∏)\n    ùúè  = (Fl - Fr) * r\n\n    # compute movements\n    ax = Fx / m\n    ay = Fy / m\n    vx_new = vx + ax * dt\n#     vy_new = vx + ay * dt # old version\n    vy_new = vy + ay * dt   # new version\n    x_new  = x + vx * dt + ax * dt^2 / 2\n    y_new  = y + vy * dt + ay * dt^2 / 2\n        \n    # compute rotations\n    Œ± = ùúè / I\n    œâ_new = œâ + Œ± * dt\n    Œ∏_new = Œ∏ + œâ * dt + Œ± * dt^2 / 2\n\t\n    return [x_new, y_new, vx_new, vy_new, Œ∏_new, œâ_new]\n\nend\n\nMain.var\"##WeaveSandBox#277\".state_transition\n\n@model function drone_model(drone, environment, initial_state, goal, horizon, dt)\t\n\n\t# extract environment properties\n\tg = get_gravity(environment)\n\n\t# extract drone properties\n\tm = get_mass(drone)\n\n\t# initial state prior\n\ts[1] ~ MvNormal(mean = initial_state, covariance = 1e-5 * I)\n\n\tfor i in 1:horizon\n\n\t\t# prior on actions (mean compensates for gravity)\n\t\tu[i] ~ MvNormal(Œº = [m * g / 2, m * g / 2], Œ£ = diageye(2))\n\n\t\t# state transition\n\t\ts[i + 1] ~ MvNormal(\n            Œº = state_transition(s[i], u[i], drone, environment, dt), \n\t\t\tŒ£ = 1e-10 * I\n\t\t)\n\tend\n\t\n\ts[end] ~ MvNormal(mean = goal, covariance = 1e-5 * diageye(6))\n\nend","category":"section"},{"location":"categories/advanced_examples/drone_dynamics/#Probabilistic-inference","page":"Drone Dynamics","title":"Probabilistic inference","text":"@meta function drone_meta()\n\n\t# approximate the state transition function using the Unscented transform\n\tstate_transition() -> Unscented()\n\nend\n\ndrone_meta (generic function with 1 method)\n\nfunction move_to_target(drone::Drone, env::Environment, start::State, target, horizon, dt)\n\n    results = infer(\n        model = drone_model(\n            drone = drone, \n            environment = env,\n            horizon = horizon,\n            dt = dt\n        ),\n        data  = (\n            initial_state = collect(get_state(start)), \n            goal = [target[1], target[2], 0, 0, 0, 0],\n        ),\n        meta  = drone_meta(),\n        returnvars = (s = KeepLast(), u = KeepLast())\n    )\n\n    return results\n\nend\n\nmove_to_target (generic function with 1 method)\n\ndrone = Drone(\n    mass = 1,\n    inertia = 1,\n    radius = 0.2,\n    force_limit = 15.0\n)\n\nenv = Environment()\n\nstart = State(0.0, 0.0, 0.0, 0.0, 0.0, 0.0)\n\ntarget = [-0.8, 0.6]\n\nresults = move_to_target(drone, env, start, target, 40, 0.05)\n\nInference results:\n  Posteriors       | available for (s, u)","category":"section"},{"location":"categories/advanced_examples/drone_dynamics/#Plotting","page":"Drone Dynamics","title":"Plotting","text":"using Plots\n\nfunction plot_drone!(p, drone::Drone, state::State; color = :black)\n    x, y, x_a, y_a, Œ∏, œâ = get_state(state)\n    _, _, radius, _ = get_properties(drone)\n    dx = radius * cos(Œ∏)\n    dy = radius * sin(Œ∏)\n\n    drone_position = [ x ], [ y ]\n    drone_engines  = [ x - dx, x + dx ], [ y + dy, y - dy ]\n    drone_coordinates = [ x - dx, x, x + dx ], [ y + dy, y, y - dy ]\n\n    rotation_matrix = [ cos(-Œ∏) -sin(-Œ∏); sin(-Œ∏) cos(-Œ∏) ]\n    engine_shape = [ -1 0 1; 1 -1 1 ]\n    drone_shape  = [ -2 -2 2 2 ; -1 1 1 -1 ]\n    \n    engine_shape = rotation_matrix * engine_shape\n    drone_shape  = rotation_matrix * drone_shape\n    engine_marker = Shape(engine_shape[1, :], engine_shape[2, :])\n    drone_marker  = Shape(drone_shape[1, :], drone_shape[2, :])\n    \n    scatter!(p, drone_position[1], drone_position[2]; color = color, label = false, marker = drone_marker)\n    scatter!(p, drone_engines[1], drone_engines[2]; color = color, label = false, marker = engine_marker, ms = 10)\n    plot!(p, drone_coordinates; color = color, label = false)\n\n    return p\nend\n\nplot_drone! (generic function with 1 method)\n\nfunction animate_drone(drone::Drone, target, results::InferenceResult)\n\n    states = hcat(map(p -> mean(p), results.posteriors[:s])...)\n    \n\n    animation = @animate for k in 1:size(states,2)\n\n        # plot target\n        p = scatter([target[1]], [target[2]], label = \"target\"; color = :red)\n\n        # plot drone\n        plot_drone!(p, drone, State(states[:, k]...))\n\n        xlims!(-1.5, 1.5)\n        ylims!(-1.5, 1.5)\n    \n    end\n\n    gif(animation, \"drone.gif\", show_msg = false)\n\n    nothing\nend\n\nanimate_drone (generic function with 1 method)\n\nanimate_drone(drone, target, results)\n\n(Image: )\n\nlet \n    inferred_angle_mean = map(p -> mean(p)[5], results.posteriors[:s])\n    inferred_angle_std  = map(p -> std(p)[5],  results.posteriors[:s])\n    plot(inferred_angle_mean; ribbon = inferred_angle_std, fillalpha = 0.2, label = \"inferred angle\", size=(600,300))\nend\n\n(Image: )\n\nlet \n    inferred_forces_mean = hcat(map(p -> mean(p), results.posteriors[:u])...)'\n    inferred_forces_std  = hcat(map(p -> sqrt.(var(p)),  results.posteriors[:u])...)'\n    plot(inferred_forces_mean[:,1]; ribbon = inferred_forces_std[:,1], fillalpha = 0.2, label = \"Fl\", size=(600,300))\n    plot!(inferred_forces_mean[:,2]; ribbon = inferred_forces_std[:,2], fillalpha = 0.2, label = \"Fr\", size=(600,300))\n    \n    hline!([get_mass(drone) * get_gravity(env) / 2], label = \"Fg/2\")\nend\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/drone_dynamics/#3D-Drone-Extension","page":"Drone Dynamics","title":"3D Drone Extension","text":"This section extends our 2D drone model into three-dimensional space, allowing for full spatial navigation. The model includes:\n\n6 degrees of freedom (position and orientation)\nFour-motor configuration\nBasic aerodynamic forces\n\nNote: This implementation is a simplified model intended for educational purposes. While it captures the fundamental dynamics of a quadcopter, it omits advanced aerodynamic effects and motor dynamics for clarity.\n\n# Extended Drone structure for 4 motors\nBase.@kwdef struct Drone3D\n    mass::Float64\n    inertia::Matrix{Float64}  # 3x3 inertia matrix\n    radius::Float64\n    arm_length::Float64\n    force_limit::Float64\nend\n\nMain.var\"##WeaveSandBox#277\".Drone3D\n\nfunction get_properties(drone::Drone3D)\n    return (\n        drone.mass,\n        drone.inertia,\n        drone.radius,\n        drone.arm_length,\n        drone.force_limit\n    )\nend\n\nget_properties (generic function with 2 methods)\n\n# Extended State for 3D\nstruct State3D\n    x::Float64   # position\n    y::Float64\n    z::Float64\n    vx::Float64  # velocity\n    vy::Float64\n    vz::Float64\n    œï::Float64   # roll\n    Œ∏::Float64   # pitch\n    œà::Float64   # yaw\n    œâx::Float64  # angular velocity\n    œây::Float64\n    œâz::Float64\nend\n\nfunction get_state(state::State3D)\n    return (\n        state.x, state.y, state.z,\n        state.vx, state.vy, state.vz,\n        state.œï, state.Œ∏, state.œà,\n        state.œâx, state.œây, state.œâz\n    )\nend\n\nget_state (generic function with 2 methods)\n\n\"\"\"\n    rotation_matrix(œà, Œ∏, œï)\n\nCreate a 3D rotation matrix from yaw (œà), pitch (Œ∏), and roll (œï) angles.\n\"\"\"\nfunction rotation_matrix(œà, Œ∏, œï)\n    # Rotation matrices for each axis\n    Rz = [cos(œà) -sin(œà) 0;\n          sin(œà)  cos(œà) 0;\n          0       0      1]\n    \n    Ry = [cos(Œ∏)  0  sin(Œ∏);\n          0       1  0;\n         -sin(Œ∏)  0  cos(Œ∏)]\n    \n    Rx = [1  0       0;\n          0  cos(œï) -sin(œï);\n          0  sin(œï)  cos(œï)]\n    \n    # Combined rotation matrix (ZYX order)\n    return Rz * Ry * Rx\nend\n\nMain.var\"##WeaveSandBox#277\".rotation_matrix\n\n\"\"\"\n    state_transition_3d(state, actions, drone, environment, dt)\n\nCompute the next state of the 3D drone given current state and four motor forces.\n\"\"\"\nfunction state_transition_3d(state, actions, drone::Drone3D, environment::Environment, dt)\n    # Extract properties\n    m, I, r, L, limit = get_properties(drone)\n    g = get_gravity(environment)\n    \n    # Clamp motor forces\n    F1, F2, F3, F4 = clamp.(actions, 0, limit)\n    \n    # Extract state\n    x, y, z, vx, vy, vz, œï, Œ∏, œà, œâx, œây, œâz = state\n    \n    # Current rotation matrix\n    R = rotation_matrix(œà, Œ∏, œï)\n    \n    # Total thrust force in body frame\n    F_total = sum([F1, F2, F3, F4])\n    \n    # Compute torques\n    œÑx = L * (F2 - F4)  # roll torque\n    œÑy = L * (F1 - F3)   # pitch torque\n    œÑz = (F1 + F3 - F2 - F4) * r  # yaw torque\n    \n    # Forces in world frame\n    F_world = R * [0, 0, F_total]\n    \n    # Accelerations\n    ax = F_world[1] / m\n    ay = F_world[2] / m\n    az = F_world[3] / m - g\n    \n    # Angular accelerations\n    Œ± = I \\ ([œÑx, œÑy, œÑz] - cross([œâx, œây, œâz], I * [œâx, œây, œâz]))\n    \n    # Update velocities\n    vx_new = vx + ax * dt\n    vy_new = vy + ay * dt\n    vz_new = vz + az * dt\n    \n    # Update positions\n    x_new = x + vx * dt + ax * dt^2 / 2\n    y_new = y + vy * dt + ay * dt^2 / 2\n    z_new = z + vz * dt + az * dt^2 / 2\n    \n    # Update angular velocities\n    œâx_new = œâx + Œ±[1] * dt\n    œây_new = œây + Œ±[2] * dt\n    œâz_new = œâz + Œ±[3] * dt\n    \n    # Update angles\n    œï_new = œï + œâx * dt + Œ±[1] * dt^2 / 2\n    Œ∏_new = Œ∏ + œây * dt + Œ±[2] * dt^2 / 2\n    œà_new = œà + œâz * dt + Œ±[3] * dt^2 / 2\n    \n    return [\n        x_new, y_new, z_new,\n        vx_new, vy_new, vz_new,\n        œï_new, Œ∏_new, œà_new,\n        œâx_new, œây_new, œâz_new\n    ]\nend\n\nMain.var\"##WeaveSandBox#277\".state_transition_3d\n\n@model function drone_model_3d(drone, environment, initial_state, goal, horizon, dt)\n    # Extract properties\n    g = get_gravity(environment)\n    m = drone.mass\n    \n    # Initial state prior\n    s[1] ~ MvNormal(mean = initial_state, covariance = 1e-5 * I)\n    \n    for i in 1:horizon\n        # Prior on motor actions (mean compensates for gravity)\n        hover_force = m * g / 4\n        u[i] ~ MvNormal(Œº = [hover_force, hover_force, hover_force, hover_force], Œ£ = diageye(4))\n        \n        # State transition\n        s[i + 1] ~ MvNormal(\n            Œº = state_transition_3d(s[i], u[i], drone, environment, dt),\n            Œ£ = 1e-10 * I\n        )\n    end\n    \n    s[end] ~ MvNormal(mean = goal, covariance = 1e-5 * diageye(12))\nend\n\n@meta function drone_meta_3d()\n    state_transition_3d() -> Unscented()\nend\n\ndrone_meta_3d (generic function with 1 method)\n\nfunction move_to_target_3d(drone::Drone3D, env::Environment, start::State3D, target, horizon, dt)\n    results = infer(\n        model = drone_model_3d(\n            drone = drone,\n            environment = env,\n            horizon = horizon,\n            dt = dt\n        ),\n        data = (\n            initial_state = collect(get_state(start)),\n            goal = [target[1], target[2], target[3], 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        ),\n        meta = drone_meta_3d(),\n        returnvars = (s = KeepLast(), u = KeepLast())\n    )\n    \n    return results\nend\n\nmove_to_target_3d (generic function with 1 method)\n\nfunction move_through_waypoints(drone::Drone3D, env::Environment, start::State3D, waypoints, steps_per_segment=40, dt=0.05)\n    current_state = start\n    all_results = []\n    all_states = []\n    \n    # Move through each waypoint\n    for (i, target) in enumerate(waypoints)\n        println(\"Moving to waypoint $i: $target\")\n        \n        # Get results for this segment\n        results = move_to_target_3d(drone, env, current_state, target, steps_per_segment, dt)\n        push!(all_results, results)\n        \n        # Extract final state for next segment\n        final_states = hcat(map(p -> mean(p), results.posteriors[:s])...)\n        final_state = State3D(final_states[:, end]...)\n        push!(all_states, final_states)\n        \n        # Update current state\n        current_state = final_state\n    end\n    \n    # Combine all states for animation\n    combined_states = hcat(all_states...)\n    \n    return combined_states, waypoints\nend\n\nmove_through_waypoints (generic function with 3 methods)\n\n# Visualization function for 3D drone\nfunction plot_drone_3d!(p, drone::Drone3D, state::State3D; color=:black)\n    x, y, z, _, _, _, œï, Œ∏, œà, _, _, _ = get_state(state)\n    _, _, radius, arm_length, _ = get_properties(drone)\n    \n    # Create rotation matrix\n    R = rotation_matrix(œà, Œ∏, œï)\n    \n    # Define arm endpoints in body frame (relative to center)\n    arm_endpoints = [\n        [arm_length, 0, 0],   # Right arm (X configuration)\n        [0, arm_length, 0],   # Front arm\n        [-arm_length, 0, 0],  # Left arm\n        [0, -arm_length, 0]   # Back arm\n    ]\n    \n    # Transform arm endpoints to world frame\n    world_endpoints = []\n    for endpoint in arm_endpoints\n        # Convert endpoint to column vector for matrix multiplication\n        endpoint_vec = reshape(endpoint, :, 1)\n        # Apply rotation and translation\n        world_point = R * endpoint_vec + [x, y, z]\n        push!(world_endpoints, vec(world_point))\n    end\n    \n    # Plot center\n    scatter!(p, [x], [y], [z], color=color, label=false, markersize=5)\n    \n    # Plot arms and motors\n    for endpoint in world_endpoints\n        # Draw arm\n        plot!(p, [x, endpoint[1]], [y, endpoint[2]], [z, endpoint[3]], \n              color=color, label=false, linewidth=2)\n        # Draw motor\n        scatter!(p, [endpoint[1]], [endpoint[2]], [endpoint[3]], \n                color=color, label=false, markersize=3)\n    end\nend\n\nplot_drone_3d! (generic function with 1 method)\n\nfunction animate_drone_3d_multi(drone::Drone3D, states, targets; fps=30)\n    # Note: The rain animation is purely for visualization aesthetics\n    # and does not affect the drone's dynamics or trajectory planning\n    \n    # Create initial rain streaks\n    function generate_raindrops(n=50)\n        x = 4 * rand(n) .- 2  # range [-2, 2]\n        y = 4 * rand(n) .- 2\n        z1 = 2 .+ 4 * rand(n)  # start higher up to have some offscreen\n        z2 = z1 .- 0.3  # fixed length rain streaks\n        return (x, y, z1, z2)\n    end\n    \n    # Initialize raindrops\n    raindrops = generate_raindrops()\n    \n    # Determine dynamic plot bounds based on states and targets\n    x_vals = [states[1,:]; [t[1] for t in targets]]\n    y_vals = [states[2,:]; [t[2] for t in targets]]\n    z_vals = [states[3,:]; [t[3] for t in targets]]\n    \n    x_min, x_max = minimum(x_vals) - 0.5, maximum(x_vals) + 0.5\n    y_min, y_max = minimum(y_vals) - 0.5, maximum(y_vals) + 0.5\n    z_min, z_max = minimum(z_vals) - 0.5, maximum(z_vals) + 0.5\n    \n    # Ensure the plot window is at least 4x4x4 for good visualization\n    x_range = max(x_max - x_min, 4.0)\n    y_range = max(y_max - y_min, 4.0)\n    z_range = max(z_max - z_min, 4.0)\n    \n    # Center the plot window\n    x_center = (x_min + x_max) / 2\n    y_center = (y_min + y_max) / 2\n    z_center = (z_min + z_max) / 2\n    \n    x_min, x_max = x_center - x_range/2, x_center + x_range/2\n    y_min, y_max = y_center - y_range/2, y_center + y_range/2\n    z_min, z_max = z_center - z_range/2, z_center + z_range/2\n    \n    animation = @animate for k in 1:size(states,2)\n        # Update raindrop positions\n        fall_speed = 0.1\n        z1 = raindrops[3] .- fall_speed\n        z2 = raindrops[4] .- fall_speed\n        \n        # Regenerate raindrops that have fallen below view\n        below_view = findall(z2 .<= z_min)\n        if !isempty(below_view)\n            new_drops = generate_raindrops(length(below_view))\n            raindrops[1][below_view] = new_drops[1]\n            raindrops[2][below_view] = new_drops[2]\n            z1[below_view] = new_drops[3]\n            z2[below_view] = new_drops[4]\n        end\n        \n        # Update raindrops state\n        raindrops = (raindrops[1], raindrops[2], z1, z2)\n        \n        p = plot3d(\n            xlims=(x_min, x_max), ylims=(y_min, y_max), zlims=(z_min, z_max),\n            xlabel=\"X\", ylabel=\"Y\", zlabel=\"Z\",\n            camera=(45, 30),\n            title=\"Multi-Waypoint Drone Flight\",\n            background=:white\n        )\n        \n        # Draw rain streaks\n        for i in 1:length(raindrops[1])\n            if raindrops[4][i] > z_min  # only draw if in view\n                plot!(p, [raindrops[1][i], raindrops[1][i]], \n                        [raindrops[2][i], raindrops[2][i]], \n                        [raindrops[3][i], raindrops[4][i]],\n                     color=:grey, \n                     linestyle=:dash,\n                     alpha=0.6,\n                     legend=false,\n                     linewidth=1)\n            end\n        end\n        \n        # Plot all targets\n        for (i, target) in enumerate(targets)\n            scatter!(p, [target[1]], [target[2]], [target[3]], \n                    label=i == 1 ? \"waypoints\" : false, \n                    color=:red,\n                    markersize=i == 1 ? 5 : 3)\n            \n            # Connect waypoints with lines\n            if i > 1\n                prev_target = targets[i-1]\n                plot!(p, [prev_target[1], target[1]], \n                         [prev_target[2], target[2]], \n                         [prev_target[3], target[3]],\n                     color=:red, linestyle=:dash, label=false, linewidth=1)\n            end\n        end\n        \n        # Plot drone\n        if size(states, 1) >= 12  # Make sure we have all 12 components for State3D\n            current_state = State3D(states[:, k]...)\n            plot_drone_3d!(p, drone, current_state)\n        else\n            # If we don't have enough state components, just plot a point at the position\n            scatter!(p, [states[1,k]], [states[2,k]], [states[3,k]], \n                   color=:black, markersize=4, label=false)\n        end\n        \n        # Add trajectory trace (last 100 points)\n        trace_start = max(1, k-100)\n        if k > 1\n            plot!(p, states[1,trace_start:k], states[2,trace_start:k], states[3,trace_start:k],\n                  color=:blue, label=false, linewidth=1, linealpha=0.5)\n        end\n    end\n\n    gif(animation, \"drone_3d_multi.gif\", fps=fps, show_msg = false)\n\n    nothing\nend\n\nanimate_drone_3d_multi (generic function with 1 method)\n\n# Create drone instance\ndrone_3d = Drone3D(\n    mass = 1.0,\n    inertia = diagm([0.1, 0.1, 0.15]),  # 3√ó3 diagonal inertia matrix\n    radius = 0.1,\n    arm_length = 0.2,\n    force_limit = 15.0\n)\n\nenv = Environment()\n\n# Initial state\nstart = State3D(\n    0.0, 0.0, 0.0,  # position (x, y, z)\n    0.0, 0.0, 0.0,  # velocity (vx, vy, vz)\n    0.0, 0.0, 0.0,  # orientation (œï, Œ∏, œà)\n    0.0, 0.0, 0.0   # angular velocity (œâx, œây, œâz)\n)\n\n# Define a sequence of waypoints for a square pattern\nwaypoints = [\n    [1.0, 1.0, 1.0],    # Front-right corner\n    [-1.0, 1.0, 1.0],   # Front-left corner\n    [-1.0, -1.0, 1.0],  # Back-left corner\n    [1.0, -1.0, 1.0],   # Back-right corner\n    [0.0, 0.0, 0.0]     # Land at center\n]\n\n# Run simulation through all waypoints\ncombined_states, targets = move_through_waypoints(drone_3d, env, start, waypoints);\n\nMoving to waypoint 1: [1.0, 1.0, 1.0]\nMoving to waypoint 2: [-1.0, 1.0, 1.0]\nMoving to waypoint 3: [-1.0, -1.0, 1.0]\nMoving to waypoint 4: [1.0, -1.0, 1.0]\nMoving to waypoint 5: [0.0, 0.0, 0.0]\n\nanimate_drone_3d_multi(drone_3d, combined_states, targets)\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [37e2e46d] LinearAlgebra v1.12.0\n\n\n","category":"section"},{"location":"categories/problem_specific/gamma_mixture/","page":"Gamma Mixture","title":"Gamma Mixture","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/problem_specific/gamma_mixture/#Gamma-Mixture-Model","page":"Gamma Mixture","title":"Gamma Mixture Model","text":"This notebook implements one of the experiments outlined in https://biaslab.github.io/publication/mp-based-inference-in-gmm/.","category":"section"},{"location":"categories/problem_specific/gamma_mixture/#Load-packages","page":"Gamma Mixture","title":"Load packages","text":"using RxInfer, Random, StatsPlots\n\n# create custom structure for model parameters for simplicity\nstruct GammaMixtureModelParameters\n    nmixtures   # number of mixtures\n    priors_as   # tuple of priors for variable a\n    priors_bs   # tuple of priors for variable b\n    prior_s     # prior of variable s\nend","category":"section"},{"location":"categories/problem_specific/gamma_mixture/#Model-specification","page":"Gamma Mixture","title":"Model specification","text":"@model function gamma_mixture_model(y, parameters)\n\n    # fetch information from struct\n    nmixtures = parameters.nmixtures\n    priors_as = parameters.priors_as\n    priors_bs = parameters.priors_bs\n    prior_s   = parameters.prior_s\n\n    # set prior on global selection variable\n    s ~ prior_s\n\n    # allocate variables for mixtures\n    local as\n    local bs\n\n    # set priors on variables of mixtures\n    for i in 1:nmixtures\n        as[i] ~ Gamma(shape = shape(priors_as[i]), rate = rate(priors_as[i]))\n        bs[i] ~ Gamma(shape = shape(priors_bs[i]), rate = rate(priors_bs[i]))\n    end\n\n    # allocate variables for local selection variable\n    local z\n    # specify local selection variable and data generating process\n    for i in 1:length(y)\n        z[i] ~ Categorical(s)\n        y[i] ~ GammaMixture(switch = z[i], a = as, b = bs)\n    end\n    \nend\n\nconstraints = @constraints begin \n\n    q(z, as, bs, s) = q(z)q(as)q(bs)q(s)\n\n    q(as) = q(as[begin])..q(as[end])\n    q(bs) = q(bs[begin])..q(bs[end])\n    \n    q(as)::PointMassFormConstraint(starting_point = (args...) -> [1.0])\nend\n\nConstraints: \n  q(z, as, bs, s) = q(z)q(as)q(bs)q(s)\n  q(as) = q(as[(begin)..(end)])\n  q(bs) = q(bs[(begin)..(end)])\n  q(as) :: PointMassFormConstraint()\n\n# specify seed and number of data points\nrng = MersenneTwister(43)\nn_samples = 2500\n\n# specify parameters of mixture model that generates the data\n# Note that mixture components have exactly the same means\nmixtures  = [ Gamma(9.0, inv(27.0)), Gamma(90.0, inv(270.0)) ]\nnmixtures = length(mixtures)\nmixing    = rand(rng, nmixtures)\nmixing    = mixing ./ sum(mixing)\nmixture   = MixtureModel(mixtures, mixing)\n\n# generate data set\ndataset = rand(rng, mixture, n_samples);\n\n# specify priors of probabilistic model\n# NOTE: As the means of the mixtures \"collide\", we specify informative prior for selector variable\nnmixtures = 2\ngpriors = GammaMixtureModelParameters(\n    nmixtures,                                                    # number of mixtures\n    [ Gamma(1.0, 0.1), Gamma(1.0, 1.0) ],                         # priors on variables a\n    [ GammaShapeRate(10.0, 2.0), GammaShapeRate(1.0, 3.0) ],      # priors on variables b\n    Dirichlet(1e3*mixing)                                         # prior on variable s\n)\n\ngmodel         = gamma_mixture_model(parameters = gpriors)\ngdata          = (y = dataset, )\ninit           = @initialization begin \n    q(s) = gpriors.prior_s\n    q(z) = vague(Categorical, gpriors.nmixtures)\n    q(bs) = GammaShapeRate(1.0, 1.0)\nend\ngreturnvars    = (s = KeepLast(), z = KeepLast(), as = KeepEach(), bs = KeepEach())\n\ngoptions = (\n     \n    default_factorisation = MeanField() # Mixture models require Mean-Field assumption currently\n)\n\ngresult = infer(\n    model          = gmodel, \n    data           = gdata,\n    constraints    = constraints,\n    options        = (limit_stack_depth = 100,),\n    initialization = init,\n    returnvars     = greturnvars,\n    free_energy    = true,\n    iterations     = 250, \n    showprogress   = true\n);\n\n# extract inferred parameters\n_as, _bs = mean.(gresult.posteriors[:as][end]), mean.(gresult.posteriors[:bs][end])\n_dists   = map(g -> Gamma(g[1], inv(g[2])), zip(_as, _bs))\n_mixing = mean(gresult.posteriors[:s])\n\n# create model from inferred parameters\n_mixture   = MixtureModel(_dists, _mixing);\n\n# report on outcome of inference\nprintln(\"Generated means: $(mean(mixtures[1])) and $(mean(mixtures[2]))\")\nprintln(\"Inferred means: $(mean(_dists[1])) and $(mean(_dists[2]))\")\nprintln(\"========\")\nprintln(\"Generated mixing: $(mixing)\")\nprintln(\"Inferred mixing: $(_mixing)\")\n\nGenerated means: 0.3333333333333333 and 0.33333333333333337\nInferred means: 0.33503922980941936 and 0.3333889004608452\n========\nGenerated mixing: [0.4617110702349237, 0.5382889297650763]\nInferred mixing: [0.3727573351926404, 0.6272426648073596]\n\n# plot results\np1 = histogram(dataset, ylim = (0, 13), xlim = (0, 1), normalize=:pdf, label=\"data\", opacity=0.3)\np1 = plot!(mixture, label=false, title=\"Generated mixtures\", linewidth=3.0)\n\np2 = histogram(dataset, ylim = (0, 13), xlim = (0, 1), normalize=:pdf, label=\"data\", opacity=0.3)\np2 = plot!(_mixture, label=false, title=\"Inferred mixtures\", linewidth=3.0)\n\n# evaluate the convergence of the algorithm by monitoring the BFE\np3 = plot(gresult.free_energy, label=false, xlabel=\"iterations\", title=\"Bethe FE\")\n\nplot(plot(p1, p2, layout = @layout([ a; b ])), plot(p3), layout = @layout([ a b ]), size = (800, 400))\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [86711068] RxInfer v4.7.0\n  [f3b207a7] StatsPlots v0.15.8\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/problem_specific/probit_model/","page":"Probit Model","title":"Probit Model","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/problem_specific/probit_model/#Probit-Model","page":"Probit Model","title":"Probit Model","text":"","category":"section"},{"location":"categories/problem_specific/probit_model/#Estimation-of-pollutant","page":"Probit Model","title":"Estimation of pollutant","text":"Mortality y_t of fishs in a lake is observed over time. Mortality rate textBer(Phi(x_t)) is linked to the level of pollutant x_t in the lake according to the probit model (see below). The municipality wants to keep track of the pollution. To do so, the level of pollutant in the lake is tracked over time through observations of the fishs.","category":"section"},{"location":"categories/problem_specific/probit_model/#Objective","page":"Probit Model","title":"Objective","text":"Probit model aims to infer a random proces value from noisy binary observations of it. RxInfer comes with support for expectation propagation (EP). In this demo we illustrate EP in the context of state-estimation in a linear state-space model that combines a Gaussian state-evolution model with a discrete observation model. Here, the probit function links continuous variable x_t with the discrete variable y_t. The model is defined as:\n\nbeginaligned\n    u = 01 \n    x_0 sim mathcalN(0 100) \n    x_t sim mathcalN(x_t-1+ u 001) \n    y_t sim mathrmBer(Phi(x_t))\nendaligned","category":"section"},{"location":"categories/problem_specific/probit_model/#Import-packages","page":"Probit Model","title":"Import packages","text":"using RxInfer, GraphPPL,StableRNGs, Random, Plots, Distributions\nusing StatsFuns: normcdf","category":"section"},{"location":"categories/problem_specific/probit_model/#Data-generation","page":"Probit Model","title":"Data generation","text":"function generate_data(nr_samples::Int64; seed = 123)\n    \n    rng = StableRNG(seed)\n    \n    # hyper parameters\n    u = 0.1\n\n    # allocate space for data\n    data_x = zeros(nr_samples + 1)\n    data_y = zeros(nr_samples)\n    \n    # initialize data\n    data_x[1] = -2\n    \n    # generate data\n    for k in eachindex(data_y)\n        \n        # calculate new x\n        data_x[k+1] = data_x[k] + u + sqrt(0.01)*randn(rng)\n        \n        # calculate y\n        data_y[k] = normcdf(data_x[k+1]) > rand(rng)\n        \n    end\n    \n    # return data\n    return data_x, data_y\n    \nend;\n\nn = 40\n\n40\n\ndata_x, data_y = generate_data(n);\n\np = plot(xlabel = \"t\", ylabel = \"x, y\")\np = scatter!(p, data_y, label = \"y\")\np = plot!(p, data_x[2:end], label = \"x\")\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/probit_model/#Model-specification","page":"Probit Model","title":"Model specification","text":"@model function probit_model(y, prior_x)\n    \n    # specify uninformative prior\n    x_prev ~ prior_x\n    \n    # create model \n    for k in eachindex(y)\n        x[k] ~ Normal(mean = x_prev + 0.1, precision = 100)\n        y[k] ~ Probit(x[k]) where {\n            # Probit node by default uses RequireMessage pipeline with vague(NormalMeanPrecision) message as initial value for `in` edge\n            # To change initial value user may specify it manually, like. Changes to the initial message may improve stability in some situations\n            dependencies = RequireMessageFunctionalDependencies(in = NormalMeanPrecision(0.0, 0.01))\n        }\n        x_prev = x[k]\n    end\n    \nend;","category":"section"},{"location":"categories/problem_specific/probit_model/#Probit-Node","page":"Probit Model","title":"Probit Node","text":"Probit node needs an initialisation of the 'in' message because of this computation methodology. The input message is not directly calculated. First the marginal q(in) is computed and then the output message, this using the margianalisation formula. \n\noverrightarrowmu(x) overleftarrowmu(x) = q(x)\n\nConsequently an initial message overleftarrowmu(in) is needed to start iterate. It can be speficied as in the above example. Otherwise RxInfer will initiate it at a default value.","category":"section"},{"location":"categories/problem_specific/probit_model/#Inference","page":"Probit Model","title":"Inference","text":"result = infer(\n    model = probit_model(prior_x=Normal(0.0, 100.0)), \n    data  = (y = data_y, ), \n    iterations = 5, \n    returnvars = (x = KeepLast(),),\n    free_energy  = true\n)\n\nInference results:\n  Posteriors       | available for (x)\n  Free Energy:     | Real[25.6698, 18.0157, 17.9199, 17.9194, 17.9194]","category":"section"},{"location":"categories/problem_specific/probit_model/#Results","page":"Probit Model","title":"Results","text":"mx = result.posteriors[:x]\n\np = plot(xlabel = \"t\", ylabel = \"x, y\", legend = :bottomright)\np = scatter!(p, data_y, label = \"y\")\np = plot!(p, data_x[2:end], label = \"x\", lw = 2)\np = plot!(mean.(mx)[2:end], ribbon = std.(mx)[2:end], fillalpha = 0.2, label=\"x (inferred mean)\")\n\nf = plot(xlabel = \"t\", ylabel = \"BFE\")\nf = plot!(result.free_energy, label = \"Bethe Free Energy\")\n\nplot(p, f, size = (800, 400))\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [31c24e10] Distributions v0.25.123\n  [b3f8163a] GraphPPL v4.6.5\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [4c63d2b9] StatsFuns v1.5.2\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"#RxInfer.jl-Examples","page":"Home","title":"RxInfer.jl Examples","text":"Welcome to the examples gallery for RxInfer.jl, a Julia package for reactive message passing and probabilistic programming.\n\nnote: Note\nThis documentation is automatically generated from Jupyter notebooks in the repository. The examples are regularly tested to ensure they work with the latest version of RxInfer.jl.","category":"section"},{"location":"#About-RxInfer.jl","page":"Home","title":"About RxInfer.jl","text":"RxInfer.jl is a Julia package that combines message passing-based inference with reactive programming paradigms. It provides:\n\nA flexible framework for probabilistic programming\nReactive message passing for real-time inference\nEfficient and scalable inference algorithms\nSupport for both online and offline inference\nIntegration with the Julia ecosystem\nPython integration through client-server infrastructure\n\nRead more about RxInfer.jl in the RxInfer.jl Documentation.","category":"section"},{"location":"#Python-Integration","page":"Home","title":"Python Integration","text":"RxInfer can be used from Python through our client-server infrastructure:\n\nRxInferServer.jl - A RESTful API service for deploying RxInfer models\nRxInferClient.py - Python SDK for interacting with RxInferServer\n\nThe server provides OpenAPI-compliant endpoints for model deployment and inference, while the Python client offers a convenient interface to:\n\nCreate and manage model instances\nExecute inference tasks\nMonitor inference progress\nHandle authentication and API keys\nProcess results in a native format\n\nFor more information, visit:\n\nServer Documentation\nPython SDK Documentation","category":"section"},{"location":"#Examples","page":"Home","title":"Examples","text":"Browse our comprehensive collection of examples in the List of Examples section. Each example demonstrates different aspects of RxInfer.jl's capabilities and includes detailed explanations and code.","category":"section"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"We welcome contributions from the community! Whether you want to fix bugs, improve existing examples, or add new ones, please check our contribution guide for detailed instructions and best practices.","category":"section"},{"location":"#Getting-Started","page":"Home","title":"Getting Started","text":"To run these examples locally:\n\nClone the repository:\n\ngit clone https://github.com/ReactiveBayes/RxInferExamples.jl.git\n\nBuild the examples:\n\nmake examples\n\nAll the examples are Jupyter notebooks, which also can be run with Jupyter.  Note, however, that the automatic build process merges the dependencies in all the examples into one single temporary environment.  This means that dependencies can be resolved differently when running examples individually in comparison with the automatic build process.\n\nBuild the documentation:\n\nmake docs\n\nPreview the documentation:\n\nmake preview","category":"section"},{"location":"#Resources","page":"Home","title":"Resources","text":"How to Contribute\nRxInfer.jl Documentation\nRxInfer.jl GitHub Repository\nJulia Documentation\n\ninfo: For Developers\nIf you're interested in how the examples and documentation are built, check out our Build System Documentation.","category":"section"},{"location":"#License","page":"Home","title":"License","text":"RxInfer.jl and these examples are licensed under the MIT License. See the LICENSE file in the repository for more details.\n\n","category":"section"},{"location":"categories/basic_examples/bayesian_multinomial_regression/","page":"Bayesian Multinomial Regression","title":"Bayesian Multinomial Regression","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/basic_examples/bayesian_multinomial_regression/#Bayesian-Multinomial-Regression","page":"Bayesian Multinomial Regression","title":"Bayesian Multinomial Regression","text":"This notebook is an introductory tutorial to Bayesian multinomial regression with RxInfer.\n\nusing RxInfer, Plots, StableRNGs, Distributions, ExponentialFamily, StatsPlots\nimport ExponentialFamily: softmax","category":"section"},{"location":"categories/basic_examples/bayesian_multinomial_regression/#Model-Description","page":"Bayesian Multinomial Regression","title":"Model Description","text":"The key innovation in Linderman et al. (2015) is extending the P√≥lya-gamma augmentation scheme to the multinomial case. This allows us to transform the non-conjugate multinomial likelihood into a conditionally conjugate form by introducing auxiliary P√≥lya-gamma random variables.\n\nThe multinomial regression model with P√≥lya-gamma augmentation can be written as: p(y  psi N) = textMultinomial(y N psi)\n\nwhere:\n\ny\nis a K-dimensional vector of count data with N total counts\npsi\nis a K-1 -dimensional Gaussian random variable","category":"section"},{"location":"categories/basic_examples/bayesian_multinomial_regression/#Implementation","page":"Bayesian Multinomial Regression","title":"Implementation","text":"In this notebook, we will implement the P√≥lya-gamma augmented Bayesian multinomial regression model with RxInfer by performing inference using message passing to estimate the posterior distribution of the regression coefficients\n\nfunction generate_multinomial_data(rng=StableRNG(123);N = 20, k=9, nsamples = 1000)\n    Œ® = randn(rng, k)\n    p = softmax(Œ®)\n    X = rand(rng, Multinomial(N, p), nsamples)\n    X= [X[:,i] for i in 1:size(X,2)];\n    return X, Œ®,p\nend\n\ngenerate_multinomial_data (generic function with 2 methods)\n\nnsamples = 5000\nN = 30\nk = 40\nX, Œ®, p = generate_multinomial_data(N=N,k=k,nsamples=nsamples);\n\nThe MultinomialPolya factor node is used to model the likelihood of the multinomial distribution. \n\nDue to non-conjugacy of the likelihood and the prior distribution, we need to use a more complex inference algorithm. RxInfer provides an Expectation Propagation (EP) [2] algorithm to infer the posterior distribution. Due to EP's approximation, we need to specify an inbound message for the regression coefficients while using the MultinomialPolya factor node. This feature is implemented in the dependencies keyword argument during the creation of the MultinomialPolya factor node. ReactiveMP.jl provides a RequireMessageFunctionalDependencies type that is used to specify the inbound message for the regression coefficients œà. Refer to the ReactiveMP.jl documentation for more information.\n\n@model function multinomial_model(obs, N, Œæ_œà, W_œà)\n    œà ~ MvNormalWeightedMeanPrecision(Œæ_œà, W_œà)\n    obs .~ MultinomialPolya(N, œà) where {dependencies = RequireMessageFunctionalDependencies(œà = MvNormalWeightedMeanPrecision(Œæ_œà, W_œà))}\nend\n\nresult = infer(\n    model = multinomial_model(Œæ_œà=zeros(k-1), W_œà=rand(Wishart(3, diageye(k-1))), N=N),\n    data = (obs=X, ),\n    iterations = 50,\n    free_energy = true,\n    showprogress = true,\n    options = (\n        limit_stack_depth = 100,\n    )\n)\n\nInference results:\n  Posteriors       | available for (œà)\n  Free Energy:     | Real[4.46321e5, 2.92436e5, 2.37894e5, 2.1217e5, 1.9808\n8e5, 1.8962e5, 1.84184e5, 1.80523e5, 1.77961e5, 1.76115e5  ‚Ä¶  1.69572e5, 16\n9565.0, 1.69559e5, 1.69553e5, 1.69548e5, 1.69543e5, 1.69539e5, 1.69536e5, 1\n.69533e5, 1.6953e5]\n\nplot(result.free_energy[1:end], \n     title=\"Free Energy Over Iterations\",\n     xlabel=\"Iteration\",\n     ylabel=\"Free Energy\",\n     linewidth=2,\n     legend=false,\n     grid=true,\n     )\n\n(Image: )\n\npredictive = @call_rule MultinomialPolya(:x, Marginalisation) (q_N = PointMass(N), q_œà = result.posteriors[:œà][end], meta = MultinomialPolyaMeta(21))\nprintln(\"Estimated data generation probabilities: $(predictive.p)\")\nprintln(\"True data generation probabilities: $(p)\")\n\nEstimated data generation probabilities: [0.012053995872832911, 0.027502050\n303520112, 0.004516413196205192, 0.012921616988871721, 0.01339714630810129,\n 0.03744352160150754, 0.007542114227184686, 0.007069085014269098, 0.0058961\n75658907185, 0.004142272530417706, 0.005505594740130777, 0.0037309864817522\n16, 0.004342432469546663, 0.036157420147324426, 0.10874833393635622, 0.0722\n9156890374912, 0.02631130923998673, 0.02428542572555059, 0.0102201330716841\n23, 0.008645700856303064, 0.039781950061060556, 0.005043438574951307, 0.008\n433870186334307, 0.026621029285982676, 0.0064535303995955666, 0.00788860688\n4947967, 0.009365753947270166, 0.007425300280600728, 0.017504221894968735, \n0.007056493032847854, 0.008608871868756739, 0.00372866068689085, 0.01135803\n3439474861, 0.010481143640479765, 0.09500356413221656, 0.04364134830714717,\n 0.13263813120982576, 0.02759491660456495, 0.03063633628834655, 0.068011501\n99953573]\nTrue data generation probabilities: [0.012475572764691347, 0.02759115956301\n153, 0.004030932560100506, 0.013008651265311708, 0.012888510278451618, 0.03\n7656116813111006, 0.007242363105598982, 0.006930069564505769, 0.00538389836\n228327, 0.0036198124274772225, 0.005212387391120808, 0.003185556887255863, \n0.003820168769118259, 0.036849638787622915, 0.109428569898501, 0.0726075387\n5224316, 0.026079268674281158, 0.024477855252934583, 0.010207778995219957, \n0.008532295265944583, 0.040242532118754906, 0.005181587450423221, 0.0082073\n91370854009, 0.02741148713822125, 0.006623087410725917, 0.00836770271463416\n2, 0.009668643362989908, 0.007171783607096945, 0.016985615150215773, 0.0070\n80691453323701, 0.008297044496975403, 0.0037359000700039487, 0.011142755810\n390478, 0.010256554277897088, 0.09528238587772694, 0.04369806970660494, 0.1\n3308101804159636, 0.02665693577960761, 0.030479170124456504, 0.069201498658\n71575]\n\nmse = mean((predictive.p - p).^2);\nprintln(\"MSE between estimated and true data generation probabilities: $mse\")\n\nMSE between estimated and true data generation probabilities: 1.89054912889\n50783e-7\n\n@model function multinomial_regression(obs, N, X, œï, ŒæŒ≤, WŒ≤)\n    Œ≤ ~ MvNormalWeightedMeanPrecision(ŒæŒ≤, WŒ≤)\n    for i in eachindex(obs)\n        Œ®[i] := œï(X[i])*Œ≤\n        obs[i] ~ MultinomialPolya(N, Œ®[i]) where {dependencies = RequireMessageFunctionalDependencies(œà = MvNormalWeightedMeanPrecision(zeros(length(obs[i])-1), diageye(length(obs[i])-1)))}\n    end\nend\n\nfunction generate_regression_data(rng=StableRNG(123);œï = identity,N = 3, k=5, nsamples = 1000)\n    Œ≤ = randn(rng, k)\n    X = randn(rng, nsamples, k, k)\n    X = [X[i,:,:] for i in 1:size(X,1)];\n    Œ® = œï.(X)\n    p = map(x -> logistic_stick_breaking(x*Œ≤), Œ®)\n    return map(x -> rand(rng, Multinomial(N, x)), p), X, Œ≤, p\nend\n\ngenerate_regression_data (generic function with 2 methods)\n\nœï = x -> sin(x)\nobs_regression, X_regression, Œ≤_regression, p_regression = generate_regression_data(;nsamples = 5000, œï = œï);\n\nreg_results = infer(  \n    model = multinomial_regression(N = 3, œï = œï, ŒæŒ≤ = zeros(5), WŒ≤ = rand(Wishart(5, diageye(5)))),\n    data = (obs=obs_regression,X = X_regression ),\n    iterations = 20,\n    free_energy = true,\n    showprogress = true,\n    returnvars = KeepLast(),\n    options = (\n        limit_stack_depth = 100,\n    ) \n)\n\nInference results:\n  Posteriors       | available for (Œ®, Œ≤)\n  Free Energy:     | Real[11948.1, 11580.9, 11498.1, 11476.9, 11471.2, 1146\n9.6, 11469.1, 11469.0, 11469.0, 11469.0, 11468.9, 11468.9, 11468.9, 11468.9\n, 11468.9, 11468.9, 11468.9, 11468.9, 11468.9, 11468.9]\n\nprintln(\"estimated Œ≤: with mean and covariance: $(mean_cov(reg_results.posteriors[:Œ≤]))\")\nprintln(\"true Œ≤: $(Œ≤_regression)\")\n\nestimated Œ≤: with mean and covariance: ([-0.11449795234034406, 0.6638985532\n247678, -1.2561369410479188, -0.084937516087038, -0.07981372208298623], [0.\n00014804099745771847 -2.1623085598137334e-6 3.5724137105960578e-6 -1.605629\n6019653144e-6 3.179460897821635e-6; -2.1623085598137334e-6 0.00015180200850\n437899 -1.9380677557043336e-5 -1.676690496969613e-7 1.334236986728766e-6; 3\n.5724137105960578e-6 -1.9380677557043336e-5 0.00018000274217229 4.430620591\n130175e-6 5.211485556919953e-7; -1.6056296019653144e-6 -1.676690496969613e-\n7 4.430620591130175e-6 0.0001401831440838639 3.186293119683969e-6; 3.179460\n897821635e-6 1.334236986728766e-6 5.211485556919953e-7 3.186293119683969e-6\n 0.00013945367383737446])\ntrue Œ≤: [-0.12683768965424458, 0.6668851724871252, -1.2566124895590247, -0.\n08499562516549662, -0.094274004848194]\n\nplot(reg_results.free_energy,\ntitle=\"Free Energy Over Iterations\",\nxlabel=\"Iteration\",\nylabel=\"Free Energy\",\nlinewidth=2,\nlegend=false,\ngrid=true,)\n\n(Image: )\n\nmse_Œ≤ =  mean((mean(reg_results.posteriors[:Œ≤]) - Œ≤_regression).^2)\nprintln(\"MSE of Œ≤ estimate: $mse_Œ≤\")\n\nMSE of Œ≤ estimate: 7.410366245910666e-5\n\nWe can visualize how the logistic stick-breaking transformation of the simplex coordinates of the regression coefficients affects the prior distribution of the regression coefficients and vice versa since the logistic stick-breaking transformation is invertible.\n\n\n# Previous helper functions remain the same\nœÉ(x) = 1 / (1 + exp(-x))\nœÉ_inv(x) = log(x / (1 - x))\n\nfunction jacobian_det(œÄ)\n    K = length(œÄ)\n    det = 1.0\n    for k in 1:(K-1)\n        num = 1 - sum(œÄ[1:(k-1)])\n        den = œÄ[k] * (1 - sum(œÄ[1:k]))\n        det *= num / den\n    end\n    return det\nend\n\nfunction œà_to_œÄ(œà::Vector{Float64})\n    K = length(œà) + 1\n    œÄ = zeros(K)\n    for k in 1:(K-1)\n        œÄ[k] = œÉ(œà[k]) * (1 - sum(œÄ[1:(k-1)]))\n    end\n    œÄ[K] = 1 - sum(œÄ[1:(K-1)])\n    return œÄ\nend\n\nfunction œÄ_to_œà(œÄ)\n    K = length(œÄ)\n    œà = zeros(K-1)\n    œà[1] = œÉ_inv(œÄ[1])\n    for k in 2:(K-1)\n        œà[k] = œÉ_inv(œÄ[k] / (1 - sum(œÄ[1:(k-1)])))\n    end\n    return œà\nend\n\n# Function to compute density in simplex coordinates\nfunction compute_simplex_density(x::Float64, y::Float64, Œ£::Matrix{Float64})\n    # Check if point is inside triangle\n    if y < 0 || y > 1 || x < 0 || x > 1 || (x + y) > 1\n        return 0.0\n    end\n    \n    # Convert from simplex coordinates to œÄ\n    œÄ1 = x\n    œÄ2 = y\n    œÄ3 = 1 - x - y\n    \n    try\n        œà = œÄ_to_œà([œÄ1, œÄ2, œÄ3])\n        # Compute Gaussian density\n        dist = MvNormal(zeros(2), Œ£)\n        return pdf(dist, œà) * abs(jacobian_det([œÄ1, œÄ2, œÄ3]))\n    catch\n        return 0.0\n    end\n   \nend\n\nfunction plot_transformed_densities()\n    # Create three different covariance matrices\n    ###For higher variances values needs scaling for proper visualization.\n    œÉ¬≤ = 1.0\n    Œ£_corr = [œÉ¬≤ 0.9œÉ¬≤; 0.9œÉ¬≤ œÉ¬≤]\n    Œ£_anticorr = [œÉ¬≤ -0.9œÉ¬≤; -0.9œÉ¬≤ œÉ¬≤]\n    Œ£_uncorr = [œÉ¬≤ 0.0; 0.0 œÉ¬≤]\n    \n    # Plot Gaussian densities\n    œà1, œà2 = range(-4sqrt(œÉ¬≤), 4sqrt(œÉ¬≤), length=500), range(-4sqrt(œÉ¬≤), 4sqrt(œÉ¬≤), length=100)\n    \n    p1 = contour(œà1, œà2, (x,y) -> pdf(MvNormal(zeros(2), Œ£_corr), [x,y]),\n                 title=\"Correlated Prior\", xlabel=\"œà‚ÇÅ\", ylabel=\"œà‚ÇÇ\")\n    p2 = contour(œà1, œà2, (x,y) -> pdf(MvNormal(zeros(2), Œ£_anticorr), [x,y]),\n                 title=\"Anti-correlated Prior\", xlabel=\"œà‚ÇÅ\", ylabel=\"œà‚ÇÇ\")\n    p3 = contour(œà1, œà2, (x,y) -> pdf(MvNormal(zeros(2), Œ£_uncorr), [x,y]),\n                 title=\"Uncorrelated Prior\", xlabel=\"œà‚ÇÅ\", ylabel=\"œà‚ÇÇ\")\n    \n    # Plot simplex densities\n    n_points = 500\n    x = range(0, 1, length=n_points)\n    y = range(0, 1, length=n_points)\n    \n    # Plot simplices\n    p4 = contour(x, y, (x,y) -> compute_simplex_density(x, y, Œ£_corr),\n                 title=\"Correlated Simplex\")\n    \n    # Add simplex boundaries and median lines\n    plot!(p4, [0,1,0,0], [0,0,1,0], color=:black, label=\"\")  # Triangle boundaries\n    \n    p5 = contour(x, y, (x,y) -> compute_simplex_density(x, y, Œ£_anticorr),\n                 title=\"Anti-correlated Simplex\")\n    plot!(p5, [0,1,0,0], [0,0,1,0], color=:black, label=\"\")\n    \n    p6 = contour(x, y, (x,y) -> compute_simplex_density(x, y, Œ£_uncorr),\n                 title=\"Uncorrelated Simplex\")\n    plot!(p6, [0,1,0,0], [0,0,1,0], color=:black, label=\"\")\n    \n    # Combine all plots\n    plot(p1, p2, p3, p4, p5, p6, layout=(2,3), size=(900,600))\nend\n\n# Generate the plots\nplot_transformed_densities()\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [31c24e10] Distributions v0.25.123\n  [62312e5e] ExponentialFamily v2.2.0\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [f3b207a7] StatsPlots v0.15.8\n\n\n","category":"section"},{"location":"categories/basic_examples/pomdp_control/","page":"Pomdp Control","title":"Pomdp Control","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/basic_examples/pomdp_control/#POMDP-Control-with-Reactive-Inference","page":"Pomdp Control","title":"POMDP Control with Reactive Inference","text":"This notebook demonstrates how to perform control in Partially Observable Markov Decision Processes (POMDPs) using reactive message passing and variational inference in RxInfer.jl.\n\nWe will cover:\n\nSetting up a simple POMDP model\nDefining the state transition and observation models\nImplementing the control policy\nPerforming inference and control using message passing\nVisualizing the results\n\nusing RxInfer\nusing Distributions\nusing Plots\nusing Random\nusing ProgressMeter","category":"section"},{"location":"categories/basic_examples/pomdp_control/#Environment-Setup","page":"Pomdp Control","title":"Environment Setup","text":"For this example, we will implement the Windy Gridworld environment using RxEnvironments.jl. The Windy Gridworld is a simple gridworld environment with deterministic transitions and observations. This code is adapted from the RxEnvironments.jl documentation, and a more elaborate explanation of can be found there. \n\nThe environment consists of:\n\nA grid with wind values for each column\nAn agent with a current position\nA goal position to reach\n\nThe agent can:\n\nMove in cardinal directions (one step at a time)\nObserve its current position\nBe affected by wind when moving\n\nThe wind effect is applied after each movement, potentially pushing the agent upward by 0-2 positions depending on the column.\n\nFirst we will define the environment and the agent.\n\nusing RxEnvironments\nusing Plots\n\nstruct WindyGridWorld{N}\n    wind::NTuple{N,Int}\n    agents::Vector\n    goal::Tuple{Int,Int}\nend\n\nmutable struct WindyGridWorldAgent\n    position::Tuple{Int,Int}\nend\n\n\nRxEnvironments.update!(env::WindyGridWorld, dt) = nothing # The environment has no \"internal\" updating process over time\n\nfunction RxEnvironments.receive!(env::WindyGridWorld{N}, agent::WindyGridWorldAgent, action::Tuple{Int,Int}) where {N}\n    if action[1] != 0\n        @assert action[2] == 0 \"Only one of the two actions can be non-zero\"\n    elseif action[2] != 0\n        @assert action[1] == 0 \"Only one of the two actions can be non-zero\"\n    end\n    new_position = (agent.position[1] + action[1], agent.position[2] + action[2] + env.wind[agent.position[1]])\n    if all(elem -> 0 < elem < N, new_position)\n        agent.position = new_position\n    end\nend\n\nfunction RxEnvironments.what_to_send(env::WindyGridWorld, agent::WindyGridWorldAgent)\n    return agent.position\nend\n\nfunction RxEnvironments.what_to_send(agent::WindyGridWorldAgent, env::WindyGridWorld)\n    return agent.position\nend\n\nfunction RxEnvironments.add_to_state!(env::WindyGridWorld, agent::WindyGridWorldAgent)\n    push!(env.agents, agent)\nend\n\nfunction reset_env!(environment::RxEnvironments.RxEntity{<:WindyGridWorld,T,S,A}) where {T,S,A}\n    env = environment.decorated\n    for agent in env.agents\n        agent.position = (1, 1)\n    end\n    for subscriber in RxEnvironments.subscribers(environment)\n        send!(subscriber, environment, (1, 1))\n    end\nend\n\nfunction plot_environment(environment::RxEnvironments.RxEntity{<:WindyGridWorld,T,S,A}) where {T,S,A}\n    env = environment.decorated\n    p1 = scatter([env.goal[1]], [env.goal[2]], color=:blue, label=\"Goal\", xlims=(0, 6), ylims=(0, 6))\n    for agent in env.agents\n        p1 = scatter!([agent.position[1]], [agent.position[2]], color=:red, label=\"Agent\")\n    end\n    return p1\nend\n\nplot_environment (generic function with 1 method)\n\nenv = RxEnvironment(WindyGridWorld((0, 1, 1, 1, 0), [], (4, 3)))\nagent = add!(env, WindyGridWorldAgent((1, 1)))\nplot_environment(env)\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/pomdp_control/#Model-Setup","page":"Pomdp Control","title":"Model Setup","text":"First, we'll define our POMDP model structure. We will use the DiscreteTransition node in RxInfer to define the state transition model. The DiscreteTransition node is a special node that accepts any number of Categorical distributions as input, and outputs a Categorical distribution. This means that we can use it to define a state transition model that accepts the previous state and the control as Categorical random variables, but we can also use it to define our observation model! Furthermore, the DiscreteTransition node can be used both for parameter inference and for inference-as-planning, isn't that neat?\n\n@model function pomdp_model(p_A, p_B, p_goal, p_control, previous_control, p_previous_state, current_y, future_y, T, m_A, m_B)\n    # Instantiate all model parameters with priors\n    A ~ p_A\n    B ~ p_B\n    previous_state ~ p_previous_state\n    \n    # Paremeter inference\n    current_state ~ DiscreteTransition(previous_state, B, previous_control)\n    current_y ~ DiscreteTransition(current_state, A)\n\n    prev_state = current_state\n    # Inference-as-planning\n    for t in 1:T\n        controls[t] ~ p_control\n        s[t] ~ DiscreteTransition(prev_state, m_B, controls[t])\n        future_y[t] ~ DiscreteTransition(s[t], m_A)\n        prev_state = s[t]\n    end\n    # Goal prior initialization\n    s[end] ~ p_goal\nend\n\nNow, this model, because we use A and B for every timestep, contains loops, so we have to initialize the inference procedure properly. Furthermore, RxInfer does not support learning a joint probability distribution over the parameters and the states, so we have to supply the model with variational constraints that reflect this:\n\ninit = @initialization begin\n    q(A) = DirichletCollection(diageye(25) .+ 0.1)\n    q(B) = DirichletCollection(ones(25, 25, 4))\nend\n\nconstraints = @constraints begin\n    q(previous_state, previous_control, current_state, B) = q(previous_state, previous_control, current_state)q(B)\n    q(current_state, current_y, A) = q(current_state, current_y)q(A)\n    q(current_state, s, controls, B) = q(current_state, s, controls), q(B)\n    q(s, future_y, A) = q(s, future_y), q(A)\nend\n\nConstraints: \n  q(previous_state, previous_control, current_state, B) = q(previous_state,\n previous_control, current_state)q(B)\n  q(current_state, current_y, A) = q(current_state, current_y)q(A)\n  q(current_state, s, controls, B) = q(current_state, s, controls)q(B)\n  q(s, future_y, A) = q(s, future_y)q(A)\n\nNow, in order to use this model, we have to define the priors for the model parameters. The WindyGridworld environment has a 5-by-5 grid, so we need to instantiate a prior 25-by-25 transition matrices for every control! That's quite a lot of parameters, but as we will see, RxInfer will handle this just fine. We will give our agent a control space of 4 actions, so we need to instantiate 4 transition matrices. Furthermore, we have to transform the output from the environment to a 1-in-25 index, and the controls from a 1-in-4 index to a direction tuple.\n\nThe prior on our observation model tells our model that the prior belief is to trust it's observations, but we might be able to deviate from this. However, in this example, the observation model is deterministic and has no noise, meaning that our agent won't have any reason to deviate from the prior.\n\np_A = DirichletCollection(diageye(25) .+ 0.1)\np_B = DirichletCollection(ones(25, 25, 4))\n\nfunction grid_location_to_index(pos::Tuple{Int, Int})\n    return (pos[2] - 1) * 5 + pos[1]\nend\n\nfunction index_to_grid_location(index::Int)\n    return (index % 5, index √∑ 5 + 1,)\nend\n\nfunction index_to_one_hot(index::Int)\n    return [i == index ? 1.0 : 0.0 for i in 1:25]\nend\n\ngoal = Categorical(index_to_one_hot(grid_location_to_index((4, 3))))\n\nDistributions.Categorical{Float64, Vector{Float64}}(\nsupport: Base.OneTo(25)\np: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  ‚Ä¶  0.0, 0.0, 0.0, 0.0\n, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n)\n\nRxEnvironments.jl is a package that allows us to easily communicate between our agent and our environment. We can send actions to the environment, and the environment will automatically respond with the corresponding observations. In order to access these in our model, we can subscribe to the observations and then use the data function to access the last observation.\n\nNow for our main control loop, we will use a receding horizon control strategy. We will first take an action, observe the environment, and then update our belief. We will then repeat this process for a horizon of 10 steps. In order to learn the parameters of our model, we will conduct this experiment 100 times. We can use the infer function from RxInfer to perform inference on our model.\n\n# Number of times to run the experiment\nn_experiments = 100\n# Number of steps in each experiment\nT = 4\nobservations = keep(Any)\n# Subscribe the agent to receive observations\nRxEnvironments.subscribe_to_observations!(agent, observations)\nsuccesses = []\n\n\n@showprogress for i in 1:n_experiments\n    # Reset environment to initial state and initialize state belief to starting position (1,1)\n    reset_env!(env)\n    p_s = Categorical(index_to_one_hot(grid_location_to_index((1, 1))))\n    # Initialize previous action as \"down\", as this is neutral from the starting position\n    policy = [Categorical([0.0, 0.0, 1.0, 0.0])]\n    prev_u = [0.0, 0.0, 1.0, 0.0]\n    # Run for T-1 steps in each experiment\n    for t in 1:T\n\n         # Convert policy to actual movement in environment\n         current_action = mode(first(policy))\n         if current_action == 1\n             send!(env, agent, (0, 1))  # Move up \n             prev_u = [1.0, 0.0, 0.0, 0.0]\n         elseif current_action == 2\n             send!(env, agent, (1, 0))  # Move right\n             prev_u = [0.0, 1.0, 0.0, 0.0]\n         elseif current_action == 3\n             send!(env, agent, (0, -1))  # Move down\n             prev_u = [0.0, 0.0, 1.0, 0.0]\n         elseif current_action == 4\n             send!(env, agent, (-1, 0))  # Move left\n             prev_u = [0.0, 0.0, 0.0, 1.0]\n         end\n\n        # Get last observation and convert to one-hot encoding\n        last_observation = index_to_one_hot(grid_location_to_index(RxEnvironments.data(last(observations))))\n        \n        # Perform inference using the POMDP model\n        inference_result = infer(\n            model = pomdp_model(\n                p_A = p_A,  # prior on observation model parameters\n                p_B = p_B,  # prior on transition model parameters\n                T = max(T - t, 1),  # remaining time steps\n                p_previous_state = p_s,  # posterior belief on previous state\n                p_goal = goal,  # prior on goal state\n                p_control = vague(Categorical, 4),  # prior over controls\n                m_A = mean(p_A),\n                m_B = mean(p_B)\n            ),\n            # Provide data for inference\n            data = (\n                previous_control = prev_u,\n                current_y = last_observation,\n                future_y = UnfactorizedData(fill(missing, max(T - t, 1)))\n            ),\n            constraints = constraints,\n            initialization = init,\n            iterations = 10\n        )\n        \n        # Update beliefs based on inference results\n        p_s = last(inference_result.posteriors[:current_state])  # Update state belief\n        policy = last(inference_result.posteriors[:controls])  # Get policy\n\n        # Update model parameters globally for the entire notebook\n        global p_A = last(inference_result.posteriors[:A])  # Update observation model\n        global p_B = last(inference_result.posteriors[:B])  # Update transition model\n\n        if RxEnvironments.data(last(observations)) == (4, 3)\n            break\n        end\n    end\n    if RxEnvironments.data(last(observations)) == (4, 3)\n        push!(successes, true)\n    else\n        push!(successes, false)\n    end\nend\n\nNow, in this example, we have used a trick: we supplied the mean of p_A and p_B to the model to do the predictions for the future in order to learn the controls. The real reason we did this is because we do not want messages from the future to influence the model parameters, instead only learning the model parameters from past data. This is a simple way to do this, but it is not the only way. We could have supplied the full distribution p_A and p_B to the model, and used A and B in the predictive step as well, but then we would need a separate way to make sure we do not use future messages to influence the model parameters.\n\nmean(successes)\n\n0.85\n\nWe see that our agent is able to learn the optimal policy for this environment, and reaches the goal state in 85% of cases!\n\nplot_environment(env)\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [31c24e10] Distributions v0.25.123\n  [91a5bcdd] Plots v1.41.6\n  [92933f4c] ProgressMeter v1.11.0\n  [5ea003d0] RxEnvironments v0.2.15\n  [86711068] RxInfer v4.7.0\n\n\n","category":"section"},{"location":"categories/advanced_examples/gp_regression_by_ssm/","page":"Gp Regression By Ssm","title":"Gp Regression By Ssm","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/gp_regression_by_ssm/#Solve-GP-regression-by-SDE","page":"Gp Regression By Ssm","title":"Solve GP regression by SDE","text":"In this notebook, we solve a GP regression problem by using \"Stochastic Differential Equation\" (SDE). This method is well described in the dissertation \"Stochastic differential equation methods for spatio-temporal Gaussian process regression.\" by Arno Solin and \"Sequential Inference for Latent Temporal Gaussian Process Models\" by Jouni Hartikainen. The idea of the method is as follows.\n\nSuppose a function f(x) follows a zero-mean Gaussian Process beginaligned f(x) sim mathcalGP(0 k(xx)) endaligned\n\nWhen the dimensionality of x is 1, we can consider f(x) as a stochastic process over time, i.e. f(t). For a certain classses of covariance functions, f(t) is a solution to an m-th order linear stochastic differential equation (SDE) beginaligned a_0 f(t) + a_1 fracd f(t)dt + dots + a_m fracd^m f(t)dt^m = w(t)  endaligned\n\nwhere w(t) is a zero-mean white noise process with spectral density Q_c. If we define a vector-valued function mathbff(t) = (f(t) ddt f(t)dots d^m-1dt^m-1f(t)), then we can rewrite the above SDE under the companion form\n\nbeginaligned\nfracd mathbff(t)dt = mathbfF mathbff(t) + mathbfL w(t) quad (1)\nendaligned\n\nwhere mathbfF and mathbfL are defined based on the choice of covariance functions.  From (1), we have the following state-space model: beginaligned mathbff_k = mathbfA_k-1  mathbff_k-1 + mathbfq_k-1 quad mathbfq_k-1 sim mathcalN(mathbf0 mathbfQ_k-1) quad(2a) \ny_k = mathbfH  mathbff(t_k) + epsilon_k  quad epsilon_k sim mathcalN(0 sigma^2_noise) quad(2b) \nendaligned\n\nwhere mathbfA_k = exp(mathbfFDelta t_k), with Delta t_k = t_k+1 - t_k, is called the discrete-time state transition matrix, and mathbfQ_k the process noise covariance matrix. For the computation of mathbfQ_k, we will come back later. According to Arno Solin and Jouni Hartikainen's dissertation, the GP regression problem amounts to the inference problem of the above state-space model, and this can be solved by RTS-smoothing. The state-space model starts from  the initial state f_0 sim mathcalN(mathbf0 mathbfP_0). For stationary covariance function, the SDE has a stationary state f_infty sim mathcalN(mathbf0 mathbfP_infty), where mathbfP_infty is the solution to beginaligned fracdmathbfP_inftydt = mathbfF mathbfP_infty + mathbfP_infty mathbfF^T + mathbfL mathbfQ_c mathbfL^T = 0 quad (mathrmLyapunov  equation) endaligned\n\nWith this stationary condition, the process noise covariance mathbfQ_k is computed as follows beginaligned mathbfQ_k = mathbfP_infty - mathbfA_k mathbfP_infty mathbfA_k^T  endaligned\n\nFor one-dimensional problem the SDE representation of the GP is defined by the matrices mathbfF  mathbfL  mathbfQ_c  mathbfP_0 and mathbfH. Once we obtain all the matrices, we can do GP regression by implementing RTS-smoothing on the state-space model (2). In this notebook we will particularly use the Matern class of covariance functions for Gaussian Process.\n\nusing RxInfer, Random, Distributions, LinearAlgebra, Plots","category":"section"},{"location":"categories/advanced_examples/gp_regression_by_ssm/#Create-state-space-model-for-GP-regression","page":"Gp Regression By Ssm","title":"Create state space model for GP regression","text":"Here we create a state-space model beginaligned mathbff_k = mathbfA_k-1  mathbff_k-1 + mathbfq_k-1 quad mathbfq_k-1 sim mathcalN(mathbf0 mathbfQ_k-1) \ny_k = mathbfH  mathbff(t_k) + epsilon_k  quad epsilon_k sim mathcalN(0 sigma^2_noise) \nendaligned where y_k is the noisy observation of the function f at time t_k, and sigma^2_noise is the noise variance and assumed to be known.\n\n@model function gp_regression(y, P, A, Q, H, var_noise)\n    f_prev ~ MvNormal(Œº = zeros(length(H)), Œ£ = P) #initial state\n    for i in eachindex(y)\n        f[i] ~ MvNormal(Œº = A[i] * f_prev,Œ£ = Q[i])\n        y[i] ~ Normal(Œº = dot(H, f[i]), var = var_noise)\n        f_prev = f[i]\n    end\nend","category":"section"},{"location":"categories/advanced_examples/gp_regression_by_ssm/#Generate-data","page":"Gp Regression By Ssm","title":"Generate data","text":"Random.seed!(10)\nn = 100\nœÉ¬≤_noise = 0.04;\nt = collect(range(-2, 2, length=n)); #timeline\nf_true = sinc.(t); # true process\nf_noisy = f_true + sqrt(œÉ¬≤_noise)*randn(n); #noisy process\n\npos = sort(randperm(75)[1:2:75]); \nt_obser = t[pos]; # time where we observe data\n\ny_data = Array{Union{Float64,Missing}}(missing, n)\nfor i in pos \n    y_data[i] = f_noisy[i]\nend\n\nŒ∏ = [1., 1.]; # store [l, œÉ¬≤]\nŒît = [t[1]]; # time difference\nappend!(Œît, t[2:end] - t[1:end-1]);","category":"section"},{"location":"categories/advanced_examples/gp_regression_by_ssm/#Let's-visualize-our-data","page":"Gp Regression By Ssm","title":"Let's visualize our data","text":"plot(t, f_true, label=\"True process f(t)\")\nscatter!(t_obser, y_data[pos], label = \"Noisy observations\")\nxlabel!(\"t\")\nylabel!(\"f(t)\")\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/gp_regression_by_ssm/#Covariance-function:-Matern-3/2","page":"Gp Regression By Ssm","title":"Covariance function: Matern-3/2","text":"The Matern is a stationary covariance function and defined as follows beginaligned k(tau) = sigma^2 frac2^1-nuGamma(nu) left(fracsqrt2nutaul right)^nu K_nuleft(fracsqrt2nutaul right) endaligned where  beginaligned sigma^2 textthe magnitude scale hyperparameter\nl textthe characteristic length-scale\nnu textthe smoothness hyperparameter\nK_nu() textthe modified Bessel function of the second kind endaligned When we say the Matern-3/2, we mean nu=32. The matrices for the state space model are computed as follows beginaligned mathbfF = beginpmatrix 0  1\n-lambda^2  -2lambda endpmatrix quad quad mathbfL = beginpmatrix 0  1 endpmatrix quad quad mathbfP_infty = beginpmatrix sigma^2  0  0  lambda^2sigma^2 endpmatrix quad quad mathbfH = beginpmatrix 1  0 endpmatrix quad quad Q_c = 4lambda^3sigma^2 endaligned  where lambda = fracsqrt3l  From these matrices we can define mathbfA_k and mathbfQ_k.\n\nŒª = sqrt(3)/Œ∏[1];\n#### compute matrices for the state-space model ######\nL = [0., 1.];\nH = [1., 0.];\nF = [0. 1.; -Œª^2 -2Œª]\nP‚àû = [Œ∏[2] 0.; 0. (Œª^2*Œ∏[2]) ]\nA = [exp(F * i) for i in Œît]; \nQ = [P‚àû - i*P‚àû*i' for i in A];\n\nresult_32 = infer(\n    model = gp_regression(P = P‚àû, A = A, Q = Q, H = H, var_noise = œÉ¬≤_noise),\n    data = (y = y_data,)\n)\n\nInference results:\n  Posteriors       | available for (f, f_prev)\n  Predictions      | available for (y)","category":"section"},{"location":"categories/advanced_examples/gp_regression_by_ssm/#Covariance-function:-Matern-5/2","page":"Gp Regression By Ssm","title":"Covariance function: Matern-5/2","text":"Now let's try the Matern-5/2 kernel. The matrices for the SDE representation of the Matern-5/2 are:\n\nbeginaligned\nmathbfF = beginpmatrix\n0  1  0\n0  0  1 \n-lambda^3  -3lambda^2  -3lambda\nendpmatrix quad quad mathbfL = beginpmatrix\n0  0  1\nendpmatrix quad quad mathbfH = beginpmatrix\n1  0  0\nendpmatrix quad quad Q_c = frac163 sigma^2 lambda^5 \nendaligned\n\nwhere lambda = sqrt5  l. To find mathbfP_infty, we solve the Lyapunov equation\n\nbeginaligned\nfracdmathbfP_inftydt = mathbfF mathbfP_infty + mathbfP_infty mathbfF^T + mathbfL mathbfQ_c mathbfL^T = 0\nendaligned\n\nof which the solution is\n\nbeginaligned\nvec(mathbfP_infty) = (mathbfI otimes mathbfF + mathbfFotimesmathbfI)^-1 vec(-mathbfLQ_cmathbfL^T)\nendaligned\n\nwhere vec() is the vectorization operator and otimes denotes the Kronecker product. Now we can find mathbfA_k and mathbfQ_k \n\nbeginaligned\nmathbfA_k = exp(mathbfFDelta t_k) \nendaligned\n\nbeginaligned\nmathbfQ_k = mathbfP_infty - mathbfA_k mathbfP_infty mathbfA_k^T  \nendaligned\n\nŒª = sqrt(5)/Œ∏[1];\n#### compute matrices for the state-space model ######\nL = [0., 0., 1.];\nH = [1., 0., 0.];\nF = [0. 1. 0.; 0. 0. 1.;-Œª^3 -3Œª^2 -3Œª]\nQc = 16/3 * Œ∏[2] * Œª^5;\n\nI = diageye(3) ; \nvec_P = inv(kron(I,F) + kron(F,I)) * vec(-L * Qc * L'); \nP‚àû = reshape(vec_P,3,3);\nA = [exp(F * i) for i in Œît]; \nQ = [P‚àû - i*P‚àû*i' for i in A];\n\nresult_52 = infer(\n    model = gp_regression(P = P‚àû, A = A, Q = Q, H = H, var_noise = œÉ¬≤_noise),\n    data = (y = y_data,)\n)\n\nInference results:\n  Posteriors       | available for (f, f_prev)\n  Predictions      | available for (y)","category":"section"},{"location":"categories/advanced_examples/gp_regression_by_ssm/#Result","page":"Gp Regression By Ssm","title":"Result","text":"slicedim(dim) = (a) -> map(e -> e[dim], a)\n\nplot(t, mean.(result_32.posteriors[:f]) |> slicedim(1), ribbon = var.(result_32.posteriors[:f]) |> slicedim(1) .|> sqrt, label =\"Approx. process_M32\", title = \"Matern-3/2\", legend =false, lw = 2)\nplot!(t, mean.(result_52.posteriors[:f]) |> slicedim(1), ribbon = var.(result_52.posteriors[:f]) |> slicedim(1) .|> sqrt, label =\"Approx. process_M52\",legend = :bottomleft, title = \"GPRegression by SSM\", lw = 2)\nplot!(t, f_true,label=\"true process\", lw = 2)\nscatter!(t_obser, f_noisy[pos], label=\"Observations\")\nxlabel!(\"t\")\nylabel!(\"f(t)\")\n\n(Image: )\n\nAs we can see from the plot, both cases of Matern kernel provide good approximations (small variance) to the true process at the area with dense observations (namely from t = 0 to around 3.5), and when we move far away from this region the approximated processes become less accurate (larger variance). This result makes sense because GP regression exploits the correlation between observations to predict unobserved points, and the choice of covariance functions as well as their hyperparameters might not be optimal. We can increase the accuracy of the approximated processes by simply adding more observations. This way of improvement does not trouble the state-space method much but it might cause computational problem for naive GP regression, because with N observations the complexity of naive GP regression scales with N^3 while the state-space method scales linearly with N.     \n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [31c24e10] Distributions v0.25.123\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/","page":"Bayesian Trust Learning","title":"Bayesian Trust Learning","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#Bayesian-Trust-Learning-for-LLM-Routing:-Teaching-Routers-to-Learn-from-Their-Mistakes","page":"Bayesian Trust Learning","title":"Bayesian Trust Learning for LLM Routing: Teaching Routers to Learn from Their Mistakes","text":"Or: How We Taught Our Router to Stop Worrying and Learn to Love Production Feedback","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#The-Question-That-Started-It-All","page":"Bayesian Trust Learning","title":"The Question That Started It All","text":"Picture this: It's 3 AM. Your support system just routed a critical database corruption ticket to Claude Haiku (the 0.25/million token model) because it looked \"simple enough.\" Six hours and three escalations later, your biggest client is furious, and you're wondering why your \"intelligent\" router keeps making the same mistakes.\n\nMeanwhile, across town, your competitor is sending every single ticket to GPT-4 \"just to be safe,\" burning through 100,000 monthly for questions like \"how do I reset my password?\"\n\nThere has to be a better way. And there is‚Äîbut it involves teaching your router something most systems never learn: humility.","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#The-Routing-Revolution-(and-Its-Dirty-Little-Secret)","page":"Bayesian Trust Learning","title":"The Routing Revolution (and Its Dirty Little Secret)","text":"The LLM routing world has come a long way! OpenRouter elegantly handles 400+ models behind one API (processing over 100M in inference annually), while RouteLLM demonstrates impressive ~85% cost reductions on benchmarks. These are genuinely great tools that have solved real problems. But here's the thing they don't really learn if they were right.\n\nImagine having a waiter who keeps recommending the \"chef's special ghost pepper curry\" to people who can barely handle mild salsa - and never learns from all those red-faced, teary-eyed customers running for water.","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#Your-Tickets-Are-Special-Snowflakes-(Really!)","page":"Bayesian Trust Learning","title":"Your Tickets Are Special Snowflakes (Really!)","text":"Let me tell you a secret about those benchmark numbers everyone quotes: they were tested on public data, which is about as similar to your production tickets as a philosophy debate is to debugging Kubernetes.\n\nYour tickets have:\n\nThat weird error code (rule not found) your senior engineer created in 2019\nCustomer complaints that somehow always spike during Mercury retrograde\nTechnical terms that would make GPT-4 cry (\"MethodError: no method matching make_node!\")\nA mysterious correlation between ticket complexity and whether it's submitted before lunch\n\nStatic routers look at this chaos and confidently apply rules learned from \"how to write a haiku\" queries. No wonder they struggle.","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#Enter-the-Bayesian-Router:-The-Router-That-Says-\"I-Don't-Know-(Yet)\"","page":"Bayesian Trust Learning","title":"Enter the Bayesian Router: The Router That Says \"I Don't Know (Yet)\"","text":"Here's our proposition: what if your router could learn from its mistakes?\n\nNot in the \"we'll retrain the model quarterly\" way, but in the \"oh, I messed that up, let me remember that for next time\" way. You know, like humans do (ideally).\n\nusing RxInfer\nusing Distributions\n\n# The three stages of router grief:\n# 1. Denial: \"This ticket looks simple!\" (routes to Haiku)\n# 2. Anger: \"Why is the customer escalating?!\" (still routes to Haiku)\n# 3. Acceptance: \"Maybe I should learn from this...\" (our Bayesian approach)","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#The-Architecture:-Three-Routers-Walk-into-a-Support-Queue...","page":"Bayesian Trust Learning","title":"The Architecture: Three Routers Walk into a Support Queue...","text":"We're going to create three different routing \"personalities\" and let them duke it out for your trust. Think of it as \"The Voice\" but for routing algorithms:\n\n@model function routing_strategy(y, ticket_context)\n    # Meet our contestants:\n    # 1. The Optimist - \"Everything is fine! Use the cheap model!\"\n    Œ∏_simple ~ simple_router(ticket_context = ticket_context)\n    \n    # 2. The Pessimist - \"It's all terrible! GPT-4 for everything!\"\n    Œ∏_complex ~ complex_router(ticket_context = ticket_context)\n    \n    # 3. The Realist - \"Let's be reasonable about this...\"\n    Œ∏_medium  ~ medium_router(ticket_context = ticket_context)\n    \n    # We start by trusting them equally (how naive!)\n    routing_strategy ~ Categorical(ones(3) ./ 3)\n    \n    # But then reality hits...\n    Œ∏ ~ Mixture(switch = routing_strategy, inputs = [Œ∏_simple, Œ∏_medium, Œ∏_complex])\n    \n    # And we learn who's actually worth trusting\n    for i in eachindex(y)\n        y[i] ~ Bernoulli(Œ∏)  # 1 = \"big model needed!\", 0 = \"small model worked\"\n    end\nend","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#The-Secret-Sauce:-LLMs-All-the-Way-Down","page":"Bayesian Trust Learning","title":"The Secret Sauce: LLMs All the Way Down","text":"Now, you might be thinking: \"Wait, you're using LLMs to decide which LLM to use? Isn't that like asking the fox to guard the henhouse?\" Yes! But here's the twist: we're asking multiple foxes with different biases, then learning which fox is actually good at guarding (spoiler: it's rarely the one you'd expect).\n\n\"\"\"\n    LLMPrior: Where LLMs Judge Other LLMs\n    \n    It's like asking your friends which restaurant to go to,\n    except your friends are language models and the restaurant\n    is also a language model. Welcome to 2025!\n\"\"\"\nstruct LLMPrior end\n\n@node LLMPrior Stochastic [ \n    (b, aliases = [belief]),     # What the LLM believes\n    (m, aliases = [model]),      # Which LLM we're asking\n    (c, aliases = [context]),    # The ticket in question\n    (t, aliases = [task])        # \"Should we panic and use GPT-4?\"\n]\n\nEach LLM has its own personality when it comes to routing decisions. After extensive psychological profiling (read: we made educated guesses), here's what we found:\n\n@rule LLMPrior(:b, Marginalisation) (q_m::PointMass{<:String}, q_c::PointMass{<:String}, q_t::PointMass{<:String}) = begin\n    model_name = q_m.point\n    \n    # GPT models: The anxious overachievers\n    # \"This could be complex! Better use GPT-4! What if it's not complex? \n    #  Still use GPT-4! WHAT IF WE'RE WRONG?!\"\n    if model_name in [\"gpt-5\", \"gpt-4.1\"]\n        return Beta(0.20, 0.05)  # Almost always says \"use complex model\"\n    \n    # Claude models: The confident minimalists\n    # \"Pfft, this is easy. Haiku can handle it. Trust me, I'm Claude.\"\n    elseif model_name in [\"claude-sonnet\", \"claude-opus\"]\n        return Beta(3.0, 9.0)  # Usually says \"use simple model\"\n        \n    # Claude Haiku: The wild card\n    # \"Maybe complex? Maybe simple? Life is uncertain, embrace the chaos!\"\n    elseif model_name in [\"claude-haiku\"]\n        return Beta(3.0, 3.0)  # 50/50 with high variance\n        \n    # GPT-4o-mini: The pessimistic realist\n    # \"It's probably fine with a simple model... but I've been hurt before.\"\n    elseif model_name in [\"gpt-4o-mini\"]\n        return Beta(1.0, 5.0)  # Leans toward simple but cautious\n    end\nend\n\nWe obviously cheat here, we just don't want to burn tokens on CI each time we run test. In a production, you'd actually call an LLM (we suggest PromptingTools.jl if you stick to Julia)\n\nusing PromptingTools as PT\nusing Distributions\n\n# Define what we want from the LLM\nstruct BetaParams\n    alpha::Float64  # Œ± parameter (how much we believe \"complex model needed\")\n    beta::Float64   # Œ≤ parameter (how much we believe \"simple model sufficient\")\nend\n\n@rule LLMPrior(:b, Marginalisation) (q_m::PointMass{<:String}, q_c::PointMass{<:String}, q_t::PointMass{<:String}) = begin\n    context = q_c.point\n    model = q_m.point\n    \n    # Ask the LLM for its honest opinion (in Beta distribution form)\n    response = PT.aiextract(\n        \"\"\"You're a routing expert. Given this ticket:\n           $context\n           \n           Return Beta distribution parameters for P(needs complex model).\n           Higher alpha = more complex, Higher beta = more simple.\"\"\";\n        return_type = BetaParams,\n        model = model,\n        temperature = 0.0  # We want consistency, not creativity\n    )\n    \n    # Sanitize because LLMs sometimes return nonsense\n    Œ± = response.content.alpha > 0 ? response.content.alpha : 1.0\n    Œ≤ = response.content.beta > 0 ? response.content.beta : 1.0\n    \n    return Beta(Œ±, Œ≤)\nend","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#Building-the-Routing-Dream-Team","page":"Bayesian Trust Learning","title":"Building the Routing Dream Team","text":"Now let's assemble our routers. Each one consults different LLMs and blends their opinions:\n\n@model function complex_router(Œ∏, ticket_context)\n    # The premium committee: Only the finest LLMs\n    Œ∏_opus ~ LLMPrior(m = \"claude-opus\", c = ticket_context, t = \"assess_complexity\")\n    Œ∏_gpt  ~ LLMPrior(m = \"gpt-5\", c = ticket_context, t = \"assess_complexity\")\n    \n    # We trust Opus more because it sounds fancier\n    switch ~ Categorical([0.2, 0.8]) \n    Œ∏ ~ Mixture(switch = switch, inputs = [Œ∏_opus, Œ∏_gpt])\nend\n\n@model function medium_router(Œ∏, ticket_context)\n    # The balanced committee: Not too hot, not too cold\n    Œ∏_claude ~ LLMPrior(m = \"claude-sonnet\", c = ticket_context, t = \"assess_complexity\")\n    Œ∏_gpt    ~ LLMPrior(m = \"gpt-4.1\", c = ticket_context, t = \"assess_complexity\")\n    \n    # Sonnet gets more weight because it's more poetic about its decisions\n    switch ~ Categorical([0.7, 0.3]) \n    Œ∏ ~ Mixture(switch = switch, inputs = [Œ∏_claude, Œ∏_gpt])\nend\n\n@model function simple_router(Œ∏, ticket_context)\n    # The budget committee: \"Have you considered... not spending money?\"\n    Œ∏_claude_haiku ~ LLMPrior(m = \"claude-haiku\", c = ticket_context, t = \"assess_complexity\")\n    Œ∏_gpt_mini     ~ LLMPrior(m = \"gpt-4o-mini\", c = ticket_context, t = \"assess_complexity\")\n    \n    # Slight preference for Haiku because it's more zen about everything\n    switch ~ Categorical([0.6, 0.4]) \n    Œ∏ ~ Mixture(switch = switch, inputs = [Œ∏_claude_haiku, Œ∏_gpt_mini])\nend","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#The-Moment-of-Truth:-Learning-from-Reality","page":"Bayesian Trust Learning","title":"The Moment of Truth: Learning from Reality","text":"Let's see what happens when we feed our system some real outcomes. Imagine a customer with a money transfer issue:\n\nticket = \"I have been trying to transfer money to my other bank account for the last 10 days but it keeps failing. Can you help me?\"\n\n# The harsh reality of what happened when we routed this:\n# 0 = Ticket was successfully resolved with simple model\n# 1 = Ticket was successfully resolved with complex model\noutcomes = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,  # 11 simple model worked\n            1.0,                                                    # 1 complex model worked\n            0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,                 # 8 simple model worked\n            1.0, 1.0]                                               # 2 complex model worked\n\n# Let the Bayesian magic happen\nresult_joint = infer(\n    model = routing_strategy(ticket_context=ticket), \n    data  = (y = outcomes, ),\n    returnvars = KeepLast(),\n    addons = AddonLogScale(),\n    postprocess = UnpackMarginalPostprocess(),\n)\n\n# The verdict is in!\nprintln(\"Trust scores after learning from reality:\")\nprintln(\"Simple Router: \", mean(result_joint.posteriors[:routing_strategy].p[1]))\nprintln(\"Medium Router: \", mean(result_joint.posteriors[:routing_strategy].p[2]))  \nprintln(\"Complex Router: \", mean(result_joint.posteriors[:routing_strategy].p[3]))\n\nTrust scores after learning from reality:\nSimple Router: 0.3420062143831011\nMedium Router: 0.4792506103356868\nComplex Router: 0.17874317528121217","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#The-Results-Are-In:-What-Did-We-Learn?","page":"Bayesian Trust Learning","title":"The Results Are In: What Did We Learn?","text":"","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#Understanding-What-We-Measured","page":"Bayesian Trust Learning","title":"Understanding What We Measured","text":"First, let's be crystal clear about what our data means:\n\n0 = Ticket was successfully resolved with a SIMPLE model (for example, Haiku worked!) 1 = Ticket required a COMPLEX model (for example, GPT-5 worked!)\n\nOur data: 20 zeros, 3 ones = 87% of similar tickets were solved by cheap models!","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#The-Trust-Report-Card","page":"Bayesian Trust Learning","title":"The Trust Report Card","text":"After processing our banking tickets, here's how much we trust each router:\n\nresult_joint.posteriors[:routing_strategy]\n\nDistributions.Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), \np=[0.3420062143831011, 0.4792506103356868, 0.17874317528121217])\n\nLet's translate that from \"statistical gibberish\" to \"executive presentation\":\n\nusing Plots\nusing Printf\n# using Distributions, Statistics  # keep if you still need them elsewhere\n\n# Backend (GR is default; feel free to switch to plotlyjs(), pyplot(), etc.)\ngr()\n\n# Extract trust scores - remember the order: [complex, medium, simple]\ntrust_scores = result_joint.posteriors[:routing_strategy].p\n\n# Prepare data\nlabels = [\"Simple Router\\n(The Optimist)\",\n          \"Medium Router\\n(The Realist)\",\n          \"Complex Router\\n(The Pessimist)\"]\nx = 1:3\ny = trust_scores .* 100\ncolors = [:darkgreen, :lightblue, :lightcoral]\n\n# Bar plot\nbar(\n    x, y;\n    bar_width = 0.6,\n    fillcolor = colors,\n    linecolor = :black,       # outline like strokecolor\n    linewidth = 2,\n    xticks = (x, labels),\n    ylim = (0, 60),\n    ylabel = \"Trust Level (%)\",\n    title = \"Router Trust Scores: Who Saw It Coming?\",\n    legend = :topright,\n    size = (800, 500)\n)\n\n# Reference line at 33.3% with legend entry\nhline!([33.3]; color = :gray, linestyle = :dash, linewidth = 2, label = \"Initial Trust (Equal)\")\n\n# Value labels above bars\nfor (i, yi) in enumerate(y)\n    annotate!(i, yi + 2, text(@sprintf(\"%.1f%%\", yi), 12, :center, :bottom))\nend\nplot!()\n\n(Image: )","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#The-Verdict-Makes-Perfect-Sense-Now:","page":"Bayesian Trust Learning","title":"The Verdict Makes Perfect Sense Now:","text":"Complex Router (17.9% trust): \"I told you to use GPT-4... I was wrong 87% of the time!\" üí∏\nStarted at 33%, crashed to 17%. The pessimist who always escalates got schooled by reality.\nMedium Router (47.9% trust): \"Sometimes you need complexity, mostly you don't\" ‚öñÔ∏è\nUp from 33%. Balanced approach proved wise.\nSimple Router (34.2% trust): \"Still unsure about this!\"\nSimple router remains unsure about this.","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#Diving-Deeper:-What-Each-Router-Learned","page":"Bayesian Trust Learning","title":"Diving Deeper: What Each Router Learned","text":"","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#Complex-Router's-Reality-Check:","page":"Bayesian Trust Learning","title":"Complex Router's Reality Check:","text":"println(result_joint.posteriors[:Œ∏_complex])\n\nBayesBase.MixtureDistribution{Distributions.Beta{Float64}, Float64}(Distrib\nutions.Beta{Float64}[Distributions.Beta{Float64}(Œ±=6.0, Œ≤=28.0), Distributi\nons.Beta{Float64}(Œ±=3.2, Œ≤=19.05)], [0.7379918929276147, 0.2620081070723853\n])\n\nAfter seeing the data, we can conclude that our trust in the complex router was shattered.\n\nprintln(result_joint.posteriors[:Œ∏_simple])\n\nBayesBase.MixtureDistribution{Distributions.Beta{Float64}, Float64}(Distrib\nutions.Beta{Float64}[Distributions.Beta{Float64}(Œ±=6.0, Œ≤=22.0), Distributi\nons.Beta{Float64}(Œ±=4.0, Œ≤=24.0)], [0.26239067055393556, 0.7376093294460644\n])\n\nThe simple router switched to believe in GPT-4o-mini.\n\nprintln(result_joint.posteriors[:Œ∏_medium])\n\nBayesBase.MixtureDistribution{Distributions.Beta{Float64}, Float64}(Distrib\nutions.Beta{Float64}[Distributions.Beta{Float64}(Œ±=6.0, Œ≤=28.0), Distributi\nons.Beta{Float64}(Œ±=3.2, Œ≤=19.05)], [0.9633551632505475, 0.0366448367494525\n8])\n\nThe medium router switched to believe to Sonnet and in fact turned out to be right most of the time.","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#The-\"Aha!\"-Moments","page":"Bayesian Trust Learning","title":"The \"Aha!\" Moments","text":"","category":"section"},{"location":"categories/experimental_examples/bayesian_trust_learning/#Discovery-#1:-The-87/13-Rule","page":"Bayesian Trust Learning","title":"Discovery #1: The 87/13 Rule","text":"simple_share  = result_joint.posteriors[:routing_strategy].p[1]\nmedium_share  = result_joint.posteriors[:routing_strategy].p[2]\ncomplex_share = result_joint.posteriors[:routing_strategy].p[3];\n\n# Normalize defensively\ns = simple_share + medium_share + complex_share\nsimple_share, medium_share, complex_share = simple_share/s, medium_share/s, complex_share/s\n\n# --- Model costs (edit as needed) ---\nsimple_cost  = 0.03   # e.g., Haiku per request (placeholder)\nmedium_cost  = 0.10   # whatever you pay for models within medium router\ncomplex_cost = 3.00   # e.g., GPT-5 per request (placeholder)\n\n# --- Cost per 100 tickets ---\nblind_cost_per100  = 100 * complex_cost\nperfect_per100     = 100 * (simple_share * simple_cost +\n                            medium_share * medium_cost +\n                            complex_share * complex_cost)\n# Escalate policy: try Simple ‚Üí Medium ‚Üí Complex\nescalate_per100    = 100 * (simple_cost +\n                            (1 - simple_share) * medium_cost +\n                            complex_share * complex_cost)\n\nsavings_perfect_pct  = 100 * (1 - perfect_per100  / blind_cost_per100)\nsavings_escalate_pct = 100 * (1 - escalate_per100 / blind_cost_per100)\n\nprintln(\"üéØ Reality-informed routing mix:\")\nprintln(\"‚îú‚îÄ Simple: $(round(simple_share * 100,  digits=1))%\")\nprintln(\"‚îú‚îÄ Medium: $(round(medium_share * 100,  digits=1))%\")\nprintln(\"‚îî‚îÄ Complex: $(round(complex_share * 100, digits=1))%\")\n\nprintln(\"\\nüí∞ Cost Impact (per 100 tickets):\")\nprintln(\"‚îú‚îÄ Blind Complex (send all to Complex): $(round(blind_cost_per100, digits=2))\")\nprintln(\"‚îú‚îÄ Smart routing (perfect):             $(round(perfect_per100, digits=2))  ‚Üí savings $(round(savings_perfect_pct, digits=1))%\")\nprintln(\"‚îî‚îÄ Smart routing (escalate S‚ÜíM‚ÜíC):      $(round(escalate_per100, digits=2)) ‚Üí savings $(round(savings_escalate_pct, digits=1))%\")\n\nüéØ Reality-informed routing mix:\n‚îú‚îÄ Simple: 34.2%\n‚îú‚îÄ Medium: 47.9%\n‚îî‚îÄ Complex: 17.9%\n\nüí∞ Cost Impact (per 100 tickets):\n‚îú‚îÄ Blind Complex (send all to Complex): 300.0\n‚îú‚îÄ Smart routing (perfect):             59.44  ‚Üí savings 80.2%\n‚îî‚îÄ Smart routing (escalate S‚ÜíM‚ÜíC):      63.2 ‚Üí savings 78.9%\n\n# Bayesian routing: Sample from learned posteriors to make decisions (we don't do continuous learning here (yet))\n# How that could look like:\n\n# Helper to sample from MixtureDistribution (not natively supported)\nsample_mixture(m::MixtureDistribution) = rand(m.components[rand(Categorical(m.weights))])\n\nfunction route(posteriors, ticket_context)\n\n    # here your logic to cluster tickets into a category\n\n    # Sample which router to use\n    router_idx = rand(posteriors[:routing_strategy])\n    \n    # Get complexity from selected router\n    router_posteriors = [posteriors[:Œ∏_complex], posteriors[:Œ∏_medium], posteriors[:Œ∏_simple]]\n    complexity = sample_mixture(router_posteriors[router_idx])\n    \n    # Decision based on sampled complexity  \n    model = complexity > 0.5 ? \"complex\" : \"simple\"\n    \n    return (model=model, complexity=complexity, router=router_idx)\nend\n\n# Use it\nticket = \"I have been trying to transfer money to my other bank account for the last 10 days but it keeps failing. Can you help me?\"\n\ndecision = route(result_joint.posteriors, ticket)\nprintln(\"Route to $(decision.model)\")\n\nRoute to simple\n\nThese results brought to you by Bayes' Theorem: Teaching expensive AI models humility since 1763.\n\nP.S. - The Complex Router is now in therapy, learning to let go of its need to overcomplicate everything. The Medium Router has been promoted to Chief Optimization Officer.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [31c24e10] Distributions v0.25.123\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n\n\n","category":"section"},{"location":"categories/problem_specific/rts_vs_bifm_smoothing/","page":"Rts Vs Bifm Smoothing","title":"Rts Vs Bifm Smoothing","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/problem_specific/rts_vs_bifm_smoothing/#RTS-vs-BIFM-Smoothing","page":"Rts Vs Bifm Smoothing","title":"RTS vs BIFM Smoothing","text":"___Credits to Martin de Quincey___\n\nThis notebook performs Kalman smoothing on a factor graph using message passing, based on the BIFM Kalman smoother. This notebook is based on:\n\nF. Wadehn, ‚ÄúState Space Methods with Applications in Biomedical Signal Processing,‚Äù ETH Zurich, 2019. Accessed: Jun. 16, 2021. [Online]. Available: https://www.research-collection.ethz.ch/handle/20.500.11850/344762\nH. Loeliger, L. Bruderer, H. Malmberg, F. Wadehn, and N. Zalmai, ‚ÄúOn sparsity by NUV-EM, Gaussian message passing, and Kalman smoothing,‚Äù in 2016 Information Theory and Applications Workshop (ITA), Jan. 2016, pp. 1‚Äì10. doi: 10.1109/ITA.2016.7888168.\n\nWe perform Kalman smoothing in the linear state space model, represented by:\n\nbeginaligned\n    Z_k+1 = A Z_k + B U_k \n    Y_k = C Z_k + W_k\nendaligned\n\nwith observations Y_k, latent states Z_k and inputs U_k. W_k is the observation noise. A in mathrmR^n times n, B in mathrmR^n times m and C in mathrmR^d times n are the transition matrices in the model. Here n, m and d denote the dimensionality of the latent, input and output dimension, respectively.\n\nThe corresponding probabilistic model can be represented as \n\nbeginaligned\n        p(y z u)\n        = p(z_0) prod_k=1^N p(y_k mid z_k) p(z_kmid z_k-1 u_k-1) p(u_k-1) \n        = mathcalN(z_0 mid mu_z_0 Sigma_z_0) left( prod_k=1^N mathcalN(y_k mid C z_k Sigma_W) delta(z_k - (Az_k-1 + Bu_k-1)) mathcalN(u_k-1 mid mu_i_k-1 Sigma_u_k-1) right)\nendaligned","category":"section"},{"location":"categories/problem_specific/rts_vs_bifm_smoothing/#Import-packages","page":"Rts Vs Bifm Smoothing","title":"Import packages","text":"using RxInfer, Random, LinearAlgebra, BenchmarkTools, ProgressMeter, Plots, StableRNGs","category":"section"},{"location":"categories/problem_specific/rts_vs_bifm_smoothing/#Data-generation","page":"Rts Vs Bifm Smoothing","title":"Data generation","text":"function generate_parameters(dim_out::Int64, dim_in::Int64, dim_lat::Int64; seed::Int64 = 123)\n    \n    # define noise levels\n    input_noise  = 500.0\n    output_noise = 50.0\n\n    # create random generator for reproducibility\n    rng = StableRNG(seed)\n\n    # generate matrices, input statistics and noise matrices\n    A      = diagm(0.8 .* ones(dim_lat) .+ 0.2 * rand(rng, dim_lat))                                            # size (dim_lat x dim_lat)\n    B      = rand(rng, dim_lat, dim_in)                                                                         # size (dim_lat x dim_in)\n    C      = rand(rng, dim_out, dim_lat)                                                                        # size (dim_out x dim_lat)\n    Œºu     = rand(rng, dim_in) .* collect(1:dim_in)                                                             # size (dim_in x 1)\n    Œ£u     = input_noise  .* collect(Hermitian(randn(rng, dim_in, dim_in) + diagm(10 .+ 10*rand(rng, dim_in))))      # size (dim_in x dim_in)\n    Œ£y     = output_noise .* collect(Hermitian(randn(rng, dim_out, dim_out) + diagm(10 .+ 10*rand(rng, dim_out))))   # size (dim_out x dim_out)\n    Wu     = inv(Œ£u)\n    Wy     = inv(Œ£y)\n    \n    # return parameters\n    return A, B, C, Œºu, Œ£u, Œ£y, Wu, Wy\n\nend;\n\nfunction generate_data(nr_samples::Int64, A::Array{Float64,2}, B::Array{Float64,2}, C::Array{Float64,2}, Œºu::Array{Float64,1}, Œ£u::Array{Float64,2}, Œ£y::Array{Float64,2}; seed::Int64 = 123)\n        \n    # create random data generator\n    rng = StableRNG(seed)\n    \n    # preallocate space for variables\n    z = Vector{Vector{Float64}}(undef, nr_samples)\n    y = Vector{Vector{Float64}}(undef, nr_samples)\n    u = rand(rng, MvNormal(Œºu, Œ£u), nr_samples)'\n    \n    # set initial value of latent states\n    z_prev = zeros(size(A,1))\n    \n    # generate data\n    for i in 1:nr_samples\n\n        # generate new latent state\n        z[i] = A * z_prev + B * u[i,:]\n\n        # generate new observation\n        y[i] = C * z[i] + rand(rng, MvNormal(zeros(dim_out), Œ£y))\n        \n        # generate new observation\n        z_prev .= z[i]\n        \n    end\n    \n    # return generated data\n    return z, y, u\n    \nend\n\ngenerate_data (generic function with 1 method)\n\n# specify settings\nnr_samples = 200\ndim_out = 3\ndim_in = 3\ndim_lat = 25\nseed = 42\n\n# generate parameters\nA, B, C, Œºu, Œ£u, Œ£y, Wu, Wy = generate_parameters(dim_out, dim_in, dim_lat; seed = seed);\n            \n# generate data\ndata_z, data_y, data_u = generate_data(nr_samples, A, B, C, Œºu, Œ£u, Œ£y);\n\n# visualise data\np = Plots.plot(xlabel = \"sample\", ylabel = \"observations\")\n# plot each dimension independently\nfor i in 1:dim_out\n    Plots.scatter!(p, getindex.(data_y, i), label = \"y_$i\", alpha = 0.5, ms = 2)\nend\np\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/rts_vs_bifm_smoothing/#Model-specification","page":"Rts Vs Bifm Smoothing","title":"Model specification","text":"@model function RTS_smoother(y, A, B, C, Œºu, Wu, Wy)\n    \n    # fetch dimensionality\n    dim_lat = size(A, 1)\n    dim_out = size(C, 1)\n    \n    # set initial hidden state\n    z_prev ~ MvNormal(mean = zeros(dim_lat), precision = 1e-5*diagm(ones(dim_lat)))\n\n    # loop through observations\n    for i in eachindex(y)\n\n        # specify input as random variable\n        u[i] ~ MvNormal(mean = Œºu, precision = Wu)\n        \n        # specify updated hidden state\n        z[i] ~ A * z_prev + B * u[i]\n        \n        # specify observation\n        y[i] ~ MvNormal(mean = C * z[i], precision = Wy)\n        \n        # update last/previous hidden state\n        z_prev = z[i]\n\n    end\nend\n\n@model function BIFM_smoother(y, A, B, C, Œºu, Wu, Wy)\n\n    # fetch dimensionality\n    dim_lat = size(A, 1)\n    \n    # set priors\n    z_prior ~ MvNormal(mean = zeros(dim_lat), precision = 1e-5*diagm(ones(dim_lat)))\n    z[1]  ~ BIFMHelper(z_prior)\n    \n    # loop through observations\n    for i in eachindex(y)\n\n        # specify input as random variable\n        u[i]   ~ MvNormal(mean = Œºu, precision = Wu)\n\n        # specify observation\n        yt[i]  ~ BIFM(u[i], z[i], new(z[i+1])) where { meta = BIFMMeta(A, B, C) }\n        y[i]   ~ MvNormal(mean = yt[i], precision = Wy)\n    end\n    \n    # set final value\n    z[end] ~ MvNormal(mean = zeros(dim_lat), precision = zeros(dim_lat, dim_lat))\nend\n\n@constraints function bifm_constraint()\n    q(z_prior,z) = q(z_prior)q(z)\nend\n\nbifm_constraint (generic function with 1 method)","category":"section"},{"location":"categories/problem_specific/rts_vs_bifm_smoothing/#Probabilistic-inference","page":"Rts Vs Bifm Smoothing","title":"Probabilistic inference","text":"function inference_RTS(data_y, A, B, C, Œºu, Wu, Wy)\n    \n    # In this task the inference is unstable and can diverge\n    meta = @meta begin \n        *() -> ReactiveMP.MatrixCorrectionTools.ClampSingularValues(tiny, Inf)\n    end\n    \n    result = infer(\n        model      = RTS_smoother(A = A, B = B, C = C, Œºu = Œºu, Wu = Wu, Wy = Wy),\n        data       = (y = data_y, ),\n        returnvars = (z = KeepLast(), u = KeepLast()),\n        meta = meta\n    )\n    qs = result.posteriors\n    return (qs[:z], qs[:u])\nend\n\ninference_RTS (generic function with 1 method)\n\nfunction inference_BIFM(data_y, A, B, C, Œºu, Wu, Wy)\n    result = infer(\n        model      = BIFM_smoother(A = A, B = B, C = C, Œºu = Œºu, Wu = Wu, Wy = Wy),\n        data       = (y = data_y, ),\n        constraints = bifm_constraint(),\n        returnvars = (z = KeepLast(), u = KeepLast())\n    )\n    qs = result.posteriors\n    return (qs[:z], qs[:u])\nend\n\ninference_BIFM (generic function with 1 method)","category":"section"},{"location":"categories/problem_specific/rts_vs_bifm_smoothing/#Experiments-for-200-observations","page":"Rts Vs Bifm Smoothing","title":"Experiments for 200 observations","text":"z_BIFM, u_BIFM = inference_BIFM(data_y, A, B, C, Œºu, Wu, Wy)\nz_RTS, u_RTS = inference_RTS(data_y, A, B, C, Œºu, Wu, Wy);\n\nax1 = Plots.plot(title = \"RTS smoother\", xlabel = \"sample\", ylabel = \"latent state z\")\nax2 = Plots.plot(title = \"BIFM smoother\", xlabel = \"sample\", ylabel = \"latent state z\")\n\nmz_RTS = mean.(z_RTS)\nmz_BIFM = mean.(z_BIFM)\n\n# Do not plot all latent states, otherwise the output is just too cluttered\n# The main idea here is to check that both algorithms return the (approximately) same output\nfor i in 1:5\n    Plots.scatter!(ax1, getindex.(data_z, i), alpha = 0.1, ms = 2, color = :blue, label = nothing)\n    Plots.plot!(ax1, getindex.(mz_RTS, i), label = nothing)\n    Plots.scatter!(ax2, getindex.(data_z, i), alpha = 0.1, ms = 2, color = :blue, label = nothing)    \n    Plots.plot!(ax2, getindex.(mz_BIFM, i), label = nothing)\nend\n\nPlots.plot(ax1, ax2, layout = @layout([ a; b ]))\n\n(Image: )\n\nax1 = Plots.plot(title = \"RTS smoother\", xlabel = \"sample\", ylabel = \"latent state u\")\nax2 = Plots.plot(title = \"BIFM smoother\", xlabel = \"sample\", ylabel = \"latent state u\")\n\nrdata_u = collect(eachrow(data_u))\nmu_RTS = mean.(u_RTS)\nmu_BIFM = mean.(u_BIFM)\n\n# Do not plot all latent states, otherwise the output is just too cluttered\n# The main idea here is to check that both algorithms return the (approximately) same output\nfor i in 1:1\n    Plots.scatter!(ax1, getindex.(rdata_u, i), alpha = 0.1, ms = 2, color = :blue, label = nothing)\n    Plots.plot!(ax1, getindex.(mu_RTS, i), label = nothing)\n    Plots.scatter!(ax2, getindex.(rdata_u, i), alpha = 0.1, ms = 2, color = :blue, label = nothing)    \n    Plots.plot!(ax2, getindex.(mu_BIFM, i), label = nothing)\nend\n\nPlots.plot(ax1, ax2, layout = @layout([ a; b ]))\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/rts_vs_bifm_smoothing/#Benchmark","page":"Rts Vs Bifm Smoothing","title":"Benchmark","text":"# This example runs in our documentation pipeline, benchmark executes approximatelly in 20 minutes so we bypass it in the documentation\n# For those who are interested in exact benchmark numbers clone this example and set `run_benchmark = true`\nrun_benchmark = false\n\nif run_benchmark\n    trials_range = 30\n    trials_n = 500\n    trials_RTS  = Array{BenchmarkTools.Trial, 1}(undef, trials_range)\n    trials_BIFM = Array{BenchmarkTools.Trial, 1}(undef, trials_range)\n\n\n    @showprogress for k = 1 : trials_range\n\n        # generate parameters\n        local A, B, C, Œºu, Œ£u, Œ£y, Wu, Wy = generate_parameters(3, 3, k);\n                    \n        # generate data|\n        local data_z, data_y, data_u = generate_data(trials_n, A, B, C, Œºu, Œ£u, Œ£y);\n\n        # run inference\n        trials_RTS[k] = @benchmark inference_RTS($data_y, $A, $B, $C, $Œºu, $Wu, $Wy)\n        trials_BIFM[k] = @benchmark inference_BIFM($data_y, $A, $B, $C, $Œºu, $Wu, $Wy)\n\n    end\n\n    m_RTS = [median(trials_RTS[k].times) for k=1:trials_range] ./ 1e9\n    q1_RTS = [quantile(trials_RTS[k].times, 0.25) for k=1:trials_range] ./ 1e9\n    q3_RTS = [quantile(trials_RTS[k].times, 0.75) for k=1:trials_range] ./ 1e9\n    m_BIFM = [median(trials_BIFM[k].times) for k=1:trials_range] ./ 1e9\n    q1_BIFM = [quantile(trials_BIFM[k].times, 0.25) for k=1:trials_range] ./ 1e9\n    q3_BIFM = [quantile(trials_BIFM[k].times, 0.75) for k=1:trials_range] ./ 1e9;\n\n    p = Plots.plot(ylabel = \"duration [sec]\", xlabel = \"latent state dimension\", title = \"Benchmark\", yscale = :log)\n    p = Plots.plot!(p, m_RTS, ribbon = ((q1_RTS .- q3_RTS) ./ 2), color = \"blue\", label = \"mean (RTS)\")\n    p = Plots.plot!(p, 1:trials_range, m_BIFM, ribbon = ((q1_BIFM .- q3_BIFM) ./ 2), color = \"orange\", label = \"mean (BIFM)\")\n    Plots.savefig(p, \"rts_bifm_benchmark.png\")\n    p\nend\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [91a5bcdd] Plots v1.41.6\n  [92933f4c] ProgressMeter v1.11.0\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/basic_examples/forgetting_factors_for_online_inference/","page":"Forgetting Factors For Online Inference","title":"Forgetting Factors For Online Inference","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/basic_examples/forgetting_factors_for_online_inference/#Forgetting-Factors-for-Online-Inference","page":"Forgetting Factors For Online Inference","title":"Forgetting Factors for Online Inference","text":"In this example, we explore a technique for online Bayesian inference which is called forgetting factors. When working with real-world data that changes over time, posterior distributions can become \"stuck\" in the past, leading to poor performance on recent observations. Forgetting factors provide an elegant solution to this problem. Imagine you're monitoring a sensor network, tracking financial markets, or analyzing social media trends. The underlying dynamics of these systems change over time. This can lead to the following problems when doing online inference:\n\nThe model becomes overly confident in outdated parameters\nInability to track changing patterns in the data\nContinuing to update parameters that are no longer relevant","category":"section"},{"location":"categories/basic_examples/forgetting_factors_for_online_inference/#The-Solution:-Forgetting-Factors","page":"Forgetting Factors For Online Inference","title":"The Solution: Forgetting Factors","text":"Forgetting factors implement exponential forgetting, where older observations are gradually \"forgotten\" with a decay rate controlled by a parameter Œì (gamma). This allows the model to adapt to recent changes in the data and maintain stability by not forgetting everything at once.\n\nWe will demonstrate the technique with a simple example: a Kalman filter tracking a non-stationary signal.\n\nNote: For a related example that solves a similar non-stationary tracking problem using a different approach, see the Hierarchical Gaussian Filter example. This example specifically focuses on using Forgetting Factors.\n\nusing RxInfer, StableRNGs, Plots","category":"section"},{"location":"categories/basic_examples/forgetting_factors_for_online_inference/#Setting-Up-the-Problem","page":"Forgetting Factors For Online Inference","title":"Setting Up the Problem","text":"Let's start by creating a realistic scenario with non-stationary noise. We'll generate a signal where the observation precision (inverse variance) changes sinusoidally over time, simulating real-world scenarios like varying sensor accuracy or changing market volatility.\n\nKey Insight: Notice how the true precision varies significantly over time (from ~20 to ~180). As we show later, a stationary model will fail to capture this variation while the forgetting factor model will adapt to it.\n\nrng = StableRNG(1234)\ntime_points = 0.0:0.1:300.0\nunstationary_noise = 100 .+ 80 .* sin.(0.075 * time_points)\ndata_points = map(d -> rand(rng, NormalMeanPrecision(0.0, d[2])), zip(time_points, unstationary_noise))\n\np1 = plot(time_points, data_points, seriestype = :line, title = \"Signal\", xlabel = \"Time\", ylabel = \"Observation\")\np2 = plot(time_points, unstationary_noise, seriestype = :line, title = \"True Precision of Observations\", xlabel = \"Time\", ylabel = \"Std\")\nplot(p1, p2, layout = (2, 1))\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/forgetting_factors_for_online_inference/#Understanding-the-Generated-Data","page":"Forgetting Factors For Online Inference","title":"Understanding the Generated Data","text":"Let's examine the data we just generated:\n\nThe top plot shows our observations over time. These are random samples drawn from a normal distribution with mean 0 and a time-varying precision.\n\nThe bottom plot shows how the true precision (inverse variance) of the noise changes over time:\n\nIt oscillates sinusoidally between approximately 20 and 180\nThe period of oscillation is relatively slow, allowing us to track the changes\nThis simulates real-world scenarios where noise characteristics drift over time\n\nThis setup creates an interesting challenge for our inference: the model needs to adapt its beliefs about the noise precision as the true value changes. A static model would try to find a single \"best\" precision value, while we want our model to track these changes over time.\n\nLet's create a simple model that tracks a non-stationary signal. We'll use a Kalman filter with a state variable and an unknown noise precision that we'll try to infer. The model assumes that the state evolves with small random changes (controlled by a fixed precision of 1000.0) and generates observations with unknown precision.\n\n@model function kalman_filter(observation, state_prior_mean, state_prior_var, obs_noise_shape, obs_noise_rate)\n    state_prior ~ Normal(mean = state_prior_mean, var = state_prior_var)\n    next_state ~ Normal(mean = state_prior, precision = 1000.0)\n    noise_precision ~ Gamma(shape = obs_noise_shape, rate = obs_noise_rate)\n    observation ~ Normal(mean = next_state, precision = noise_precision)\nend\n\nNow let's set up the inference process. First, we'll create an update rule that specifies how the model parameters should be updated after each observation. This includes updating our beliefs about both the state of the system and the noise precision. We'll also define an initialization that sets reasonable starting values for our variables.\n\nautoupdates_without_forgetting = @autoupdates begin\n    # Update the state prior mean and variance\n    state_prior_mean = mean(q(next_state))\n    state_prior_var = var(q(next_state))\n    # Update the noise precision\n    obs_noise_shape = shape(q(noise_precision))\n    obs_noise_rate = rate(q(noise_precision))\nend\n\ninitialization = @initialization begin\n    q(next_state) = NormalMeanPrecision(0.0, 1000.0)\n    q(noise_precision) = GammaShapeRate(1.0, 0.005)\nend\n\nInitial state: \n  q(next_state) = ExponentialFamily.NormalMeanPrecision{Float64}(Œº=0.0, w=1\n000.0)\n  q(noise_precision) = ExponentialFamily.GammaShapeRate{Float64}(a=1.0, b=0\n.005)\n\nLet's run the inference using our model and update rules. We'll use the infer function with our specified kalman_filter model and autoupdates_without_forgetting update rules. This will process our data points sequentially and track how the model's beliefs evolve over time.\n\nresult_without_forgetting = infer(\n    model = kalman_filter(),\n    data = (observation = data_points,),\n    autoupdates = autoupdates_without_forgetting,\n    initialization = initialization,\n    autostart = true,\n    constraints = MeanField(),\n    historyvars = (noise_precision = KeepLast(), ),\n    iterations = 50,\n    keephistory = length(data_points)\n)\n\ninferred_without_forgetting = result_without_forgetting.history[:noise_precision]\n\nplot(time_points, mean.(inferred_without_forgetting), ribbon = 3std.(inferred_without_forgetting), seriestype = :line, title = \"Inferred Noise Precision\", xlabel = \"Time\", ylabel = \"Std\", label = \"Inferred (+/- 3 std)\")\nplot!(time_points, unstationary_noise, seriestype = :line, title = \"True Precision of Observations\", xlabel = \"Time\", ylabel = \"Std\", label = \"True\")\n\n(Image: )\n\nThe plot above shows how our model's inference of the noise precision compares to the true underlying precision. While the model successfully tracks the general magnitude of the precision, it fails to capture the non-stationary nature of the data. This is because our current inference approach assumes the noise precision is constant over time, leading to estimates that converge to a fixed value rather than adapting to the changing precision levels. This limitation motivates the need for a more flexible approach that can handle non-stationary dynamics.","category":"section"},{"location":"categories/basic_examples/forgetting_factors_for_online_inference/#Introducing-Forgetting-Factors","page":"Forgetting Factors For Online Inference","title":"Introducing Forgetting Factors","text":"To address the non-stationary nature of our data, we introduce a forgetting factor Œì. This factor controls how quickly the model forgets past observations, allowing it to focus more on recent data.\n\nThe forgetting factor Œì is a parameter that ranges between 0 and 1. A value of Œì = 1 means the model does not forget anything, while a value of Œì = 0 means the model forgets everything. We will apply this technique to the parameters of the prior distribution of the noise precision. For this, we will create a callable structure that updates the parameters of the noise precision distribution based on the forgetting factor.\n\nmutable struct UpdateParamsWithForgetting\n    forgetting_factor::Float64\n    previous_params::Union{Nothing, Tuple{Float64, Float64}}\n\n    function UpdateParamsWithForgetting(; Œì = 0.99)\n        return new(Œì, nothing)\n    end\nend\n\n# Create a callable structure\n# https://docs.julialang.org/en/v1/manual/methods/#Function-like-objects\n# it allows us to have a local state, in this case `previous_params`\nfunction (update::UpdateParamsWithForgetting)(gamma_posterior)\n\n    if isnothing(update.previous_params)\n        update.previous_params = (shape(gamma_posterior), rate(gamma_posterior))\n        return (shape(gamma_posterior), rate(gamma_posterior))\n    else \n        shape_prev, rate_prev = update.previous_params\n        shape_current, rate_current = (shape(gamma_posterior), rate(gamma_posterior))\n        shape_delta = shape_current - shape_prev\n        rate_delta = rate_current - rate_prev\n\n        @assert (shape_delta > 0) && (rate_delta > 0) \"Shape and rate deltas must be strictly positive\"\n        \n        Œì = update.forgetting_factor\n\n        f_shape = shape_prev * Œì + shape_delta\n        f_rate = rate_prev * Œì + rate_delta\n\n        update.previous_params = (f_shape, f_rate)\n        return (f_shape, f_rate)\n    end\n\nend\n\nNext, we define a function that implements the forgetting factor mechanism in our inference process. The function autoupdates_with_forgetting takes a forgetting factor parameter and creates an update procedure that maintains the state estimates while applying forgetting to the noise precision parameters. It first updates the state prior mean and variance from the current beliefs, then creates an instance of our UpdateParamsWithForgetting structure with the specified forgetting factor. This structure will handle the gradual forgetting of old noise precision information. Finally, it updates the noise precision parameters using this forgetting mechanism, returning both the shape and rate parameters of the gamma distribution.\n\n# we make it a function because it must create `obs_update` every time it is called\n@autoupdates function autoupdates_with_forgetting(; forgetting_factor)\n    # Update the state prior mean and variance\n    state_prior_mean = mean(q(next_state))\n    state_prior_var = var(q(next_state))\n\n    # Update the forgetting factor, callable structure\n    obs_update = UpdateParamsWithForgetting(Œì = forgetting_factor)\n\n    # Update the noise precision, two at once\n    obs_noise_shape, obs_noise_rate = obs_update(q(noise_precision))\nend\n\nautoupdates_with_forgetting (generic function with 1 method)\n\nEverything is ready to run the inference with the forgetting factor.\n\nresult_with_forgetting = infer(\n    model = kalman_filter(),\n    data = (observation = data_points,),\n    autoupdates = autoupdates_with_forgetting(forgetting_factor = 0.97),\n    initialization = initialization,\n    autostart = true,\n    constraints = MeanField(),\n    historyvars = (noise_precision = KeepLast(), ),\n    iterations = 100,\n    keephistory = length(data_points)\n)\n\ninferred_with_forgetting = result_with_forgetting.history[:noise_precision]\n\nplot(time_points, mean.(inferred_with_forgetting), ribbon = 3std.(inferred_with_forgetting), seriestype = :line, title = \"Inferred Noise Precision\", xlabel = \"Time\", ylabel = \"Std\", label = \"Inferred (+/- 3 std)\")\nplot!(time_points, unstationary_noise, seriestype = :line, title = \"True Precision of Observations\", xlabel = \"Time\", ylabel = \"Precision\", label = \"True\")\n\n(Image: )\n\nThe plot shows how the forgetting factor mechanism allows the model to adapt to changes in the noise precision over time. The blue line and shaded area represent the inferred noise precision with uncertainty bounds (¬±3 standard deviations), while the orange line shows the true underlying noise precision that was used to generate the data. We can see that the model successfully tracks the changing noise levels, though with some lag due to the forgetting factor. The uncertainty bounds (shaded area) indicate the model's confidence in its estimates, which varies as it adapts to the non-stationary noise. This demonstrates that our forgetting factor approach effectively handles time-varying noise characteristics in the system.\n\nThe result depends on the choice of the forgetting factor. A higher forgetting factor (closer to 1) means the model has a longer memory and adapts more slowly to changes, while a lower value makes it more responsive but potentially more sensitive to noise. Here we try a forgetting factor of 0.99 instead of the previous 0.97 to see how it affects the inference.\n\nresult_with_forgetting = infer(\n    model = kalman_filter(),\n    data = (observation = data_points,),\n    autoupdates = autoupdates_with_forgetting(forgetting_factor = 0.99),\n    initialization = initialization,\n    autostart = true,\n    constraints = MeanField(),\n    historyvars = (noise_precision = KeepLast(), ),\n    iterations = 100,\n    keephistory = length(data_points)\n)\n\ninferred_with_forgetting = result_with_forgetting.history[:noise_precision]\n\nplot(time_points, mean.(inferred_with_forgetting), ribbon = 3std.(inferred_with_forgetting), seriestype = :line, title = \"Inferred Noise Precision\", xlabel = \"Time\", ylabel = \"Std\", label = \"Inferred (+/- 3 std)\")\nplot!(time_points, unstationary_noise, seriestype = :line, title = \"True Precision of Observations\", xlabel = \"Time\", ylabel = \"Precision\", label = \"True\")\n\n(Image: )\n\nWith a higher forgetting factor of 0.99, we can observe that the model adapts more slowly to changes in the noise precision compared to the previous case with 0.97. This results in smoother estimates but increased lag in tracking sudden changes. The trade-off between responsiveness and stability is evident - while the 0.99 forgetting factor provides more stable estimates by being less sensitive to temporary fluctuations, it takes longer to adapt to genuine changes in the underlying noise characteristics.\n\nThis example demonstrates how forgetting factors can be effectively used in online inference to handle non-stationary data. By carefully choosing the forgetting factor, we can balance between the model's ability to retain historical information and its adaptability to changing conditions. This approach is particularly valuable in real-world applications where system characteristics evolve over time and require continuous adaptation of the inference process.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/problem_specific/litter_model/","page":"Litter Model","title":"Litter Model","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/problem_specific/litter_model/#Litter-Model","page":"Litter Model","title":"Litter Model","text":"Adapted from LearnableLoopAI\n\nusing RxInfer, Random, Distributions, Plots, LaTeXStrings, XLSX, DataFrames\n\nIn this project the client is responsible for the delittering of a mile-long beach walk-way in the Pacific Northwest in the USA. The density of foot traffic is roughly uniform along its length. Volunteers provide their services for cleaning up litter.","category":"section"},{"location":"categories/problem_specific/litter_model/#Symbols-Nomenclature-Notation-(KUF)","page":"Litter Model","title":"Symbols | Nomenclature |Notation (KUF)","text":"informed by Powell Universal Framework (PUF), Bert de Vries, AIF literature","category":"section"},{"location":"categories/problem_specific/litter_model/#Taxonomy-of-Machine-Learning","page":"Litter Model","title":"Taxonomy of Machine Learning","text":"","category":"section"},{"location":"categories/problem_specific/litter_model/#Supervised-Learning","page":"Litter Model","title":"Supervised Learning","text":"","category":"section"},{"location":"categories/problem_specific/litter_model/#State-Functions","page":"Litter Model","title":"State Functions","text":"Provision (Acquisition)\nmathbfp_i = f_p(i)","category":"section"},{"location":"categories/problem_specific/litter_model/#Observation-Functions","page":"Litter Model","title":"Observation Functions","text":"Response: mathbfr_i = f_r(brevemathbfs_i)\nObservation with Noise: mathbfy_i = mathbfbreves_t + mathbfv_t\nCovariate noise (optional)\nObservation noise: mathbfv_i = mathcalN(mathbfbrevem_i mathbfbreveSigma_V)","category":"section"},{"location":"categories/problem_specific/litter_model/#Observation-Sets","page":"Litter Model","title":"Observation Sets","text":"Without state noise: (mathbfbreves y)\nWith state noise: (mathbfz y)","category":"section"},{"location":"categories/problem_specific/litter_model/#Unsupervised-Learning","page":"Litter Model","title":"Unsupervised Learning","text":"","category":"section"},{"location":"categories/problem_specific/litter_model/#State-Functions-2","page":"Litter Model","title":"State Functions","text":"Provision (Acquisition)\nmathbfp_i = f_p(i)","category":"section"},{"location":"categories/problem_specific/litter_model/#Observation-Functions-2","page":"Litter Model","title":"Observation Functions","text":"Response: mathbfr_i = f_r(brevemathbfs_i)\nDirect Observation: mathbfy_t = mathbfbreves_t","category":"section"},{"location":"categories/problem_specific/litter_model/#Observation-Sets-2","page":"Litter Model","title":"Observation Sets","text":"Unordered independent observations: y","category":"section"},{"location":"categories/problem_specific/litter_model/#Sequential/Series-Learning","page":"Litter Model","title":"Sequential/Series Learning","text":"","category":"section"},{"location":"categories/problem_specific/litter_model/#State-Functions-3","page":"Litter Model","title":"State Functions","text":"Provision (Transition)\nBase transition: mathbfp_t = f_p(brevemathbfs_t-1)\nComplete state equation:   mathbfbreves_t = f_B(mathbfbreves_t-1)+ f_E(mathbfa_t) + mathbfw_dt + mathbfw_t\nComponents:\nAction: f_E(mathbfa_t) (optional)\nSystem noise: mathbfw_t = mathcalN(mathbfp_t mathbfbreveSigma_W)\nDisturbance/exogenous: mathbfw_dt (optional)","category":"section"},{"location":"categories/problem_specific/litter_model/#Observation-Functions-3","page":"Litter Model","title":"Observation Functions","text":"Response: mathbfr_t = f_r(brevemathbfs_t) = f_A(brevemathbfs_t) = brevemathbfA brevemathbfs_t\nObservation with Noise: mathbfy_t = f_A(mathbfbreves_t) + mathbfv_t\nObservation noise: mathbfv_t = mathcalN(mathbfr_t mathbfbreveSigma_V)","category":"section"},{"location":"categories/problem_specific/litter_model/#Observation-Sequence","page":"Litter Model","title":"Observation Sequence","text":"Ordered correlated observations y (time/spatial)","category":"section"},{"location":"categories/problem_specific/litter_model/#Overall-Structure","page":"Litter Model","title":"Overall Structure","text":"Experiment has one-to-many Batches\n\n- Batch (into the page) has one-to-many Sequences\n\t- Sequence (down the page) has one-to-many Datapoints\n\t\t- Datapoint (into the page) has one-to-many Matrices\n\t\t\t- Matrix (down the page) has one-to-many Vectors\n\t\t\t\t- Vector (towards right) has one-to-many Components\n\t\t\t\t\t- Component/Element of type\n\t\t\t\t\t\t- Numerical [continuous/proportional]\n\t\t\t\t\t\t\t- int/real/float (continuous)\n\t\t\t\t\t\t- Categorical [non-continuous/non-formal]\n\t\t\t\t\t\t\t- AIF calls it 'discrete'\n\t\t\t\t\t\t\t- ordinal (ordered)\n\t\t\t\t\t\t\t- nominal (no order)\n\t\t\t\t\t\t- for computers, elements need to be numbers, so categoricals encoded as numbers too\n\nMost complex Datapoint handled is a multispectral image, i.e. 3D","category":"section"},{"location":"categories/problem_specific/litter_model/#True-vs-Inferred-variables:","page":"Litter Model","title":"True vs Inferred variables:","text":"True variables associated with Generative Process genpr\ne.g. breves brevemathbfs brevetheta\nInferred variables associated with Generative Model agent\ne.g. s mathbfs theta","category":"section"},{"location":"categories/problem_specific/litter_model/#General","page":"Litter Model","title":"General","text":"Global code variables will be prefixed with an underscore '_'.","category":"section"},{"location":"categories/problem_specific/litter_model/#Active-Inference:-Bridging-Minds-and-Machines","page":"Litter Model","title":"Active Inference: Bridging Minds and Machines","text":"In recent years, the landscape of machine learning has undergone a profound transformation with the emergence of active inference, a novel paradigm that draws inspiration from the principles of biological systems to inform intelligent decision-making processes. Unlike traditional approaches to machine learning, which often passively receive data and adjust internal parameters to optimize performance, active inference represents a dynamic and interactive framework where agents actively engage with their environment to gather information and make decisions in real-time.\n\nAt its core, active inference is rooted in the notion of agents as embodied entities situated within their environments, constantly interacting with and influencing their surroundings. This perspective mirrors the fundamental processes observed in living organisms, where perception, action, and cognition are deeply intertwined to facilitate adaptive behavior. By leveraging this holistic view of intelligence, active inference offers a unified framework that seamlessly integrates perception, decision-making, and action, thereby enabling agents to navigate complex and uncertain environments more effectively.\n\nOne of the defining features of active inference is its emphasis on the active acquisition of information. Rather than waiting passively for sensory inputs, agents proactively select actions that are expected to yield the most informative outcomes, thus guiding their interactions with the environment. This active exploration not only enables agents to reduce uncertainty and make more informed decisions but also allows them to actively shape their environments to better suit their goals and objectives.\n\nFurthermore, active inference places a strong emphasis on the hierarchical organization of decision-making processes, recognizing that complex behaviors often emerge from the interaction of multiple levels of abstraction. At each level, agents engage in a continuous cycle of prediction, inference, and action, where higher-level representations guide lower-level processes while simultaneously being refined and updated based on incoming sensory information.\n\nThe applications of active inference span a wide range of domains, including robotics, autonomous systems, neuroscience, and cognitive science. In robotics, active inference offers a promising approach for developing robots that can adapt and learn in real-time, even in unpredictable and dynamic environments. In neuroscience and cognitive science, active inference provides a theoretical framework for understanding the computational principles underlying perception, action, and decision-making in biological systems.\n\nIn conclusion, active inference represents a paradigm shift in machine learning, offering a principled and unified framework for understanding and implementing intelligent behavior in artificial systems. By drawing inspiration from the principles of biological systems, active inference holds the promise of revolutionizing our approach to building intelligent machines and understanding the nature of intelligence itself.","category":"section"},{"location":"categories/problem_specific/litter_model/#Business-Understanding","page":"Litter Model","title":"Business Understanding","text":"Although the current project covers a small part of the span of Active Inference, we would nevertheless like to execute it within this context.\n\nThe client is responsible for the delittering of a mile-long beach walk-way in the Pacific Northwest in the USA. The density of foot traffic is roughly uniform along its length. Volunteers provide their services for cleaning up litter. One of the key determinants of the client's planning is an estimation of the number of daily litter events along this walkway. The client does not want to over-engage his team of volunteers, nor does he want litter to become too noticeable.","category":"section"},{"location":"categories/problem_specific/litter_model/#Data-Understanding","page":"Litter Model","title":"Data Understanding","text":"The number of daily litter events will be modeled by a Poisson distribution with parameter theta. This parameter, usually denoted by lambda, represents both the mean as well as the variance of the Poisson distribution. The theta parameter will be learned or inferred by a model.\n\nFor additional insight, we will simulate some litter event data.","category":"section"},{"location":"categories/problem_specific/litter_model/#Data-Preparation","page":"Litter Model","title":"Data Preparation","text":"We will use simulated data to prepare the model. To apply the model we will use data gathered from observations along the walk-way. There is no need to perform additional data preparation.","category":"section"},{"location":"categories/problem_specific/litter_model/#Modeling","page":"Litter Model","title":"Modeling","text":"","category":"section"},{"location":"categories/problem_specific/litter_model/#Core-Elements","page":"Litter Model","title":"Core Elements","text":"This section attempts to answer three important questions:\n\nWhat metrics are we going to track?\nWhat decisions do we intend to make?\nWhat are the sources of uncertainty?\n\nFor this problem, the only metric we are interested in is the daily number of litter events so that we can use Bayesian inference to estimate the mean of the Poisson distribution that that represents the littering events.","category":"section"},{"location":"categories/problem_specific/litter_model/#Environment-Model-(Generative-Process)","page":"Litter Model","title":"Environment Model (Generative Process)","text":"The number of daily litter events will be given by $ n^{Daily} \\sim Pois(\\theta) $","category":"section"},{"location":"categories/problem_specific/litter_model/#State-variables","page":"Litter Model","title":"State variables","text":"We do not have state variables. The only variable that needs to be inferred is theta, the mean (and variance) of the generative process, i.e. the Poisson distribution.","category":"section"},{"location":"categories/problem_specific/litter_model/#Decision-variables","page":"Litter Model","title":"Decision variables","text":"There will be no decision variables for this project.","category":"section"},{"location":"categories/problem_specific/litter_model/#Exogenous-information-variables","page":"Litter Model","title":"Exogenous information variables","text":"We assume that the volunteers that inspect the walk-way do not miscount litter events. Consequently we will not make provision for exogenous information variables.","category":"section"},{"location":"categories/problem_specific/litter_model/#Next-State-function","page":"Litter Model","title":"Next State function","text":"The provision function, f_p(), provides another state/datapoint, called the provision/pre-state. Because this is a combinatorial system, the provision function acquires the next state/datapoint making use of a simulation or a data set.\n\nmathbfp_i = f_p(i)\n\n## provision function, provides another state/datapoint from simulation\nfunction fÀ¢‚Å±·µê‚Çö(s; Œ∏ÃÜ, ùôº, ùöÖ, ùô≤, rng)\n    dp = Vector{Vector{Vector{Float64}}}(undef, ùôº)\n    for m in 1:ùôº ## Matrices\n        dp[m] = Vector{Vector{Float64}}(undef, ùöÖ)\n        for v in 1:ùöÖ ## Vectors\n            dp[m][v] = Vector{Float64}(undef, ùô≤)\n            for c in 1:ùô≤ ## Components\n               dp[m][v][c] = float(rand(rng, Poisson(Œ∏ÃÜ)))\n            end\n        end\n    end\n    sÃÜ = dp\n    return sÃÜ\nend\n\n_s = 1 ## s for sequence\n_Œ∏ÃÜÀ¢‚Å±·µê = 15 ## lambda of Poisson distribution\n_rng = MersenneTwister(57)\n## _sÃÜ = fÀ¢‚Å±·µê‚Çö(_s, Œ∏ÃÜ=_Œ∏ÃÜÀ¢‚Å±·µê, ùôº=3, ùöÖ=4, ùô≤=5, rng=_rng) ## color image with 3 colors, 4 rows, 5 cols of elements\n## _sÃÜ = fÀ¢‚Å±·µê‚Çö(_s, Œ∏ÃÜ=_Œ∏ÃÜÀ¢‚Å±·µê, ùôº=1, ùöÖ=4, ùô≤=5, rng=_rng) ## b/w image with 4 rows, 5 cols of elements\n_sÃÜ = fÀ¢‚Å±·µê‚Çö(_s, Œ∏ÃÜ=_Œ∏ÃÜÀ¢‚Å±·µê, ùôº=1, ùöÖ=1, ùô≤=5, rng=_rng) ## vector with 5 elements\n## _sÃÜ = fÀ¢‚Å±·µê‚Çö(_s, Œ∏ÃÜ=_Œ∏ÃÜÀ¢‚Å±·µê, ùôº=1, ùöÖ=1, ùô≤=1, rng=_rng) ## vector with 1 element\n;\n\n## provision function, provides another state/datapoint from field\nfunction f·∂†À°·µà‚Çö(s; ùôº, ùöÖ, ùô≤, df)\n    dp = Vector{Vector{Vector{Float64}}}(undef, ùôº)\n    for m in 1:ùôº ## Matrices\n        dp[m] = Vector{Vector{Float64}}(undef, ùöÖ)\n        for v in 1:ùöÖ ## Vectors\n            dp[m][v] = Vector{Float64}(undef, ùô≤)\n            for c in 1:ùô≤ ## Components\n                dp[m][v][c] = df[s, :incidents]\n            end\n        end\n    end\n    sÃÜ = dp\n    return sÃÜ\nend\n## _s = 1 ## s for sequence\n## dp = f·∂†À°·µà‚Çö(_s, ùôº=3, ùöÖ=4, ùô≤=5, df=_fld_df) ## color image with 3 colors, 4 rows, 5 cols of elements\n## dp = f·∂†À°·µà‚Çö(_s, ùôº=1, ùöÖ=4, ùô≤=5, df=_fld_df) ## b/w image with 4 rows, 5 cols of elements\n## dp = f·∂†À°·µà‚Çö(_s, ùôº=1, ùöÖ=1, ùô≤=5, df=_fld_df) ## vector with 5 elements\n## dp = f·∂†À°·µà‚Çö(_s, ùôº=1, ùöÖ=1, ùô≤=1, df=_fld_df) ## vector with 1 element\n\nf·∂†À°·µà‚Çö (generic function with 1 method)\n\nBecause there is no noise to be combined with, the next state becomes\n\nbrevemathbfs_i = mathbfp_i\n\nThe breve/bowl indicates that the parameters and variables are hidden and not observed.","category":"section"},{"location":"categories/problem_specific/litter_model/#Observation-function","page":"Litter Model","title":"Observation function","text":"The response function, f_r(), provides the response to the state/datapoint, called the response: mathbfr_i = f_r(brevemathbfs_i)\n\n## response function, provides the response to a state/datapoint\nfunction f·µ£(sÃÜ)\n    return sÃÜ ## no noise\nend\nf·µ£(_sÃÜ);\n\nBecause there is no noise to be combined with, the next observation becomes\n\nmathbfy_i = mathbfbreves_i\n\nThe breve/bowl indicates that the parameters and variables are hidden and not observed.","category":"section"},{"location":"categories/problem_specific/litter_model/#Implementation-of-the-Environment-Model-(Generative-Process)","page":"Litter Model","title":"Implementation of the Environment Model (Generative Process)","text":"Let's simulate some data with IID observations from a Poisson distribution, that represents the litter incidents. We also assume that the mean incidents per day is 15:\n\n## Data comes from either a simulation/lab (sim|lab) OR from the field (fld)\n## Data are handled either in batches (batch) OR online as individual points (point)\nfunction sim_data(rng, ùöÇ, ùô≥, ùôº, ùöÖ, ùô≤, Œ∏ÃÜ)\n    p = Vector{Vector{Vector{Vector{Vector{Float64}}}}}(undef, ùöÇ)\n    sÃÜ = Vector{Vector{Vector{Vector{Vector{Float64}}}}}(undef, ùöÇ)\n    r = Vector{Vector{Vector{Vector{Vector{Float64}}}}}(undef, ùöÇ)\n    y = Vector{Vector{Vector{Vector{Vector{Float64}}}}}(undef, ùöÇ)\n    for s in 1:ùöÇ ## sequences\n        p[s] = Vector{Vector{Vector{Vector{Float64}}}}(undef, ùô≥)\n        sÃÜ[s] = Vector{Vector{Vector{Vector{Float64}}}}(undef, ùô≥)\n        r[s] = Vector{Vector{Vector{Vector{Float64}}}}(undef, ùô≥)\n        y[s] = Vector{Vector{Vector{Vector{Float64}}}}(undef, ùô≥)\n        for d in 1:ùô≥ ## datapoints\n            p[s][d] = fÀ¢‚Å±·µê‚Çö(s; Œ∏ÃÜ=Œ∏ÃÜ, ùôº=ùôº, ùöÖ=ùöÖ, ùô≤=ùô≤, rng=rng)\n            sÃÜ[s][d] = p[s][d] ## no system noise\n            r[s][d] = f·µ£(sÃÜ[s][d])\n            y[s][d] = r[s][d]\n        end\n    end\n    return y\nend;\n\nfunction fld_data(df, ùöÇ, ùô≥, ùôº, ùöÖ, ùô≤)\n    p = Vector{Vector{Vector{Vector{Vector{Float64}}}}}(undef, ùöÇ)\n    sÃÜ = Vector{Vector{Vector{Vector{Vector{Float64}}}}}(undef, ùöÇ)\n    r = Vector{Vector{Vector{Vector{Vector{Float64}}}}}(undef, ùöÇ)\n    y = Vector{Vector{Vector{Vector{Vector{Float64}}}}}(undef, ùöÇ)\n    for s in 1:ùöÇ ## sequences\n        p[s] = Vector{Vector{Vector{Vector{Float64}}}}(undef, ùô≥)\n        sÃÜ[s] = Vector{Vector{Vector{Vector{Float64}}}}(undef, ùô≥)\n        r[s] = Vector{Vector{Vector{Vector{Float64}}}}(undef, ùô≥)\n        y[s] = Vector{Vector{Vector{Vector{Float64}}}}(undef, ùô≥)\n        for d in 1:ùô≥ ## datapoints\n            p[s][d] = f·∂†À°·µà‚Çö(s; ùôº=ùôº, ùöÖ=ùöÖ, ùô≤=ùô≤, df=df)\n            sÃÜ[s][d] = p[s][d] ## no system noise\n            r[s][d] = f·µ£(sÃÜ[s][d])\n            y[s][d] = r[s][d]\n        end\n    end\n    return y\nend;\n\n## number of Batches in an experiment\n## _ùô± = 1 ## not used yet\n\n## number of Sequences/examples in a batch\n_ùöÇ = 365\n## _ùöÇ = 3\n\n## number of Datapoints in a sequence\n_ùô≥ = 1\n## _ùô≥ = 2\n## _ùô≥ = 3\n\n## number of Matrices in a datapoint\n_ùôº = 1\n\n## number of Vectors in a matrix\n_ùöÖ = 1\n\n## number of Components in a vector\n_ùô≤ = 1\n\n_Œ∏ÃÜÀ¢‚Å±·µê = 15 ## hidden lambda of Poisson distribution\n_rng = MersenneTwister(57);\n\n_yÀ¢‚Å±·µê = sim_data(_rng, _ùöÇ, _ùô≥, _ùôº, _ùöÖ, _ùô≤, _Œ∏ÃÜÀ¢‚Å±·µê) ## simulated data\n_yÀ¢‚Å±·µê = first.(first.(first.(first.(_yÀ¢‚Å±·µê))));\n\n## methods(print)\n## print(_yÀ¢‚Å±·µê[1:2])\n\n## Customize the display width to control positioning or prevent wrapping\n## io = IOContext(stdout, :displaysize => (50, 40)) ## (rows, cols)\n## print(io, _yÀ¢‚Å±·µê[1:3])\n## print(io, _yÀ¢‚Å±·µê)\n\nprint(IOContext(stdout, :displaysize => (24, 5)), _yÀ¢‚Å±·µê[1:10]);\n\n[8.0, 10.0, 14.0, 9.0, 15.0, 9.0, 12.0, 15.0, 19.0, 18.0]\n\n_rŒ∏ = range(0, _ùöÇ, length=1*_ùöÇ)\n_p = plot(title=\"Simulated Daily Litter Events\", xlabel=\"Day\")\n_p = plot!(_rŒ∏, _yÀ¢‚Å±·µê, linetype=:steppre, label=\"# daily events\", c=1)\nplot(_p)\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/litter_model/#Uncertainty-Model","page":"Litter Model","title":"Uncertainty Model","text":"","category":"section"},{"location":"categories/problem_specific/litter_model/#Agent-Model-(Generative-Model)","page":"Litter Model","title":"Agent Model (Generative Model)","text":"In this project, we are going to perform an exact inference for a litter model that can be represented as:\n\nbeginaligned\np(theta) = mathrmGamma(theta mid alpha^Gamma theta^Gamma)\np(x_i mid theta) = mathrmPois(x_i mid theta)\nendaligned\n\nwhere x_i in 0 1  is an observation induced by a Poisson likelihood while p(theta) is a Gamma prior distribution on the parameter of the Poisson distribution. We are interested in inferring the posterior distribution of theta.\n\nThe generative model is:\n\n$\n\n\\begin{aligned} p(x:,\\theta)    &= p(x: \\mid \\theta) \\cdot p(\\theta) \\\n                 &= p(x{1:N} \\mid \\theta) \\cdot p(\\theta) \\\n                 &= \\prod{i=1}^N{p(xi \\mid \\theta)} \\cdot p(\\theta) \\\n                 &= \\prod{i=1}^N{\\mathrm{Pois}(x_i \\mid \\theta)} \\cdot \\Gamma(\\theta \\mid \\alpha^{\\Gamma}, \\theta^{\\Gamma}) \\end{aligned} $","category":"section"},{"location":"categories/problem_specific/litter_model/#Implementation-of-the-Agent-Model-(Generative-Model)","page":"Litter Model","title":"Implementation of the Agent Model (Generative Model)","text":"We will use the RxInfer Julia package. RxInfer stands at the forefront of Bayesian inference tools within the Julia ecosystem, offering a powerful and versatile platform for probabilistic modeling and analysis. Built upon the robust foundation of the Julia programming language, RxInfer provides researchers, data scientists, and practitioners with a streamlined workflow for conducting Bayesian inference tasks with unprecedented speed and efficiency.\n\nAt its core, RxInfer leverages cutting-edge techniques from the realm of reactive programming to enable dynamic and interactive model specification and estimation. This unique approach empowers users to define complex probabilistic models with ease, seamlessly integrating prior knowledge, data, and domain expertise into the modeling process.\n\nWith RxInfer, conducting Bayesian inference tasks becomes a seamless and intuitive experience. The package offers a rich set of tools for performing parameter estimation, model comparison, and uncertainty quantification, all while leveraging the high-performance capabilities of Julia to deliver results in a fraction of the time required by traditional methods.\n\nWhether tackling problems in machine learning, statistics, finance, or any other field where uncertainty reigns supreme, RxInfer equips users with the tools they need to extract meaningful insights from their data and make informed decisions with confidence.\n\nRxInfer represents a paradigm shift in the world of Bayesian inference, combining the expressive power of Julia with the flexibility of reactive programming to deliver a state-of-the-art toolkit for probabilistic modeling and analysis. With its focus on speed, simplicity, and scalability, RxInfer is poised to become an indispensable tool for researchers and practitioners seeking to harness the power of Bayesian methods in their work.\n\nTo transfer the above factorized generative model to the RxInfer package, we need to include each of the factors:\n\nN\nKronecker-delta factors (for the N observations)\n1\nGamma factor (for the prior distribution)\nN\nPoisson factors (for the litter events)\n\n## parameters for the prior distribution\n_Œ±·¥≥·µÉ·µê, _Œ∏·¥≥·µÉ·µê = 350., .05;\n\n## Litter model: Gamma-Poisson\n@model function litter_model(x, Œ±·¥≥·µÉ·µê, Œ∏·¥≥·µÉ·µê)\n    ## prior on Œ∏ parameter of the model\n    Œ∏ ~ Gamma(shape=Œ±·¥≥·µÉ·µê, rate=Œ∏·¥≥·µÉ·µê) ## 1 Gamma factor\n\n    ## assume daily number of litter incidents is a Poisson distribution\n    for i in eachindex(x)\n        x[i] ~ Poisson(Œ∏) ## not Œ∏ÃÉ; N Poisson factors\n    end\nend","category":"section"},{"location":"categories/problem_specific/litter_model/#Agent-(Policy)-Evaluation","page":"Litter Model","title":"Agent (Policy) Evaluation","text":"","category":"section"},{"location":"categories/problem_specific/litter_model/#Evaluate-with-simulated-data","page":"Litter Model","title":"Evaluate with simulated data","text":"_result = infer(\n    model= litter_model(Œ±·¥≥·µÉ·µê= _Œ±·¥≥·µÉ·µê, Œ∏·¥≥·µÉ·µê= _Œ∏·¥≥·µÉ·µê), \n    data= (x= _yÀ¢‚Å±·µê, )\n)\n\nInference results:\n  Posteriors       | available for (Œ∏)\n\n_Œ∏À¢‚Å±·µê = _result.posteriors[:Œ∏]\n\nExponentialFamily.GammaShapeRate{Float64}(a=5838.0, b=365.05)\n\n_rŒ∏ = range(0, 20, length=500)\n_p = plot(title=\"Simulation results: Distribution of \"*L\"Œ∏^{\\mathrm{sim}}=Œª\")\nplot!(_rŒ∏, (x) -> pdf(Gamma(_Œ±·¥≥·µÉ·µê, _Œ∏·¥≥·µÉ·µê), x), fillalpha=0.3, fillrange=0, label=\"P(Œ∏)\", c=1,)\nplot!(_rŒ∏, (x) -> pdf(_Œ∏À¢‚Å±·µê, x), fillalpha=0.3, fillrange=0, label=\"P(Œ∏|x)\", c=3)\nvline!([_Œ∏ÃÜÀ¢‚Å±·µê], label=\"Hidden Œ∏\", c=2)\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/litter_model/#Evaluation","page":"Litter Model","title":"Evaluation","text":"The following data comes from the inspections of the volunteers over a period of 12 months:\n\n_fld_df = DataFrame(XLSX.readtable(\"litter_incidents.xlsx\", \"Sheet1\"))\n_y·∂†À°·µà = fld_data(_fld_df, _ùöÇ, _ùô≥, _ùôº, _ùöÖ, _ùô≤) ## field data\n_y·∂†À°·µà = first.(first.(first.(first.(_y·∂†À°·µà))))\nprint(IOContext(stdout, :displaysize => (24, 30)), _y·∂†À°·µà[1:10]);\n\n[5.0, 7.0, 6.0, 10.0, 8.0, 5.0, 7.0, 9.0, 13.0, 9.0]\n\n_rŒ∏ = range(0, _ùöÇ, length=1*_ùöÇ)\n_p = plot(title=\"Field Daily Litter Events\", xlabel=\"Day\")\n_p = plot!(_rŒ∏, _y·∂†À°·µà, linetype=:steppre, label=\"# daily events\", c=1)\nplot(_p)\n\n(Image: )\n\n_result = infer(\n    model=litter_model(Œ±·¥≥·µÉ·µê= _Œ±·¥≥·µÉ·µê, Œ∏·¥≥·µÉ·µê= _Œ∏·¥≥·µÉ·µê), \n    data= (x= _y·∂†À°·µà, )\n)\n\nInference results:\n  Posteriors       | available for (Œ∏)\n\n_Œ∏·∂†À°·µà = _result.posteriors[:Œ∏]\n\nExponentialFamily.GammaShapeRate{Float64}(a=3200.0, b=365.05)\n\n_rŒ∏ = range(0, 20, length=500)\n_p = plot(title=\"Field results: Distribution of \"*L\"Œ∏^{\\mathrm{fld}}=Œª\")\nplot!(_rŒ∏, (x) -> pdf(Gamma(_Œ±·¥≥·µÉ·µê, _Œ∏·¥≥·µÉ·µê), x), fillalpha=0.3, fillrange=0, label=\"P(Œ∏)\", c=1,)\nplot!(_rŒ∏, (x) -> pdf(_Œ∏·∂†À°·µà, x), fillalpha=0.3, fillrange=0, label=\"P(Œ∏|x)\", c=3)\n\n(Image: )\n\nThe actual generative process actually had a much lower mean daily litter events, around about 8 events per day. The client can work with this value during planning of how to use his volunteers in the field.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [a93c6f00] DataFrames v1.8.1\n  [31c24e10] Distributions v0.25.123\n  [b964fa9f] LaTeXStrings v1.4.0\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [fdbf4ff8] XLSX v0.10.4\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/advanced_examples/bayesian_structured_time_series/","page":"Bayesian Structured Time Series","title":"Bayesian Structured Time Series","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/bayesian_structured_time_series/#Bayesian-Structured-Time-Series","page":"Bayesian Structured Time Series","title":"Bayesian Structured Time Series","text":"","category":"section"},{"location":"categories/advanced_examples/bayesian_structured_time_series/#The-Great-NeurIPS-2025-Taco-Forecast","page":"Bayesian Structured Time Series","title":"The Great NeurIPS 2025 Taco Forecast üåÆ","text":"Location: San Diego, CA Objective: Decompose the latent drivers of Al Pastor consumption.\n\nWelcome to San Diego! You are attending NeurIPS 2025. Between the Deep Learning keynotes and the poster sessions, there is one variable that dominates the conference dynamics: The hunger for Tacos.\n\nWe suspect that local weather plays a role (San Diegans are notoriously sensitive to the cold), but it implies only part of the story. There are hidden rhythms‚Äîweekly cycles, trend shifts, and random shocks‚Äîthat govern the lines at the taqueria.\n\nIn this notebook, we will build a Bayesian Structured Time Series (STS) model using RxInfer.jl to predict this demand.\n\nThis notebook is inspired by the excellent STS repository from here (sts-jax).\n\nWe are going to extend it by treating the transition dynamics matrix (which governs the frequency and damping of these cycles) as a collection of unknown random variables and learn them simultaneously with the states. Instead of hard-coding \"Taco Tuesday\" to exactly 7 days, we let the model discover the rhythm.","category":"section"},{"location":"categories/advanced_examples/bayesian_structured_time_series/#1.-Setup-and-Data-Generation","page":"Bayesian Structured Time Series","title":"1. Setup & Data Generation","text":"We need RxInfer for the probabilistic inference and HTTP to fetch real San Diego weather data to ground our simulation in reality.\n\nusing RxInfer, LinearAlgebra, Statistics, Plots, StableRNGs\nusing HTTP, JSON3, DataFrames, Dates, Random, Distributions\n\ntheme(:wong)\n\nrng = StableRNG(42)\n\nprintln(\"Libraries loaded. Preparation for consumption initiated.\")\n\nLibraries loaded. Preparation for consumption initiated.","category":"section"},{"location":"categories/advanced_examples/bayesian_structured_time_series/#The-Data:-\"World-Knowledge\"-Logic","page":"Bayesian Structured Time Series","title":"The Data: \"World Knowledge\" Logic","text":"We don't have the actual sales ledger from the taqueria yet, so we will generate a Taco Demand Index based on real weather history and some \"World Knowledge\" assumptions:\n\nThe Patio Curve: Humans prefer eating tacos outside at 72¬∞F.\nThe Rain Penalty: Rain kills the vibe.\nThe Calendar: Tuesdays and Weekends imply higher demand.\n\nconst LAT = 32.7157\nconst LON = -117.1611\nconst START_DATE = Date(today()) - Year(3)\nconst ARCHIVE_END_DATE = Date(today())\n\nfunction fetch_real_weather()\n    println(\"üì° Fetching San Diego Weather...\")\n    url = \"https://archive-api.open-meteo.com/v1/archive\"\n    params = Dict(\n        \"latitude\" => LAT, \"longitude\" => LON,\n        \"start_date\" => string(START_DATE), \"end_date\" => string(ARCHIVE_END_DATE),\n        \"daily\" => \"temperature_2m_max,rain_sum\",\n        \"temperature_unit\" => \"fahrenheit\", \"precipitation_unit\" => \"inch\",\n        \"timezone\" => \"America/Los_Angeles\"\n    )\n    query_str = join([\"$k=$v\" for (k,v) in params], \"&\")\n    try\n        resp = HTTP.get(\"$url?$query_str\")\n        data = JSON3.read(resp.body)\n        return DataFrame(\n            Date = Date.(String.(data.daily.time)),\n            Max_Temp_F = Float64.(data.daily.temperature_2m_max),\n            Rain_Inches = Float64.(data.daily.rain_sum)\n        )\n    catch e\n        println(\"API Error.\"); rethrow(e)\n    end\nend\n\n# Feel free to change the logic or use real data (please share!)\nfunction calculate_taco_demand(df_weather::DataFrame; \n                                   # 1. Define \"True\" Parameters\n                                   Œ≤_true = 2.0,           # Temp coefficient\n                                   œÉ_obs  = 5.0,           # Measurement noise (epsilon)\n                                   \n                                   # 2. Process Noise Variances (The \"Jitter\" of the states)\n                                   œÉ_level  = 0.5,         # Trend wobble\n                                   œÉ_daily  = 1.0,         # Daily cycle wobble\n                                   œÉ_weekly = 0.8,         # Weekly cycle wobble\n                                   œÉ_ar     = 2.0,         # AR residual noise\n                                   \n                                   # 3. Cycle Dynamics (Damping & Frequency)\n                                   # We pick reasonable \"Physics\" for the cycles\n                                   damp_daily = 0.99, freq_daily = 2œÄ/1,  \n                                   damp_week  = 0.98, freq_week  = 2œÄ/7,\n                                   rho_ar     = 0.7)\n    \n    # --- A. Construct Matrices ---\n    \n    # State Dimensions: [Level, DailyCos, DailySin, WeeklyCos, WeeklySin, AR]\n    D = 6 \n    \n    # R Matrix: Maps 4 noise sources to 6 states\n    R = [1.0 0.0 0.0 0.0;\n         0.0 1.0 0.0 0.0;\n         0.0 0.0 0.0 0.0; # Sine component gets no direct noise (deterministic rotation)\n         0.0 0.0 1.0 0.0;\n         0.0 0.0 0.0 0.0; # Sine component gets no direct noise\n         0.0 0.0 0.0 1.0]\n\n    # Q Matrix: Covariance of Process Noise eta\n    Q_diag = [œÉ_level^2, œÉ_daily^2, œÉ_weekly^2, œÉ_ar^2]\n    dist_Œ∑ = MvNormal(zeros(4), diagm(Q_diag))\n\n    # H Matrix: Observation Selection\n    H = [1.0, 1.0, 0.0, 1.0, 0.0, 1.0]\n\n    # F Matrix: Transition Dynamics\n    # We build the rotation blocks manually for the \"True\" simulation\n    F = zeros(D, D)\n    F[1,1] = 1.0 # Random Walk Trend\n    \n    # Daily Block\n    F[2,2] = damp_daily * cos(freq_daily); F[2,3] = damp_daily * sin(freq_daily)\n    F[3,2] = -damp_daily * sin(freq_daily); F[3,3] = damp_daily * cos(freq_daily)\n    \n    # Weekly Block\n    F[4,4] = damp_week * cos(freq_week); F[4,5] = damp_week * sin(freq_week)\n    F[5,4] = -damp_week * sin(freq_week); F[5,5] = damp_week * cos(freq_week)\n    \n    # AR Block\n    F[6,6] = rho_ar\n\n    # --- B. Simulation Loop ---\n    \n    n_steps = size(df_weather, 1)\n    \n    # Storage\n    z_history = zeros(D, n_steps)\n    y_history = zeros(n_steps)\n    \n    # Initial State z_0\n    # [Level=150, Daily=10, DailySin=0, Weekly=20, WeeklySin=0, AR=0]\n    z_current = [150.0, 10.0, 0.0, 20.0, 0.0, 0.0]\n    \n    for t in 1:n_steps\n        # 1. Sample Noise\n        Œ∑_t = rand(rng, dist_Œ∑)       # Process Noise\n        œµ_t = randn(rng) * œÉ_obs    # Measurement Noise\n        \n        # 2. State Transition: z(t) = F * z(t-1) + R * Œ∑\n        # Note: In the formula z(t+1) depends on z(t), here we update step-by-step\n        z_new = F * z_current + R * Œ∑_t\n        \n        # 3. Regression Component: x(t)' * beta\n        # Center temp at 72F (Patio curve proxy) just for linearity\n        temp_effect = (df_weather.Max_Temp_F[t] - 72.0) * Œ≤_true\n        \n        # 4. Observation: y(t) = H * z(t) + Regression + epsilon\n        y_val = dot(H, z_new) + temp_effect + œµ_t\n        \n        # Store & Update\n        z_history[:, t] = z_new\n        y_history[t]    = y_val\n        z_current       = z_new\n    end\n    \n    df_out = deepcopy(df_weather)\n    df_out.Taco_Demand_Index = round.(y_history, digits=1)\n    \n    return df_out\nend\n\ndf_weather_history = fetch_real_weather()\ndf_history = calculate_taco_demand(deepcopy(df_weather_history))\ndemand = df_history.Taco_Demand_Index\ntemperature = df_history.Max_Temp_F\ndates = df_history.Date\n\n# Split Train/Test\nn_total = length(demand)\nn_predict = round(Int, n_total * 0.1) # Holdout 10% of data\nn_train = n_total - n_predict\n\nprintln(\"Data Ready. Training on $n_train days.\")\np1 = plot(dates[1:n_train], demand[1:n_train], label=\"Observed Demand\", title=\"Taco Demand Index\", color=:gray)\np2 = plot(dates[1:n_train], temperature[1:n_train], label=\"Temperature\", color=:red)\nplot(p1, p2, layout=(2,1), size=(1000, 600))\n\nüì° Fetching San Diego Weather...\nData Ready. Training on 987 days.\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/bayesian_structured_time_series/#2.-The-Gaussian-STS-Model","page":"Bayesian Structured Time Series","title":"2. The Gaussian STS Model","text":"We define a State Space Model (SSM) with the following full formulation:\n\ny_t = H_t z_t + x_t^T beta + epsilon_t quad epsilon_t sim N(0 sigma_t^2)\n\nz_t+1 = F_t z_t + R_t eta_t quad eta_t sim N(0 Q_t)","category":"section"},{"location":"categories/advanced_examples/bayesian_structured_time_series/#The-Latent-Dynamics","page":"Bayesian Structured Time Series","title":"The Latent Dynamics","text":"Our state vector z_t has dimension D=6, representing: [Level, Daily_Cos, Daily_Sin, Weekly_Cos, Weekly_Sin, AR_Residual]","category":"section"},{"location":"categories/advanced_examples/bayesian_structured_time_series/#a.-The-Transition-Matrix-(F)","page":"Bayesian Structured Time Series","title":"a. The Transition Matrix (F)","text":"The transition matrix F is constructed from 5 non-zero learnable components (parameters), which we infer from data. These aren't just static numbers; they represent the physics of seasonality:\n\nF_1 F_2\n: Control the damping and rotation frequency of the Daily cycle.\nF_3 F_4\n: Control the damping and rotation frequency of the Weekly cycle.\nF_5\n: Controls the decay rate of the Autoregressive (AR) trend.\n\n$   F(\\theta) = \\begin{pmatrix}   1 & 0 & 0 & 0 & 0 & 0 \\\n  0 & F1 & F2 & 0 & 0 & 0 \\\n  0 & -F2 & F1 & 0 & 0 & 0 \\\n  0 & 0 & 0 & F3 & F4 & 0 \\\n  0 & 0 & 0 & -F4 & F3 & 0 \\\n  0 & 0 & 0 & 0 & 0 & F_5   \\end{pmatrix}   $","category":"section"},{"location":"categories/advanced_examples/bayesian_structured_time_series/#b.-The-Selection-Matrix-(R)","page":"Bayesian Structured Time Series","title":"b. The Selection Matrix (R)","text":"R\n\nis a selection matrix, which is a subset of columns of the base vector e_i. It acts as a bridge, converting the non-singular covariance matrix Q_t (of the lower-dimensional noise eta_t) into the (possibly singular) covariance matrix of the latent state z_t.\n\nIn our case, we have 4 sources of noise driving 6 states (Level, Daily Base, Weekly Base, AR), so R maps mathbbR^4 to mathbbR^6.\n\n# State Dimension\nD = 6\n# Observation Matrix: We sum Level(1) + Daily(2) + Weekly(4) + AR(6)\nH_vec = [1.0, 1.0, 0.0, 1.0, 0.0, 1.0]\n\n# Transition Function: Dynamically builds M based on parameter F\nfunction transition(F)\n    FT = eltype(F)\n    M = zeros(FT, 6, 6)\n    M[1,1] = one(FT) # Random Walk Trend\n    \n    # Daily Block (Rotation Matrix)\n    M[2,2] = F[1]; M[2,3] = F[2]; \n    M[3,2] = -F[2]; M[3,3] = F[1]\n    \n    # Weekly Block (Rotation Matrix)\n    M[4,4] = F[3]; M[4,5] = F[4]; \n    M[5,4] = -F[4]; M[5,5] = F[3]\n    \n    # AR Block\n    M[6,6] = F[5]\n    return M\nend\n\ntransition (generic function with 1 method)\n\n# The Gaussian STS Model\n@model function rxsts(H, X, y, R, priors)\n    # Hyperparameters\n    œÑy    ~ priors[:œÑy]\n    Œ≤     ~ priors[:Œ≤]\n    # Prior for the covariance matrix Q\n    Q     ~ Wishart(priors[:Q].df, priors[:Q].S)\n    zprev ~ priors[:z0]\n    F     ~ priors[:F] # Learning the 5 non-zero components\n    \n    for t in eachindex(y)\n        # Process Noise sampled FRESH at every step\n        Œ∑[t] ~ MvNormal(mean=zeros(4), precision=Q)\n        # 1. State Transition\n        # We use ContinuousTransition because M depends on the random variable F\n        z_mean[t] ~ ContinuousTransition(zprev, F, diageye(D)) # z‚ÇÅ[t] := F * z‚ÇÅ[t-1]\n        # Map the 4D noise to 6D state\n        z_shock[t] ~ R * Œ∑[t]\n\n        # Combine: Next State = (F * Prev) + (R * Noise)\n        z[t]  ~ z_mean[t] + z_shock[t]\n        \n        # 2. Observation\n        Œº[t]  ~ dot(H, z[t]) + dot(X[t], Œ≤)\n        y[t]  ~ Normal(mean = Œº[t], precision = œÑy)\n        \n        zprev = z[t]\n    end\nend\n\n# Constraints & Meta\n@constraints function rxsts_constraints()\n    q(z, z_mean, z_shock, zprev, F, Q, Œ∑, Œº, y, œÑy, Œ≤) = q(z, z_mean, z_shock, zprev,Œº, y, Œ≤, Œ∑)q(F)q(Q)q(œÑy)\nend\n\n@meta function rxsts_meta()\n    ContinuousTransition() -> CTMeta(transition)\nend\n\nrxsts_meta (generic function with 1 method)","category":"section"},{"location":"categories/advanced_examples/bayesian_structured_time_series/#Inference","page":"Bayesian Structured Time Series","title":"Inference","text":"We prepare the priors and the R matrix. Note that we center the temperature data (Regressors X) so the beta coefficient is interpretable as deviation from the mean.\n\n# R Matrix: Selection matrix mapping noise to specific states\n# Indices 1(Level), 2(Daily), 4(Weekly), 6(AR) get noise.\nR = [1 0 0 0; \n     0 1 0 0; \n     0 0 0 0; \n     0 0 1 0; \n     0 0 0 0; \n     0 0 0 1]\n\n# Data Prep\nX_input = [[temp] for temp in temperature]\ny_input = [demand[1:n_train]; fill(missing, n_predict)]\n\npriors = Dict(\n    :œÑy => GammaShapeRate(10.0, 1.0),\n    :Œ≤  => MvNormalMeanPrecision(zeros(1), diageye(1)),\n    :z0 => MvNormalMeanPrecision(ones(D), diageye(D)),\n    :F  => MvNormalMeanPrecision(randn(rng, 5), diageye(5)),\n    :Q  => Wishart(6, diagm([1.0, 1.0, 1.0, 1.0])),\n    :Œ∑  => MvNormalMeanPrecision(zeros(4), diageye(4))\n)\n\n@initialization function rxsts_init(priors)\n    q(F)  = priors[:F]\n    q(Q)  = priors[:Q]\n    q(œÑy) = priors[:œÑy]\n    Œº(z)  = priors[:z0]\n\nend\n\nresults = infer(\n    model = rxsts(H=H_vec, X=X_input, R=R, priors=priors),\n    data = (y = y_input,),\n    constraints = rxsts_constraints(),\n    meta = rxsts_meta(),\n    initialization = rxsts_init(priors),\n    options = (limit_stack_depth = 100,),\n    returnvars = KeepLast(),\n    iterations = 15, # VMP Iterations\n    showprogress = true\n)\n\nInference results:\n  Posteriors       | available for (z_shock, Œº, F, œÑy, Q, z, Œ≤, Œ∑, zprev, z\n_mean)\n  Predictions      | available for (y)","category":"section"},{"location":"categories/advanced_examples/bayesian_structured_time_series/#Visualization-and-Decomposition","page":"Bayesian Structured Time Series","title":"Visualization & Decomposition","text":"Let's see what the model discovered:\n\n# Extract learned Beta\nŒ≤_mean = mean(results.posteriors[:Œ≤])[1]\nŒ≤_var  = var(results.posteriors[:Œ≤])[1]\nprintln(\"Learned Temperature Coefficient Œ≤:  $(round(Œ≤_mean, digits=3)) ¬± $(round(sqrt(Œ≤_var), digits=3))\")\n\nLearned Temperature Coefficient Œ≤:  2.003 ¬± 0.003\n\nConsidering we had 2 as the ground truth parameter for Œ≤, we can be satisfied with this estimate. Now we compare the Transition Matrix. \n\n# 1. Reconstruct the \"True\" Transition Matrix F\n# Using the same parameters used in the data generation\ndamp_daily_true = 0.99\nfreq_daily_true = 2œÄ/1    # Period of 1 day\ndamp_week_true  = 0.98\nfreq_week_true  = 2œÄ/7    # Period of 7 days\nrho_ar_true     = 0.7\n\nF_true = zeros(6, 6)\nF_true[1,1] = 1.0 # Random Walk Trend\n\n# Daily Block\nF_true[2,2] = damp_daily_true * cos(freq_daily_true); F_true[2,3] = damp_daily_true * sin(freq_daily_true)\nF_true[3,2] = -damp_daily_true * sin(freq_daily_true); F_true[3,3] = damp_daily_true * cos(freq_daily_true)\n\n# Weekly Block\nF_true[4,4] = damp_week_true * cos(freq_week_true); F_true[4,5] = damp_week_true * sin(freq_week_true)\nF_true[5,4] = -damp_week_true * sin(freq_week_true); F_true[5,5] = damp_week_true * cos(freq_week_true)\n\n# AR Block\nF_true[6,6] = rho_ar_true\n\n# 2. Extract the Learned F (Mean of the Posterior)\n# Assuming 'results' contains the output of the first infer() call\nF_learned_mean = transition(mean(results.posteriors[:F]))\n\n# 3. Compare and Visualize\nprintln(\"--- Transition Matrix Comparison ---\")\nprintln(\"True Transition Matrix F:\")\ndisplay(round.(F_true, digits=3))\n\nprintln(\"\\nLearned Transition Matrix F (Posterior Mean):\")\ndisplay(round.(F_learned_mean, digits=3))\n\n# Calculate error metrics\nmse_f = mean((F_learned_mean .- F_true).^2)\nprintln(\"\\nMean Squared Error of F elements: \", round(mse_f, digits=6))\n\n# Plot Comparison Heatmaps\np_true = heatmap(F_true, title=\"True F\", yflip=true, aspect_ratio=:equal, clim=(0,1))\np_learned = heatmap(F_learned_mean, title=\"Learned F\", yflip=true, aspect_ratio=:equal, clim=(0,1))\np_diff = heatmap(abs.(F_learned_mean - F_true), title=\"Abs. Difference\", yflip=true, aspect_ratio=:equal, color=:viridis)\n\nplot(p_true, p_learned, p_diff, layout=(1,3), size=(1200, 350))\n\n--- Transition Matrix Comparison ---\nTrue Transition Matrix F:\n6√ó6 Matrix{Float64}:\n 1.0  0.0    0.0    0.0    0.0    0.0\n 0.0  0.99  -0.0    0.0    0.0    0.0\n 0.0  0.0    0.99   0.0    0.0    0.0\n 0.0  0.0    0.0    0.611  0.766  0.0\n 0.0  0.0    0.0   -0.766  0.611  0.0\n 0.0  0.0    0.0    0.0    0.0    0.7\n\nLearned Transition Matrix F (Posterior Mean):\n6√ó6 Matrix{Float64}:\n 1.0   0.0    0.0     0.0    0.0    0.0\n 0.0   0.237  0.235   0.0    0.0    0.0\n 0.0  -0.235  0.237   0.0    0.0    0.0\n 0.0   0.0    0.0     0.262  0.073  0.0\n 0.0   0.0    0.0    -0.073  0.262  0.0\n 0.0   0.0    0.0     0.0    0.0    0.246\n\nMean Squared Error of F elements: 0.073706\n\n(Image: )\n\nWe can see that the model is able to capture the structure of the data and the weekly cycle. It fails to capture the daily cycle, this makes sense as the model is only given data with the weekly cycle as input. \n\nz_means = mean.(results.posteriors[:z])\nz_vars = var.(results.posteriors[:z]);\n\nlevel_means, level_vars = getindex.(z_means, 1), getindex.(z_vars, 1)\ndaily_means, daily_vars = getindex.(z_means, 2), getindex.(z_vars, 2)\nweekly_means, weekly_vars = getindex.(z_means, 4), getindex.(z_vars, 4)\nar_means, ar_vars = getindex.(z_means, 6), getindex.(z_vars, 6)\ntemp_means = Œ≤_mean .* temperature\n\npred_means = mean.(results.predictions[:y][end])\npred_vars = var.(results.predictions[:y][end]);\n\n\nhistory_window = 50 \n\nstart_idx = max(1, n_train - history_window)\n\np_forecast = plot(dates[start_idx:n_train], demand[start_idx:n_train], \n    label=\"Training Data (last $history_window days)\", color=:gray, \n    title=\"Forecast: $(n_predict) Steps Ahead\",\n    legend=:topleft\n)\n\nplot!(dates[n_train+1:end], demand[n_train+1:end], \n    label=\"Simulated Demand\", color=:red, lw=2\n)\n\n# We assume pred_means aligns with the full dataset length\nplot!(dates[n_train+1:end], pred_means[n_train+1:end], \n    ribbon=sqrt.(pred_vars[n_train+1:end]), \n    label=\"Mean Forecast (¬±2œÉ)\", color=:green, fillalpha=0.2, lw=2\n)\n\nvline!([dates[n_train]], label=\"Cutoff\", color=:black, linestyle=:dash)\n\ndisplay(p_forecast)\n\n(Image: )\n\nl = @layout [a; b; c; d]\np_trend = plot(dates[1:n_train], level_means[1:n_train], ribbon=sqrt.(level_vars[1:n_train]), label=\"Trend (Base Demand)\", color=:blue)\np_week  = plot(dates[1:n_train], weekly_means[1:n_train], ribbon=sqrt.(weekly_vars[1:n_train]), label=\"Weekly Seasonality (Zoom)\", color=:purple, lw=2)\np_daily = plot(dates[1:n_train], daily_means[1:n_train], ribbon=sqrt.(daily_vars[1:n_train]), label=\"Daily Seasonality (Zoom)\", color=:orange)\np_ar    = plot(dates[1:n_train], ar_means[1:n_train], ribbon=sqrt.(ar_vars[1:n_train]), label=\"AR Residuals\", color=:gray)\n\nplot(p_trend, p_week, p_daily, p_ar, layout=l, size=(800, 1000))\n\n(Image: )\n\nAnd now! Let's predict some future! For that we need to download some predictions over the next 7 days [Note by the time you read this, it could be way beyond Neurips 2025, or even way beyond 2025 :D] but hope you could still use it for some tacos predictions in San Diego :D\n\nfunction get_forecast(days::Int)\n    println(\"üì° Fetching Forecast\")\n    url = \"https://api.open-meteo.com/v1/forecast\"\n    params = Dict(\n        \"latitude\" => LAT, \"longitude\" => LON,\n        \"daily\" => \"temperature_2m_max,rain_sum\",\n        \"temperature_unit\" => \"fahrenheit\",\n        \"forecast_days\" => string(days), \n        \"precipitation_unit\" => \"inch\",\n        \"timezone\" => \"America/Los_Angeles\"\n    )\n    query = join([\"$k=$v\" for (k,v) in params], \"&\")\n    resp = HTTP.get(\"$url?$query\")\n    data = JSON3.read(resp.body)\n    return DataFrame(\n        Date = Date.(String.(data.daily.time)),\n        Max_Temp_F = Float64.(data.daily.temperature_2m_max),\n        Rain_Inches = Float64.(data.daily.rain_sum)\n    )\nend\n\nget_forecast (generic function with 1 method)","category":"section"},{"location":"categories/advanced_examples/bayesian_structured_time_series/#Showtime","page":"Bayesian Structured Time Series","title":"Showtime","text":"Now, let's predict the future! We need to download weather forecasts for the next 14 days. (Note: By the time you read this, Neurips 2025 might be ancient history, but hopefully, the code still helps you find the best days for tacos in San Diego!)\n\ndays_ahead = 14\n\ndf_weather_future  = get_forecast(days_ahead)\n\ndf_weather_full = vcat(df_weather_history, df_weather_future)\nunique!(df_weather_full, :Date)\nsort!(df_weather_full, :Date)\n\ndf_demand_history = calculate_taco_demand(deepcopy(df_weather_history))\ndemand_history = df_demand_history.Taco_Demand_Index\n\ntemperature_full = df_weather_full.Max_Temp_F\ndates_full = df_weather_full.Date;\n\n\nX_input_future = [[temp] for temp in temperature_full]\ny_input_future = [demand_history; fill(missing, days_ahead - 2)]\n\nresults_future = infer(\n    model = rxsts(H=H_vec, X=X_input_future, R=R, priors=priors),\n    data = (y = y_input_future,),\n    constraints = rxsts_constraints(),\n    meta = rxsts_meta(),\n    initialization = rxsts_init(priors),\n    options = (limit_stack_depth = 100,),\n    returnvars = KeepLast(),\n    iterations = 15, # VMP Iterations\n    showprogress = true\n)\n\nüì° Fetching Forecast\nInference results:\n  Posteriors       | available for (z_shock, Œº, F, œÑy, Q, z, Œ≤, Œ∑, zprev, z\n_mean)\n  Predictions      | available for (y)\n\ny_pred_mean = mean.(results_future.predictions[:y][end])\ny_pred_var = var.(results_future.predictions[:y][end]);\n\nn_view = 30\nn_total = length(dates_full)\nview_range = (n_total - n_view):n_total\nn_train = length(demand_history)\n\n# Indices\nhist_indices = intersect(view_range, 1:n_train)\npred_indices = intersect(view_range, n_train:n_total)\n\nfuture_means = y_pred_mean[n_train+1:end]\nmin_val, min_idx_local = findmin(future_means)\n\n# Map back to global index\nbest_idx_global = n_train + min_idx_local\nbest_date = dates_full[best_idx_global]\n\nprintln(\"The optimal date for tacos is: $best_date\")\n\n# PLOT\np = plot(dates_full[hist_indices], demand_history[hist_indices], \n    label = \"Simulated Demand\", color = :red, lw = 2,\n    title = \"Forecast: Next $(length(pred_indices)-1) Days\", \n    legend = :topleft, ylabel=\"Demand Index\")\n\nplot!(dates_full[pred_indices], y_pred_mean[pred_indices], \n    ribbon = sqrt.(y_pred_var[pred_indices]),\n    label = \"Forecast\", color = :blue, lw = 2, fillalpha=0.2)\n\n# Mark \"Today\"\nvline!([today()], label=\"Today\", color=:black, linestyle=:dash)\n\n# Mark \"Best Date\" with a Vertical Line + EXACT DATE in Legend\nvline!([best_date], \n    linestyle = :dot, linewidth = 2, color = :green, \n    label = \"Best Date: $best_date\")\n\n# Highlight the specific minimum point\nscatter!([best_date], [min_val], \n    color = :gold, markersize = 8, markerstrokecolor = :green, label = \"\")\n\n# Simplified Annotation pointing to the date\nannotate!(best_date, min_val - 10, \n    text(\"Use this entry point!\", :top, :center, 8, :green))\n\ndisplay(p)\n\nThe optimal date for tacos is: 2026-03-05\nError: BoundsError: attempt to access 1109-element Vector{Float64} at index\n [1097:1110]","category":"section"},{"location":"categories/advanced_examples/bayesian_structured_time_series/#3.-Bonus-Track:-Poisson-Likelihood-(Counting-Tacos)","page":"Bayesian Structured Time Series","title":"3. Bonus Track: Poisson Likelihood (Counting Tacos)","text":"The Gaussian model assumes demand is continuous. But tacos are discrete integers! To handle this, we swap the Likelihood to Poisson. Since Poisson is not conjugate to Gaussian states, we use the Augmented Poisson node to approximate the posterior.\n\nstruct AugmentedPoisson end\n@node AugmentedPoisson Stochastic [out , Œ∑] \n\n@rule AugmentedPoisson(:Œ∑, Marginalisation) (q_out::PointMass,) = begin\n    m_Œª = @call_rule Poisson(:l, Marginalisation) (q_out = q_out, )\n    samples = rand(rng, m_Œª, 500)\n    map!(Œª -> log(Œª + 1e-6), samples, samples)\n    return NormalMeanVariance(mean(samples), var(samples))\nend\n\n#Return the median of the log Normal distribution after exp because the mean is causing instability.\n@rule AugmentedPoisson(:out, Marginalisation) (q_Œ∑::GaussianDistributionsFamily,) = begin\n    return Poisson(exp(mean(q_Œ∑)))\nend\n\n\n@model function rxsts_poisson(H, X, y, R, priors)\n    Œ≤  ~ priors[:Œ≤]\n    Q  ~ priors[:Q]\n    Œ∑  ~ MvNormal(mean=mean(priors[:Œ∑]), precision=Q)\n    zprev ~ priors[:z0]\n    F     ~ priors[:F]\n    for t in eachindex(y)\n        z‚ÇÅ[t] ~ ContinuousTransition(zprev, F, 1e-2diageye(D))\n        z‚ÇÇ[t] ~ R * Œ∑\n        z[t]  ~ z‚ÇÅ[t] + z‚ÇÇ[t]\n        Œº[t]  ~ dot(H, z[t]) + dot(X[t], Œ≤)\n        y[t]  ~ AugmentedPoisson(Œº[t])\n        zprev = z[t]\n    end\nend\n\n@constraints function rxsts_poisson_constraints()\n    q(z, z‚ÇÅ, z‚ÇÇ, zprev, F, Q, Œ∑, Œº, Œ≤, y) = q(z, z‚ÇÅ, z‚ÇÇ, zprev, Œ≤, Œ∑, Œº,y)q(F)q(Q)\nend\n\n@meta function rxsts_poisson_meta()\n    ContinuousTransition() -> CTMeta(transition)\nend\n\npriors_poisson = Dict(\n    :Œ≤  => MvNormalMeanPrecision(zeros(1), diageye(1)),\n    :z0 => MvNormalMeanPrecision(ones(D), diageye(D)),\n    :F  => MvNormalMeanPrecision(randn(rng, 5), diageye(5)),\n    :Q  => Wishart(6, diagm([1.0, 1.0, 1.0, 1.0])),\n    :Œ∑  => MvNormalMeanPrecision(randn(rng, 4), diageye(4))\n)\n\n@initialization function rxsts_poisson_init(priors)\n    q(F)  = priors[:F]\n    q(Q)  = priors[:Q]\n    Œº(z)  = priors[:z0]\n    Œº(z‚ÇÅ) = priors[:z0]\n \nend\n\nX_input = [[temp] for temp in df_history.Max_Temp_F] \n\nn_total_current = length(X_input)\nn_predict_current = Int(round(n_total_current * 0.05))\nn_train_current   = n_total_current - n_predict_current\n\ny_poisson_in = [\n    round.(Int, df_history.Taco_Demand_Index[1:n_train_current] / 5) ; \n    fill(missing, n_predict_current)\n]\n\ny_poisson_future = round.(Int, df_history.Taco_Demand_Index[n_train_current+1:end] / 5) \n\nresults_poi = infer(\n    model = rxsts_poisson(H=H_vec, X=X_input, R=R, priors=priors),\n    data = (y = y_poisson_in,),\n    constraints = rxsts_poisson_constraints(),\n    meta = rxsts_poisson_meta(),\n    initialization = rxsts_poisson_init(priors),\n    returnvars = KeepLast(),\n    options = (limit_stack_depth = 100,),\n    iterations = 15, showprogress = true\n)\n\nInference results:\n  Posteriors       | available for (Œº, F, z‚ÇÇ, Q, z, Œ≤, Œ∑, zprev, z‚ÇÅ)\n  Predictions      | available for (y)\n\ny_dists = results_poi.predictions[:y][end]\nmax_count = maximum(filter(!ismissing, y_poisson_in)) + 20  \n\nn_show_history = 50 \ntime_range = max(1, n_train_current - n_show_history):n_total_current\n\npmf_matrix = zeros(max_count+1, length(time_range))\nfor (i, t) in enumerate(time_range)\n    dist = y_dists[t]  \n    for k in 0:max_count\n        pmf_matrix[k+1, i] = pdf(dist, k)\n    end\nend\n\ny_actual = filter(!ismissing, y_poisson_in)\n\np_pmf = heatmap(time_range, 0:max_count, pmf_matrix,\n    xlabel=\"Time Index\", ylabel=\"Demand Count\", \n    title=\"Prediction PMF at Each Time Point\",\n    color=:viridis, colorbar_title=\"Probability\")\n\nscatter!(collect(1:n_train_current)[end-n_show_history:end], y_actual[end-n_show_history:end], label=\"Training Data\", color=:orange, markersize=3, alpha=0.8)\nscatter!(collect(n_train_current+1:n_total_current), y_poisson_future, label=\"Simulated future\", color=:red, markersize=3, alpha=0.8)\nvline!([n_train_current], label=\"Forecast Start\", linestyle=:dash, color=:white, lw=2)\ndisplay(p_pmf)\n\n(Image: )\n\ntime_stretch = 10.0\nprob_scale = 10.0\ny_pred_means = mean.(y_dists)\n\nn_train_show = 30\ntrain_start = max(1, n_train_current - n_train_show)\n\np_pred = plot(xlabel=\"Time Index\", ylabel=\"Demand\", \n    title=\"Forecast: $(n_predict_current) Steps Ahead\",\n    size=(1400, 600), legend=:topleft)\n\n\nscatter!(collect(1:n_train_current)[end-n_show_history:end], y_actual[end-n_show_history:end], label=\"Training Data\", color=:blue, markersize=3, alpha=1.0)\n\nfor t in n_train_current:n_total_current\n    dist = y_dists[t]\n    Œª = mean(dist)\n    support = max(0, floor(Int, Œª-3*sqrt(Œª))):ceil(Int, Œª+3*sqrt(Œª))\n    probs = pdf.(dist, support)\n    \n    for (k, prob) in zip(support, probs)\n        plot!([t - prob*prob_scale, t + prob*prob_scale], [k, k], \n            lw=5, alpha=0.4, color=:green, label=\"\")\n    end\n    \n \nend\nscatter!(collect(n_train_current+1:n_total_current), y_pred_means[n_train_current+1:n_total_current], \ncolor=:darkgreen, markersize=5, label=\"Predictions\", alpha=0.8)\nscatter!(collect(n_train_current+1:n_total_current), y_poisson_future, color=:red, markersize=8, \nlabel=\"Simulated Future\", alpha=0.8, markershape=:star5)\n\n\nvline!([n_train_current], label=\"Forecast Start\", linestyle=:dash, color=:black, lw=2)\ndisplay(p_pred)\n\n(Image: )\n\n\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [a93c6f00] DataFrames v1.8.1\n  [31c24e10] Distributions v0.25.123\n  [cd3eb016] HTTP v1.10.19\n  [0f8b85d8] JSON3 v1.14.3\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [10745b16] Statistics v1.11.1\n  [ade2ca70] Dates v1.11.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/advanced_examples/active_inference_mountain_car/","page":"Active Inference Mountain Car","title":"Active Inference Mountain Car","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/active_inference_mountain_car/#Active-Inference-Mountain-car","page":"Active Inference Mountain Car","title":"Active Inference Mountain car","text":"using RxInfer, Plots\n\nA group of friends is going to a camping site that is located on the biggest mountain in the Netherlands. They use an electric car for the trip. When they are almost there, the car's battery is almost empty and is therefore limiting the engine force. Unfortunately, they are in the middle of a valley and don't have enough power to reach the camping site. Night is falling and they still need to reach the top of the mountain. As rescuers, let us develop an Active Inference (AI) agent that can get them up the hill with the limited engine power.","category":"section"},{"location":"categories/advanced_examples/active_inference_mountain_car/#The-environmental-process-of-the-mountain","page":"Active Inference Mountain Car","title":"The environmental process of the mountain","text":"Firstly, we specify the environmental process according to Ueltzhoeffer (2017) \"Deep active inference\". This process shows how the environment evolves after interacting with the agent.\n\nParticularly, let's denote z_t = (phi_t dotphi_t) as the environmental state depending on the position phi_t and velocity dotphi_t of the car; a_t as the action of the environment on the car. Then the evolution of the state is described as follows  \n\nbeginaligned \ndotphi_t = dotphi_t-1 + F_g(phi_t-1) + F_f(dotphi_t-1) + F_a(a_t)\nphi_t = phi_t-1 + dotphi_t \nendaligned\n\nwhere F_g(phi_t-1) is the gravitational force of the hill landscape that depends on the car's position\n\nF_g(phi) = begincases\n        -005(2phi + 1)    mathrmif  phi  0 \n        -005 left(1 + 5phi^2)^-frac12 + phi^2 (1 + 5phi^2)^-frac32 + frac116phi^4 right   mathrmotherwise\nendcases\n\nF_f(dotphi)\n\nis the friction on the car defined through the car's velocity F_f(dotphi)  = -01  dotphi and F_a(a) is the engine force F_a(a) = 004 tanh(a) Since the car is on low battery, we use the tanh(cdot) function to limit the engine force to the interval [-0.04, 0.04].\n\nIn the cell below, the create_physics function defines forces F_g F_f F_a; and the create_world function defines the environmental process of the mountain.\n\nimport HypergeometricFunctions: _‚ÇÇF‚ÇÅ\n\nfunction create_physics(; engine_force_limit = 0.04, friction_coefficient = 0.1)\n    # Engine force as function of action\n    Fa = (a::Real) -> engine_force_limit * tanh(a) \n\n    # Friction force as function of velocity\n    Ff = (y_dot::Real) -> -friction_coefficient * y_dot \n    \n    # Gravitational force (horizontal component) as function of position\n    Fg = (y::Real) -> begin\n        if y < 0\n            0.05*(-2*y - 1)\n        else\n            0.05*(-(1 + 5*y^2)^(-0.5) - (y^2)*(1 + 5*y^2)^(-3/2) - (y^4)/16)\n        end\n    end\n    \n    # The height of the landscape as a function of the horizontal coordinate\n    height = (x::Float64) -> begin\n        if x < 0\n            h = x^2 + x\n        else\n            h = x * _‚ÇÇF‚ÇÅ(0.5,0.5,1.5, -5*x^2) + x^3 * _‚ÇÇF‚ÇÅ(1.5, 1.5, 2.5, -5*x^2) / 3 + x^5 / 80\n        end\n        return 0.05*h\n    end\n\n    return (Fa, Ff, Fg,height)\nend;\n\nfunction create_world(; Fg, Ff, Fa, initial_position = -0.5, initial_velocity = 0.0)\n\n    y_t_min = initial_position\n    y_dot_t_min = initial_velocity\n    \n    y_t = y_t_min\n    y_dot_t = y_dot_t_min\n    \n    execute = (a_t::Float64) -> begin\n        # Compute next state\n        y_dot_t = y_dot_t_min + Fg(y_t_min) + Ff(y_dot_t_min) + Fa(a_t)\n        y_t = y_t_min + y_dot_t\n    \n        # Reset state for next step\n        y_t_min = y_t\n        y_dot_t_min = y_dot_t\n    end\n    \n    observe = () -> begin \n        return [y_t, y_dot_t]\n    end\n        \n    return (execute, observe)\nend\n\ncreate_world (generic function with 1 method)\n\nLet's visualize the mountain landscape and the situation of the car. \n\nengine_force_limit   = 0.04\nfriction_coefficient = 0.1\n\nFa, Ff, Fg, height = create_physics(\n    engine_force_limit = engine_force_limit,\n    friction_coefficient = friction_coefficient\n);\ninitial_position = -0.5\ninitial_velocity = 0.0\n\nx_target = [0.5, 0.0] \n\nvalley_x = range(-2, 2, length=400)\nvalley_y = [ height(xs) for xs in valley_x ]\nplot(valley_x, valley_y, title = \"Mountain valley\", label = \"Landscape\", color = \"black\")\nscatter!([ initial_position ], [ height(initial_position) ], label=\"initial car position\")   \nscatter!([x_target[1]], [height(x_target[1])], label=\"camping site\")\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/active_inference_mountain_car/#Naive-approach","page":"Active Inference Mountain Car","title":"Naive approach","text":"Well, let's see how our friends were struggling with the low-battery car when they tried to get it to the camping site before we come to help. They basically used the brute-force method, i.e. just pushing the gas pedal for full power.\n\nN_naive  = 100 # Total simulation time\npi_naive = 100.0 * ones(N_naive) # Naive policy for right full-power only\n\n# Let there be a world\n(execute_naive, observe_naive) = create_world(; \n    Fg = Fg, Ff = Ff, Fa = Fa, \n    initial_position = initial_position, \n    initial_velocity = initial_velocity\n);\n\ny_naive = Vector{Vector{Float64}}(undef, N_naive)\nfor t = 1:N_naive\n    execute_naive(pi_naive[t]) # Execute environmental process\n    y_naive[t] = observe_naive() # Observe external states\nend\n\nanimation_naive = @animate for i in 1:N_naive\n    plot(valley_x, valley_y, title = \"Naive policy\", label = \"Landscape\", color = \"black\", size = (800, 400))\n    scatter!([y_naive[i][1]], [height(y_naive[i][1])], label=\"car\")\n    scatter!([x_target[1]], [height(x_target[1])], label=\"goal\")   \nend\n\n# The animation is saved and displayed as markdown picture for the automatic HTML generation\ngif(animation_naive, \"ai-mountain-car-naive.gif\", fps = 24, show_msg = false);\n\n(Image: )\n\nThey failed as expected since the car doesn't have enough power. This helps to understand that the brute-force approach is not the most efficient one in this case and hopefully a bit of swinging is necessary to achieve the goal.","category":"section"},{"location":"categories/advanced_examples/active_inference_mountain_car/#Active-inference-approach","page":"Active Inference Mountain Car","title":"Active inference approach","text":"Now let's help them solve the problem with an active inference approach. Particularly, we create an agent that predicts the future car position as well as the best possible actions in a probabilistic manner.\n\nWe start by specifying a probabilistic model for the agent that describes the agent's internal beliefs over the external dynamics of the environment. The generative model is defined as follows\n\nbeginaligned\np_t(xsu) propto p(s_t-1) prod_k=t^t+T p(x_k mid s_k)  p(s_k mid s_k-1u_k)  p(u_k)  p(x_k) nonumber\nendaligned\n\nwhere the factors are defined as\n\np(x_k) = mathcalN(x_k mid x_goalV_goal)  quad (mathrmtarget)\n\np(s_k mid s_k-1u_k) = mathcalN(s_k mid tildeg(s_k-1)+h(u_k)gamma^-1)  quad (mathrmstate  transition)\n\np(x_k mid s_k) = mathcalN(x_k mid s_ktheta) quad (mathrmobservation)\n\np(u_k) = mathcalN(u_k mid m_uV_u) quad (mathrmcontrol)\n\np(s_t-1) = mathcalN(s_t-1 mid m_t-1V_t-1) quad (mathrmprevious  state)\n\nwhere \n\nx\ndenotes observations of the agent after interacting with the environment; \ns_t = (s_tdots_t)\nis the state of the car embodying its position and velocity; \nu_t\ndenotes the control state of the agent; \nh(cdot)\nis the tanh(cdot) function modeling engine control; \ntildeg(cdot)\nexecutes a linear approximation of equations (1) and (2): \n\nbeginaligned \ndots_t = dots_t-1 + F_g(s_t-1) + F_f(dots_t-1)\ns_t = s_t-1 + dots_t\nendaligned\n\nIn the cell below, the @model macro and the meta blocks are used to define the probabilistic model and the approximation methods for the nonlinear state-transition functions, respectively. In addition, the beliefs over the future states (up to T steps ahead) of the agent is included.\n\n@model function mountain_car(m_u, V_u, m_x, V_x, m_s_t_min, V_s_t_min, T, Fg, Fa, Ff, engine_force_limit)\n    \n    # Transition function modeling transition due to gravity and friction\n    g = (s_t_min::AbstractVector) -> begin \n        s_t = similar(s_t_min) # Next state\n        s_t[2] = s_t_min[2] + Fg(s_t_min[1]) + Ff(s_t_min[2]) # Update velocity\n        s_t[1] = s_t_min[1] + s_t[2] # Update position\n        return s_t\n    end\n    \n    # Function for modeling engine control\n    h = (u::AbstractVector) -> [0.0, Fa(u[1])] \n    \n    # Inverse engine force, from change in state to corresponding engine force\n    h_inv = (delta_s_dot::AbstractVector) -> [atanh(clamp(delta_s_dot[2], -engine_force_limit+1e-3, engine_force_limit-1e-3)/engine_force_limit)] \n    \n    # Internal model perameters\n    Gamma = 1e4*diageye(2) # Transition precision\n    Theta = 1e-4*diageye(2) # Observation variance\n\n    s_t_min ~ MvNormal(mean = m_s_t_min, cov = V_s_t_min)\n    s_k_min = s_t_min\n\n    local s\n    \n    for k in 1:T\n        u[k] ~ MvNormal(mean = m_u[k], cov = V_u[k])\n        u_h_k[k] ~ h(u[k]) where { meta = DeltaMeta(method = Linearization(), inverse = h_inv) }\n        s_g_k[k] ~ g(s_k_min) where { meta = DeltaMeta(method = Linearization()) }\n        u_s_sum[k] ~ s_g_k[k] + u_h_k[k]\n        s[k] ~ MvNormal(mean = u_s_sum[k], precision = Gamma)\n        x[k] ~ MvNormal(mean = s[k], cov = Theta)\n        x[k] ~ MvNormal(mean = m_x[k], cov = V_x[k]) # goal\n        s_k_min = s[k]\n    end\n    \n    return (s, )\nend\n\nAfter specifying the generative model, let's create an Active Inference(AI) agent for the car.  Technically, the agent goes through three phases: Act-Execute-Observe, Infer and Slide.\n\nAct-Execute-Observe:   In this phase, the agent performs an action onto the environment at time t and gets T observations in exchange. These observations are basically the prediction of the agent on how the environment evolves over the next T time step. \nInfer:  After receiving observations, the agent starts updating its internal probabilistic model by doing inference. Particularly, it finds the posterior distributions over the state s_t and control u_t, i.e. p(s_tmid x_t) and p(u_tmid x_t).\nSlide:  After updating its internal belief, the agent moves to the next time step and uses the inferred action u_t in the previous time step to interact with the environment.  \n\nIn the cell below, we create the agent through the create_agent function, which includes compute, act, slide and future functions:\n\nThe act function selects the next action based on the inferred policy. On the other hand, the future function predicts the next T positions based on the current action. These two function implement the Act-Execute-Observe phase.\nThe compute function infers the policy (which is a set of actions for the next T time steps) and the agent's state using the agent internal model. This function implements the Infer phase. We call it compute to avoid the clash with the infer function of RxInfer.jl.\nThe slide function implements the Slide phase, which moves the agent internal model to the next time step.\n\n# We are going to use some private functionality from ReactiveMP, \n# in the future we should expose a proper API for this\nimport RxInfer.ReactiveMP: getrecent, messageout\n\nfunction create_agent(;T = 20, Fg, Fa, Ff, engine_force_limit, x_target, initial_position, initial_velocity)\n    huge = 1e6\n    tiny = 1e-6\n    Epsilon = fill(huge, 1, 1)                # Control prior variance\n    m_u = Vector{Float64}[ [ 0.0] for k=1:T ] # Set control priors\n    V_u = Matrix{Float64}[ Epsilon for k=1:T ]\n\n    Sigma    = 1e-4*diageye(2) # Goal prior variance\n    m_x      = [zeros(2) for k=1:T]\n    V_x      = [huge*diageye(2) for k=1:T]\n    V_x[end] = Sigma # Set prior to reach goal at t=T\n\n    # Set initial brain state prior\n    m_s_t_min = [initial_position, initial_velocity] \n    V_s_t_min = tiny * diageye(2)\n    \n    # Set current inference results\n    result = nothing\n\n    # The `infer` function is the heart of the agent\n    # It calls the `RxInfer.inference` function to perform Bayesian inference by message passing\n    compute = (upsilon_t::Float64, y_hat_t::Vector{Float64}) -> begin\n        m_u[1] = [ upsilon_t ] # Register action with the generative model\n        V_u[1] = fill(tiny, 1, 1) # Clamp control prior to performed action\n\n        m_x[1] = y_hat_t # Register observation with the generative model\n        V_x[1] = tiny*diageye(2) # Clamp goal prior to observation\n\n        data = Dict(:m_u       => m_u, \n                    :V_u       => V_u, \n                    :m_x       => m_x, \n                    :V_x       => V_x,\n                    :m_s_t_min => m_s_t_min,\n                    :V_s_t_min => V_s_t_min)\n        \n        model  = mountain_car(T = T, Fg = Fg, Fa = Fa, Ff = Ff, engine_force_limit = engine_force_limit) \n        result = infer(model = model, data = data)\n    end\n    \n    # The `act` function returns the inferred best possible action\n    act = () -> begin\n        if result !== nothing\n            return mode(result.posteriors[:u][2])[1]\n        else\n            return 0.0 # Without inference result we return some 'random' action\n        end\n    end\n    \n    # The `future` function returns the inferred future states\n    future = () -> begin \n        if result !== nothing \n            return getindex.(mode.(result.posteriors[:s]), 1)\n        else\n            return zeros(T)\n        end\n    end\n\n    # The `slide` function modifies the `(m_s_t_min, V_s_t_min)` for the next step\n    # and shifts (or slides) the array of future goals `(m_x, V_x)` and inferred actions `(m_u, V_u)`\n    slide = () -> begin\n\n        model  = RxInfer.getmodel(result.model)\n        (s, )  = RxInfer.getreturnval(model)\n        varref = RxInfer.getvarref(model, s) \n        var    = RxInfer.getvariable(varref)\n        \n        slide_msg_idx = 3 # This index is model dependend\n        (m_s_t_min, V_s_t_min) = mean_cov(getrecent(messageout(var[2], slide_msg_idx)))\n\n        m_u = circshift(m_u, -1)\n        m_u[end] = [0.0]\n        V_u = circshift(V_u, -1)\n        V_u[end] = Epsilon\n\n        m_x = circshift(m_x, -1)\n        m_x[end] = x_target\n        V_x = circshift(V_x, -1)\n        V_x[end] = Sigma\n    end\n\n    return (compute, act, slide, future)    \nend\n\ncreate_agent (generic function with 1 method)\n\nNow it's time to see if we can help our friends arrive at the camping site by midnight?\n\n(execute_ai, observe_ai) = create_world(\n    Fg = Fg, Ff = Ff, Fa = Fa, \n    initial_position = initial_position, \n    initial_velocity = initial_velocity\n) # Let there be a world\n\nT_ai = 50\n\n(compute_ai, act_ai, slide_ai, future_ai) = create_agent(; # Let there be an agent\n    T  = T_ai, \n    Fa = Fa,\n    Fg = Fg, \n    Ff = Ff, \n    engine_force_limit = engine_force_limit,\n    x_target = x_target,\n    initial_position = initial_position,\n    initial_velocity = initial_velocity\n) \n\nN_ai = 100\n\n# Step through experimental protocol\nagent_a = Vector{Float64}(undef, N_ai) # Actions\nagent_f = Vector{Vector{Float64}}(undef, N_ai) # Predicted future\nagent_x = Vector{Vector{Float64}}(undef, N_ai) # Observations\n\nfor t=1:N_ai\n    agent_a[t] = act_ai()               # Invoke an action from the agent\n    agent_f[t] = future_ai()            # Fetch the predicted future states\n    execute_ai(agent_a[t])              # The action influences hidden external states\n    agent_x[t] = observe_ai()           # Observe the current environmental outcome (update p)\n    compute_ai(agent_a[t], agent_x[t]) # Infer beliefs from current model state (update q)\n    slide_ai()                          # Prepare for next iteration\nend\n\nanimation_ai = @animate for i in 1:N_ai\n    # pls - plot landscape\n    pls = plot(valley_x, valley_y, title = \"Active inference results\", label = \"Landscape\", color = \"black\")\n    pls = scatter!(pls, [agent_x[i][1]], [height(agent_x[i][1])], label=\"car\")\n    pls = scatter!(pls, [x_target[1]], [height(x_target[1])], label=\"goal\")   \n    pls = scatter!(pls, agent_f[i], height.(agent_f[i]), label = \"Predicted future\", alpha = map(i -> 0.5 / i, 1:T_ai))\n    \n    # pef - plot engine force\n    pef = plot(Fa.(agent_a[1:i]), title = \"Engine force (agents actions)\", xlim = (0, N_ai), ylim = (-0.05, 0.05))\n    \n    plot(pls, pef, size = (800, 400))\nend\n    \n# The animation is saved and displayed as markdown picture for the automatic HTML generation\ngif(animation_ai, \"ai-mountain-car-ai.gif\", fps = 24, show_msg = false);\n\n(Image: )\n\nVoila! The car now is able to reach the camping site with a smart strategy.\n\nThe left figure shows the agent reached its goal by swinging and the right one shows the corresponding engine force. As we can see, at the beginning the agent tried to reach the goal directly (with full engine force) but after some trials it realized that's not possible. Since the agent looks ahead for 50 time steps, it has enough time to explore other policies, helping it learn to move back to get more momentum to reach the goal.\n\nNow our friends can enjoy their trip at the camping site!. ","category":"section"},{"location":"categories/advanced_examples/active_inference_mountain_car/#Reference","page":"Active Inference Mountain Car","title":"Reference","text":"We refer reader to the Thijs van de Laar (2019) \"Simulating active inference processes by message passing\" original paper with more in-depth overview and explanation of the active inference agent implementation by message passing. The original environment/task description is from Ueltzhoeffer (2017) \"Deep active inference\".\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [34004b35] HypergeometricFunctions v0.3.28\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n\n\n","category":"section"},{"location":"categories/problem_specific/autoregressive_models/","page":"Autoregressive Models","title":"Autoregressive Models","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Autoregressive-Models","page":"Autoregressive Models","title":"Autoregressive Models","text":"Ever wondered how financial analysts predict tomorrow's stock prices, how meteorologists forecast next week's weather, or how engineers anticipate system failures before they happen? Welcome to the fascinating world of autoregressive models ‚Äì the mathematical engines that power predictions when the future depends on the past.\n\nIn this hands-on example, we'll dive into the elegant framework of Bayesian autoregressive modeling using RxInfer.jl, a powerful probabilistic programming library that makes complex inference tasks surprisingly accessible. Unlike traditional approaches that give you a single prediction, our Bayesian approach provides complete predictive distributions, capturing the uncertainty that's inherent in any real-world forecast.\n\nYou'll discover how to:\n\nCreate and understand AR models through a Bayesian lens with RxInfer.jl and @model macro\nGenerate synthetic data to test your inference algorithms\nPerform automated variational Bayesian inference with RxInfer.jl\nMake probabilistic predictions with quantified uncertainty\nApply these techniques to real-world stock price data\nAs a bonus we implement a simple version of ARMA models\n\nWhether you're predicting financial markets, analyzing sensor readings, modeling climate patterns, or exploring any time-dependent phenomenon, the techniques you'll learn here provide a robust foundation for sophisticated time series analysis using autoregressive models.","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#The-Mathematics-Behind-Autoregressive-Models","page":"Autoregressive Models","title":"The Mathematics Behind Autoregressive Models","text":"At their core, autoregressive (AR) models capture a fundamental principle: the future depends on the past. But how do we translate this intuition into mathematical precision? Let's build the framework together.\n\nImagine we're tracking a variable over time - stock prices, temperature readings, or any quantity that evolves sequentially. In an AR model, we express the current value as a function of its previous values, plus some random noise. This elegantly captures both deterministic patterns and inherent uncertainty.\n\nIn our Bayesian formulation, we model this process as:\n\nbeginaligned\np(gamma) = Gamma(gammaa b)\np(mathbftheta) = mathcalN(mathbfthetamathbfmu Sigma)\np(x_tmathbfx_t-1t-k) = mathcalN(x_tmathbftheta^Tmathbfx_t-1t-k gamma^-1)\np(y_tx_t) = mathcalN(y_tx_t tau^-1)\nendaligned\n\nHere's what this means in plain language:\n\nx_t\nrepresents our system's true state at time t\nmathbfx_t-1t-k\ncaptures the sequence of k previous states\nmathbftheta\nholds the \"memory coefficients\" - how much each past state influences the present\ngamma\ncontrols the randomness in state transitions (higher values mean less randomness)\ny_t\nis what we actually observe, which includes some measurement noise controlled by tau\n\nIt's worth noting that this particular formulation is a latent autoregressive model, where the AR process (x_t) is hidden behind the likelihood function. In classical AR models, the states are directly observed without this additional observation layer. This latent structure gives us more flexibility in modeling real-world phenomena where measurements contain noise or where the underlying process isn't directly observable.\n\nThe beauty of this formulation is that it handles both the \"signal\" (predictable patterns) and the \"noise\" (random fluctuations) in a principled way.\n\nFor readers interested in the deeper theoretical foundations, we recommend Albert Podusenko's excellent work on Message Passing-Based Inference for Time-Varying Autoregressive Models.\n\nNow, let's translate this mathematical framework into code and see it in action!\n\nusing RxInfer, Distributions, LinearAlgebra, Plots, StableRNGs, DataFrames, CSV, Dates","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Starting-Simple:-From-Synthetic-to-Real-World-Data","page":"Autoregressive Models","title":"Starting Simple: From Synthetic to Real-World Data","text":"In our code implementation, we begin by generating synthetic data using predefined sets of coefficients for autoregressive models with orders 1, 2, and 5.\n\nStarting with synthetic data offers several advantages:\n\nGround Truth: We know the exact coefficients that generated the data, making it possible to evaluate how well our inference algorithms recover these parameters.\nControl: We can test our models under different noise levels, sample sizes, and process specifications without the complexity of real-world data.\nLearning Progression: By beginning with synthetic examples, we can build intuition about how AR models behave before tackling the messier challenges of real data.\n\nLater in the example, we'll transition to real-world stock price data, where the true generative process is unknown.\n\n# The following coefficients correspond to stable poles\ncoefs_ar_1 = [-0.27002517200218096]\ncoefs_ar_2 = [0.4511170798064709, -0.05740081602446657]\ncoefs_ar_5 = [0.10699399235785655, -0.5237303489793305, 0.3068897071844715, -0.17232255282458891, 0.13323964347539288];\n\nThe coefficients we've selected aren't arbitrary - they're carefully chosen to ensure stability in our autoregressive processes. In signal processing and time series analysis, stable poles refer to coefficients that keep the AR process from exploding or diverging over time. Mathematically, this means that the roots of the AR characteristic polynomial must lie inside the unit circle in the complex plane. For example, in a first-order AR model where x_t = theta x_t-1 + varepsilon_t, we need theta  1 to ensure stability. For higher-order models, the constraints become more complex, but the principle remains the same: without stability, our models would produce unrealistic, explosive behavior.\n\nfunction generate_synthetic_dataset(; n, Œ∏, Œ≥ = 1.0, œÑ = 1.0, rng = StableRNG(42), states1 = randn(rng, length(Œ∏)))\n    order = length(Œ∏)\n\n    # Convert precision parameters to standard deviation\n    œÑ_std = sqrt(inv(œÑ))\n\n    # Initialize states and observations\n    states       = Vector{Vector{Float64}}(undef, n + 3order)\n    observations = Vector{Float64}(undef, n + 3order)\n\n    # `NormalMeanPrecision` is exported by `RxInfer.jl`\n    # and is a part of `ExponentialFamily.jl`\n    states[1]       = states1\n    observations[1] = rand(rng, NormalMeanPrecision(states[1][1], Œ≥))\n    \n    for i in 2:(n + 3order)\n        previous_state  = states[i - 1]\n        transition      = dot(Œ∏, previous_state)\n        next_x          = rand(rng, NormalMeanPrecision(transition, œÑ))\n        states[i]       = vcat(next_x, previous_state[1:end-1])\n        observations[i] = rand(rng, NormalMeanPrecision(next_x, Œ≥))\n    end\n    \n    return states[1+3order:end], observations[1+3order:end]\nend\n\ngenerate_synthetic_dataset (generic function with 1 method)\n\nWe can now generate several synthetic datasets and plot them to see how they look like:\n\nfunction plot_synthetic_dataset(; dataset, title)\n    states, observations = dataset\n    p = plot(first.(states), label = \"Hidden states\", title = title)\n    p = scatter!(p, observations, label = \"Observations\")\n    return p\nend\n\nplot_synthetic_dataset (generic function with 1 method)\n\ndataset_1 = generate_synthetic_dataset(n = 100, Œ∏ = coefs_ar_1)\ndataset_2 = generate_synthetic_dataset(n = 100, Œ∏ = coefs_ar_2)\ndataset_5 = generate_synthetic_dataset(n = 100, Œ∏ = coefs_ar_5)\n\np1 = plot_synthetic_dataset(dataset = dataset_1, title = \"AR(1)\")\np2 = plot_synthetic_dataset(dataset = dataset_2, title = \"AR(2)\")\np3 = plot_synthetic_dataset(dataset = dataset_5, title = \"AR(5)\")\n\nplot(p1, p2, p3, layout = @layout([ a b ; c ]))\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Model-Specification:-Translating-Theory-to-Code","page":"Autoregressive Models","title":"Model Specification: Translating Theory to Code","text":"With our synthetic data ready, we now tackle the critical step of encoding our autoregressive model as a probabilistic program in RxInfer. This translation from mathematical notation to executable code is where the power of probabilistic programming truly shines.\n\n@model function lar_multivariate(y, order, Œ≥)\n    # `c` is a unit vector of size `order` with first element equal to 1\n    c = ReactiveMP.ar_unit(Multivariate, order)\n    \n    œÑ  ~ Gamma(Œ± = 1.0, Œ≤ = 1.0)\n    Œ∏  ~ MvNormal(mean = zeros(order), precision = diageye(order))\n    x0 ~ MvNormal(mean = zeros(order), precision = diageye(order))\n    \n    x_prev = x0\n    \n    for i in eachindex(y)\n \n        x[i] ~ AR(x_prev, Œ∏, œÑ) \n        y[i] ~ Normal(mean = dot(c, x[i]), precision = Œ≥)\n        \n        x_prev = x[i]\n    end\nend","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Constraints-specification","page":"Autoregressive Models","title":"Constraints specification","text":"Bayesian inference for complex models often requires approximations. Our code uses variational inference with a specific factorization constraint:\n\n@constraints function ar_constraints() \n    q(x0, x, Œ∏, œÑ) = q(x0, x)q(Œ∏)q(œÑ)\nend\n\nar_constraints (generic function with 1 method)\n\nThis constraint defines how we'll approximate the joint posterior:\n\nWe factorize it into three independent components\nStates (x0, x) remain jointly distributed, preserving temporal dependencies\nModel parameters (Œ∏, œÑ) are separated from states and each other\nEach component can be updated independently during inference\n\nThis factorization balances statistical accuracy with computational efficiency and allows RxInfer to apply efficient message-passing algorithms while maintaining the most important dependencies in the model.","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Meta-specification","page":"Autoregressive Models","title":"Meta specification","text":"The @meta block in RxInfer provides essential configuration information to specific nodes in your probabilistic model. In short, it tells RxInfer how to customize inference algorithms, what approximation methods to use, and allows to specify extra computational parameters for custom complex factor nodes. \n\n@meta function ar_meta(order)\n    AR() -> ARMeta(Multivariate, order, ARsafe())\nend\n\nar_meta (generic function with 1 method)\n\nFor autoregressive models, this block tells RxInfer:\n\nWhich type of AR process to use (Univariate/Multivariate)\nThe order of the process (how many past values influence the current one)\nAny stability constraints to apply during inference\n\nFor more information about specific arguments refer to the AR node documentation. For more information on meta blocks, see the RxInfer.jl documentation.","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Initialization-specification","page":"Autoregressive Models","title":"Initialization specification","text":"The @initialization block in RxInfer specifies the initial marginal distributions for the model parameters. This is crucial for the convergence of inference algorithms, especially for complex models like autoregressive processes.\n\nFor our autoregressive models, we initialize:\n\n@initialization function ar_init(order)\n    q(œÑ) = GammaShapeRate(1.0, 1.0)\n    q(Œ∏) = MvNormalMeanPrecision(zeros(order), diageye(order))\nend\n\nar_init (generic function with 1 method)","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Inference","page":"Autoregressive Models","title":"Inference","text":"With our model defined, constraints established, and meta configurations in place, we're now at the exciting moment of truth - running Bayesian inference on our latent autoregressive model!\n\nreal_Œ∏ = coefs_ar_5\nreal_œÑ = 0.5\nreal_Œ≥ = 2.0\n\norder = length(real_Œ∏)\nn     = 500 \n\nstates, observations = generate_synthetic_dataset(n = n, Œ∏ = real_Œ∏, œÑ = real_œÑ, Œ≥ = real_Œ≥)\n\nresult = infer(\n    model          = lar_multivariate(order = order, Œ≥ = real_Œ≥), \n    data           = (y = observations, ),\n    constraints    = ar_constraints(),\n    meta           = ar_meta(order),\n    initialization = ar_init(order),\n    options        = (limit_stack_depth = 500, ),\n    returnvars     = (x = KeepLast(), œÑ = KeepEach(), Œ∏ = KeepEach()),\n    free_energy    = true,\n    iterations     = 20\n)\n\nInference results:\n  Posteriors       | available for (œÑ, Œ∏, x)\n  Free Energy:     | Real[1575.77, 1261.1, 1056.63, 1011.25, 1001.28, 997.4\n91, 995.92, 995.375, 995.066, 994.961, 994.913, 994.833, 994.899, 994.864, \n994.834, 994.894, 994.872, 994.88, 994.897, 994.913]\n\nNow that our inference procedure has completed, we've obtained posterior distributions for all our model parameters and latent states. The AR coefficients, precision parameters, and hidden state sequence have all been inferred from the data, with complete uncertainty quantification.\n\nmean(result.posteriors[:Œ∏][end])\n\n5-element Vector{Float64}:\n  0.06182696232009309\n -0.5172296604873058\n  0.18038487975628942\n -0.1591736495117487\n  0.0966030389097711\n\ncov(result.posteriors[:Œ∏][end])\n\n5√ó5 Matrix{Float64}:\n  0.0019919    -9.0483e-5     0.00100443  -0.000263633   0.000309501\n -9.0483e-5     0.00194875   -9.51917e-5   0.000858899  -0.000261436\n  0.00100443   -9.51917e-5    0.00241975  -9.69051e-5    0.00100208\n -0.000263633   0.000858899  -9.69051e-5   0.00195085   -9.23067e-5\n  0.000309501  -0.000261436   0.00100208  -9.23067e-5    0.00199453\n\nreal_Œ∏\n\n5-element Vector{Float64}:\n  0.10699399235785655\n -0.5237303489793305\n  0.3068897071844715\n -0.17232255282458891\n  0.13323964347539288\n\nBut numbers alone don't tell the full story. Let's visualize these results to better understand what our model has captured. By plotting the inferred latent states against our observations, we can see how well our model has filtered out the noise to reveal the underlying process dynamics.\n\nposterior_states       = result.posteriors[:x]\nposterior_œÑ            = result.posteriors[:œÑ]\n\np1 = plot(first.(states), label=\"Hidden state\")\np1 = scatter!(p1, observations, label=\"Observations\")\np1 = plot!(p1, first.(mean.(posterior_states)), ribbon = 3first.(std.(posterior_states)), label=\"Inferred states (+-3œÉ)\", legend = :bottomright)\np1 = lens!(p1, [20, 40], [-2, 2], inset = (1, bbox(0.2, 0.0, 0.4, 0.4)))\n\np2 = plot(mean.(posterior_œÑ), ribbon = 3std.(posterior_œÑ), label = \"Inferred œÑ (+-3œÉ)\", legend = :topright)\np2 = plot!([ real_œÑ ], seriestype = :hline, label = \"Real œÑ\")\n\n\nplot(p1, p2, layout = @layout([ a; b ]))\n\n(Image: )\n\nWhen performing variational inference in RxInfer, the Bethe Free Energy (BFE) graph is a crucial diagnostic tool that reveals the convergence properties of our inference algorithm.\n\nThe Bethe Free Energy represents the objective function being minimized during variational inference. On the graph:\n\nThe vertical axis shows the BFE value (lower is better)\nThe horizontal axis shows iteration number\nThe downward slope indicates the algorithm is improving its approximation\nA plateau signals convergence - the point where additional iterations yield minimal improvement\n\nplot(result.free_energy, label = \"Bethe Free Energy\")\n\n(Image: )\n\nFor autoregressive models specifically, the BFE graph helps us:\n\nConfirm convergence: Ensuring our parameter and state estimates are reliable\nDetect inference challenges: Slow convergence may indicate model misspecification\nCompare models: Different AR orders or constraints can be compared by their final BFE values\n\nA sharply decreasing curve that quickly plateaus suggests efficient, successful inference In contrast, a slowly decreasing or unstable curve might indicate challenges with our model specification or data characteristics.\n\nIt is also interesting to plot the convergence of our AR coefficients:\n\nposterior_coefficients = result.posteriors[:Œ∏]\n\npŒ∏ = []\ncŒ∏ = Plots.palette(:tab10)\n\nŒ∏ms = mean.(posterior_coefficients)\nŒ∏vs = 3std.(posterior_coefficients)\n\nfor i in 1:length(first(Œ∏ms))\n    push!(pŒ∏, plot(getindex.(Œ∏ms, i), ribbon = getindex.(Œ∏vs, i), label = \"Estimated Œ∏[$i]\", color = cŒ∏[i]))\nend\n\nfor i in 1:length(real_Œ∏)\n    plot!(pŒ∏[i], [ real_Œ∏[i] ], seriestype = :hline, label = \"Real Œ∏[$i]\", color = cŒ∏[i], linewidth = 2)\nend\n\nplot(pŒ∏..., size = (800, 300), legend = :bottomright)\n\n(Image: )\n\nThe inference process has successfully recovered the key parameters of our autoregressive model with good precision. Looking at the plots, we can see well-formed posterior distributions for both our AR coefficients (Œ∏) and precision parameters (œÑ). The visualization reveals not just point estimates, but complete distributions that capture the remaining uncertainty in each parameter. ","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Prediction-with-Autoregressive-Models","page":"Autoregressive Models","title":"Prediction with Autoregressive Models","text":"In the next section, we'll put our inferred model to the ultimate test: prediction. Having captured the underlying dynamics of our time series through Bayesian inference, we can now use these posterior distributions to forecast future values with quantified uncertainty. \n\nIt's worth emphasizing that in our latent autoregressive model, we're predicting the hidden state process rather than directly observed values. This is a more challenging task than prediction in classical AR models where states are directly observed. We must account for both the uncertainty in the AR dynamics and the additional uncertainty introduced by the observation model.\n\nRxInfer makes this process remarkably straightforward, allowing us to propagate our beliefs about model parameters and states forward in time. The resulting predictive distributions will show not just what we expect to happen next, but how confident we should be in those expectations.","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Example-with-Sinusoidal-Autoregressive-Pattern","page":"Autoregressive Models","title":"Example with Sinusoidal Autoregressive Pattern","text":"For this demonstration, we'll use a sinusoidal-like signal to test our predictive capabilities. This choice is particularly meaningful since sinusoidal patterns can be perfectly generated by second-order autoregressive processes with specific coefficients.\n\nfunction generate_sinusoidal_coefficients(; f) \n    a1 = 2cos(2pi*f)\n    a2 = -1\n    return [a1, a2]\nend\n\ngenerate_sinusoidal_coefficients (generic function with 1 method)\n\nThe signal then would look something like:\n\n# Generate coefficients\npredictions_coefficients = generate_sinusoidal_coefficients(f = 0.03)\n\n# Generate dataset\npredictions_dataset = generate_synthetic_dataset(n = 350, Œ∏ = predictions_coefficients, œÑ = 1.0, Œ≥ = 0.01)\n\n# Plot dataset\nplot_synthetic_dataset(dataset = predictions_dataset, title = \"Sinusoidal AR(2)\")\n\n(Image: )\n\nWe can use the same model as before to automatically infer the coefficients of the sinusoidal pattern and predict the future values in the following way:\n\nnumber_of_predictions = 100\n\npredictions_states, predictions_observations = predictions_dataset\n\n# We inject `missing` values to the observations to simulate \n# the future values that we want to predict\npredictions_observations_with_predictions = vcat(\n    predictions_observations,\n    [ missing for _ in 1:number_of_predictions ]\n)\n\n# It is better to use `UnfactorizedData` for prediction\npredictions_result = infer(\n    model          = lar_multivariate(order = 2, Œ≥ = 0.01), \n    data           = (y = UnfactorizedData(predictions_observations_with_predictions), ),\n    constraints    = ar_constraints(),\n    meta           = ar_meta(2),\n    initialization = ar_init(2),\n    options        = (limit_stack_depth = 500, ),\n    returnvars     = (x = KeepLast(), œÑ = KeepEach(), Œ∏ = KeepEach()),\n    free_energy    = false,\n    iterations     = 20\n)\n\nInference results:\n  Posteriors       | available for (œÑ, Œ∏, x)\n  Predictions      | available for (y)\n\nNote: In the current version of RxInfer, the free_energy option is not supported for prediction. Thus we explicitly set it to false. However, we already verified that the inference procedure converges to the correct coefficients with the previous example.","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Prediction-results","page":"Autoregressive Models","title":"Prediction results","text":"We first can check if the inference procedure has converged to the correct coefficients:\n\n# Extract the inferred coefficients (mean of posterior)\ninferred_coefficients = predictions_result.posteriors[:Œ∏][end]\n\nprintln(\"True coefficients: \", predictions_coefficients)\nprintln(\"Inferred coefficients (mean value): \", mean(inferred_coefficients))\n\nŒº_true = predictions_coefficients\nŒº_inferred = mean(inferred_coefficients)\n\n# Create grid of points\nx = range(Œº_true[1]-0.025, Œº_true[1]+0.025, length=100)\ny = range(Œº_true[2]-0.025, Œº_true[2]+0.025, length=100)\n\n# Create contour plot\ncoefficients_plot = contour(x, y, (x, y) -> pdf(inferred_coefficients, [x, y]), \n    fill=true, \n    title=\"True vs Inferred AR Coefficients\",\n    xlabel=\"Œ∏‚ÇÅ\",\n    ylabel=\"Œ∏‚ÇÇ\",\n    levels = 14, \n    color=:turbo,\n    colorbar = false\n)\n\n# Add point for true coefficients\nscatter!(coefficients_plot, [Œº_true[1]], [Œº_true[2]], \n    label=\"True coefficients\",\n    marker=:star,\n    markersize=20,\n    color=:red\n)\n\n# Add point for inferred mean\nscatter!(coefficients_plot, [Œº_inferred[1]], [Œº_inferred[2]], \n    label=\"Inferred mean\",\n    markersize=8,\n    color=:white\n)\n\nTrue coefficients: [1.9645745014573774, -1.0]\nInferred coefficients (mean value): [1.9607030557929608, -0.997248085033154\n8]\n\n(Image: )\n\nNow let's visualize our prediction results to see how well our model captures the underlying temporal patterns. By plotting the predicted values against the actual test data, we can immediately assess the quality of our forecasts. Pay special attention to the confidence intervals (shaded regions) surrounding our predictions ‚Äì these represent our model's uncertainty with propagated uncertainty from the inferred coefficients. \n\npredictions_posterior_states = predictions_result.predictions[:y][end]\n\npredictions_posterior_states_mean = mean.(predictions_posterior_states)\npredictions_posterior_states_std = std.(predictions_posterior_states)\n\npred_p = scatter(predictions_observations, label=\"Observations\", ms=2)\npred_p = plot!(pred_p, predictions_posterior_states_mean, ribbon=3predictions_posterior_states_std, label=\"Predictions\")\n\n(Image: )\n\nWide intervals suggest high uncertainty, while narrow ones indicate confidence in specific outcomes. When forecasting with AR models, several limitations deserve attention. First, AR models inherently assume that future patterns will resemble past ones - a tenuous assumption during regime changes or external shocks. Second, uncertainty compounds rapidly with prediction horizon; while one-step-ahead forecasts may appear precise, multi-step predictions quickly develop wide confidence intervals that reflect the model's decreasing predictive power.\n\nTo put it in the comparison, we could also use the inferred parameters to predict the future values using the inferred coefficients and the precision parameter. This approach however, will not yield the uncertainty estimates that we get from the inference procedure.\n\nfunction predict_manual(; number_of_predictions, coefficients, precision, first_state, rng = StableRNG(42))\n    states = [ first_state ]\n    for i in 1:(number_of_predictions + 1)\n        next_x     = rand(rng, NormalMeanPrecision(dot(coefficients, states[end]), precision))\n        next_state = vcat(next_x, states[end][1:end-1])\n        push!(states, next_state)\n    end\n    return states[2:end]\nend\n\npredict_manual (generic function with 1 method)\n\npredicted_manually = predict_manual(; \n    number_of_predictions = number_of_predictions, \n    coefficients = predictions_coefficients, \n    precision = 0.1, \n    first_state = predictions_states[end]\n)\n\nplot(1:length(predictions_states), first.(predictions_states), label = \"Real state\")\nscatter!(1:length(predictions_observations), first.(predictions_observations), label = \"Observations\", ms = 2)\nplot!((length(predictions_observations)+1):length(predictions_observations) + number_of_predictions + 1, first.(predicted_manually), label = \"Predictions manually\")\n\n(Image: )\n\nLet's plot both predictions together to see the difference:\n\npred_p_manual = scatter(predictions_observations, label=\"Observations\", ms=2)\npred_p_manual = plot!(pred_p_manual, predictions_posterior_states_mean, ribbon=3predictions_posterior_states_std, label=\"Predictions\")\npred_p_manual = plot!(pred_p_manual, (length(predictions_observations)+1):length(predictions_observations) + number_of_predictions + 1, first.(predicted_manually), label = \"Predictions manual\")\n\n(Image: )\n\nWe can see that manual prediction calculations, while computationally simpler, lack the crucial uncertainty quantification that we get from a proper Bayesian inference procedure. Additionally, the predictive power of an AR process directly relates to its order N - higher orders can capture more complex temporal dependencies and longer memory effects, but at the cost of potential overfitting. An AR(2) process can only predict based on the immediate previous observation, creating simple exponential trends, while an AR(5) can detect and forecast more intricate patterns like seasonal oscillations or cyclical behaviors. However, this improved predictive power comes with diminishing returns as N increases, requiring careful model selection to balance complexity against generalization ability for optimal forecasting performance.","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Stock-Prices-Dataset","page":"Autoregressive Models","title":"Stock Prices Dataset","text":"Stock prices make for a challenging but instructive test case. They're notoriously difficult to predict, but often exhibit both short-term momentum (AR components) and characteristic responses to market shocks (MA components). We will use American Airlines stock data downloaded from Kaggle\n\nx_df = CSV.read(\"aal_stock.csv\", DataFrame)\n\n1259√ó7 DataFrame\n  Row ‚îÇ date        open     high     low      close    volume    Name\n      ‚îÇ Date        Float64  Float64  Float64  Float64  Int64     String3\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    1 ‚îÇ 2013-02-08    15.07    15.12   14.63     14.75   8407500  AAL\n    2 ‚îÇ 2013-02-11    14.89    15.01   14.26     14.46   8882000  AAL\n    3 ‚îÇ 2013-02-12    14.45    14.51   14.1      14.27   8126000  AAL\n    4 ‚îÇ 2013-02-13    14.3     14.94   14.25     14.66  10259500  AAL\n    5 ‚îÇ 2013-02-14    14.94    14.96   13.16     13.99  31879900  AAL\n    6 ‚îÇ 2013-02-15    13.93    14.61   13.93     14.5   15628000  AAL\n    7 ‚îÇ 2013-02-19    14.33    14.56   14.08     14.26  11354400  AAL\n    8 ‚îÇ 2013-02-20    14.17    14.26   13.15     13.33  14725200  AAL\n  ‚ãÆ   ‚îÇ     ‚ãÆ          ‚ãÆ        ‚ãÆ        ‚ãÆ        ‚ãÆ        ‚ãÆ         ‚ãÆ\n 1253 ‚îÇ 2018-01-30    52.45    53.05   52.36     52.59   4741808  AAL\n 1254 ‚îÇ 2018-01-31    53.08    54.71   53.0      54.32   5962937  AAL\n 1255 ‚îÇ 2018-02-01    54.0     54.64   53.59     53.88   3623078  AAL\n 1256 ‚îÇ 2018-02-02    53.49    53.99   52.03     52.1    5109361  AAL\n 1257 ‚îÇ 2018-02-05    51.99    52.39   49.75     49.76   6878284  AAL\n 1258 ‚îÇ 2018-02-06    49.32    51.5    48.79     51.18   6782480  AAL\n 1259 ‚îÇ 2018-02-07    50.91    51.98   50.89     51.4    4845831  AAL\n                                                         1244 rows omitted\n\n# We will use \"close\" column\nx_data = filter(!ismissing, x_df[:, 5])\n\n# Plot data\nplot(x_data, xlabel=\"Day\", ylabel=\"Price\", label=\"Close\")\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Preparing-the-dataset-for-inference-and-prediction","page":"Autoregressive Models","title":"Preparing the dataset for inference and prediction","text":"To validate the inference and prediction results we will also split our dataset into two parts \"observed\" and \"to_predict\", which commonly also reffered as to \"train\" and \"test\" sets.\n\nobserved_size = length(x_data) - 50\n\n# Observed part\nx_observed    = Float64.(x_data[1:observed_size])\n\n# We need to predict this part\nx_to_predict   = Float64.(x_data[observed_size+1:end])\n\nx_observed_length   = length(x_observed)\nx_to_predict_length = length(x_to_predict)\n\nplot(1:x_observed_length, x_observed, label = \"Observed signal\")\nplot!((x_observed_length + 1):(x_observed_length + x_to_predict_length), x_to_predict, label = \"To predict\")\n\n(Image: )\n\nWe can use the same model as before for the stock prices dataset. Let's however put the model to the ultimate test and use AR(50) to predict the future values. \n\nstock_observations_with_predictions = vcat(\n    x_observed,\n    [ missing for _ in 1:length(x_to_predict) ]\n)\n\nstock_predictions_result = infer(\n    model          = lar_multivariate(order = 50, Œ≥ = 1.0), \n    data           = (y = UnfactorizedData(stock_observations_with_predictions), ),\n    constraints    = ar_constraints(),\n    meta           = ar_meta(50),\n    initialization = ar_init(50),\n    options        = (limit_stack_depth = 500, ),\n    returnvars     = (x = KeepLast(), œÑ = KeepEach(), Œ∏ = KeepEach()),\n    free_energy    = false,\n    iterations     = 20\n)\n\nInference results:\n  Posteriors       | available for (œÑ, Œ∏, x)\n  Predictions      | available for (y)\n\nplot(1:x_observed_length, x_observed, label = \"Observed signal\")\nplot!((x_observed_length + 1):(x_observed_length + x_to_predict_length), x_to_predict, label = \"To predict\")\n\nstock_predictions = stock_predictions_result.predictions[:y][end]\n\nplot!(mean.(stock_predictions), ribbon = std.(stock_predictions), label = \"Predictions\")\n\n(Image: )\n\nWe can also plot it against the hidden states in the model and using only the first component of the hidden state:\n\nplot(1:x_observed_length, x_observed, label = \"Observed signal\")\nplot!((x_observed_length + 1):(x_observed_length + x_to_predict_length), x_to_predict, label = \"To predict\")\n\nstock_hidden_states = stock_predictions_result.posteriors[:x]\n\nplot!(first.(mean.(stock_hidden_states)), ribbon = first.(std.(stock_hidden_states)), label = \"x[1]\")\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Autoregressive-Moving-Average-Model","page":"Autoregressive Models","title":"Autoregressive Moving Average Model","text":"As a final touch, we will implement a fully Bayesian version of ARMA model. Autoregressive Moving Average (ARMA) models represent a powerful synthesis of two fundamental time series components: the autoregressive (AR) part, which captures how current values depend on past observations, and the moving average (MA) part, which models the persistence of random shocks. This combination makes ARMA models particularly well-suited for financial data like stock prices, where both momentum effects (AR) and reaction to news or market shocks (MA) influence price movements. In this example, we'll see how Bayesian inference with RxInfer can reveal these underlying dynamics while quantifying our uncertainty every step of the way.","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Mathematical-Formulation-of-ARMA-Model","page":"Autoregressive Models","title":"Mathematical Formulation of ARMA Model","text":"Bayesian ARMA model can be effectively implemeted in RxInfer.jl. For theoretical details on Varitional Inference for ARMA model, we refer the reader to the following paper.  The Bayesian ARMA model can be written as follows:\n\nbeginaligned\ne_t sim mathcalN(0 gamma^-1) \ntheta sim mathcalN(mathbf0 mathbfI) \neta sim mathcalN(mathbf0 mathbfI) \nmathbfh_0 sim mathcalNleft(beginbmatrix\ne_-1 \ne_-2\nendbmatrix mathbfIright) \nmathbfh_t = mathbfSmathbfh_t-1 + mathbfc e_t-1 \nmathbfx_t = boldsymboltheta^topmathbfx_t-1 + boldsymboleta^topmathbfh_t + e_t \nendaligned\n\nwhere shift matrix mathbfS is defined as\n\nbeginaligned\nmathbfS = beginpmatrix\n0  0 \n1  0 \nendpmatrix\nendaligned\n\nfunction shift(dim)\n    S = Matrix{Float64}(I, dim, dim)\n    for i in dim:-1:2\n        S[i,:] = S[i-1, :]\n    end\n    S[1, :] = zeros(dim)\n    return S\nend\n\nshift (generic function with 1 method)\n\nshift(2)\n\n2√ó2 Matrix{Float64}:\n 0.0  0.0\n 1.0  0.0\n\nand unit vector mathbfc: \n\nbeginaligned\nmathbfc=1 0\nendaligned\n\nwhen MA order is 2. In this way, mathbfh_t containing errors e_t can be viewed as hidden state.","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Intractabilities-in-ARMA-model","page":"Autoregressive Models","title":"Intractabilities in ARMA model","text":"In short, the Bayesian ARMA model has two intractabilities: \n\ninduced by the multiplication of two Gaussian RVs, i.e., boldsymboleta^topmathbfh_t, \ninduced by errors e_t that prevents analytical update of precision parameter gamma (this can be easily seen when constructing the Factor Graph, i.e. there is a loop). \n\nBoth problems can be easily resolved in RxInfer.jl, by creating a hybrid inference algorithm based on Loopy Variational Message Passing.","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#ARMA-model-specification","page":"Autoregressive Models","title":"ARMA model specification","text":"The model specification is the trickiest part of this implementation. Note how we need to carefully define the relationship between observed values, latent states, and error terms. The ARMA model's loops create inference challenges that wouldn't exist in simpler models - this is why we need to specify proper initialization and factorization constraints to avoid convergence problems. For the @meta we will simply reuse the previously defined ar_meta function.\n\n@model function ARMA(x, x_prev, priors, p_order, q_order)\n    \n    # arguments\n    c = zeros(q_order); c[1] = 1.0;\n    S = shift(q_order); # MA\n\n    # set priors\n    Œ≥    ~ priors[:Œ≥]\n    Œ∑    ~ priors[:Œ∑]\n    Œ∏    ~ priors[:Œ∏]\n    œÑ    ~ priors[:œÑ]\n    \n    h[1] ~ priors[:h]\n    z[1] ~ AR(h[1], Œ∑, œÑ)\n    e[1] ~ Normal(mean = 0.0, precision = Œ≥)\n    x[1] ~ dot(c, z[1]) + dot(Œ∏, x_prev[1]) + e[1]\n\n    for t in 1:length(x)-1\n        h[t+1] ~ S * h[t] + c * e[t]\n        z[t+1] ~ AR(h[t+1], Œ∑, œÑ)\n        e[t+1] ~ Normal(mean = 0.0, precision = Œ≥)\n        x[t+1] ~ dot(c, z[t+1]) + dot(Œ∏, x_prev[t+1]) + e[t+1]\n    end\nend\n\n@constraints function arma_constraints()\n    q(z, h, Œ∑, œÑ, Œ≥,e) = q(z, h)q(Œ∑)q(œÑ)q(Œ≥)q(e)\nend\n\n@initialization function arma_initialization(priors) \n    q(h)   = priors[:h]\n    Œº(h)   = priors[:h]\n    q(Œ≥)   = priors[:Œ≥]\n    q(œÑ)   = priors[:œÑ]\n    q(Œ∑)   = priors[:Œ∑]\n    q(Œ∏)   = priors[:Œ∏]\nend\n\narma_initialization (generic function with 1 method)\n\np_order = 10 # AR\nq_order = 4  # MA\n\n4","category":"section"},{"location":"categories/problem_specific/autoregressive_models/#Inference-with-ARMA-model","page":"Autoregressive Models","title":"Inference with ARMA model","text":"Now, everything should be ready for the infer call from RxInfer on the stock prices dataset defined earlier.\n\npriors  = (\n    h = MvNormalMeanPrecision(zeros(q_order), diageye(q_order)),\n    Œ≥ = GammaShapeRate(1e4, 1.0),\n    œÑ = GammaShapeRate(1e2, 1.0),\n    Œ∑ = MvNormalMeanPrecision(ones(q_order), diageye(q_order)),\n    Œ∏ = MvNormalMeanPrecision(zeros(p_order), diageye(p_order))\n)\n\narma_x_data = Float64.(x_data[p_order+1:end])[1:observed_size]\narma_x_prev_data = [Float64.(x_data[i+p_order-1:-1:i]) for i in 1:length(x_data)-p_order][1:observed_size]\n\nresult = infer(\n    model = ARMA(priors=priors, p_order = p_order, q_order = q_order), \n    data  = (x = arma_x_data, x_prev = arma_x_prev_data),\n    initialization = arma_initialization(priors),\n    constraints    = arma_constraints(),\n    meta           = ar_meta(q_order),\n    returnvars     = KeepLast(),\n    iterations     = 20,\n    options        = (limit_stack_depth = 400, ),\n)\n\nInference results:\n  Posteriors       | available for (Œ≥, e, œÑ, h, z, Œ∏, Œ∑)\n\nplot(mean.(result.posteriors[:e]), ribbon = var.(result.posteriors[:e][end]), label = \"e‚Çú\")\n\n(Image: )\n\nWhat we've seen in this example is more than just a stock price forecast - it's a demonstration of how modern probabilistic programming with RxInfer enables sophisticated time series modeling with relatively concise code. The same techniques can be applied across domains from economics to engineering, wherever systems exhibit both memory effects and response to external shocks. And most importantly, the Bayesian approach gives us a principled way to quantify uncertainty in our predictions - essential for robust decision-making in any domain.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [336ed68f] CSV v0.10.16\n  [a93c6f00] DataFrames v1.8.1\n  [31c24e10] Distributions v0.25.123\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/basic_examples/bayesian_binomial_regression/","page":"Bayesian Binomial Regression","title":"Bayesian Binomial Regression","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/basic_examples/bayesian_binomial_regression/#Bayesian-Binomial-Regression","page":"Bayesian Binomial Regression","title":"Bayesian Binomial Regression","text":"This notebook is an introductory tutorial to Bayesian binomial regression with RxInfer.\n\nusing RxInfer, ReactiveMP, Random, Plots, StableRNGs, LinearAlgebra, StatsPlots, LaTeXStrings","category":"section"},{"location":"categories/basic_examples/bayesian_binomial_regression/#Likelihood-Specification","page":"Bayesian Binomial Regression","title":"Likelihood Specification","text":"For observations y_i with predictors mathbfx_i, Binomial regression models the number of successes y_i as a function of the predictors mathbfx_i and the regression coefficients boldsymbolbeta\n\nbeginequation\ny_i sim textBinomial(n_i p_i)\nendequation\n\nwhere:\n\ny_i\n\nis the number of successes, n_i is the number of trials, p_i is the probability of success. The probability p_i is linked to the predictors through the logistic function:\n\nbeginequation\np_i = frac11 + e^-mathbfx_i^Tboldsymbolbeta\nendequation","category":"section"},{"location":"categories/basic_examples/bayesian_binomial_regression/#Prior-Distributions","page":"Bayesian Binomial Regression","title":"Prior Distributions","text":"We specify priors for the regression coefficients:\n\nbeginequation\nboldsymbolbeta sim mathcalN_xi(boldsymbolxi boldsymbolLambda)\nendequation\n\nas a Normal distribution in precision-weighted mean form.","category":"section"},{"location":"categories/basic_examples/bayesian_binomial_regression/#Model-Specification","page":"Bayesian Binomial Regression","title":"Model Specification","text":"The likelihood and the prior distributions form the probabilistic model\n\np(y x beta n) = p(beta) prod_i=1^N p(y_i mid x_i beta n_i)\n\nwhere the goal is to infer the posterior distributions p(beta mid y x n). Due to logistic link function, the posterior distribution is not conjugate to the prior distribution. This means that we need to use a more complex inference algorithm to infer the posterior distribution. Before dwelling into the details of the inference algorithm, let's first generate some synthetic data to work with.\n\nfunction generate_synthetic_binomial_data(\n    n_samples::Int,\n    true_beta::Vector{Float64};\n    seed::Int=42\n)\n    n_features = length(true_beta)\n    rng = StableRNG(seed)\n    \n    X = randn(rng, n_samples, n_features)\n    \n    n_trials = rand(rng, 5:20, n_samples)\n    \n    logits = X * true_beta\n    probs = 1 ./ (1 .+ exp.(-logits))\n    \n    y = [rand(rng, Binomial(n_trials[i], probs[i])) for i in 1:n_samples]\n    \n    return X, y, n_trials, probs\nend\n\n\nn_samples = 10000\ntrue_beta =  [-3.0 , 2.6]\n\nX, y, n_trials,probs = generate_synthetic_binomial_data(n_samples, true_beta);\nX = [collect(row) for row in eachrow(X)];\n\nWe generate X as the design matrix and y as the number of successes and n_trials as the number of trials. Next task is to define the graphical model. RxInfer provides a BinomialPolya factor node that is a combination of a Binomial distribution and a PolyaGamma distribution introduced in [1]. The BinomialPolya factor node is used to model the likelihood of the binomial distribution. \n\nDue to non-conjugacy of the likelihood and the prior distribution, we need to use a more complex inference algorithm. RxInfer provides an Expectation Propagation (EP) [2] algorithm to infer the posterior distribution. Due to EP's approximation, we need to specify an inbound message for the regression coefficients while using the BinomialPolya factor node. This feature is implemented in the dependencies keyword argument during the creation of the BinomialPolya factor node. ReactiveMP.jl provides a RequireMessageFunctionalDependencies type that is used to specify the inbound message for the regression coefficients Œ≤. Refer to the ReactiveMP.jl documentation for more information.\n\n@model function binomial_model(prior_xi, prior_precision, n_trials, X, y) \n    Œ≤ ~ MvNormalWeightedMeanPrecision(prior_xi, prior_precision)\n    for i in eachindex(y)\n        y[i] ~ BinomialPolya(X[i], n_trials[i], Œ≤) where {\n            dependencies = RequireMessageFunctionalDependencies(Œ≤ = MvNormalWeightedMeanPrecision(prior_xi, prior_precision))\n        }\n    end\nend\n\nThis example uses the precision-weighted mean parametrization (MvNormalWeightedMeanPrecision) of the Gaussian distribution for efficiency reasons. While this is less conventional than the standard mean-covariance form, the example would work equally well with any parametrization. The choice of parametrization mainly affects computational efficiency and numerical stability, not the underlying model or results.\n\nHaving specified the model, we can now utilize the infer function to infer the posterior distribution.\n\nn_features = length(true_beta)\nresults = infer(\n    model = binomial_model(prior_xi = zeros(n_features), prior_precision = diageye(n_features),),\n    data = (X=X, y=y,n_trials=n_trials),\n    iterations = 30,\n    free_energy = true,\n    showprogress = true,\n    options = (\n        limit_stack_depth = 100, # to prevent stack-overflow errors\n    )\n)\n\nInference results:\n  Posteriors       | available for (Œ≤)\n  Free Energy:     | Real[21992.9, 16235.8, 13785.0, 12519.7, 11800.1, 1136\n6.2, 11094.1, 10918.7, 10803.3, 10726.3  ‚Ä¶  10561.6, 10560.6, 10559.9, 1055\n9.4, 10559.0, 10558.8, 10558.6, 10558.5, 10558.4, 10558.3]\n\nWe can now plot the free energy to see if the inference algorithm is converging.\n\nplot(results.free_energy,fontfamily = \"Computer Modern\", label=\"Free Energy\", xlabel=\"Iteration\", ylabel=\"Free Energy\", title=\"Free Energy Convergence\")\n\n(Image: )\n\nFree energy is converging to a stable value, indicating that the inference algorithm is converging. Let's visualize the posterior distribution and how it compares to the true parameters.\n\n# Create an animation showing how posterior evolves\nanim = @animate for i in 1:length(results.posteriors[:Œ≤])\n    # Get posterior at current iteration\n    m_i = mean(results.posteriors[:Œ≤][i])\n    Œ£_i = cov(results.posteriors[:Œ≤][i])\n    \n    # Calculate dynamic limits based on current mean and covariance\n    # Add some padding (3 standard deviations) to ensure true parameters are visible\n    x_std = sqrt(Œ£_i[1,1])\n    y_std = sqrt(Œ£_i[2,2])\n    \n    x_min = min(m_i[1] - 3*x_std, true_beta[1] - 0.1)\n    x_max = max(m_i[1] + 3*x_std, true_beta[1] + 0.1)\n    y_min = min(m_i[2] - 3*y_std, true_beta[2] - 0.1)\n    y_max = max(m_i[2] + 3*y_std, true_beta[2] + 0.1)\n    \n    p = plot(xlims=(x_min, x_max), ylims=(y_min, y_max),\n             fontfamily = \"Computer Modern\",\n             title=\"Iteration $i\", aspect_ratio=1)\n    \n    # Plot confidence ellipses\n    covellipse!(m_i, Œ£_i, n_std=1, label=\"1œÉ Contour\", color=:green, fillalpha=0.2)\n    covellipse!(m_i, Œ£_i, n_std=3, label=\"3œÉ Contour\", color=:blue, fillalpha=0.2)\n    \n    # Plot mean estimate and true parameters\n    scatter!([m_i[1]], [m_i[2]], label=\"Current Estimate\", color=:blue)\n    scatter!([true_beta[1]], [true_beta[2]], label=\"True Parameters\", color=:red)\nend\n\n# Save the animation as a GIF\ngif(anim, \"bayesian_regression_posterior.gif\", fps=3)\n\nPlots.AnimatedGif(\"/home/runner/work/RxInferExamples.jl/RxInferExamples.jl/\ndocs/src/categories/basic_examples/bayesian_binomial_regression/bayesian_re\ngression_posterior.gif\")\n\n(Image: )\n\nWe can perform prediction by augmenting the data with missing values. For that, we can create a new vector y_with_missing that contains missing values for the last 2000 samples.\n\ny_with_missing = Vector{Union{Missing, Int}}(missing, n_samples)\nfor i in 1:n_samples\n    if i > 8000\n        y_with_missing[i] = missing\n    else\n        y_with_missing[i] = y[i]\n    end\nend\n\nresults_with_missing = infer(\n    model = binomial_model(prior_xi = zeros(n_features), prior_precision = diageye(n_features),),\n    data = (X=X, y=y_with_missing,n_trials=n_trials),\n    iterations = 30,\n    showprogress = true,\n    options = (\n        limit_stack_depth = 100, # to prevent stack-overflow errors\n    )\n)\n\nInference results:\n  Posteriors       | available for (Œ≤)\n  Predictions      | available for (y)\n\nprobs_prediction = map(d -> d.p,results_with_missing.predictions[:y][end][8000:end])\nerr = probs_prediction .- probs[8000:end]\nmse = mean(err.^2)\nprintln(\"Mean squared error: \", mse)\n\nMean squared error: 3.541846183800687e-6\n\nfunction bin_predictions(true_probs, pred_probs; n_bins=20)\n    bins = range(0, 1, length=n_bins+1)\n    bin_means = Float64[]\n    bin_stds = Float64[]\n    bin_centers = Float64[]\n    \n    for i in 1:n_bins\n        mask = (true_probs .>= bins[i]) .& (true_probs .< bins[i+1])\n        if any(mask)\n            push!(bin_means, mean(pred_probs[mask]))\n            push!(bin_stds, std(pred_probs[mask]))\n            push!(bin_centers, (bins[i] + bins[i+1])/2)\n        end\n    end\n    return bin_centers, bin_means, bin_stds\nend\n\n# Create the plot\nbin_centers, bin_means, bin_stds = bin_predictions(probs[8000:end], probs_prediction)\n\np = plot(\n    xlabel = \"True Probability\",\n    ylabel = \"Predicted Probability\",\n    title = \"Prediction Performance\",\n    aspect_ratio = 1,\n    legend = :bottomright,\n    grid = true,\n    fontfamily = \"Computer Modern\",\n    dpi = 300\n)\n\n# Add perfect prediction line\nplot!([0, 1], [0, 1], \n    label = \"Perfect Prediction\", \n    color = :black, \n    linestyle = :dash,\n    linewidth = 2\n)\n\n# Add scatter plot with reduced opacity and size\nscatter!(\n    probs[8000:end], \n    probs_prediction,\n    label = \"Individual Predictions\",\n    alpha = 0.1,  # Reduced opacity\n    color = :blue,\n    markersize = 1,\n    markerstrokewidth = 0\n)\n\n# Add binned means with error bars\nscatter!(\n    bin_centers,\n    bin_means,\n    yerror = bin_stds,\n    label = \"Binned Mean ¬± SD\",\n    color = :red,\n    markersize = 4\n)\n\nannotate!(\n    0.05, \n    0.95, \n    text(\"MSE = $(round(mse, digits=8))\", 8, :left, :top)\n)\n\n# Customize axes\nplot!(\n    xlims = (0,1),\n    ylims = (0,1),\n    xticks = 0:0.2:1,\n    yticks = 0:0.2:1\n)\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/bayesian_binomial_regression/#References","page":"Bayesian Binomial Regression","title":"References","text":"[1] Polson, N. G., Scott, J. G., & Windle, J. (2013). Bayesian inference for logistic models using Polya-Gamma latent variables. Journal of the American Statistical Association, 108(1), 136-146.\n\n[2] Minka, T. (2001). Expectation Propagation for approximate Bayesian inference. Uncertainty in Artificial Intelligence, 2, 362-369.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [b964fa9f] LaTeXStrings v1.4.0\n  [91a5bcdd] Plots v1.41.6\n  [a194aa59] ReactiveMP v5.6.5\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [f3b207a7] StatsPlots v0.15.8\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/basic_examples/bayesian_networks/","page":"Bayesian Networks","title":"Bayesian Networks","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/basic_examples/bayesian_networks/#Bayesian-Networks:-The-Sprinkler-Model","page":"Bayesian Networks","title":"Bayesian Networks: The Sprinkler Model","text":"In this tutorial, we'll explore how to build and perform inference in Bayesian networks using RxInfer. Bayesian networks are probabilistic graphical models that represent conditional dependencies between random variables through directed acyclic graphs. We'll use the DiscreteTransition node type to encode conditional probability tables (CPTs) that define how each variable depends on its parents in the network. Through a classic sprinkler example, we'll demonstrate how to construct these networks and perform probabilistic inference to answer queries about the model.\n\nusing RxInfer, Plots, GraphViz\n\nThis example implements a classic Bayesian network known as the sprinkler model. The model represents causal relationships between:\n\nWhether it is cloudy (clouded)\nWhether it is raining (rain) \nWhether the sprinkler is on (sprinkler)\nWhether the grass is wet (wet_grass)\n\nThe relationships are:\n\nCloudy weather influences both rain and sprinkler usage\nBoth rain and sprinkler usage affect whether the grass is wet\n\nWe'll use this model to demonstrate inference under different scenarios and evidence.\n\nThe bayesian network for the sprinkler model is shown below:\n\n(Image: Sprinkler model diagram showing the relationships between clouded, rain, sprinkler and wet_grass nodes)\n\nLet's translate this into an RxInfer model. We'll start by putting a Categorial prior on the clouded variable, and we'll use DiscreteTransition nodes to encode the CPTs for the rain and sprinkler variables, which depend on the clouded variable. Denote that we denote a binary probability distribution as a vector of two probabilities, where the first probability is the probability of the event not occurring and the second probability is the probability of the event occurring.\n\n@model function sprinkler_model(wet_grass)\n    clouded ~ Categorical([0.5, 0.5]) # Probability of cloudy being false or true\n    rain ~ DiscreteTransition(clouded, [0.8 0.2; 0.2 0.8])\n    sprinkler ~ DiscreteTransition(clouded, [0.5 0.9; 0.5 0.1])\n    wet_grass ~ DiscreteTransition(sprinkler, [1.0 0.1; 0.0 0.9;;; 0.1 0.01; 0.9 0.99], rain)\nend\n\nOptionally, let's inspect the model structure that RxInfer creates using the GraphViz package:\n\nmodel_generator = sprinkler_model() | (wet_grass = [ 1.0, 0.0 ], )\nmodel_to_plot   = RxInfer.getmodel(RxInfer.create_model(model_generator))\nGraphViz.load(model_to_plot, strategy = :simple)\n\n(Image: )\n\nBecause we have a loop in the resulting factor graph, we have to initialize messages to run the loopy belief propagation algorithm. We'll initialize the messages for the sprinkler variable to be uniform. Afterwards, we can run the inference with the infer function from RxInfer. Furthermore, we can specify the number of iterations to run the loopy belief propagation algorithm, and we can query the free_energy to monitor the convergence of the algorithm.\n\ninitialization = @initialization begin\n    Œº(sprinkler) = Categorical([0.5, 0.5])\nend\n\ndata = (wet_grass = [1.0, 0.0],) # Grass is dry\n\nresult = infer(model=sprinkler_model(), data=data, iterations=10, initialization=initialization)\n\nInference results:\n  Posteriors       | available for (rain, sprinkler, clouded)\n\nNow, let's inspect the posterior probabilities for the clouded, rain, and sprinkler variables:\n\np1 = bar(last(result.posteriors[:clouded]).p,\n    xticks=(1:2, [\"Not Clouded\", \"Clouded\"]),\n    ylabel=\"Probability\",\n    title=\"Posterior Probability of Clouded Variable\",\n    titlefontsize=10,\n    legend=false)\n\np2 = bar(last(result.posteriors[:rain]).p,\n    xticks=(1:2, [\"No Rain\", \"Rain\"]),\n    ylabel=\"Probability\", \n    title=\"Posterior Probability of Rain Variable\",\n    titlefontsize=10,\n    legend=false)\n\np3 = bar(last(result.posteriors[:sprinkler]).p,\n    xticks=(1:2, [\"Off\", \"On\"]),\n    ylabel=\"Probability\",\n    title=\"Posterior Probability of Sprinkler Variable\", \n    titlefontsize=10,\n    legend=false)\n\nplot(p1, p2, p3, layout=(1,3), size=(900,300))\n\n(Image: )\n\nLooks like, when the grass is dry, it is less likely to be cloudy, less likely to rain and the sprinkler is probably off. Let's look at what happens when we observe wet grass:\n\nresult = infer(model=sprinkler_model(), data=(wet_grass=[0.0, 1.0],), iterations=10, initialization=initialization)\np1 = bar(last(result.posteriors[:clouded]).p,\n    xticks=(1:2, [\"Not Clouded\", \"Clouded\"]),\n    ylabel=\"Probability\",\n    title=\"Posterior Probability of Clouded Variable\",\n    titlefontsize=10,\n    legend=false)\n\np2 = bar(last(result.posteriors[:rain]).p,\n    xticks=(1:2, [\"No Rain\", \"Rain\"]),\n    ylabel=\"Probability\", \n    title=\"Posterior Probability of Rain Variable\",\n    titlefontsize=10,\n    legend=false)\n\np3 = bar(last(result.posteriors[:sprinkler]).p,\n    xticks=(1:2, [\"Off\", \"On\"]),\n    ylabel=\"Probability\",\n    title=\"Posterior Probability of Sprinkler Variable\", \n    titlefontsize=10,\n    legend=false)\n\nplot(p1, p2, p3, layout=(1,3), size=(900,300))\n\n(Image: )\n\nPerfect! When the grass is wet, it is more likely to be cloudy, more likely to rain and the sprinkler is more likely to be on. However, this model only allows observations on the grass being wet, and not on the sprinkler being on or off. Let's extend the model to also observe the sprinkler and rain variables:","category":"section"},{"location":"categories/basic_examples/bayesian_networks/#Extending-the-model","page":"Bayesian Networks","title":"Extending the model","text":"We will now also accept observations on the sprinkler, rain  and clouded variables, which means that we will have to add the variables to the model signature and denote how this data is generated. We know that these datapoints are the same as the hidden variables they are conditioned on, so we can use a DiscreteTransition node to encode this identity relationship between the data and the hidden variables.\n\n@model function sprinkler_model(wet_grass_data, sprinkler_data, rain_data, clouded_data)\n    clouded ~ Categorical([0.5, 0.5]) # Probability of cloudy being false or true\n    clouded_data ~ DiscreteTransition(clouded, diageye(2))  \n    rain ~ DiscreteTransition(clouded, [0.8 0.2; 0.2 0.8])\n    rain_data ~ DiscreteTransition(rain, diageye(2))\n    sprinkler ~ DiscreteTransition(clouded, [0.5 0.9; 0.5 0.1])\n    sprinkler_data ~ DiscreteTransition(sprinkler, diageye(2))\n    wet_grass ~ DiscreteTransition(sprinkler, [1.0 0.1; 0.0 0.9;;; 0.1 0.01; 0.9 0.99], rain)\n    wet_grass_data ~ DiscreteTransition(wet_grass, diageye(2))\nend\n\nNow, we can run the inference with the extended model, where we pass in the data for the observations we have, and pass missing for the observations we don't have. What happens, for example, if we observe the grass being wet and the sprinkler being on?\n\nresult = infer(model=sprinkler_model(), data=(wet_grass_data=[0.0, 1.0], sprinkler_data=[0.0, 1.0], rain_data=missing, clouded_data=missing), iterations=10, initialization=initialization)\n\nInference results:\n  Posteriors       | available for (rain, sprinkler, wet_grass, clouded)\n  Predictions      | available for (rain_data, clouded_data)\n\nPerfect! When the grass is wet and the sprinkler is on, it is less likely to rain, and therefore less likely to be cloudy. What happens to the grass when we observe rain and the sprinkler is off?\n\nresult = infer(model=sprinkler_model(), data=(wet_grass_data=missing, sprinkler_data=[1.0, 0.0], rain_data=[0.0, 1.0], clouded_data=missing), iterations=10, initialization=initialization)\n\n\np1 = bar(last(result.posteriors[:rain]).p,\n    xticks=(1:2, [\"No\", \"Yes\"]),\n    ylabel=\"Probability\", \n    title=\"Posterior Probability of Rain Variable\",\n    titlefontsize=8,\n    legend=false)\n\np2 = bar(last(result.posteriors[:clouded]).p,\n    xticks=(1:2, [\"No\", \"Yes\"]),\n    ylabel=\"Probability\",\n    title=\"Posterior Probability of Clouded Variable\",\n    titlefontsize=8,\n    legend=false)\n\np3 = bar(last(result.posteriors[:sprinkler]).p,\n    xticks=(1:2, [\"Off\", \"On\"]),\n    ylabel=\"Probability\",\n    title=\"Posterior Probability of Sprinkler Variable\", \n    titlefontsize=8,\n    legend=false)\n\np4 = bar(last(result.posteriors[:wet_grass]).p,\n    xticks=(1:2, [\"No\", \"Yes\"]),\n    ylabel=\"Probability\",\n    title=\"Posterior Probability of Wet Grass Variable\",\n    titlefontsize=8,\n    legend=false)\n\nplot(p1, p2, p3, p4, layout=(1,4), size=(1200,300))\n\n(Image: )\n\nFinally, what happens if we observe the grass being wet and the sky being blue?\n\nresult = infer(model=sprinkler_model(), data=(wet_grass_data=[0.0, 1.0], sprinkler_data=missing, rain_data=missing, clouded_data=[1.0, 0.0]), iterations=10, initialization=initialization)\n\n\np1 = bar(last(result.posteriors[:rain]).p,\n    xticks=(1:2, [\"No\", \"Yes\"]),\n    ylabel=\"Probability\", \n    title=\"Posterior Probability of Rain Variable\",\n    titlefontsize=8,\n    legend=false)\n\np2 = bar(last(result.posteriors[:clouded]).p,\n    xticks=(1:2, [\"No\", \"Yes\"]),\n    ylabel=\"Probability\",\n    title=\"Posterior Probability of Clouded Variable\",\n    titlefontsize=8,\n    legend=false)\n\np3 = bar(last(result.posteriors[:sprinkler]).p,\n    xticks=(1:2, [\"Off\", \"On\"]),\n    ylabel=\"Probability\",\n    title=\"Posterior Probability of Sprinkler Variable\", \n    titlefontsize=8,\n    legend=false)\n\np4 = bar(last(result.posteriors[:wet_grass]).p,\n    xticks=(1:2, [\"No\", \"Yes\"]),\n    ylabel=\"Probability\",\n    title=\"Posterior Probability of Wet Grass Variable\",\n    titlefontsize=8,\n    legend=false)\n\nplot(p1, p2, p3, p4, layout=(1,4), size=(1200,300))\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/bayesian_networks/#Learning-the-CPTs","page":"Bayesian Networks","title":"Learning the CPTs","text":"We can also use RxInfer to learn the CPT's when we have data available, for this, let's generate some data\n\n# Generate synthetic data from the true model\nn_samples = 10000\n\n# Initialize arrays to store the samples\nclouded_samples = zeros(Int, n_samples)\nrain_samples = zeros(Int, n_samples)\nsprinkler_samples = zeros(Int, n_samples) \nwet_grass_samples = zeros(Int, n_samples)\n\n# Sample from the model\nfor i in 1:n_samples\n    # Sample clouded (prior)\n    clouded_samples[i] = rand() < 0.5 ? 1 : 2\n    \n    # Sample rain (depends on clouded)\n    rain_prob = clouded_samples[i] == 1 ? 0.2 : 0.8\n    rain_samples[i] = rand() > rain_prob ? 1 : 2\n    \n    # Sample sprinkler (depends on clouded)\n    sprinkler_prob = clouded_samples[i] == 1 ? 0.5 : 0.1\n    sprinkler_samples[i] = rand() > sprinkler_prob ? 1 : 2\n    \n    # Sample wet grass (depends on rain and sprinkler)\n    if rain_samples[i] == 2 && sprinkler_samples[i] == 2\n        wet_prob = 0.99\n    elseif rain_samples[i] == 2\n        wet_prob = 0.9\n    elseif sprinkler_samples[i] == 2\n        wet_prob = 0.9\n    else\n        wet_prob = 0.0\n    end\n    wet_grass_samples[i] = rand() < wet_prob ? 2 : 1\nend\n# Convert to one-hot encoding\nclouded_data = [[i == s ? 1.0 : 0.0 for i in 1:2] for s in clouded_samples]\nrain_data = [[i == s ? 1.0 : 0.0 for i in 1:2] for s in rain_samples]\nsprinkler_data = [[i == s ? 1.0 : 0.0 for i in 1:2] for s in sprinkler_samples]\nwet_grass_data = [[i == s ? 1.0 : 0.0 for i in 1:2] for s in wet_grass_samples];\n\nThe model now becomes a little bit more complex, as we have to put a prior on the CPT's, and we have to materialze the model for every datapoint we have. Luckily, in RxInfer, we can make a submodel and reuse it for every datapoint. We can put a DirichletCollection prior on the CPT's, as it is the conjugate prior of the CPT's. Because we cannot do belief propagation with a DirichletCollection prior, we have to introduce variational constraints to introduce an Expectation Maximization-style schema. This can be done with the @constraints macro. Furthermore, we can use the @initialization macro to initialize the variational distributions and kickstart the inference procedure.\n\n@model function sprinkler_model(clouded_data, rain_data, sprinkler_data, wet_grass_data, cpt_cloud_rain, cpt_cloud_sprinkler, cpt_sprinkler_rain_wet_grass)\n    clouded ~ Categorical([0.5, 0.5]) # Probability of cloudy being false or true\n    clouded_data ~ DiscreteTransition(clouded, diageye(2))\n    rain ~ DiscreteTransition(clouded, cpt_cloud_rain)\n    rain_data ~ DiscreteTransition(rain, diageye(2))\n    sprinkler ~ DiscreteTransition(clouded, cpt_cloud_sprinkler)\n    sprinkler_data ~ DiscreteTransition(sprinkler, diageye(2))\n    wet_grass ~ DiscreteTransition(sprinkler, cpt_sprinkler_rain_wet_grass, rain)\n    wet_grass_data ~ DiscreteTransition(wet_grass, diageye(2))\nend\n\n@model function learn_sprinkler_model(clouded_data, rain_data, sprinkler_data, wet_grass_data)\n    cpt_cloud_rain ~ DirichletCollection(ones(2, 2))\n    cpt_cloud_sprinkler ~ DirichletCollection(ones(2, 2))\n    cpt_sprinkler_rain_wet_grass ~ DirichletCollection(ones(2, 2, 2))\n    for i in 1:length(clouded_data)\n        wet_grass_data[i] ~ sprinkler_model(clouded_data = clouded_data[i], rain_data = rain_data[i], sprinkler_data = sprinkler_data[i], cpt_cloud_rain = cpt_cloud_rain, cpt_cloud_sprinkler = cpt_cloud_sprinkler, cpt_sprinkler_rain_wet_grass = cpt_sprinkler_rain_wet_grass)\n    end\nend\n\ninitialization = @initialization begin\n    q(cpt_cloud_rain) = DirichletCollection(ones(2, 2))\n    q(cpt_cloud_sprinkler) = DirichletCollection(ones(2, 2))\n    q(cpt_sprinkler_rain_wet_grass) = DirichletCollection(ones(2, 2, 2))\n    for init in sprinkler_model\n        Œº(sprinkler) = Categorical([0.5, 0.5])\n    end\nend\n\nconstraints = @constraints begin\n    for q in sprinkler_model\n        q(cpt_cloud_rain, clouded, rain) = q(clouded,rain)q(cpt_cloud_rain)\n        q(cpt_cloud_sprinkler, clouded, sprinkler) = q(clouded,sprinkler)q(cpt_cloud_sprinkler)\n        q(cpt_sprinkler_rain_wet_grass, sprinkler, rain, wet_grass) = q(sprinkler,rain,wet_grass)q(cpt_sprinkler_rain_wet_grass)\n    end\nend\n\nresult = infer(model=learn_sprinkler_model(), \n            data=(clouded_data=clouded_data, rain_data=rain_data, sprinkler_data=sprinkler_data, wet_grass_data=wet_grass_data), \n            constraints=constraints, \n            initialization=initialization, \n            iterations=5, \n            showprogress=true,\n            options=(limit_stack_depth=500,))\n\nInference results:\n  Posteriors       | available for (cpt_cloud_sprinkler, cpt_cloud_rain, cp\nt_sprinkler_rain_wet_grass)\n\nWow! That was fast! Let's inspect the learned CPT's:\n\nusing Plots\n\n# Plot CPT for cloud -> rain\ncloud_rain = mean(last(result.posteriors[:cpt_cloud_rain]))\np1 = heatmap(cloud_rain, \n        title=\"P(Rain | Cloudy)\", \n        xlabel=\"Cloudy\", \n        ylabel=\"Rain\",\n        xticks=(1:2, [\"False\", \"True\"]),\n        yticks=(1:2, [\"False\", \"True\"]),\n        xrotation=45,\n        left_margin=10Plots.mm,\n        bottom_margin=10Plots.mm)\n\n# Plot CPT for cloud -> sprinkler\ncloud_sprinkler = mean(last(result.posteriors[:cpt_cloud_sprinkler]))\np2 = heatmap(cloud_sprinkler,\n        title=\"P(Sprinkler | Cloudy)\",\n        xlabel=\"Cloudy\",\n        ylabel=\"Sprinkler\", # Remove y-label since it's shown in p1\n        xticks=(1:2, [\"False\", \"True\"]),\n        yticks=(1:2, [\"False\", \"True\"]),\n        xrotation=45,\n        bottom_margin=10Plots.mm)\n\n# Plot CPT for sprinkler,rain -> wet grass\nsprinkler_rain_wet = mean(last(result.posteriors[:cpt_sprinkler_rain_wet_grass]))\np3 = heatmap(sprinkler_rain_wet[:,:,1],\n        title=\"P(Wet Grass=False | Sprinkler,Rain)\",\n        xlabel=\"Rain\",\n        ylabel=\"Sprinkler\", # Remove y-label since it's shown in p1\n        xticks=(1:2, [\"False\", \"True\"]),\n        yticks=(1:2, [\"False\", \"True\"]),\n        xrotation=45,\n        bottom_margin=10Plots.mm)\np4 = heatmap(sprinkler_rain_wet[:,:,2],\n        title=\"P(Wet Grass=True | Sprinkler,Rain)\", \n        xlabel=\"Rain\",\n        ylabel=\"Sprinkler\", # Remove y-label since it's shown in p1\n        xticks=(1:2, [\"False\", \"True\"]),\n        yticks=(1:2, [\"False\", \"True\"]),\n        xrotation=45,\n        bottom_margin=15Plots.mm)\n\nplot(p1, p2, p3, p4, layout=(1,4), size=(1700,305))\n\n(Image: )\n\nThis concludes our tutorial on Bayesian networks. We have seen how to build and perform inference in Bayesian networks using RxInfer. We have also seen how to learn the CPT's when we have data available. As we have seen, RxInfer is able to learn posterior distributions even when some of the data is missing, what do you think will happen if we pass missing data to our model that learns the CPT's?\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [f526b714] GraphViz v0.2.0\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n\n\n","category":"section"},{"location":"categories/basic_examples/hidden_markov_model/","page":"Hidden Markov Model","title":"Hidden Markov Model","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/basic_examples/hidden_markov_model/#How-to-train-your-Hidden-Markov-Model","page":"Hidden Markov Model","title":"How to train your Hidden Markov Model","text":"In this example, we'll be tracking a Roomba as it moves throughout a 3-bedroom apartment consisting of a bathroom, a master bedroom, and a living room. It's important to keep track of your AI's, so we want to make sure we can keep tabs on it whenever we leave the apartment. \n\nFirst, in order to track the Roomba's movements using RxInfer, we need to come up with a model. Since we have a discrete set of rooms in the apartment, we can use a categorical distribution to represent the Roomba's position. There are three  rooms in the apartment, meaning we need three states in our categorical distribution. At time t, let's call the estimate of the Roomba's position s_t.\n\nHowever, we also know that some rooms are more accessible than others, meaning the Roomba is more likely to move between these rooms - for example, it's rare to have a door directly between the bathroom and the master bedroom. We can encode this information using a transition matrix, which we will call A.\n\nOur Roomba is equipped with a small camera that tracks the surface it is moving over. We will use this camera to obtain our observations since we know that there is a carpet in the living room, tiles in the bathroom, and hardwood floors in the master bedroom. However, this method is not foolproof, and sometimes the Roomba will make mistakes and mistake the hardwood floor for tiles or the carpet for hardwood. Don't be too hard on the little guy, it's just a Roomba after all.\n\nAt time t, we will call our observations x_t and encode the mapping from the Roomba's position to the observations in a matrix we call B. B also encodes the likelihood that the Roomba will make a mistake and get the wrong observation. This leaves us with the following model specification:\n\nbeginaligned\n    s_t  sim mathcalCat(A s_t-1)\n    x_t  sim mathcalCat(B s_t)\nendaligned\n\nThis type of discrete state space model is known as a Hidden Markov Model or HMM for short. Our goal is to learn the matrices A and B so we can use them to track the whereabouts of our little cleaning agent.\n\nusing RxInfer, Random, BenchmarkTools, Distributions, LinearAlgebra, Plots\n\nIn order to generate data to mimic the observations of the Roomba, we need to specify two things: the actual transition probabilities between the states (i.e., how likely is the Roomba to move from one room to another), and the observation distribution (i.e., what type of texture will the Roomba encounter in each room). We can then use these specifications to generate observations from our hidden Markov model (HMM).\n\nTo generate our observation data, we'll follow these steps:\n\nAssume an initial state for the Roomba. For example, we can start the Roomba in the bedroom.\nDetermine where the Roomba went next by drawing from a Categorical distribution with the transition probabilities between the different rooms.\nDetermine the observation encountered in this room by drawing from a Categorical distribution with the corresponding observation probabilities.\nRepeat steps 2-3 for as many samples as we want.\n\nThe following code implements this process and generates our observation data:\n\n\"\"\"\n    rand_vec(rng, distribution::Categorical)\n\nThis function returns a one-hot encoding of a random sample from a categorical distribution. The sample is drawn with the `rng` random number generator.\n\"\"\"\nfunction rand_vec(rng, distribution::Categorical) \n    k = ncategories(distribution)\n    s = zeros(k)\n    drawn_category = rand(rng, distribution)\n    s[drawn_category] = 1.0\n    return s\nend\n\nfunction generate_data(n_samples; seed = 42)\n    \n    rng = MersenneTwister(seed)\n    \n    # Transition probabilities bed|livi|bath-room \n    state_transition_matrix = [0.9 0.05 0.0;\n                               0.1 0.9  0.1; \n                               0.0 0.05 0.9] \n    # Observation noise\n    observation_distribution_matrix = [0.9 0.05 0.05;\n                                                                         0.05 0.9 0.05;\n                                                                         0.05 0.05 0.9] \n    # Initial state\n    s_initial = [1.0, 0.0, 0.0] \n    \n    states = Vector{Vector{Float64}}(undef, n_samples) # one-hot encoding of the states\n    observations = Vector{Vector{Float64}}(undef, n_samples) # one-hot encoding of the observations\n    \n    s_prev = s_initial\n    \n    for t = 1:n_samples\n        s_probvec = state_transition_matrix * s_prev\n        states[t] = rand_vec(rng, Categorical(s_probvec ./ sum(s_probvec)))\n        obs_probvec = observation_distribution_matrix * states[t]\n        observations[t] = rand_vec(rng, Categorical(obs_probvec ./ sum(obs_probvec)))\n        s_prev = states[t]\n    end\n    \n    return observations, states\nend\n\ngenerate_data (generic function with 1 method)\n\nWe will generate 100 data points to simulate 100 ticks of the Roomba moving through the apartment. x_data will contain the Roomba's measurements of the floor it's currently on, and s_data will contain information on the room the Roomba was actually in.\n\n# Test data\nN = 100\nx_data, s_data = generate_data(N);\n\nscatter(argmax.(s_data), leg=false, xlabel=\"Time\",yticks= ([1,2,3],[\"Bedroom\",\"Living room\",\"Bathroom\"]))\n\n(Image: )\n\nNow it is time to build our model. As mentioned earlier, we will use Categorical distributions for the states and observations. To learn the A and B matrices we can use DirichletCollection priors. For the A-matrix, since we have no apriori idea how the roomba is actually going to move we will assume that it moves randomly. We can represent this by filling our DirichletCollection prior on A with ones. Remember that this will get updated once we start learning, so it's fine if our initial guess is not quite accurate. As for the observations, we have good reason to trust our Roomba's measurements. To represent this, we will add large values to the diagonal of our prior on B. However, we also acknowledge that the Roomba is not infallible, so we will add some noise on the off-diagonal entries.\n\nSince we will use Variational Inference, we also have to specify inference constraints. We will use a structured variational approximation to the true posterior distribution, where we decouple the variational posterior over the states (q(s_0, s)) from the posteriors over the transition matrices (q(A) and q(B)). This dependency decoupling in the approximate posterior distribution ensures that inference is tractable. Let's build the model!\n\n# Model specification\n@model function hidden_markov_model(x)\n    \n    A ~ DirichletCollection(ones(3,3))\n    B ~ DirichletCollection([ 10.0 1.0 1.0; \n                                            1.0 10.0 1.0; \n                                            1.0 1.0 10.0 ])\n    \n    s_0 ~ Categorical(fill(1.0 / 3.0, 3))\n    \n    s_prev = s_0\n    \n    for t in eachindex(x)\n        s[t] ~ DiscreteTransition(s_prev, A) \n        x[t] ~ DiscreteTransition(s[t], B)\n        s_prev = s[t]\n    end\n    \nend\n\n# Constraints specification\n@constraints function hidden_markov_model_constraints()\n    q(s_0, s, A, B) = q(s_0, s)q(A)q(B)\nend\n\nhidden_markov_model_constraints (generic function with 1 method)\n\nNow it's time to perform inference and find out where the Roomba went in our absence. Did it remember to clean the bathroom?\n\nWe'll be using Variational Inference to perform inference, which means we need to set some initial marginals as a starting point. RxInfer makes this easy with the vague function, which provides an uninformative guess. If you have better ideas, you can try a different initial guess and see what happens.\n\nSince we're only interested in the final result - the best guess about the Roomba's position - we'll only keep the last results. Let's start the inference process!\n\nimarginals = @initialization begin\n    q(A) = vague(DirichletCollection, (3, 3))\n    q(B) = vague(DirichletCollection, (3, 3)) \n    q(s) = vague(Categorical, 3)\nend\n\nireturnvars = (\n    A = KeepLast(),\n    B = KeepLast(),\n    s = KeepLast()\n)\n\nresult = infer(\n    model         = hidden_markov_model(), \n    data          = (x = x_data,),\n    constraints   = hidden_markov_model_constraints(),\n    initialization = imarginals, \n    returnvars    = ireturnvars, \n    iterations    = 20, \n    free_energy   = true\n);\n\nThat was fast! Let's take a look at our results. If we're successful, we should have a good idea about the actual layout of the apartment (a good posterior marginal over A) and about the uncertainty in the roombas observations (A good posterior over B). Let's see if it worked\n\nprintln(\"Posterior Marginal for A:\")\nmean(result.posteriors[:A])\n\nPosterior Marginal for A:\n3√ó3 Matrix{Float64}:\n 0.906367   0.040203   0.0744687\n 0.0703318  0.90382    0.0974548\n 0.0233017  0.0559774  0.828076\n\nprintln(\"Posterior Marginal for B:\")\nmean(result.posteriors[:B])\n\nPosterior Marginal for B:\n3√ó3 Matrix{Float64}:\n 0.891502   0.0523554  0.0347455\n 0.0429615  0.927224   0.0360346\n 0.0655369  0.0204209  0.92922\n\nFinally, we can check if we were successful in keeping tabs on our Roomba's whereabouts. We can also check if our model has converged by looking at the Free Energy. \n\np1 = scatter(argmax.(s_data), \n                        title=\"Inference results\", \n                        label = \"Real\", \n                        ms = 6, \n                        legend=:right,\n                        xlabel=\"Time\" ,\n                        yticks= ([1,2,3],[\"Bedroom\",\"Living room\",\"Bathroom\"]),\n                        size=(900,550)\n                        )\n\np1 = scatter!(p1, argmax.(ReactiveMP.probvec.(result.posteriors[:s])),\n                        label = \"Inferred\",\n                        ms = 3\n                        )\n\np2 = plot(result.free_energy, \n                    label=\"Free energy\",\n                    xlabel=\"Iteration Number\"\n                    )\n\nplot(p1, p2, layout = @layout([ a; b ]))\n\n(Image: )\n\nNeat! Now you know how to track a Roomba if you ever need to. You also learned how to fit a Hidden Markov Model using RxInfer in the process.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [31c24e10] Distributions v0.25.123\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/basic_examples/kalman_filtering_and_smoothing/","page":"Kalman Filtering And Smoothing","title":"Kalman Filtering And Smoothing","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/basic_examples/kalman_filtering_and_smoothing/#Kalman-filtering-and-smoothing","page":"Kalman Filtering And Smoothing","title":"Kalman filtering and smoothing","text":"In the following set of examples the goal is to estimate hidden states of a Dynamical process where all hidden states are Gaussians.\n\nWe start our journey with a simple multivariate Linear Gaussian State Space Model (LGSSM), which can be solved analytically.\n\nWe then solve an identification problem which does not have an analytical solution.\n\nUtimately, we show how RxInfer.jl can deal with missing observations.","category":"section"},{"location":"categories/basic_examples/kalman_filtering_and_smoothing/#Gaussian-Linear-Dynamical-System","page":"Kalman Filtering And Smoothing","title":"Gaussian Linear Dynamical System","text":"LGSSM can be described with the following equations:\n\nbeginaligned\n p(x_ix_i - 1)  = mathcalN(x_iA * x_i - 1 mathcalP)\n p(y_ix_i)  = mathcalN(y_iB * x_i mathcalQ)\nendaligned\n\nwhere x_i are hidden states, y_i are noisy observations, A, B are state transition and observational matrices, mathcalP and mathcalQ are state transition noise and observation noise covariance matrices. For a more rigorous introduction to Linear Gaussian Dynamical systems we refer to Simo Sarkka, Bayesian Filtering and Smoothing book.\n\nTo model this process in RxInfer, first, we start with importing all needed packages:\n\nusing RxInfer, BenchmarkTools, Random, LinearAlgebra, Plots\n\nNext step, is to generate some synthetic data:\n\nfunction generate_data(rng, A, B, P, Q)\n    x_prev = [ 10.0, -10.0 ]\n\n    x = Vector{Vector{Float64}}(undef, n)\n    y = Vector{Vector{Float64}}(undef, n)\n\n    for i in 1:n\n        x[i] = rand(rng, MvNormalMeanCovariance(A * x_prev, P))\n        y[i] = rand(rng, MvNormalMeanCovariance(B * x[i], Q))\n        x_prev = x[i]\n    end\n    \n    return x, y\nend\n\ngenerate_data (generic function with 1 method)\n\n# Seed for reproducibility\nseed = 1234\n\nrng = MersenneTwister(seed)\n\n# We will model 2-dimensional observations with rotation matrix `A`\n# To avoid clutter we also assume that matrices `A`, `B`, `P` and `Q`\n# are known and fixed for all time-steps\nŒ∏ = œÄ / 35\nA = [ cos(Œ∏) -sin(Œ∏); sin(Œ∏) cos(Œ∏) ]\nB = diageye(2)\nQ = 25.0 * diageye(2)\nP = diageye(2)\n\n# Number of observations\nn = 300;\n\nx, y = generate_data(rng, A, B, P, Q);\n\nLet's plot our synthetic dataset. Lines represent our hidden states we want to estimate using noisy observations, which are represented as dots.\n\npx = plot()\n\npx = plot!(px, getindex.(x, 1), label = \"Hidden Signal (dim-1)\", color = :orange)\npx = scatter!(px, getindex.(y, 1), label = false, markersize = 2, color = :orange)\npx = plot!(px, getindex.(x, 2), label = \"Hidden Signal (dim-2)\", color = :green)\npx = scatter!(px, getindex.(y, 2), label = false, markersize = 2, color = :green)\n\nplot(px)\n\n(Image: )\n\nTo create a model we use GraphPPL package and @model macro:\n\n@model function rotate_ssm(y, x0, A, B, P, Q)\n    x_prior ~ x0\n    x_prev = x_prior\n    \n    for i in 1:length(y)\n        x[i] ~ MvNormalMeanCovariance(A * x_prev, P)\n        y[i] ~ MvNormalMeanCovariance(B * x[i], Q)\n        x_prev = x[i]\n    end\n\nend\n\nTo run inference we also specify prior for out first hidden state:\n\nx0 = MvNormalMeanCovariance(zeros(2), 100.0 * diageye(2));\n\n# For large number of observations you need to use limit_stack_depth = 100 option during model creation, e.g. \n# infer(..., options = (limit_stack_depth = 500, ))`\nresult = infer(\n    model = rotate_ssm(x0=x0, A=A, B=B, P=P, Q=Q), \n    data = (y = y,),\n    free_energy = true\n);\n\nxmarginals  = result.posteriors[:x]\nlogevidence = -result.free_energy; # given the analytical solution, free energy will be equal to the negative log evidence\n\npx = plot()\n\npx = plot!(px, getindex.(x, 1), label = \"Hidden Signal (dim-1)\", color = :orange)\npx = plot!(px, getindex.(x, 2), label = \"Hidden Signal (dim-2)\", color = :green)\n\npx = plot!(px, getindex.(mean.(xmarginals), 1), ribbon = getindex.(var.(xmarginals), 1) .|> sqrt, fillalpha = 0.5, label = \"Estimated Signal (dim-1)\", color = :teal)\npx = plot!(px, getindex.(mean.(xmarginals), 2), ribbon = getindex.(var.(xmarginals), 2) .|> sqrt, fillalpha = 0.5, label = \"Estimated Signal (dim-1)\", color = :violet)\n\nplot(px)\n\n(Image: )\n\nAs we can see from our plot, estimated signal resembles closely to the real hidden states with small variance. We maybe also interested in the value for minus log evidence:\n\nlogevidence\n\n1-element Vector{Float64}:\n -1891.6471934594765","category":"section"},{"location":"categories/basic_examples/kalman_filtering_and_smoothing/#System-Identification-Problem","page":"Kalman Filtering And Smoothing","title":"System Identification Problem","text":"In this example we are going to attempt to run Bayesian inference and decouple two random-walk signals, which were combined into a single single through some deterministic function f. We do not have access to the real values of these signals, but only to their combination. First, we create the generate_data function that accepts f as an argument:\n\nusing RxInfer, Distributions, StableRNGs, Plots\n\nfunction generate_data(f, n; seed = 123, x_i_min = -20.0, w_i_min = 20.0, noise = 20.0, real_x_œÑ = 0.1, real_w_œÑ = 1.0)\n\n    rng = StableRNG(seed)\n\n    real_x = Vector{Float64}(undef, n)\n    real_w = Vector{Float64}(undef, n)\n    real_y = Vector{Float64}(undef, n)\n\n    for i in 1:n\n        real_x[i] = rand(rng, Normal(x_i_min, sqrt(1.0 / real_x_œÑ)))\n        real_w[i] = rand(rng, Normal(w_i_min, sqrt(1.0 / real_w_œÑ)))\n        real_y[i] = rand(rng, Normal(f(real_x[i], real_w[i]), sqrt(noise)))\n\n        x_i_min = real_x[i]\n        w_i_min = real_w[i]\n    end\n    \n    return real_x, real_w, real_y\nend\n\ngenerate_data (generic function with 2 methods)\n\nThe function returns the real signals real_x and  real_w for later comparison (we are not going to use them during inference) and their combined version real_y (we are going to use it as our observations during the inference). We also assume that real_y is corrupted with some measurement noise.","category":"section"},{"location":"categories/basic_examples/kalman_filtering_and_smoothing/#Combination-1:-y-x-w","page":"Kalman Filtering And Smoothing","title":"Combination 1: y = x + w","text":"In our first example, we are going to use a simple addition (+) as the function f. In general, it is impossible to decouple the signals x and w without strong priors, but we can try and see how good an inference can be. The + operation on two random variables also has a special meaning in the probabilistic inference, namely the convolution of pdf's of the two random variables, and RxInfer treats it specially with many precomputed analytical rules, which may make the inference task easier. First, let us create a test dataset:\n\nn = 250\nreal_x, real_w, real_y = generate_data(+, n);\n\npl = plot(title = \"Underlying signals\")\npl = plot!(pl, real_x, label = \"x\")\npl = plot!(pl, real_w, label = \"w\")\n\npr = plot(title = \"Combined y = x + w\")\npr = scatter!(pr, real_y, ms = 3, color = :red, label = \"y\")\n\nplot(pl, pr, size = (800, 300))\n\n(Image: )\n\nTo run inference, we need to create a probabilistic model: our beliefs about how our data could have been generated. For this we can use the @model macro from RxInfer.jl:\n\n@model function identification_problem(f, y, m_x_0, œÑ_x_0, a_x, b_x, m_w_0, œÑ_w_0, a_w, b_w, a_y, b_y)\n    \n    x0 ~ Normal(mean = m_x_0, precision = œÑ_x_0)\n    œÑ_x ~ Gamma(shape = a_x, rate = b_x)\n    w0 ~ Normal(mean = m_w_0, precision = œÑ_w_0)\n    œÑ_w ~ Gamma(shape = a_w, rate = b_w)\n    œÑ_y ~ Gamma(shape = a_y, rate = b_y)\n    \n    x_i_min = x0\n    w_i_min = w0\n\n    local x\n    local w\n    local s\n    \n    for i in 1:length(y)\n        x[i] ~ Normal(mean = x_i_min, precision = œÑ_x)\n        w[i] ~ Normal(mean = w_i_min, precision = œÑ_w)\n        s[i] := f(x[i], w[i])\n        y[i] ~ Normal(mean = s[i], precision = œÑ_y)\n        \n        x_i_min = x[i]\n        w_i_min = w[i]\n    end\n    \nend\n\nRxInfer runs Bayesian inference as a variational optimisation procedure between the real solution and its variational proxy q. In our model specification we assumed noise components to be unknown, thus, we need to enforce a structured mean-field assumption for the variational family of distributions q. This inevitably reduces the accuracy of the result, but makes the task easier and allows for fast and analytical message passing-based variational inference:\n\nconstraints = @constraints begin \n    q(x0, w0, x, w, œÑ_x, œÑ_w, œÑ_y, s) = q(x, x0, w, w0, s)q(œÑ_w)q(œÑ_x)q(œÑ_y)\nend\n\nConstraints: \n  q(x0, w0, x, w, œÑ_x, œÑ_w, œÑ_y, s) = q(x, x0, w, w0, s)q(œÑ_w)q(œÑ_x)q(œÑ_y)\n\nThe next step is to assign priors, initialise needed messages and marginals and call the inference function:\n\nm_x_0, œÑ_x_0 = -20.0, 1.0\nm_w_0, œÑ_w_0 = 20.0, 1.0\n\n# We set relatively strong priors for random walk noise components\n# and sort of vague prior for the noise of the observations\na_x, b_x = 0.01, 0.01var(real_x)\na_w, b_w = 0.01, 0.01var(real_w)\na_y, b_y = 1.0, 1.0\n\n# We set relatively strong priors for messages\nxinit = map(r -> NormalMeanPrecision(r, œÑ_x_0), reverse(range(-60, -20, length = n)))\nwinit = map(r -> NormalMeanPrecision(r, œÑ_w_0), range(20, 60, length = n))\n\n\ninit = @initialization begin\n    Œº(x) = xinit\n    Œº(w) = winit\n    q(œÑ_x) = GammaShapeRate(a_x, b_x)\n    q(œÑ_w) = GammaShapeRate(a_w, b_w)\n    q(œÑ_y) = GammaShapeRate(a_y, b_y)\nend\n\nresult = infer(\n    model = identification_problem(f=+, m_x_0=m_x_0, œÑ_x_0=œÑ_x_0, a_x=a_x, b_x=b_x, m_w_0=m_w_0, œÑ_w_0=œÑ_w_0, a_w=a_w, b_w=b_w, a_y=a_y, b_y=b_y),\n    data  = (y = real_y,), \n    options = (limit_stack_depth = 500, ), \n    constraints = constraints, \n    initialization = init,\n    iterations = 50\n)\n\nInference results:\n  Posteriors       | available for (x, w, x0, s, œÑ_x, œÑ_w, œÑ_y, w0)\n\nLet's examine our inference results:\n\nœÑ_x_marginals = result.posteriors[:œÑ_x]\nœÑ_w_marginals = result.posteriors[:œÑ_w]\nœÑ_y_marginals = result.posteriors[:œÑ_y]\n\nsmarginals = result.posteriors[:s]\nxmarginals = result.posteriors[:x]\nwmarginals = result.posteriors[:w];\n\npx1 = plot(legend = :bottomleft, title = \"Estimated hidden signals\")\npx2 = plot(legend = :bottomright, title = \"Estimated combined signals\")\n\npx1 = plot!(px1, real_x, label = \"Real hidden X\")\npx1 = plot!(px1, mean.(xmarginals[end]), ribbon = var.(xmarginals[end]), label = \"Estimated X\")\n\npx1 = plot!(px1, real_w, label = \"Real hidden W\")\npx1 = plot!(px1, mean.(wmarginals[end]), ribbon = var.(wmarginals[end]), label = \"Estimated W\")\n\npx2 = scatter!(px2, real_y, label = \"Observations\", ms = 2, alpha = 0.5, color = :red)\npx2 = plot!(px2, mean.(smarginals[end]), ribbon = std.(smarginals[end]), label = \"Combined estimated signal\", color = :green)\n\nplot(px1, px2, size = (800, 300))\n\n(Image: )\n\nThe inference results are not so bad, even though RxInfer missed the correct values of the signals between 100 and 150.","category":"section"},{"location":"categories/basic_examples/kalman_filtering_and_smoothing/#Combination-2:-y-min(x,-w)","page":"Kalman Filtering And Smoothing","title":"Combination 2: y = min(x, w)","text":"In this example we use a slightly more complex function, for which RxInfer does not have precomputed analytical message update rules. We are going to attempt to run Bayesian inference with min as a combination function. Note, however, that directly using min may cause problems for the built-in approximation methods as it has zero partial derviates with respect to all but one of the variables. We generate data with the min function directly however we model it with a somewhat smoothed version:\n\n# Smoothed version of `min` without zero-ed derivatives\nfunction smooth_min(x, y)    \n    if x < y\n        return x + 1e-4 * y\n    else\n        return y + 1e-4 * x\n    end\nend\n\nsmooth_min (generic function with 1 method)\n\nRxInfer supports arbitrary nonlinear functions, but it requires an explicit approximation method specification. That can be achieved with the built-in @meta macro:\n\nmin_meta = @meta begin \n    # In this example we are going to use a simple `Linearization` method\n    smooth_min() -> Linearization()\nend\n\nMeta: \n  smooth_min() -> ReactiveMP.Linearization()\n\nn = 200\nmin_real_x, min_real_w, min_real_y = generate_data(min, n, seed = seed, x_i_min = 0.0, w_i_min = 0.0, noise = 1.0, real_x_œÑ = 1.0, real_w_œÑ = 1.0);\n\npl = plot(title = \"Underlying signals\")\npl = plot!(pl, min_real_x, label = \"x\")\npl = plot!(pl, min_real_w, label = \"w\")\n\npr = plot(title = \"Combined y = min(x, w)\")\npr = scatter!(pr, min_real_y, ms = 3, color = :red, label = \"y\")\n\nplot(pl, pr, size = (800, 300))\n\n(Image: )\n\nmin_m_x_0, min_œÑ_x_0 = -1.0, 1.0\nmin_m_w_0, min_œÑ_w_0 = 1.0, 1.0\n\nmin_a_x, min_b_x = 1.0, 1.0\nmin_a_w, min_b_w = 1.0, 1.0\nmin_a_y, min_b_y = 1.0, 1.0\n\ninit = @initialization begin\n   Œº(x) = NormalMeanPrecision(min_m_x_0, min_œÑ_x_0) \n   Œº(w) = NormalMeanPrecision(min_m_w_0, min_œÑ_w_0)\n   q(œÑ_x) = GammaShapeRate(min_a_x, min_b_x) \n   q(œÑ_w) = GammaShapeRate(min_a_w, min_b_w)\n   q(œÑ_y) = GammaShapeRate(min_a_y, min_b_y)\nend\n\n\nmin_result = infer(\n    model = identification_problem(f=smooth_min, m_x_0=min_m_x_0, œÑ_x_0=min_œÑ_x_0, a_x=min_a_x, b_x=min_b_x, m_w_0=min_m_w_0, œÑ_w_0=min_œÑ_w_0, a_w=min_a_w, b_w=min_b_w, a_y=min_a_y, b_y=min_b_y),\n    data  = (y = min_real_y,), \n    options = (limit_stack_depth = 500, ), \n    constraints = constraints, \n    initialization = init,\n    meta = min_meta,\n    iterations = 50\n)\n\nInference results:\n  Posteriors       | available for (x, w, x0, s, œÑ_x, œÑ_w, œÑ_y, w0)\n\nmin_œÑ_x_marginals = min_result.posteriors[:œÑ_x]\nmin_œÑ_w_marginals = min_result.posteriors[:œÑ_w]\nmin_œÑ_y_marginals = min_result.posteriors[:œÑ_y]\n\nmin_smarginals = min_result.posteriors[:s]\nmin_xmarginals = min_result.posteriors[:x]\nmin_wmarginals = min_result.posteriors[:w]\n\npx1 = plot(legend = :bottomleft, title = \"Estimated hidden signals\")\npx2 = plot(legend = :bottomright, title = \"Estimated combined signals\")\n\npx1 = plot!(px1, min_real_x, label = \"Real hidden X\")\npx1 = plot!(px1, mean.(min_xmarginals[end]), ribbon = var.(min_xmarginals[end]), label = \"Estimated X\")\n\npx1 = plot!(px1, min_real_w, label = \"Real hidden W\")\npx1 = plot!(px1, mean.(min_wmarginals[end]), ribbon = var.(min_wmarginals[end]), label = \"Estimated W\")\n\npx2 = scatter!(px2, min_real_y, label = \"Observations\", ms = 2, alpha = 0.5, color = :red)\npx2 = plot!(px2, mean.(min_smarginals[end]), ribbon = std.(min_smarginals[end]), label = \"Combined estimated signal\", color = :green)\n\nplot(px1, px2, size = (800, 300))\n\n(Image: )\n\nAs we can see inference with the min function is significantly harder. Even though the combined signal has been inferred with high precision the underlying x and w signals are barely inferred. This may be expected, since the min function essentially destroy the information about one of the signals, thus, making it impossible to decouple two seemingly identical random walk signals. The only one inferred signal is the one which is lower and we have no inference information about the signal which is above. It might be possible to infer the states, however, with more informative priors and structural information about two different signals (e.g. if these are not random walks). ","category":"section"},{"location":"categories/basic_examples/kalman_filtering_and_smoothing/#Online-(filtering)-identification:-y-min(x,-w)","page":"Kalman Filtering And Smoothing","title":"Online (filtering) identification: y = min(x, w)","text":"Another way to approach to this problem is to use online (filtering) inference procedure from RxInfer, but for that we also need to modify our model specification a bit:\n\n@model function rx_identification(f, m_x_0, œÑ_x_0, m_w_0, œÑ_w_0, a_x, b_x, a_y, b_y, a_w, b_w, y)\n    x0 ~ Normal(mean = m_x_0, precision = œÑ_x_0)\n    œÑ_x ~ Gamma(shape = a_x, rate = b_x)\n    w0 ~ Normal(mean = m_w_0, precision = œÑ_w_0)\n    œÑ_w ~ Gamma(shape = a_w, rate = b_w)\n    œÑ_y ~ Gamma(shape = a_y, rate = b_y)\n    \n    x ~ Normal(mean = x0, precision = œÑ_x)\n    w ~ Normal(mean = w0, precision = œÑ_w)\n\n    s := f(x, w)\n    y ~ Normal(mean = s, precision = œÑ_y)\n    \nend\n\nWe impose structured mean-field assumption for this model as well:\n\nrx_constraints = @constraints begin \n    q(x0, x, w0, w, œÑ_x, œÑ_w, œÑ_y, s) = q(x0, x)q(w, w0)q(œÑ_w)q(œÑ_x)q(s)q(œÑ_y)\nend\n\nConstraints: \n  q(x0, x, w0, w, œÑ_x, œÑ_w, œÑ_y, s) = q(x0, x)q(w, w0)q(œÑ_w)q(œÑ_x)q(s)q(œÑ_y\n)\n\nOnline inference in the RxInfer supports the @autoupdates specification, which tells inference procedure how to update priors based on new computed posteriors:\n\nautoupdates = @autoupdates begin \n    m_x_0, œÑ_x_0 = mean_precision(q(x))\n    m_w_0, œÑ_w_0 = mean_precision(q(w))\n    a_x = shape(q(œÑ_x)) \n    b_x = rate(q(œÑ_x))\n    a_y = shape(q(œÑ_y))\n    b_y = rate(q(œÑ_y))\n    a_w = shape(q(œÑ_w)) \n    b_w = rate(q(œÑ_w))\nend\n\n@autoupdates begin\n    (m_x_0, œÑ_x_0) = mean_precision(q(x))\n    (m_w_0, œÑ_w_0) = mean_precision(q(w))\n    a_x = shape(q(œÑ_x))\n    b_x = rate(q(œÑ_x))\n    a_y = shape(q(œÑ_y))\n    b_y = rate(q(œÑ_y))\n    a_w = shape(q(œÑ_w))\n    b_w = rate(q(œÑ_w))\nend\n\nAs previously we need to define the @meta structure that specifies the approximation method for the nonlinear function smooth_min (f in the model specification):\n\nrx_meta = @meta begin \n    smooth_min() -> Linearization()\nend\n\nMeta: \n  smooth_min() -> ReactiveMP.Linearization()\n\nNext step is to generate our dataset and to run the actual inference procedure! For that we use the infer function with autoupdates keyword:\n\nn = 300\nrx_real_x, rx_real_w, rx_real_y = generate_data(min, n, seed = seed, x_i_min = 1.0, w_i_min = -1.0, noise = 1.0, real_x_œÑ = 1.0, real_w_œÑ = 1.0);\n\npl = plot(title = \"Underlying signals\")\npl = plot!(pl, rx_real_x, label = \"x\")\npl = plot!(pl, rx_real_w, label = \"w\")\n\npr = plot(title = \"Combined y = min(x, w)\")\npr = scatter!(pr, rx_real_y, ms = 3, color = :red, label = \"y\")\n\nplot(pl, pr, size = (800, 300))\n\n(Image: )\n\ninit = @initialization begin\n    q(w)= NormalMeanVariance(-2.0, 1.0) \n    q(x) = NormalMeanVariance(2.0, 1.0) \n    q(œÑ_x) = GammaShapeRate(1.0, 1.0) \n    q(œÑ_w) = GammaShapeRate(1.0, 1.0) \n    q(œÑ_y) = GammaShapeRate(1.0, 20.0)\nend\n\nengine = infer(\n    model         = rx_identification(f=smooth_min),\n    constraints   = rx_constraints,\n    data          = (y = rx_real_y,),\n    autoupdates   = autoupdates,\n    meta          = rx_meta,\n    returnvars    = (:x, :w, :œÑ_x, :œÑ_w, :œÑ_y, :s),\n    keephistory   = 1000,\n    historyvars   =  KeepLast(),\n    initialization = init,\n    iterations    = 10,\n    free_energy = true, \n    free_energy_diagnostics = nothing,\n    autostart     = true,\n)\n\nRxInferenceEngine:\n  Posteriors stream    | enabled for (w, s, œÑ_x, œÑ_w, œÑ_y, x)\n  Free Energy stream   | enabled\n  Posteriors history   | available for (x, w, x0, s, œÑ_x, œÑ_w, œÑ_y, w0)\n  Free Energy history  | available\n  Enabled events       | [  ]\n\nrx_smarginals = engine.history[:s]\nrx_xmarginals = engine.history[:x]\nrx_wmarginals = engine.history[:w];\n\npx1 = plot(legend = :bottomleft, title = \"Estimated hidden signals\")\npx2 = plot(legend = :bottomright, title = \"Estimated combined signals\")\n\npx1 = plot!(px1, rx_real_x, label = \"Real hidden X\")\npx1 = plot!(px1, mean.(rx_xmarginals), ribbon = var.(rx_xmarginals), label = \"Estimated X\")\n\npx1 = plot!(px1, rx_real_w, label = \"Real hidden W\")\npx1 = plot!(px1, mean.(rx_wmarginals), ribbon = var.(rx_wmarginals), label = \"Estimated W\")\n\npx2 = scatter!(px2, rx_real_y, label = \"Observations\", ms = 2, alpha = 0.5, color = :red)\npx2 = plot!(px2, mean.(rx_smarginals), ribbon = std.(rx_smarginals), label = \"Combined estimated signal\", color = :green)\n\nplot(px1, px2, size = (800, 300))\n\n(Image: )\n\nThe results are quite similar to the smoothing case and, as we can see, one of the random walk is again in the \"disabled\" state, does not infer anything and simply increases its variance (which is expected for the random walk).","category":"section"},{"location":"categories/basic_examples/kalman_filtering_and_smoothing/#Handling-Missing-Data","page":"Kalman Filtering And Smoothing","title":"Handling Missing Data","text":"An interesting case in filtering and smoothing problems is the processing of missing data. It can happen that sometimes your reading devices failt to acquire the data leading to missing observation.\n\nLet us assume that the following model generates the data\n\nbeginaligned\n    x_t sim mathcalNleft(x_t-1 10right) \n    y_t sim mathcalNleft(x_t P right) \nendaligned\n\nwith prior x_0 sim mathcalN(m_x_0 v_x_0). Suppose that our measurement device fails to acquire data from time to time.  In this case, instead of scalar observation haty_t in mathrmR we sometimes will catch missing observations.\n\nusing RxInfer, Plots\n\n@model function smoothing(x0, y)\n    \n    P ~ Gamma(shape = 0.001, scale = 0.001)\n    x_prior ~ Normal(mean = mean(x0), var = var(x0)) \n\n    local x\n    x_prev = x_prior\n\n    for i in 1:length(y)\n        x[i] ~ Normal(mean = x_prev, precision = 1.0)\n        y[i] ~ Normal(mean = x[i], precision = P)\n        \n        x_prev = x[i]\n    end\n\nend\n\nP = 1.0\nn = 250\n\nreal_signal     = map(e -> sin(0.05 * e), collect(1:n))\nnoisy_data      = real_signal + rand(Normal(0.0, sqrt(P)), n);\nmissing_indices = 100:125\nmissing_data    = similar(noisy_data, Union{Float64, Missing}, )\n\ncopyto!(missing_data, noisy_data)\n\nfor index in missing_indices\n    missing_data[index] = missing\nend\n\nconstraints = @constraints begin\n    q(x_prior, x, y, P) = q(x_prior, x)q(P)q(y)\nend\n\nConstraints: \n  q(x_prior, x, y, P) = q(x_prior, x)q(P)q(y)\n\nx0_prior = NormalMeanVariance(0.0, 1000.0)\ninitm = @initialization begin\n    q(P) = Gamma(0.001, 0.001)\nend\n\nresult = infer(\n    model = smoothing(x0=x0_prior), \n    data  = (y = missing_data,), \n    constraints = constraints,\n    initialization = initm, \n    returnvars = (x = KeepLast(),),\n    iterations = 20\n);\n\nplot(real_signal, label = \"Noisy signal\", legend = :bottomright)\nscatter!(missing_indices, real_signal[missing_indices], ms = 2, opacity = 0.75, label = \"Missing region\")\nplot!(mean.(result.posteriors[:x]), ribbon = var.(result.posteriors[:x]), label = \"Estimated hidden state\")\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [6e4b80f9] BenchmarkTools v1.6.3\n  [31c24e10] Distributions v0.25.123\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/advanced_examples/parameter_optimisation_with_optim.jl/","page":"Parameter Optimisation With Optim.Jl","title":"Parameter Optimisation With Optim.Jl","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/parameter_optimisation_with_optim.jl/#Parameter-Optimisation-with-Optim.jl","page":"Parameter Optimisation With Optim.Jl","title":"Parameter Optimisation with Optim.jl","text":"Welcome to this hands-on tutorial where we'll explore how to optimize parameters in state space models using Julia's powerful optimization ecosystem. We'll combine the probabilistic inference capabilities of RxInfer.jl with optimization tools from Optim.jl.\n\nWhat you'll learn:\n\nHow to set up parameter optimization in state space models\nPractical techniques for both univariate and multivariate cases\nIntegration with Julia's optimization packages\nReal-world applications and best practices\n\nusing RxInfer, StableRNGs, LinearAlgebra, Plots","category":"section"},{"location":"categories/advanced_examples/parameter_optimisation_with_optim.jl/#Univariate-State-Space-Model","page":"Parameter Optimisation With Optim.Jl","title":"Univariate State Space Model","text":"Let's start with a simple but powerful example: a linear state space model with Gaussian observations. This model is foundational in many real-world applications, from tracking to financial forecasting.\n\nOur model is defined as:\n\nbeginaligned\n    x_t = x_t-1 + c \n    y_t sim mathcalNleft(x_t v right) \nendaligned\n\nwith prior x_0 sim mathcalN(m_x_0 v_x_0)\n\nKey Challenge: We'll optimize two parameters:\n\nThe drift parameter c\nThe initial state mean m_x_0\n\nAssumptions: We assume the following:\n\nThe drift parameter c stays constant\nThe observation noice v is known\n\nLet's create a state space model using RxInfer's @model macro. Our model has:\n\nA prior state x1 following a Normal distribution\nA state transition equation: x[i] := x[i - 1] + c where c is our drift parameter\nObservations y[i] following a Normal distribution with mean x[i] and variance v\n\nThe model iteratively updates the state and generates observations, maintaining the Markovian property where each state depends only on the previous state.\n\n@model function univariate_state_space_model(y, x_prior, c, v)\n    \n    x0 ~ Normal(mean = mean(x_prior), variance = var(x_prior))\n    x_prev = x0\n\n    for i in eachindex(y)\n        x[i] := x_prev + c\n        y[i] ~ Normal(mean = x[i], variance = v)\n        x_prev = x[i]\n    end\nend\n\nLet's generate some synthetic data to test our model. We'll create a sequence of observations that follow our state space model assumptions. We'll set the true drift parameter c_real to -5.0 and generate 250 data points with Gaussian noise. This synthetic data will help us validate whether our optimization procedure can recover the true parameter values.\n\nrng    = StableRNG(42)\nv      = 1.0\nn      = 250\nc_real = -5.0\nsignal = c_real .+ collect(1:n)\ndata   = map(x -> rand(rng, NormalMeanVariance(x, v)), signal);\n\nNow we'll define a function for optimization that takes a vector of parameters as input. The first element params[1] represents our drift parameter c, while params[2] represents the initial state mean Œº1. The function creates a prior distribution for the initial state x1 with the given mean and a large variance of 100.0. It then performs inference using our state space model and returns the negative free energy, which we'll minimize to find optimal parameter values. The optimization will help us recover the true parameter values from our synthetic data.\n\n# params[1] is C\n# params[2] is Œº1\nfunction f(params)\n    x_prior = NormalMeanVariance(params[2], 100.0)\n    result = infer(\n        model = univariate_state_space_model(\n            x_prior = x_prior, \n            c       = params[1], \n            v       = v\n        ), \n        data  = (y = data,), \n        free_energy = true\n    )\n    return result.free_energy[end]\nend\n\nf (generic function with 1 method)\n\nNow we'll use Optim.jl, a powerful optimization package in Julia, to find the optimal parameter values. Optim.jl provides various optimization algorithms including gradient descent, L-BFGS, and Nelder-Mead. It offers a unified interface for both gradient-based and gradient-free optimization methods, making it flexible for different types of problems. The package also provides useful features like convergence monitoring and iteration control.\n\nusing Optim\n\nNow that we have defined our objective function and imported the optimization package, we are ready to find the optimal parameter values. We will start with an initial guess of [1.0, 1.0] for our parameters (c and Œº1) and use gradient descent optimization. We'll set some optimization options including a gradient tolerance of 1e-3, maximum 100 iterations, and enable trace storage and display for monitoring convergence.\n\nres = optimize(f, ones(2), GradientDescent(), Optim.Options(g_tol = 1e-3, iterations = 100, store_trace = true, show_trace = true, show_every = 10))\n\nIter     Function value   Gradient norm \n     0     3.601256e+02     1.261348e+03\n * time: 0.04113292694091797\n    10     3.593376e+02     1.355626e+01\n * time: 20.14327883720398\n * Status: success\n\n * Candidate solution\n    Final objective value:     3.593375e+02\n\n * Found with\n    Algorithm:     Gradient Descent\n\n * Convergence measures\n    |x - x'|               = 1.04e-05 ‚â∞ 0.0e+00\n    |x - x'|/|x'|          = 2.14e-06 ‚â∞ 0.0e+00\n    |f(x) - f(x')|         = 7.06e-05 ‚â∞ 0.0e+00\n    |f(x) - f(x')|/|f(x')| = 1.96e-07 ‚â∞ 0.0e+00\n    |g(x)|                 = 9.55e-04 ‚â§ 1.0e-03\n\n * Work counters\n    Seconds run:   21  (vs limit Inf)\n    Iterations:    11\n    f(x) calls:    83\n    ‚àáf(x) calls:   83\n\nLet's analyze the optimization results. The algorithm successfully converged, as indicated by the status message. In the next cell, we'll compare the optimized parameter values with the true values used to generate our synthetic data to verify the accuracy of our parameter recovery.\n\nprintln(\"Real value vs Optimized\")\nprintln(\"Real:      \", [ 1.0, c_real ])\nprintln(\"Optimized: \", res.minimizer)\n\nReal value vs Optimized\nReal:      [1.0, -5.0]\nOptimized: [0.9990370328385715, -4.8593306526902476]\n\nThe optimization results show that we successfully recovered the true parameter values. The optimized values are very close to the real values, demonstrating that our inference approach effectively identified the underlying model parameters.","category":"section"},{"location":"categories/advanced_examples/parameter_optimisation_with_optim.jl/#Multivariate-State-Space-Model","page":"Parameter Optimisation With Optim.Jl","title":"Multivariate State Space Model","text":"Now let's tackle a more challenging scenario with multiple interacting variables. Multivariate models are essential for capturing complex dynamics in real-world systems, from robotics to econometrics.\n\nKey differences from the univariate case:\n\nHigher-dimensional state space\nMore complex parameter interactions  \nRicher dynamics and correlations\n\nWe'll see how our optimization approach scales to this more complex setting while maintaining computational efficiency.\n\nLet us consider the multivariate state space model:\n\nbeginaligned\n    mathbfx_t sim mathcalNleft(mathbfAx_t-1 mathbfQ right) \n    mathbfy_t sim mathcalNleft(mathbfx_t mathbfP right) \nendaligned\n\nwith prior \n\nbeginaligned\nmathbfx_0 sim mathcalN(mathbfm_x_0 mathbfV_x_0)\nendaligned\n\nand transition matrix \n\nbeginaligned\nmathbfA = beginbmatrix costheta  -sintheta  sintheta  costheta endbmatrix\nendaligned\n\nCovariance matrices mathbfV_x_0, mathbfP and mathbfQ are known. Our goal is to optimize parameters mathbfm_x_0 and theta.\n\n@model function multivariate_state_space_model(y, Œ∏, x0, Q, P)\n    \n    x_prior ~ MvNormal(mean = mean(x0), cov = cov(x0))\n    x_prev = x_prior\n    \n    A = [ cos(Œ∏) -sin(Œ∏); sin(Œ∏) cos(Œ∏) ]\n    \n    for i in eachindex(y)\n        x[i] ~ MvNormal(mean = A * x_prev, covariance = Q)\n        y[i] ~ MvNormal(mean = x[i], covariance = P)\n        x_prev = x[i]\n    end\n    \nend\n\nLet's generate synthetic data from our model to test the optimization. We'll create a helper function that generates data from a rotating state space model with known parameters. The data will consist of 300 timesteps, with a rotation angle of œÄ/8, and unit variance Gaussian noise in both the state and observation equations. The initial state is set to [10.0, -10.0]. This will give us ground truth data to validate our parameter estimation approach.\n\n# Generate data\nfunction generate_rotate_ssm_data()\n    rng = StableRNG(1234)\n\n    Œ∏ = œÄ / 8\n    A = [ cos(Œ∏) -sin(Œ∏); sin(Œ∏) cos(Œ∏) ]\n    Q = Matrix(Diagonal(1.0 * ones(2)))\n    P = Matrix(Diagonal(1.0 * ones(2)))\n\n    n = 300\n\n    x_prev = [ 10.0, -10.0 ]\n\n    x = Vector{Vector{Float64}}(undef, n)\n    y = Vector{Vector{Float64}}(undef, n)\n\n    for i in 1:n\n        \n        x[i] = rand(rng, MvNormal(A * x_prev, Q))\n        y[i] = rand(rng, MvNormal(x[i], Q))\n        \n        x_prev = x[i]\n    end\n\n    return Œ∏, A, Q, P, n, x, y\nend\n\ngenerate_rotate_ssm_data (generic function with 1 method)\n\nŒ∏, A, Q, P, n, x, y = generate_rotate_ssm_data();\n\nNow we'll visualize the generated data by plotting both dimensions of the state variables over time. The plot will show the true state trajectories with uncertainty bands representing one standard deviation of the state noise. This will help us verify that our data generation process is working correctly and give us a visual reference for evaluating our parameter estimation results later. The ribbon plots show how the state variables evolve with their associated uncertainty, with different colors distinguishing between the two dimensions.\n\npx = plot()\n\npx = plot!(px, getindex.(x, 1), ribbon = diag(Q)[1] .|> sqrt, fillalpha = 0.2, label = \"real‚ÇÅ\")\npx = plot!(px, getindex.(x, 2), ribbon = diag(Q)[2] .|> sqrt, fillalpha = 0.2, label = \"real‚ÇÇ\")\n\nplot(px, size = (1200, 450))\n\n(Image: )\n\nNow we'll define an objective function that takes a parameter vector params containing the rotation angle and initial state coordinates. This function will construct a model with these parameters and compute its free energy using the infer function. The free energy serves as our optimization objective - by minimizing it, we aim to find the parameter values that best explain our observed data. The parameter vector params has three components: params[1] is the rotation angle, while params[2] and params[3] represent the initial x and y coordinates respectively.\n\nfunction f(params)\n    x0 = MvNormalMeanCovariance(\n        [ params[2], params[3] ], \n        Matrix(Diagonal(0.01 * ones(2)))\n    )\n    result = infer(\n        model = multivariate_state_space_model(\n            Œ∏ = params[1], \n            x0 = x0, \n            Q = Q, \n            P = P\n        ), \n        data  = (y = y,), \n        free_energy = true\n    )\n    return result.free_energy[end]\nend\n\nf (generic function with 1 method)\n\nNow we'll use the L-BFGS optimization algorithm to find the optimal parameters that minimize our objective function. The L-BFGS algorithm is particularly well-suited for this task as it approximates the Hessian matrix while using limited memory, making it efficient for problems with many parameters. We'll start with an initial guess of zeros for all parameters and set some convergence tolerances for the optimization process.\n\nres = optimize(f, zeros(3), LBFGS(), Optim.Options(f_tol = 1e-14, g_tol = 1e-12, show_trace = true, show_every = 10))\n\nIter     Function value   Gradient norm \n     0     3.781355e+03     1.134440e+04\n * time: 8.296966552734375e-5\n * Status: success\n\n * Candidate solution\n    Final objective value:     1.151827e+03\n\n * Found with\n    Algorithm:     L-BFGS\n\n * Convergence measures\n    |x - x'|               = 1.39e-11 ‚â∞ 0.0e+00\n    |x - x'|/|x'|          = 1.27e-15 ‚â∞ 0.0e+00\n    |f(x) - f(x')|         = 9.09e-13 ‚â∞ 0.0e+00\n    |f(x) - f(x')|/|f(x')| = 7.90e-16 ‚â§ 1.0e-14\n    |g(x)|                 = 6.86e-08 ‚â∞ 1.0e-12\n\n * Work counters\n    Seconds run:   62  (vs limit Inf)\n    Iterations:    9\n    f(x) calls:    81\n    ‚àáf(x) calls:   81\n\nLet's compare the real parameter values with the optimized ones. We'll look at both the raw angle values as well as their sine and cosine transformations to verify that our optimization has found the correct rotation parameters.\n\nprintln(\"Real value vs Optimized\")\nprintln(\"sinŒ∏ = (\", sin(Œ∏), \", \", sin(res.minimizer[1]), \")\")\nprintln(\"cosŒ∏ = (\", cos(Œ∏), \", \", cos(res.minimizer[1]), \")\")\n\nReal value vs Optimized\nsinŒ∏ = (0.3826834323650898, 0.38116735460454493)\ncosŒ∏ = (0.9238795325112867, 0.9245060561098414)\n\nFinally, let's visualize how well our optimized model fits the data. We'll create a plot comparing the true state trajectories with the inferred ones, including uncertainty bands. The plot will show both dimensions of the state vector over time, with the real values and their uncertainties shown alongside the inferred values and their corresponding uncertainties.\n\nx0 = MvNormalMeanCovariance([ res.minimizer[2], res.minimizer[3] ], Matrix(Diagonal(100.0 * ones(2))))\n\nresult = infer(\n    model = multivariate_state_space_model(\n        Œ∏ = res.minimizer[1], \n        x0 = x0, \n        Q = Q, \n        P = P\n    ), \n    data  = (y = y,), \n    free_energy = true\n)\n\nxmarginals = result.posteriors[:x]\n\npx = plot()\n\npx = plot!(px, getindex.(x, 1), ribbon = diag(Q)[1] .|> sqrt, fillalpha = 0.2, label = \"real‚ÇÅ\")\npx = plot!(px, getindex.(x, 2), ribbon = diag(Q)[2] .|> sqrt, fillalpha = 0.2, label = \"real‚ÇÇ\")\npx = plot!(px, getindex.(mean.(xmarginals), 1), ribbon = getindex.(var.(xmarginals), 1) .|> sqrt, fillalpha = 0.5, label = \"inf‚ÇÅ\")\npx = plot!(px, getindex.(mean.(xmarginals), 2), ribbon = getindex.(var.(xmarginals), 2) .|> sqrt, fillalpha = 0.5, label = \"inf‚ÇÇ\")\n\nplot(px, size = (1200, 450))\n\n(Image: )\n\nThis example demonstrates how we can use Optim.jl in conjunction with RxInfer.jl to perform parameter optimization for state-space models. We've shown:\n\nHow to set up a rotating state-space model with unknown parameters\nHow to define an objective function using free energy\nHow to use different optimization algorithms (Gradient Descent and L-BFGS) \nHow to visualize and validate the results\n\nThe final plot shows that our optimized model successfully captures the dynamics of the true system, with the inferred trajectories closely matching the real ones within their uncertainty bounds. This confirms that our parameter optimization approach effectively recovered the underlying rotation parameter and initial state values.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n‚åÖ [429524aa] Optim v1.13.3\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [37e2e46d] LinearAlgebra v1.12.0\nInfo Packages marked with ‚åÖ have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated`\n\n\n","category":"section"},{"location":"how_build_works/#How-the-Build-System-Works","page":"How we build the examples","title":"How the Build System Works","text":"This document explains the build system for RxInfer.jl Examples. The build process involves two main scripts: examples/make.jl and docs/make.jl, each serving a different purpose.\n\ntip: Quick Help\nRun make help to see all available build commands and their descriptions:make help","category":"section"},{"location":"how_build_works/#Development-Options","page":"How we build the examples","title":"Development Options","text":"The build system supports using either the released version of RxInfer.jl or a local development version:\n\n# Build with released version (default)\nmake examples\n\n# Build with local development version (expects RxInfer.jl next to RxInferExamples.jl)\nmake examples-dev\n\n# Build with specific RxInfer.jl path\nmake examples-dev RXINFER=/path/to/RxInfer.jl\n\n# Build single example with development version\nmake example-dev FILTER=LinearRegression RXINFER=/path/to/RxInfer.jl\n\nWhen using the development version (--use-dev), the build system will:\n\nLook for RxInfer.jl in the specified location\nAdd it as a development dependency to each notebook's environment\nEnsure all notebooks use the same RxInfer version","category":"section"},{"location":"how_build_works/#Overview","page":"How we build the examples","title":"Overview","text":"The build process happens in two stages:\n\nConverting notebooks to markdown (examples/make.jl)\nBuilding the documentation (docs/make.jl)","category":"section"},{"location":"how_build_works/#Stage-1:-Notebook-Processing-(examples/make.jl)","page":"How we build the examples","title":"Stage 1: Notebook Processing (examples/make.jl)","text":"This script handles the conversion of Jupyter notebooks to markdown files. At the beginning of the execution the script scans the examples and their  respective Project.toml files and records all the depencies of all the examples  in one big temporary environment. This environment that is being used to run  each individual example. This have several consequences that is good to be aware of:\n\nRunning examples in bulk always resolves to the same versions of packages for ALL examples\nRunning examples in bulk reuses cached and compiled code across all dependencies, that speeds up the build process\nRunning examples individually and in bulk can resolve to difference versions of packages, in case of some conflicts, Julia usually decides to use the older version of the respective packages. That means that running examples via Jupyter notebook may use different versions since Jupyter notebook resolves the dependencies locally.\n\nOptionally, it is possible to start the build process with the development version of RxInfer.jl. Look at make help or script arguments to understand how to enable this option.\n\nAfter creation of the big temporary environment (temporary because it will be deleted as soon as the build process finishes) the script  proceeds with building each individual notebook. The notebook processing system:\n\nConverts .ipynb files to .md using Weave.jl\nUses separate julia processes for each individual notebook\nUses the shared big temporary environment\nGenerates figures in the same directory as the notebook\nFixes absolute paths to use relative paths\nAdds contribution notes automatically\n\nwarning: Self-Contained Examples\nExamples must be self-contained and cannot use include() statements. All code must be directly in the notebook cells to ensure:Examples are reproducible by copying and pasting\nThe build system can properly process all code\nDocumentation remains consistent across different environments\n\nFor auxiliary file handling, the system copies all supporting files like data files while excluding Manifest.toml files. The original directory structure is maintained throughout this process.\n\nThe error handling system checks for error blocks in the output, reports any failed conversions, and provides detailed context when errors occur to help with debugging.","category":"section"},{"location":"how_build_works/#Parallel-Processing","page":"How we build the examples","title":"Parallel Processing","text":"The build system leverages Julia's distributed computing capabilities to process multiple notebooks simultaneously. It distributes the workload across available CPU cores. After processing completes, it generates a detailed report showing how many notebooks were processed successfully and which ones failed, if any.","category":"section"},{"location":"how_build_works/#Stage-2:-Documentation-Building-(docs/make.jl)","page":"How we build the examples","title":"Stage 2: Documentation Building (docs/make.jl)","text":"This script builds the final documentation and performs several key functions:\n\nFirst, it collects metadata from all examples by reading their meta.jl files. This includes gathering titles, descriptions, and tags for each example, and organizing them into appropriate categories.\n\nNext, it generates the pages needed for the documentation site. This involves creating a comprehensive list of all examples, setting up the navigation structure between pages, and applying consistent HTML styling to the examples list.\n\nFinally, it handles the actual documentation building process using Documenter.jl. This includes deploying the built documentation to GitHub Pages and ensuring clean builds by removing old artifacts when needed.\n\n","category":"section"},{"location":"categories/basic_examples/incomplete_data/","page":"Incomplete Data","title":"Incomplete Data","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/basic_examples/incomplete_data/#Icomplete-Data","page":"Incomplete Data","title":"Icomplete Data","text":"This tutorial demonstrates how to handle incomplete observations (missing data) using RxInfer.jl. Missing data is a common challenge in real-world applications. Traditional approaches often involve imputation or deletion of incomplete observations, which can lead to biased results. Bayesian inference provides a principled way to handle missing data by treating missing values as latent variables and marginalizing over them.","category":"section"},{"location":"categories/basic_examples/incomplete_data/#Problem-Setup","page":"Incomplete Data","title":"Problem Setup","text":"We'll work with a hierarchical multivariate Gaussian model:\n\nPrecision matrix Œõ follows a Wishart distribution (conjugate prior for precision)\nMean vector m follows a multivariate normal distribution  \nLatent states x[i] are drawn from MvNormal(m, Œõ‚Åª¬π)\nObservations y[i,j] are linked to latent states, but some may be missing","category":"section"},{"location":"categories/basic_examples/incomplete_data/#Model-Definition","page":"Incomplete Data","title":"Model Definition","text":"using RxInfer, LinearAlgebra\n\n@model function incomplete_data(y, dim)\n    Œõ ~ Wishart(dim, diagm(ones(dim)))\n    m ~ MvNormal(mean=zeros(dim), precision=diagm(ones(dim)))\n    for i in 1:size(y, 1)\n        x[i] ~ MvNormal(mean=m, precision=Œõ)\n        for j in 1:dim\n            y[i, j] ~ softdot(x[i], StandardBasisVector(dim, j), huge)\n        end\n    end\nend\n\nThe softdot with StandardBasisVector effectively extracts the j-th component of x[i], creating the relationship y[i,j] = x[i][j].","category":"section"},{"location":"categories/basic_examples/incomplete_data/#Data-Generation","page":"Incomplete Data","title":"Data Generation","text":"Let's generate synthetic data with known ground truth parameters:\n\nn_samples = 100\n\nreal_m = [13.0, 1.0, 5.0, 4.0, -20.0, 10.0]\ndimension = length(real_m)\nreal_Œõ = diagm(ones(dimension))\n\nreal_x = [rand(MvNormal(real_m, inv(real_Œõ))) for _ in 1:n_samples]\nincomplete_x = Vector{Vector{Union{Float64, Missing}}}(copy(real_x))\n\nfor i in 1:n_samples\n    incomplete_x[i][rand(1:dimension)] = missing\nend\n\n# Create a matrix instead of vector of vectors\nobservations = Matrix{Union{Float64, Missing}}(undef, n_samples, dimension)\n\nfor i in 1:n_samples\n    for j in 1:dimension\n        observations[i, j] = incomplete_x[i][j]\n    end\nend\n\nKey insight: Each sample has exactly one missing element, chosen randomly. This creates a challenging scenario where every observation is incomplete, but different dimensions are missing across samples.","category":"section"},{"location":"categories/basic_examples/incomplete_data/#Inference-Configuration","page":"Incomplete Data","title":"Inference Configuration","text":"# We assume independence between the precision matrix and other variables.\nconstraints = @constraints begin\n    q(x, m, Œõ) = q(x, m)q(Œõ) \nend\n\n# We need to initialize the precision matrix.\ninit = @initialization begin\n    q(Œõ) = Wishart(dimension, diagm(ones(dimension)))\nend\n\nresult = infer(model=incomplete_data(dim=dimension), data=(y=observations,), constraints=constraints, initialization=init, showprogress=true, iterations=100);","category":"section"},{"location":"categories/basic_examples/incomplete_data/#Results-Analysis","page":"Incomplete Data","title":"Results Analysis","text":"","category":"section"},{"location":"categories/basic_examples/incomplete_data/#Recovered-Parameters","page":"Incomplete Data","title":"Recovered Parameters","text":"# Extract final posterior estimates\nestimated_covariance = inv(mean(result.posteriors[:Œõ][end]))\nestimated_mean = mean(result.posteriors[:m][end])\n\nprintln(\"True mean: \", real_m[1:dimension])  # Show first 5 elements\nprintln(\"Estimated mean: \", estimated_mean[1:dimension])\nprintln()\nprintln(\"True covariance (diagonal): \", diag(inv(real_Œõ))[1:dimension])\nprintln(\"Estimated covariance (diagonal): \", diag(estimated_covariance)[1:dimension])\n\nTrue mean: [13.0, 1.0, 5.0, 4.0, -20.0, 10.0]\nEstimated mean: [1208.4559511207249, 5879.833837833012, 2634.3339790268733,\n 957.8529375130133, -2937.1579042092226, 3802.047742519438]\n\nTrue covariance (diagonal): [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\nEstimated covariance (diagonal): [3.3016097350405186e8, 3.1322201846561126e\n7, 1.2436226226570255e8, 7.815846098669721e8, 7.470671346997115e7, 3.013846\n86619344e7]","category":"section"},{"location":"categories/basic_examples/incomplete_data/#Convergence-Analysis","page":"Incomplete Data","title":"Convergence Analysis","text":"The algorithm successfully recovers both the mean vector and covariance structure despite having incomplete observations. The Bayesian framework naturally handles the uncertainty introduced by missing data.","category":"section"},{"location":"categories/basic_examples/incomplete_data/#Key-Takeaways","page":"Incomplete Data","title":"Key Takeaways","text":"Missing data as latent variables: RxInfer treats missing observations as latent variables, avoiding the need for explicit imputation.\nPrincipled uncertainty quantification: The posterior distributions capture both parameter uncertainty and uncertainty due to missing data.\nComputational efficiency: The mean-field approximation and message-passing algorithms scale well to high-dimensional problems.\nRobustness: The method works even when every observation has missing elements, as long as there's sufficient information across the dataset.\n\n# Simple plotting code for the RxInfer incomplete data tutorial\nusing Plots, Distributions\n\nfunction plot_posterior_distributions(result, real_m, real_Œõ, max_dim=3)\n    # Get final posteriors\n    final_m_posterior = result.posteriors[:m][end]\n    final_Œõ_posterior = result.posteriors[:Œõ][end]\n    \n    # Plot mean posterior for first few dimensions\n    p1 = plot(title=\"Posterior Distribution of Mean (first $max_dim dimensions)\", \n              xlabel=\"Value\", ylabel=\"Density\")\n    \n    for i in 1:max_dim\n        # Extract marginal distribution for dimension i\n        marginal_mean = mean(final_m_posterior)[i]\n        marginal_var = inv(mean(final_Œõ_posterior))[i,i]\n        \n        # Plot the Gaussian\n        x_range = range(marginal_mean - 3*sqrt(marginal_var), \n                       marginal_mean + 3*sqrt(marginal_var), length=100)\n        gaussian = Normal(marginal_mean, sqrt(marginal_var))\n        plot!(p1, x_range, pdf.(gaussian, x_range), \n              label=\"Dimension $i\", linewidth=2, color=i)\n        \n        # Add vertical line for true value with same color\n        vline!(p1, [real_m[i]], color=i, linestyle=:dash, alpha=0.7, \n               linewidth=2, label=\"\")\n    end\n    \n    plot(p1)\nend\n\nplot_posterior_distributions (generic function with 2 methods)\n\nplot_posterior_distributions(result, real_m, real_Œõ, 6)\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [31c24e10] Distributions v0.25.123\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [37e2e46d] LinearAlgebra v1.12.0\n\n\n","category":"section"},{"location":"categories/basic_examples/coin_toss_model/","page":"Coin Toss Model","title":"Coin Toss Model","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/basic_examples/coin_toss_model/#Coin-toss-model-(Beta-Bernoulli)","page":"Coin Toss Model","title":"Coin toss model (Beta-Bernoulli)","text":"In this example, we are going to perform an exact inference for a coin-toss model that can be represented as:\n\nbeginaligned\np(theta) = mathrmBeta(thetaa b)\np(y_itheta) = mathrmBernoulli(y_itheta)\nendaligned\n\nwhere y_i in 0 1 is a binary observation induced by Bernoulli likelihood while theta is a Beta prior distribution on the parameter of Bernoulli. We are interested in inferring the posterior distribution of theta.\n\nWe start with importing all needed packages:\n\nusing RxInfer, Random\n\nLet's generate some synthetic observations using Bernoulli distribution for a biased coin-tosses that are independent and identically distributed (IID).\n\nrng = MersenneTwister(42)\nn = 500\nŒ∏_real = 0.75\ndistribution = Bernoulli(Œ∏_real)\n\ndataset = float.(rand(rng, Bernoulli(Œ∏_real), n));\n\nOnce we generate the dataset, now we define a coin-toss model using the @model macro from RxInfer.jl\n\n# GraphPPL.jl export `@model` macro for model specification\n# It accepts a regular Julia function and builds a factor graph under the hood\n@model function coin_model(y, a, b)\n\n    # We endow Œ∏ parameter of our model with \"a\" prior\n    Œ∏ ~ Beta(a, b)\n    # note that, in this particular case, the `Uniform(0.0, 1.0)` prior will also work.\n    # Œ∏ ~ Uniform(0.0, 1.0)\n\n    # here, the outcome of each coin toss is governed by the Bernoulli distribution\n    for i in eachindex(y)\n        y[i] ~ Bernoulli(Œ∏)\n    end\n\nend\n\nNow, once the model is defined, we perform a (perfect) inference:\n\nresult = infer(\n    model = coin_model(a = 4.0, b = 8.0), \n    data  = (y = dataset,)\n)\n\nInference results:\n  Posteriors       | available for (Œ∏)\n\nOnce the result is calculated, we can focus on the posteriors\n\nŒ∏estimated = result.posteriors[:Œ∏]\n\nDistributions.Beta{Float64}(Œ±=377.0, Œ≤=135.0)\n\nand visualisation of the results\n\nusing Plots\n\nrŒ∏ = range(0, 1, length = 1000)\n\np = plot(title = \"Inference results\")\n\nplot!(rŒ∏, (x) -> pdf(Beta(4.0, 8.0), x), fillalpha=0.3, fillrange = 0, label=\"P(Œ∏)\", c=1,)\nplot!(rŒ∏, (x) -> pdf(Œ∏estimated, x), fillalpha=0.3, fillrange = 0, label=\"P(Œ∏|y)\", c=3)\nvline!([Œ∏_real], label=\"Real Œ∏\")\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/advanced_examples/integrating_neural_networks_with_flux.jl/","page":"Integrating Neural Networks With Flux.Jl","title":"Integrating Neural Networks With Flux.Jl","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/integrating_neural_networks_with_flux.jl/#Integrating-Neural-Networks-with-Flux.jl","page":"Integrating Neural Networks With Flux.Jl","title":"Integrating Neural Networks with Flux.jl","text":"This advanced tutorial demonstrates the powerful combination of probabilistic programming with deep learning in Julia, specifically showing how to integrate neural networks built with Flux.jl into probabilistic models using RxInfer.jl.\n\nusing RxInfer, Flux, Random, Plots, LinearAlgebra, StableRNGs, ForwardDiff\n\nIn this example, our focus is on Bayesian state estimation in a Nonlinear State-Space Model with unknown dynamics. The main challenge in this scenario is that the dynamics of the system are often unknown or too complex to model analytically. Traditional approaches might struggle with capturing the nonlinear relationships in such systems. Neural networks offer a powerful solution by learning these complex dynamics directly from data, but incorporating them into a Bayesian framework requires careful integration to maintain probabilistic interpretations and uncertainty quantification. This tutorial demonstrates how to overcome these challenges by combining the flexibility of neural networks with the principled uncertainty handling of probabilistic programming. Specifically, we will utilize the time series generated by the Lorenz system as an example. \n\n# Lorenz system equations to be used to generate dataset\nBase.@kwdef mutable struct Lorenz\n    dt::Float64\n    œÉ::Float64\n    œÅ::Float64\n    Œ≤::Float64\n    x::Float64\n    y::Float64\n    z::Float64\nend\n\n# Define the Lorenz dynamics\nfunction step!(l::Lorenz)\n    dx = l.œÉ * (l.y - l.x);         l.x += l.dt * dx\n    dy = l.x * (l.œÅ - l.z) - l.y;   l.y += l.dt * dy\n    dz = l.x * l.y - l.Œ≤ * l.z;     l.z += l.dt * dz\nend\n\nfunction create_dataset(rng, œÉ, œÅ, Œ≤_nom; variance = 1f0, n_steps = 100, p_train = 0.8, p_test = 0.2)\n    attractor = Lorenz(0.02, œÉ, œÅ, Œ≤_nom/3.0, 1, 1, 1)\n    signal       = [Float32[1.0, 1.0, 1.0]]\n    noisy_signal = [last(signal) + randn(rng, Float32, 3) * variance]\n    for i in 1:(n_steps - 1)\n        step!(attractor)\n        push!(signal, Float32[attractor.x, attractor.y, attractor.z])\n        push!(noisy_signal, last(signal) + randn(rng, Float32, 3) * variance) \n    end\n\n    return (\n        parameters = (œÉ, œÅ, Œ≤_nom),\n        signal = signal, \n        noisy_signal = noisy_signal\n    )\nend\n\ncreate_dataset (generic function with 1 method)\n\nrng      = StableRNG(999) # dummy rng\nvariance = 2f0\ndataset  = create_dataset(rng, 11, 23, 6; variance = variance, n_steps = 200);\n\nThe dataset generated above represents the Lorenz system, a well-known chaotic dynamical system. We've created both clean trajectories following the exact Lorenz equations and noisy observations by adding Gaussian noise with variance 2.0. The dataset contains 200 time steps, providing sufficient data to train our neural network model. The parameters used for this Lorenz system are œÉ=11, œÅ=23, and Œ≤=6. This noisy dataset will allow us to test our neural network's ability to filter out noise and recover the underlying dynamics.\n\n# Extract first samples from datasets\nsample_clean = dataset.signal\nsample_noisy = dataset.noisy_signal\n\n# Pre-allocate arrays for better performance\nn_points = length(sample_clean)\ngx, gy, gz = zeros(n_points), zeros(n_points), zeros(n_points)\nrx, ry, rz = zeros(n_points), zeros(n_points), zeros(n_points)\n\n# Extract coordinates\nfor i in 1:n_points\n    # Noisy observations\n    rx[i], ry[i], rz[i] = sample_noisy[i][1], sample_noisy[i][2], sample_noisy[i][3]\n    # True state\n    gx[i], gy[i], gz[i] = sample_clean[i][1], sample_clean[i][2], sample_clean[i][3]\nend\n\n# Create three projection plots\np1 = scatter(rx, ry, label=\"Noisy observations\", alpha=0.7, markersize=2, title = \"X-Y Projection\")\nplot!(p1, gx, gy, label=\"True state\", linewidth=2)\n\np2 = scatter(rx, rz, label=\"Noisy observations\", alpha=0.7, markersize=2, title = \"X-Z Projection\")\nplot!(p2, gx, gz, label=\"True state\", linewidth=2)\n\np3 = scatter(ry, rz, label=\"Noisy observations\", alpha=0.7, markersize=2, title = \"Y-Z Projection\")\nplot!(p3, gy, gz, label=\"True state\", linewidth=2)\n\n# Combine plots with improved layout\nplot(p1, p2, p3, size=(900, 250), layout=(1,3), margin=5Plots.mm)\n\n(Image: )\n\nThe plots above visualize our noisy Lorenz system dataset from three different perspectives. We can clearly see how the noise (represented by the scattered points) obscures the true underlying dynamics (shown by the solid lines). The Lorenz system's characteristic butterfly-shaped attractor is visible in these projections, though the noisy observations make it challenging to discern the exact trajectory. This visualization highlights the challenge our neural network will face: it must learn to filter out the Gaussian noise (with variance 2.0) and recover the true state of the system at each time step. The X-Y, X-Z, and Y-Z projections each provide a different view of the same 3D dynamical system, helping us understand the full complexity of the dataset.","category":"section"},{"location":"categories/advanced_examples/integrating_neural_networks_with_flux.jl/#Bayesian-Inference-meets-Neural-Networks","page":"Integrating Neural Networks With Flux.Jl","title":"Bayesian Inference meets Neural Networks","text":"Our objective is to compute the marginal posterior distribution of the latent (hidden) state x_k at each time step k, considering the history of measurements up to that time step:\n\np(x_k  y_1k)\n\nThe above expression represents the probability distribution of the latent state x_k given the measurements y_1k up to time step k. The hidden dynamics of the Lorenz system exhibit nonlinearities and hence cannot be solved in the closed form. One manner of solving this problem is by introducing a neural network to approximate the transition matrix of the Lorenz system. \n\nbeginaligned\nA_k-1=NN(y_k-1) \np(x_k  x_k-1)=mathcalN(x_k  A_k-1x_k-1 Q) \np(y_k  x_k)=mathcalN(y_k  Bx_k R)\nendaligned\n\nwhere NN is the neural network. The input is the observation y_k-1, and output is the trasition matrix A_k-1. B denote distortion or measurment matrix. Q and R are covariance matrices. ","category":"section"},{"location":"categories/advanced_examples/integrating_neural_networks_with_flux.jl/#Define-the-Neural-Network","page":"Integrating Neural Networks With Flux.Jl","title":"Define the Neural Network","text":"We'll define a neural network using Flux.jl to approximate the transition matrix of the Lorenz system. The neural network will take the observation vector as input and output a transformation matrix that predicts the next state. This approach allows us to capture the nonlinear dynamics of the system while maintaining a tractable inference framework.\n\nFor demonstration purposes, we'll use a relatively simple neural network architecture - a single Dense layer.  However, this approach can be extended to more complex architectures such as deeper networks, convolutional  networks, or recurrent networks, depending on the complexity of the system dynamics you're trying to model. The key idea is that the neural network learns to predict the transition dynamics of the system based on  observations, which can then be integrated into our probabilistic state-space model.\n\nfunction make_neural_network(rng = StableRNG(1234))\n    model = Dense(3 => 3)\n\n    # Initialize the weights and biases of the neural network\n    flat, rebuild = Flux.destructure(model)\n\n    # We use a fixed random seed for reproducibility\n    rand!(rng, flat)\n\n    # Return the neural network with fixed weights and biases\n    return rebuild(flat)\nend\n\nmake_neural_network (generic function with 2 methods)","category":"section"},{"location":"categories/advanced_examples/integrating_neural_networks_with_flux.jl/#Probabilistic-Model-Specification","page":"Integrating Neural Networks With Flux.Jl","title":"Probabilistic Model Specification","text":"Now we'll define our probabilistic state-space model using RxInfer.jl. This model will incorporate the neural network's predictions of the transition matrices. The model consists of two main components: the state transition equation, which uses our neural network to predict how the state evolves, and the observation equation, which relates the hidden state to the measurements. By combining these components, we create a framework that can handle the nonlinear dynamics of the Lorenz system while maintaining computational tractability.\n\n@model function ssm(y, As, Q, B, R)\n    \n    x_prior_mean = ones(Float32, 3)\n    x_prior_cov  = Matrix(Diagonal(ones(Float32, 3)))\n    \n    x[1] ~ MvNormal(mean = x_prior_mean, cov = x_prior_cov)\n    y[1] ~ MvNormal(mean = B * x[1], cov = R)\n    \n    for i in 2:length(y)\n        x[i] ~ MvNormal(mean = As[i - 1] * x[i - 1], cov = Q) \n        y[i] ~ MvNormal(mean = B * x[i], cov = R)\n    end\nend\n\nWe set distortion matrix B and the covariance matrices Q and R as identity matrix. We assume that the observation noise is Gaussian with variance 2.0.\n\nQ = diageye(Float32, 3)\nB = diageye(Float32, 3)\nR = variance * diageye(Float32, 3)\n;\n\nBefore proceeding with inference, we need to build a function that extracts the transition matrix A from the neural network's output. These matrices will be fixed during the inference process.\n\nfunction get_matrices_from_neural_network(data, neural_network)\n    dd = hcat(data...)\n    As = neural_network(dd)\n    return map(c -> Matrix(Diagonal(c)), eachcol(As))\nend\n\nget_matrices_from_neural_network (generic function with 1 method)","category":"section"},{"location":"categories/advanced_examples/integrating_neural_networks_with_flux.jl/#Un-trained-network","page":"Integrating Neural Networks With Flux.Jl","title":"Un-trained network","text":"Before network training, we show the inference results for the hidden states:\n\nIn this section, we'll demonstrate how our model performs with an untrained neural network. This will serve as a baseline to compare against after training. We expect the inference results to be poor since the untrained network generates random transition matrices that don't capture the true dynamics of the system. The plots below will visualize the true states, noisy observations, and the inferred states for each of the three coordinates in our state space model.\n\n# Performance on an instance from the testset before training\nuntrained_neural_network = make_neural_network()\nuntrained_transition_matrices = get_matrices_from_neural_network(dataset.noisy_signal, untrained_neural_network)\n\nuntrained_result = infer(\n    model = ssm(As = untrained_transition_matrices, Q = Q, B = B, R = R), \n    data  = (y = dataset.noisy_signal, ), \n    returnvars = (x = KeepLast(), )\n)\n\nInference results:\n  Posteriors       | available for (x)\n\n# A helper function for plotting\nfunction plot_coordinate(result, i; title = \"\")\n    p = scatter(getindex.(dataset.noisy_signal, i), label=\"Observations\", alpha=0.7, markersize=2, title = title)\n    plot!(getindex.(dataset.signal, i), label=\"True states\", linewidth=2)\n    plot!(getindex.(mean.(result.posteriors[:x]), i), ribbon=sqrt.(getindex.(var.(result.posteriors[:x]), i)), label=\"Inferred states\", linewidth=2)\n    return p\nend\n\nfunction plot_coordinates(result)\n    p1 = plot_coordinate(result, 1, title = \"First coordinate\")\n    p2 = plot_coordinate(result, 2, title = \"Second coordinate\")\n    p3 = plot_coordinate(result, 3, title = \"Third coordinate\")\n    return plot(p1, p2, p3, size = (1000, 600), layout = (3, 1), legend=:bottomleft)\nend\n\nplot_coordinates (generic function with 1 method)\n\nplot_coordinates(untrained_result)\n\n(Image: )\n\nAs we can see from the plots above, the inference results with an untrained neural network are essentially nonsense. The inferred states (green lines) fail to track the true states (orange lines) and instead produce arbitrary values with large uncertainty bands. This is expected since the untrained neural network generates random transition matrices that don't capture the actual dynamics of the system. The large discrepancy between the inferred and true states demonstrates why proper training of the neural network is necessary to achieve meaningful results.","category":"section"},{"location":"categories/advanced_examples/integrating_neural_networks_with_flux.jl/#Training-the-network","page":"Integrating Neural Networks With Flux.Jl","title":"Training the network","text":"In this part, we use the Free Energy as the objective function to optimize the weights of our neural network.  Free Energy is a variational inference objective that balances model fit with complexity. By minimizing Free Energy, we encourage the neural network to learn transition matrices that:\n\nAccurately predict the next state given the current state (reducing prediction error)\nMaintain appropriate uncertainty in the predictions\nCapture the underlying dynamics of the system without overfitting to noise\n\nThe optimization process will iteratively update the neural network weights using gradient descent, with the goal of finding transition matrices that best explain our observed data.\n\n# free energy objective to be optimized during training\nfunction make_fe_tot_est(rebuild, data; Q = Q, B = B, R = R)\n    function fe_tot_est(v)\n        nn = rebuild(v)\n        result = infer(\n            model = ssm(As = get_matrices_from_neural_network(data, nn), Q = Q, B = B, R = R), \n            data  = (y = data, ), \n            returnvars = (x = KeepLast(), ),\n            free_energy = true,\n            session = nothing\n        )\n        return result.free_energy[end]\n    end\nend\n\nmake_fe_tot_est (generic function with 1 method)\n\nfunction train!(neural_network, data; num_epochs = 500)\n    rule = Flux.Optimise.Adam()\n    state = Flux.setup(rule, neural_network)\n\n    x, rebuild = Flux.destructure(neural_network)\n    fe_tot_est_ = make_fe_tot_est(rebuild, data)\n\n    run_epochs!(rebuild, fe_tot_est_, state, neural_network; num_epochs = num_epochs)\nend\n\nfunction run_epochs!(rebuild::F, fe_tot_est::I, state::S, neural_network::N; num_epochs::Int = 100) where {F, I, S, N}\n    print_each = num_epochs √∑ 10\n    start_time = time()\n    for epoch in 1:num_epochs\n        flat, _ = Flux.destructure(neural_network)\n        if epoch % print_each == 0\n            current_value = fe_tot_est(flat)\n            elapsed = time() - start_time\n            remaining = elapsed / epoch * (num_epochs - epoch)\n            println(\"Epoch $epoch/$num_epochs: Free Energy = $current_value, ETA: $(round(remaining; digits=1)) seconds\")\n        end\n        grads = ForwardDiff.gradient(fe_tot_est, flat);\n        Flux.update!(state, neural_network, rebuild(grads))\n    end\n    # Calculate and print total training time\n    total_time = time() - start_time\n    println(\"Finished in $(round(total_time; digits=1)) seconds\")\nend\n\nrun_epochs! (generic function with 1 method)\n\nNow that we have defined our neural network architecture, dataset, and training functions, we can proceed with the training process. We'll train the neural network to learn the underlying dynamics of our state-space model from noisy observations. The training will optimize the free energy objective function using the Adam optimizer over multiple epochs. This process will allow the neural network to capture the non-linear relationships in the data, enabling more accurate state inference compared to traditional linear models. The following cell executes the training with 2000 epochs, which should provide sufficient iterations for convergence.\n\ntrained_neural_network = make_neural_network()\n\ntrain!(trained_neural_network, dataset.noisy_signal; num_epochs = 1000)\n\nEpoch 100/1000: Free Energy = 24170.93445802461, ETA: 363.9 seconds\nEpoch 200/1000: Free Energy = 22554.71504016765, ETA: 207.9 seconds\nEpoch 300/1000: Free Energy = 20249.690550213167, ETA: 147.5 seconds\nEpoch 400/1000: Free Energy = 15243.43215265174, ETA: 112.1 seconds\nEpoch 500/1000: Free Energy = 5305.612489972754, ETA: 85.8 seconds\nEpoch 600/1000: Free Energy = 1975.3465539892043, ETA: 64.7 seconds\nEpoch 700/1000: Free Energy = 1565.5426626657077, ETA: 46.5 seconds\nEpoch 800/1000: Free Energy = 1528.6284177456932, ETA: 29.9 seconds\nEpoch 900/1000: Free Energy = 1515.1423138831697, ETA: 14.5 seconds\nEpoch 1000/1000: Free Energy = 1510.1678087715945, ETA: 0.0 seconds\nFinished in 141.9 seconds\n\nNow let's analyze the results of our neural network training. We'll visualize how well our trained model can infer the true states from noisy observations. The plots below will show the original noisy observations, the true underlying states, and our model's inferred states with confidence intervals. This comparison will help us evaluate the effectiveness of our neural network-based approach in capturing the non-linear dynamics of the system and filtering out noise.\n\ntrained_transition_matrices = get_matrices_from_neural_network(dataset.noisy_signal, trained_neural_network)\n\ntrained_result = infer(\n    model = ssm(As = trained_transition_matrices, Q = Q, B = B, R = R), \n    data  = (y = dataset.noisy_signal, ), \n    returnvars = (x = KeepLast(), )\n)\n\nplot_coordinates(trained_result)\n\n(Image: )\n\nThe results demonstrate the effectiveness of our neural network-based state-space model approach. Despite the significant noise present in the observations (shown as scattered points), our model successfully identifies the underlying hidden signal (shown by the inferred states line). The close alignment between the inferred states and the true states across all three coordinates indicates that the trained neural network has effectively learned the non-linear dynamics of the system. The narrow confidence bands (shown as ribbons) around the inferred states further suggest high confidence in the predictions. This example illustrates how combining neural networks with probabilistic state-space models can provide robust inference in scenarios with complex dynamics and noisy observations.\n\nix, iy, iz = zeros(n_points), zeros(n_points), zeros(n_points)\n\ninferred_mean = mean.(trained_result.posteriors[:x])\n\n# Extract coordinates\nfor i in 1:n_points\n    # Inferred mean\n    ix[i], iy[i], iz[i] = inferred_mean[i][1], inferred_mean[i][2], inferred_mean[i][3]\nend\n\n# Create three projection plots\np1 = scatter(rx, ry, label=\"Noisy observations\", alpha=0.7, markersize=2, title = \"X-Y Projection\")\nplot!(p1, gx, gy, label=\"True state\", linewidth=2)\nplot!(p1, ix, iy, label=\"Inferred Mean\", linewidth=2)\n\np2 = scatter(rx, rz, label=\"Noisy observations\", alpha=0.7, markersize=2, title = \"X-Z Projection\")\nplot!(p2, gx, gz, label=\"True state\", linewidth=2)\nplot!(p2, ix, iz, label=\"Inferred Mean\", linewidth=2)\n\np3 = scatter(ry, rz, label=\"Noisy observations\", alpha=0.7, markersize=2, title = \"Y-Z Projection\")\nplot!(p3, gy, gz, label=\"True state\", linewidth=2)\nplot!(p3, iy, iz, label=\"Inferred Mean\", linewidth=2)\n\n# Combine plots with improved layout\nplot(p1, p2, p3, size=(900, 250), layout=(1,3), margin=5Plots.mm)\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n‚åÖ [587475ba] Flux v0.14.25\n‚åÖ [f6369f11] ForwardDiff v0.10.39\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [37e2e46d] LinearAlgebra v1.12.0\nInfo Packages marked with ‚åÖ have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated`\n\n\n","category":"section"},{"location":"categories/problem_specific/ode_parameter_estimation/","page":"Ode Parameter Estimation","title":"Ode Parameter Estimation","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/problem_specific/ode_parameter_estimation/#ODE-Parameter-Estimation","page":"Ode Parameter Estimation","title":"ODE Parameter Estimation","text":"In this notebook we will explore how we can solve and learn the parameters of an ODE simultaneously using RxInfer. To illustrate how we can can utilize RxInfer, we will take Lotka-Volterra differential equation as an example. We will explore three different alternatives to parameter estimation. The first alternative will demonstrate how we can use free energy to obtain point estimates. The second alternative will demonstrate how we can use a prior distribution on the parameters to obtain a posterior estimate for the unknown parameters of the ODE. The second alternative will do parameter learning in two stages. The first stage will obtain the initialization for the prior hyper-parameters and then use these initial values of the prior to obtain the posterior by message passing. The third alternative will use purely message passing. \n\nusing RxInfer, Optim, LinearAlgebra, Plots,  StaticArrays, StableRNGs","category":"section"},{"location":"categories/problem_specific/ode_parameter_estimation/#Introduction-to-Lotka-Volterra-Equations","page":"Ode Parameter Estimation","title":"Introduction to Lotka-Volterra Equations","text":"The Lotka-Volterra equations, are a pair of first-order nonlinear differential equations frequently used to describe the dynamics of biological systems in which two species interact: one as a predator and the other as prey. The equations are defined as follows:\n\nPrey Population Dynamics:   fracdxdt = alpha x - beta xy\n\nPredator Population Dynamics:   fracdydt = -gamma y + delta xy\n\nIn this ODE, x is the population of the prey (e.g., rabbits), y is the population of the predator (e.g., foxes), alpha represents the maximum growth rate of the prey, beta is the rate of predation, gamma is the predator's per capita death rate and delta is the growth rate of the predator population based on the availability of prey.\n\nfunction lotka_volterra(u, z, p, t)\n    Œ±, Œ≤, Œ¥, Œ≥ = p[SA[1,2,3,4]]\n    x, y = u[SA[1, 2]]\n    du1 = Œ± * x - Œ≤ * x * y\n    du2 = -Œ¥ * y + Œ≥ * x * y\n\n    return [du1, du2]\nend;","category":"section"},{"location":"categories/problem_specific/ode_parameter_estimation/#The-Runge-Kutta-4th-Order-(RK4)-Method","page":"Ode Parameter Estimation","title":"The Runge-Kutta 4th Order (RK4) Method","text":"The Runge-Kutta 4th order method is one of the most widely used numerical techniques for solving ordinary differential equations (ODEs). For a system of the form:\n\nfracdxdt = f(x t)\n\nwhere x can be a scalar or vector-valued function, RK4 provides a numerical approximation with local truncation error of order O(h^5) and global error of order O(h^4).","category":"section"},{"location":"categories/problem_specific/ode_parameter_estimation/#Algorithm","page":"Ode Parameter Estimation","title":"Algorithm","text":"Given the current state x_n at time t_n, RK4 computes the state at t_n+1 = t_n + dt using four intermediate evaluations:\n\nbeginaligned\nk_1 = f(x_n t_n) \nk_2 = f(x_n + fracdt2k_1 t_n + fracdt2) \nk_3 = f(x_n + fracdt2k_2 t_n + fracdt2) \nk_4 = f(x_n + dtk_3 t_n + dt)\nendaligned\n\nThe solution is then advanced using a weighted average of these evaluations:\n\nx_n+1 = x_n + fracdt6(k_1 + 2k_2 + 2k_3 + k_4)\n\nfunction rk4_step(f::Function, x, u, Œ∏, t, dt; supersample = 1)\n    \n    @inbounds for i in 1:supersample\n        dt_i = dt/supersample\n        k1 = f(x, u, Œ∏, t)\n        k2 = f(x + dt_i/2*k1, u, Œ∏, t + dt_i/2)\n        k3 = f(x + dt_i/2*k2, u, Œ∏, t + dt_i/2)\n        k4 = f(x + dt_i*k3, u, Œ∏, t + dt_i)\n        x += dt_i/6*(k1 + 2*k2 + 2*k3 + k4)\n    end\n    return x\n\nend\n\nfunction lotka_volterra_rk4(x, Œ∏, t, dt, supersample = 1)\n    return rk4_step(lotka_volterra, x, 0, Œ∏, t, dt)\n  \nend\n\nlotka_volterra_rk4 (generic function with 2 methods)","category":"section"},{"location":"categories/problem_specific/ode_parameter_estimation/#Data-Generation","page":"Ode Parameter Estimation","title":"Data Generation","text":"Lotka Volterra data is generated using the RK4 method. The data is then corrupted with noise to simulate real-world observations. \n\nDISCLAIMER: Since Lotka-Volterra equations model prey and predator dynamics, adding a Gaussian noise is not realistic. Although adding other noise forms are possible it will complicate the inference process. Therefore, we will use Gaussian noise for instructive purposes. \n\nfunction generate_data(Œ∏; x = ones(2), t =0.0, dt = 0.001, n = 1000, v = 1, seed = 123)\n    rng = StableRNG(seed)\n    data = Vector{Vector{Float64}}(undef, n)\n    ts = Vector{Float64}(undef, n)\n    for i in 1:n\n        data[i] = lotka_volterra_rk4(x, Œ∏, t, dt)\n        x = data[i]\n        t += dt\n        ts[i] = t\n    end\n    noisy_data = map(data) do d\n        noise = sqrt(v) * [randn(rng), randn(rng)]\n        d + noise\n    end\n    return data, noisy_data, ts\nend\n\ndt = 0.1 # sample_interval\nnoisev = 0.35\nn = 10000\ntrue_params = [1.0, 1.5, 3.0, 1.0]\ndata_long, noisy_data_long, ts_long = generate_data(true_params,dt = dt, n = n, v = noisev);\n\n## We create a smaller dataset for the global parameter optimization. Utilizing the entire dataset for the global optimization will take too much time. \nn_train = 100\ndata = data_long[1:n_train]\nnoisy_data = noisy_data_long[1:n_train]\nts = ts_long[1:n_train];","category":"section"},{"location":"categories/problem_specific/ode_parameter_estimation/#Data-Visualization","page":"Ode Parameter Estimation","title":"Data Visualization","text":"p = plot(layout=(2,1))\nplot!(subplot=1, ts, [d[1] for d in data], label=\"True x‚ÇÅ\", color=:blue)\nplot!(subplot=1, ts, [d[1] for d in noisy_data], seriestype=:scatter, label=\"Noisy x‚ÇÅ\", color=:blue, alpha=0.3, markersize=1.3)\nplot!(subplot=2, ts, [d[2] for d in data], label=\"True x‚ÇÇ\", color=:red)\nplot!(subplot=2, ts, [d[2] for d in noisy_data], seriestype=:scatter, label=\"Noisy x‚ÇÇ\", color=:red, alpha=0.3, markersize=1.3)\nxlabel!(\"Time\")\nylabel!(subplot=1, \"Prey Population\")\nylabel!(subplot=2, \"Predator Population\")\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/ode_parameter_estimation/#First-Alternative:-Global-Parameter-Optimization","page":"Ode Parameter Estimation","title":"First Alternative: Global Parameter Optimization","text":"In the first alternative we will construct one time-segment of Lotka-Volterra equation. We will use lotka_volterra_rk4 function to create non-linear node. This function was defined earlier to numerically solve the Lotka-Volterra equations using the 4th order Runge-Kutta method. \n\n@model function lotka_volterra_model_without_prior(obs, mprev, Vprev, dt, t, Œ∏)\n    xprev ~ MvNormalMeanCovariance(mprev, Vprev)\n    x     := lotka_volterra_rk4(xprev, Œ∏, t, dt)\n    obs   ~ MvNormalMeanCovariance(x,  noisev * diageye(length(mprev)))\nend\n\nNon-linear deterministic nodes require meta specification that will determine the type of message approximations to be used. In this case, we can use the Linearization method that will trigger an Extended Kalman Filter (EKF) type of approximation or the Unscented method that will trigger an Unscented Kalman Filter (UKF) type of approximation. Moreover, because we are using RxInfer in an online setting we need to specify how the mean and covariance of the Gaussian distribution will be updated. We do this by using the @autoupdates macro and initialize using the @initialization macro. \n\ndelta_meta = @meta begin\n    lotka_volterra_rk4() ->  Linearization()\nend\n\nautoupdates_without_prior = @autoupdates begin\n    mprev, Vprev= mean_cov(q(x))\nend\n\n@initialization function initialize_without_prior(mx, Vx)\n    q(x) = MvNormalMeanCovariance(mx, Vx)\nend;","category":"section"},{"location":"categories/problem_specific/ode_parameter_estimation/#Free-Energy-Computation","page":"Ode Parameter Estimation","title":"Free Energy Computation","text":"We will now define the free energy function that will be minimized to infer the parameters of the model. Since the parameters of the model are not constrained to be positive, we will use the exp function to transform the parameters to the positive domain. We will set the free energy to true to keep track of the free energy values. \n\nfunction compute_free_energy_without_prior(Œ∏ ; mx = ones(2), Vx = 1e-6 * diageye(2))\n    Œ∏ = exp.(Œ∏)\n    result = infer(\n        model = lotka_volterra_model_without_prior(dt = dt, Œ∏ = Œ∏),\n        data = (obs = noisy_data, t= ts),\n        initialization = initialize_without_prior(mx, Vx),\n        meta = delta_meta,\n        autoupdates = autoupdates_without_prior,\n        keephistory = length(noisy_data),\n        free_energy = true\n    )\n    return sum(result.free_energy_final_only_history)\nend;\n\nNow we are ready to perform the parameter inference by minimizing the free energy function. We will use the optimize function from the Optim package to perform the optimization. We will use the NelderMead method as the optimizer as it doesn't require gradient information and is faster.\n\nres_without_prior  = optimize(compute_free_energy_without_prior, zeros(4), NelderMead(), Optim.Options(show_trace = true, show_every = 300));\n\nIter     Function value    ‚àö(Œ£(y·µ¢-yÃÑ)¬≤)/n \n------   --------------    --------------\n     0     1.274436e+03     9.650180e+00\n * time: 0.04586601257324219\n\nŒ∏_minimizer_without_prior = exp.(res_without_prior.minimizer)\nprintln(\"\\nEstimated point mass valued parameters:\")\nfor (i, (name, val)) in enumerate(zip([\"Œ±\", \"Œ≤\", \"Œ≥\", \"Œ¥\"], Œ∏_minimizer_without_prior))\n    println(\" * $name: $(round(val, digits=3))\")\nend\n\nprintln(\"\\nActual parameters used to generate data:\")\nfor (i, (name, val)) in enumerate(zip([\"Œ±\", \"Œ≤\", \"Œ≥\", \"Œ¥\"], true_params))\n    println(\" * $name: $(round(val, digits=3))\")\nend\n\nEstimated point mass valued parameters:\n * Œ±: 0.994\n * Œ≤: 1.491\n * Œ≥: 3.054\n * Œ¥: 0.997\n\nActual parameters used to generate data:\n * Œ±: 1.0\n * Œ≤: 1.5\n * Œ≥: 3.0\n * Œ¥: 1.0","category":"section"},{"location":"categories/problem_specific/ode_parameter_estimation/#Second-Alternative:-RxInfer-Model-with-Prior-on-the-Parameters","page":"Ode Parameter Estimation","title":"Second Alternative: RxInfer Model with Prior on the Parameters","text":"We will now define the corresponding RxInfer model with the prior distribution on the parameters. For this, we will use the @model macro to create a time segment for the ODE using the deterministic ODE solver lotka_volterra_rk4 as a non-linear node in the RxInfer model. For the prior distribution of the parameters, we will use a multivariate Gaussian distribution with mean mŒ∏ and covariance VŒ∏ that will be initialized using the initialize macro.\n\n@model function lotka_volterra_model(obs, mprev, Vprev, dt, t, mŒ∏, VŒ∏)\n    Œ∏     ~ MvNormalMeanCovariance(mŒ∏, VŒ∏)\n    xprev ~ MvNormalMeanCovariance(mprev, Vprev)\n    x     := lotka_volterra_rk4(xprev, Œ∏, t, dt)\n    obs   ~ MvNormalMeanCovariance(x,  noisev * diageye(length(mprev)))\nend\n\nautoupdates = @autoupdates begin\n    mprev, Vprev= mean_cov(q(x))\n    mŒ∏, VŒ∏ = mean_cov(q(Œ∏))\nend\n\n@initialization function initialize(mx, Vx, mŒ∏, VŒ∏)\n    q(x) = MvNormalMeanCovariance(mx, Vx)\n    q(Œ∏) = MvNormalMeanCovariance(mŒ∏, VŒ∏)\nend;","category":"section"},{"location":"categories/problem_specific/ode_parameter_estimation/#Prior-Initialization-by-means-of-Free-Energy-Minimization","page":"Ode Parameter Estimation","title":"Prior Initialization by means of Free Energy Minimization","text":"We will now define the free energy function that will be minimized to infer the initial hyper-parameters of the prior distribution. Since we have 4 parameters, we will initialize the mean of the prior distribution with 4 elements and the diagonal elements of the covariance matrix. Again, we will use the exp function to transform the parameters to the positive domain. \n\nfunction compute_free_energy(Œ∏ ; mx = ones(2), Vx = 1e-6 * diageye(2))\n    Œ∏ = exp.(Œ∏)\n    mŒ∏ = Œ∏[1:4]\n    VŒ∏ = Diagonal(Œ∏[5:end])\n    result = infer(\n        model = lotka_volterra_model(dt = dt,),\n        data = (obs = noisy_data, t = ts),\n        initialization = initialize(mx, Vx, mŒ∏, VŒ∏),\n        meta = delta_meta,\n        autoupdates = autoupdates,\n        keephistory = length(noisy_data),\n        free_energy = true\n    )\n    return sum(result.free_energy_final_only_history)\nend;","category":"section"},{"location":"categories/problem_specific/ode_parameter_estimation/#Parameter-Inference","page":"Ode Parameter Estimation","title":"Parameter Inference","text":"We will now perform the parameter inference by minimizing the free energy function. We will use the optimize function from the Optim package to perform the optimization. We will use the NelderMead method as the optimizer as it doesn't require gradient information and is faster.\n\nres = optimize(compute_free_energy, [zeros(4); 0.1ones(4)], NelderMead(), Optim.Options(show_trace = true, show_every = 300));\n\nIter     Function value    ‚àö(Œ£(y·µ¢-yÃÑ)¬≤)/n \n------   --------------    --------------\n     0     2.814831e+02     2.192538e-01\n * time: 0.00013399124145507812\n   300     2.714613e+02     1.554900e-03\n * time: 7.524245023727417\n   600     2.712411e+02     6.805548e-07\n * time: 14.785998821258545\n\nŒ∏_minimizer = exp.(res.minimizer)\nmŒ∏_init = Œ∏_minimizer[1:4]\nVŒ∏_init = Diagonal(Œ∏_minimizer[5:end])\n\nprintln(\"\\nEstimated initialization parameters for the prior distribution:\")\nfor (i, (name, val, var)) in enumerate(zip([\"Œ±\", \"Œ≤\", \"Œ≥\", \"Œ¥\"], mŒ∏_init, Œ∏_minimizer[5:8]))\n    println(\" * $name: $(round(val, digits=3)) ¬± $(round(sqrt(var), digits=3))\")\nend\n\nprintln(\"\\nActual parameters used to generate data:\")\nfor (i, (name, val)) in enumerate(zip([\"Œ±\", \"Œ≤\", \"Œ≥\", \"Œ¥\"], true_params))\n    println(\" * $name: $(round(val, digits=3))\")\nend\n\nEstimated initialization parameters for the prior distribution:\n * Œ±: 2.279 ¬± 1.275\n * Œ≤: 1.91 ¬± 2.119\n * Œ≥: 1.636 ¬± 2.228\n * Œ¥: 0.962 ¬± 0.693\n\nActual parameters used to generate data:\n * Œ±: 1.0\n * Œ≤: 1.5\n * Œ≥: 3.0\n * Œ¥: 1.0\n\nHaving estimated the initial hyper-parameters of the prior distribution, we can now perform the parameter inference by online message passing. We will use the infer function to perform the inference. \n\nresult = infer(\n    model = lotka_volterra_model(dt = dt,),\n    data = (obs = noisy_data_long, t= ts_long),\n    initialization = initialize(ones(2), 1e-6 * diageye(2), mŒ∏_init, VŒ∏_init),\n    meta = delta_meta,\n    autoupdates = autoupdates,\n    keephistory = length(noisy_data_long),\n    free_energy = true\n);\n\nmŒ∏_posterior = mean.(result.history[:Œ∏])\nVŒ∏_posterior = var.(result.history[:Œ∏])\n\np = plot(layout=(4,1), size=(800,1000), legend=:right)\n\nparam_names = [\"Œ±\", \"Œ≤\", \"Œ≥\", \"Œ¥\"]\n\nfor i in 1:4\n    means = [m[i] for m in mŒ∏_posterior]\n    stds = [2sqrt(v[i]) for v in VŒ∏_posterior]\n    \n    plot!(p[i], means, ribbon=stds, label=\"Posterior\", subplot=i)\n    hline!(p[i], [true_params[i]], label=\"True value\", linestyle=:dash, color=:red, subplot=i)\n    \n    title!(p[i], param_names[i], subplot=i)\n    if i == 4 \n        xlabel!(p[i], \"Time step\", subplot=i)\n    end\nend\n\n# Place legend at top right for all subplots\nplot!(p, legend=:topright)\n\ndisplay(p)\nfinal_means = last(mŒ∏_posterior)\nfinal_vars = last(VŒ∏_posterior)\nfinal_stds = sqrt.(final_vars)\n\n# Print results\nprintln(\"\\nFinal Parameter Estimates:\")\nfor (param, mean, std) in zip(param_names, final_means, final_stds)\n    println(\"$param: $mean ¬± $(std)\")\nend\n\n# Get final covariance matrix\nfinal_cov = cov(last(result.history[:Œ∏]))\nprintln(\"\\nFinal Parameter Covariance Matrix:\")\ndisplay(final_cov)\n\nFinal Parameter Estimates:\nŒ±: 0.9873125810392338 ¬± 0.022683193282629927\nŒ≤: 1.4928568988039574 ¬± 0.026900704209026783\nŒ≥: 3.0329956989098488 ¬± 0.12553964480470822\nŒ¥: 1.0192425653899293 ¬± 0.03383241259684531\n\nFinal Parameter Covariance Matrix:\n4√ó4 Matrix{Float64}:\n 0.000514527   0.00038494    8.38569e-5   3.78402e-5\n 0.00038494    0.000723648  -8.1867e-5   -4.44924e-5\n 8.38569e-5   -8.1867e-5     0.0157602    0.00373872\n 3.78402e-5   -4.44924e-5    0.00373872   0.00114463\n\n(Image: )\n\nfrom = 1\nskip = 1        \nto = 500\n\n# Get state estimates and variances\nmx = mean.(result.history[:x])\nVx = var.(result.history[:x])\n\n# Plot state estimates with uncertainty bands\np1 = plot(ts_long[from:skip:to] , getindex.(mx, 1)[from:skip:to], ribbon=2*sqrt.(getindex.(Vx, 1)[from:skip:to]), \n          label=\"Prey estimate\", legend=:topright)\nscatter!(p1, ts_long[from:skip:to], getindex.(noisy_data_long, 1)[from:skip:to], label=\"Noisy prey observations\", alpha=0.5,ms=1)\nplot!(p1, ts_long[from:skip:to], getindex.(data_long, 1)[from:skip:to], label=\"True prey\", linestyle=:dash)\ntitle!(p1, \"Prey Population\")\n\np2 = plot(ts_long[from:skip:to], getindex.(mx, 2)[from:skip:to], ribbon=2*sqrt.(getindex.(Vx, 2)[from:skip:to]), \n          label=\"Predator estimate\", legend=:topright)\nscatter!(p2, ts_long[from:skip:to], getindex.(noisy_data_long, 2)[from:skip:to], label=\"Noisy predator observations\", alpha=0.5, ms=1)\nplot!(p2, ts_long[from:skip:to], getindex.(data_long, 2)[from:skip:to] , label=\"True predator\", linestyle=:dash)\ntitle!(p2, \"Predator Population\")\n\nplot(p1, p2, layout=(2,1), size=(1000,600))\n\n(Image: )","category":"section"},{"location":"categories/problem_specific/ode_parameter_estimation/#Third-Alternative:-RxInfer-Model-with-Exponential-Transformation-on-the-Parameters","page":"Ode Parameter Estimation","title":"Third Alternative: RxInfer Model with Exponential Transformation on the Parameters","text":"So far we have used the exp function to transform the parameters to the positive domain and computed free energy. This transformation was done outside of @model macro. In this approach, we will use the exp function to transform the parameters to the positive domain but within the @model macro. We will then use the Unscented method to approximate the non-linear deterministic node. This approach is more computationally efficient than the previous one, however it may suffer from accuracy issues as we may not have a good hyper-parameter initialization. \n\nNOTE: We can not use exp.() inside the @model macro as the model macro doesn't support broadcasting yet. So we need to define a function that will apply the exp function to the parameters. \n\nlotka_volterra_rk4_transformed(x,Œ∏,t,dt) = lotka_volterra_rk4(x, exp.(Œ∏), t, dt)## This function is used to apply the exp function to the parameters within the @model macro\n\n@model function lotka_volterra_model2(obs, mprev, Vprev, dt, t, mŒ∏, VŒ∏)\n    Œ∏     ~ MvNormalMeanCovariance(mŒ∏, VŒ∏)\n    xprev ~ MvNormalMeanCovariance(mprev, Vprev)\n    x     := lotka_volterra_rk4_transformed(xprev, Œ∏, t, dt)\n    obs   ~ MvNormalMeanCovariance(x,  noisev * diageye(length(mprev)))\nend\n\ndelta_meta2 = @meta begin\n    lotka_volterra_rk4_transformed() ->  Unscented()\nend\n\nautoupdates2 = @autoupdates begin\n    mprev, Vprev= mean_cov(q(x))\n    mŒ∏, VŒ∏ = mean_cov(q(Œ∏))\nend\n\n@initialization function initialize2(mx, Vx, mŒ∏, VŒ∏)\n    q(x) = MvNormalMeanCovariance(mx, Vx)\n    q(Œ∏) = MvNormalMeanCovariance(mŒ∏, VŒ∏)\nend\n\n\nresult2  = infer(\n    model = lotka_volterra_model2(dt = dt,),\n    data = (obs = noisy_data_long, t= ts_long),\n    initialization = initialize2(ones(2),  1e-6diageye(2), zeros(4), 0.1*diageye(4)),\n    meta = delta_meta2,\n    autoupdates = autoupdates2,\n    keephistory = length(noisy_data_long),\n    free_energy = true\n)\n\nRxInferenceEngine:\n  Posteriors stream    | enabled for (Œ∏, xprev, x)\n  Free Energy stream   | enabled\n  Posteriors history   | available for (Œ∏, xprev, x)\n  Free Energy history  | available\n  Enabled events       | [  ]\n\nmŒ∏ =  mean.(result2.history[:Œ∏])\nVŒ∏ = cov.(result2.history[:Œ∏])\nexpf(Œ∏) = exp.(Œ∏)\nŒ∏dists = map((m,v) -> MvNormalMeanCovariance(m, v), mŒ∏, VŒ∏)\nŒ∏_exp_dists = map(Œ∏dist -> ReactiveMP.approximate(Unscented(), expf, (Œ∏dist,)), Œ∏dists)\n\nmŒ∏_exp =  mean.(Œ∏_exp_dists)\nVŒ∏_exp = cov.(Œ∏_exp_dists)\n\n# Plot the inferred parameters with uncertainty\np1 = plot(ts_long, getindex.(mŒ∏_exp, 1), ribbon=2*sqrt.(getindex.(VŒ∏_exp, 1,1)), label=\"Œ±\", legend=:topright)\nplot!(p1, ts_long, fill(true_params[1], length(ts_long)), label=\"True Œ±\", linestyle=:dash)\ntitle!(p1, \"Parameter Œ±\")\n\np2 = plot(ts_long, getindex.(mŒ∏_exp, 2), ribbon=2*sqrt.(getindex.(VŒ∏_exp, 2,2)), label=\"Œ≤\", legend=:topright)\nplot!(p2, ts_long, fill(true_params[2], length(ts_long)), label=\"True Œ≤\", linestyle=:dash)\ntitle!(p2, \"Parameter Œ≤\")\n\np3 = plot(ts_long, getindex.(mŒ∏_exp, 3), ribbon=2*sqrt.(getindex.(VŒ∏_exp, 3,3)), label=\"Œ≥\", legend=:topright)\nplot!(p3, ts_long, fill(true_params[3], length(ts_long)), label=\"True Œ≥\", linestyle=:dash)\ntitle!(p3, \"Parameter Œ≥\")\n\np4 = plot(ts_long, getindex.(mŒ∏_exp, 4), ribbon=2*sqrt.(getindex.(VŒ∏_exp, 4,4)), label=\"Œ¥\", legend=:topright)\nplot!(p4, ts_long, fill(true_params[4], length(ts_long)), label=\"True Œ¥\", linestyle=:dash)\ntitle!(p4, \"Parameter Œ¥\")\n\nplot(p1, p2, p3, p4, layout=(4,1), size=(1000,800))\n\n(Image: )\n\n# Print final parameter estimates and covariance\nfinal_means = last(mŒ∏_exp)\nfinal_vars = diag(last(VŒ∏_exp))\nfinal_stds = sqrt.(final_vars)\n\n# Print results\nprintln(\"\\nFinal Parameter Estimates:\")\nfor (param, mean, std) in zip(param_names, final_means, final_stds)\n    println(\"$param: $mean ¬± $(std)\")\nend\n\nprintln(\"\\nFinal parameter covariance matrix:\")\ndisplay(last(VŒ∏_exp))\n\nFinal Parameter Estimates:\nŒ±: 1.0466420644370373 ¬± 0.023551898981352345\nŒ≤: 1.5267272962373681 ¬± 0.027682602680033756\nŒ≥: 2.7961085961433128 ¬± 0.12150864747658563\nŒ¥: 0.9428781820606673 ¬± 0.032860835936904864\n\nFinal parameter covariance matrix:\n4√ó4 Matrix{Float64}:\n 0.000554692   0.000437206   8.94158e-5   3.93331e-5\n 0.000437206   0.000766326  -7.64945e-5  -5.57011e-5\n 8.94158e-5   -7.64945e-5    0.0147644    0.00347717\n 3.93331e-5   -5.57011e-5    0.00347717   0.00107983\n\n\n# Get state estimates and variances\nmx = mean.(result2.history[:x])\nVx = var.(result2.history[:x])\n\n# Plot state estimates with uncertainty bands\np1 = plot(ts_long[from:skip:to] , getindex.(mx, 1)[from:skip:to], ribbon=2*sqrt.(getindex.(Vx, 1)[from:skip:to]), \n          label=\"Prey estimate\", legend=:topright)\nscatter!(p1, ts_long[from:skip:to], getindex.(noisy_data_long, 1)[from:skip:to], label=\"Noisy prey observations\", alpha=0.5,ms=1)\nplot!(p1, ts_long[from:skip:to], getindex.(data_long, 1)[from:skip:to], label=\"True prey\", linestyle=:dash)\ntitle!(p1, \"Prey Population\")\n\np2 = plot(ts_long[from:skip:to], getindex.(mx, 2)[from:skip:to], ribbon=2*sqrt.(getindex.(Vx, 2)[from:skip:to]), \n          label=\"Predator estimate\", legend=:topright)\nscatter!(p2, ts_long[from:skip:to], getindex.(noisy_data_long, 2)[from:skip:to], label=\"Noisy predator observations\", alpha=0.5, ms=1)\nplot!(p2, ts_long[from:skip:to], getindex.(data_long, 2)[from:skip:to] , label=\"True predator\", linestyle=:dash)\ntitle!(p2, \"Predator Population\")\n\nplot(p1, p2, layout=(2,1), size=(1000,600))\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n‚åÉ [be0214bd] NonlinearSolveBase v1.14.0\n‚åÖ [429524aa] Optim v1.13.3\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [90137ffa] StaticArrays v1.9.17\n  [37e2e46d] LinearAlgebra v1.12.0\nInfo Packages marked with ‚åÉ and ‚åÖ have new versions available. Those with ‚åÉ may be upgradable, but those with ‚åÖ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`\n\n\n","category":"section"},{"location":"categories/basic_examples/predicting_bike_rental_demand/","page":"Predicting Bike Rental Demand","title":"Predicting Bike Rental Demand","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/basic_examples/predicting_bike_rental_demand/#Predicting-Bike-Rental-Demand","page":"Predicting Bike Rental Demand","title":"Predicting Bike Rental Demand","text":"Important Note: This notebook primarily aims to show how to manage missing data and generate predictions using a model. It does not serve as a comprehensive guide to building the most advanced model for this dataset or showcase the best practices in feature engineering. To keep explanations clear, we will use simplified assumptions and straightforward models. For applications in the real world, you should employ more sophisticated approaches and feature engineering methods. However, we will present a more complex model towards the end of this notebook for you to explore, albeit with less detailed guidance.\n\nusing RxInfer","category":"section"},{"location":"categories/basic_examples/predicting_bike_rental_demand/#Preamble:-Enabling-Predictions","page":"Predicting Bike Rental Demand","title":"Preamble: Enabling Predictions","text":"RxInfer.jl facilitates predictions in two primary ways. \n\nImplicit Prediction: By adding missing instances directly into the data, which are then treated as regular observations during inference.\nExplicit Prediction: By defining a separate data variable in the model. This approach doesn't necessitate passing missing instances as the data variable but does require specifying the predictvar argument in the inference function.","category":"section"},{"location":"categories/basic_examples/predicting_bike_rental_demand/#Example","page":"Predicting Bike Rental Demand","title":"Example","text":"Consider the following model:\n\n@model function example_model(y)\n\n    h ~ NormalMeanPrecision(0, 1.0)\n    x ~ NormalMeanPrecision(h, 1.0)\n    y ~ NormalMeanPrecision(x, 10.0)\nend\n\n# Implicit Prediction\nresult = infer(model = example_model(), data = (y = missing,))\n\nInference results:\n  Posteriors       | available for (h, x)\n  Predictions      | available for (y)\n\n# Explicit Prediction\nresult = infer(model = example_model(), predictvars = (y = KeepLast(),))\n\nInference results:\n  Posteriors       | available for (h, x)\n  Predictions      | available for (y)\n\nBoth approaches yield the same results, but the choice depends on personal preferences and the model's structure. In scenarios with a clear distinction between observed and predicted variables, the explicit method is preferable. However, our subsequent example will not differentiate between observations and predictions, as it utilizes a state space representation.\n\nusing CSV, DataFrames, Plots","category":"section"},{"location":"categories/basic_examples/predicting_bike_rental_demand/#Objective","page":"Predicting Bike Rental Demand","title":"Objective","text":"This example aims to simultaneously learn the dynamics of the feature space and predict hourly bike rental demand through reactive message passing, a signature approach of RxInfer.jl.","category":"section"},{"location":"categories/basic_examples/predicting_bike_rental_demand/#Dataset-Source","page":"Predicting Bike Rental Demand","title":"Dataset Source","text":"Data for this example study is sourced from the Kaggle Bike Count Prediction Dataset. For the purpose of this example, the original dataset from Kaggle has been adapted by removing categorical variables such as season, holiday, and working day. Additionally we take only 500 entries. This modification allows us to focus on modeling the continuous variables without additional complexities of handling categorical data. Nevertheless, this extension is feasible within RxInfer.jl.\n\n# Load the data\ndf = CSV.read(\"modified_bicycle.csv\", DataFrame)\ndf[1:10, :]\n\n10√ó6 DataFrame\n Row ‚îÇ datetime            temp     atemp    humidity  windspeed  count\n     ‚îÇ String31            Float64  Float64  Float64   Float64    Int64\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n   1 ‚îÇ 2011-01-01 0:00:00     9.84   14.395      81.0     0.0        16\n   2 ‚îÇ 2011-01-01 1:00:00     9.02   13.635      80.0     0.0        40\n   3 ‚îÇ 2011-01-01 2:00:00     9.02   13.635      80.0     0.0        32\n   4 ‚îÇ 2011-01-01 3:00:00     9.84   14.395      75.0     0.0        13\n   5 ‚îÇ 2011-01-01 4:00:00     9.84   14.395      75.0     0.0         1\n   6 ‚îÇ 2011-01-01 5:00:00     9.84   12.88       75.0     6.0032      1\n   7 ‚îÇ 2011-01-01 6:00:00     9.02   13.635      80.0     0.0         2\n   8 ‚îÇ 2011-01-01 7:00:00     8.2    12.88       86.0     0.0         3\n   9 ‚îÇ 2011-01-01 8:00:00     9.84   14.395      75.0     0.0         8\n  10 ‚îÇ 2011-01-01 9:00:00    13.12   17.425      76.0     0.0        14\n\n# we reserve few samples for prediction\nn_future = 24\n\n# `x` is a sequence of observed features\nX = Union{Vector{Float64}, Missing}[[row[i] for i in 2:(ncol(df))-1] for row in eachrow(df)][1:end-n_future]\n\n# `y` is a sequence of \"count\" bicycles\ny = Union{Float64, Missing}[df[:, \"count\"]...][1:end-n_future]\n\nstate_dim = length(X[1]); # dimensionality of feature space","category":"section"},{"location":"categories/basic_examples/predicting_bike_rental_demand/#Generative-Model-with-Priors","page":"Predicting Bike Rental Demand","title":"Generative Model with Priors","text":"We present a generative model that delineates the latent dynamics of feature evolution, represented by mathbfh_t, and their link to the bike rental counts, mathbfy_t.","category":"section"},{"location":"categories/basic_examples/predicting_bike_rental_demand/#Equations-and-Priors","page":"Predicting Bike Rental Demand","title":"Equations and Priors","text":"Feature Dynamics with Prior:\nPrior: mathbfa sim mathcalN(mathbf0 mathbfI)\nDynamics: mathbfh_t sim mathcalN(mathbfA h_t-1 mathbfQ)\nmathbfA\nis the transition matrix, reshaped from the prior vector mathbfa, and mathbfQ represents process noise.\nNoisy Observations:\nmathbfx_t sim mathcalN(mathbfh_t mathbfP)\nRepresents the observed noisy state of the features.\nCount Prediction with Prior:\nPrior: boldsymboltheta sim mathcalN(mathbf0 mathbfI)\nPrediction: y_t sim mathcalN(textsoftplus(boldsymboltheta^topmathbfh_t) sigma^2)\nModels the bike rental count as influenced by a non-linear transformation of the hidden state.","category":"section"},{"location":"categories/basic_examples/predicting_bike_rental_demand/#Interpretation","page":"Predicting Bike Rental Demand","title":"Interpretation","text":"This framework aims to simultaneously infer the transition matrix mathbfA and the regression parameters boldsymboltheta, providing a comprehensive view of the feature space dynamics and the count prediction.\nBy employing Gaussian priors on both mathbfa and boldsymboltheta, we incorporate beliefs about their distributions.\nThe inference process aims to discover these underlying dynamics, enabling predictions of both features mathbfx_t and counts y_t.\n\n# # We augument the dataset with missing entries for 24 hours ahead\nappend!(X, repeat([missing], n_future))\nappend!(y, repeat([missing], n_future));\n\n# Function to perform the state transition in the model.\n# It reshapes vector `a` into a matrix and multiplies it with vector `x` to simulate the transition.\nfunction transition(a, x)\n    nm, n = length(a), length(x)\n    m = nm √∑ n  # Calculate the number of rows for reshaping 'a' into a matrix\n    A = reshape(a, (m, n))  \n    return A * x\nend\n\ntransition (generic function with 1 method)\n\n# The dotsoftplus function combines a dot product and softplus transformation.\n# While useful for ensuring positivity, it may not be the optimal choice for all scenarios,\n# especially if the data suggests other forms of relationships or distributions.\nimport StatsFuns: softplus\ndotsoftplus(a, x) = softplus(dot(a, x))\n\ndotsoftplus (generic function with 1 method)\n\n# model definction\n@model function bicycle_ssm(x, y, h0, Œ∏0, a0, Q, s)\n\n    a ~ a0\n    Œ∏ ~ Œ∏0\n    h_prior ~ h0\n\n    h_prev = h_prior\n    for i in eachindex(y)\n        \n        h[i] ~ MvNormal(Œº=transition(a, h_prev), Œ£=Q)\n        x[i] ~ MvNormal(Œº=h[i], Œ£=diageye(state_dim))\n        y[i] ~ Normal(Œº=dotsoftplus(Œ∏, h[i]), œÉ¬≤=s)\n        h_prev = h[i]\n    end\n\nend\n\n# In this example, we opt for a basic Linearization approach for the transition and dotsoftplus functions.\n# However, alternative methods like Unscented or CVI approximations can also be considered.\nbicycle_ssm_meta = @meta begin \n    transition() -> Linearization()\n    dotsoftplus() -> Linearization()\nend\n\nMeta: \n  transition() -> ReactiveMP.Linearization()\n  dotsoftplus() -> ReactiveMP.Linearization()\n\n# prior_h: Based on first observation, assuming initial state is similar with equal variance.\nprior_h = MvNormalMeanCovariance(X[1], diageye(state_dim))\n# prior_Œ∏, prior_a: No initial bias, parameters independent with equal uncertainty.\nprior_Œ∏ = MvNormalMeanCovariance(zeros(state_dim), diageye(state_dim))\nprior_a = MvNormalMeanCovariance(zeros(state_dim^2), diageye(state_dim^2));\n\nNote that, in contrast with other examples, we wrap the data y in an UnfactorizedData struct. This is to indicate to the inference engine that we want to infer a joint posterior distribution over the missing values in y and the latent variables. More information on this can be found in the documentation on variational constraints.\n\n# the deterministic relationsships (transition) and (dotsoftplus) will induce loops in the graph representation of our model, this necessiates the initialization of the messages\nimessages = @initialization begin\n    Œº(h) = prior_h\n    Œº(a) = prior_a\n    Œº(Œ∏) = prior_Œ∏\nend\n# Assumptions about the model parameters:\n# Q: Process noise based on observed features' variance, assuming process variability reflects observed features variability.\n# s: Observation noise based on observed data variance, directly estimating variance in the data, important for predictions\nbicycle_model = bicycle_ssm(h0=prior_h, Œ∏0=prior_Œ∏, a0=prior_a, Q=var(filter(!ismissing, X)).*diageye(state_dim), s=var(filter(!ismissing, y)))\n\nresult = infer(\n    model = bicycle_model,\n    data  = (x=X, y=UnfactorizedData(y)), \n    options = (limit_stack_depth = 500, ), \n    returnvars = KeepLast(),\n    predictvars = KeepLast(),\n    initialization = imessages,\n    meta = bicycle_ssm_meta,\n    iterations = 20,\n    showprogress=true,\n)\n\nInference results:\n  Posteriors       | available for (a, h, h_prior, Œ∏)\n  Predictions      | available for (y, x)\n\n# For a sake of this example, we extract only predictions\nmean_y, cov_y = mean.(result.predictions[:y]), cov.(result.predictions[:y])\nmean_x, cov_x = mean.(result.predictions[:x]), var.(result.predictions[:x])\n\nmean_x1, cov_x1 = getindex.(mean_x, 1), getindex.(cov_x, 1)\nmean_x2, cov_x2 = getindex.(mean_x, 2), getindex.(cov_x, 2)\nmean_x3, cov_x3 = getindex.(mean_x, 3), getindex.(cov_x, 3)\nmean_x4, cov_x4 = getindex.(mean_x, 4), getindex.(cov_x, 4);\n\nslice = (300, length(y))\ndata = df[:, \"count\"][length(y)-n_future:length(y)]\n\np = scatter(y, \n            color=:darkblue, \n            markerstrokewidth=0,\n            label=\"Observed Count\", \n            alpha=0.6)\n\n# Plotting the mean prediction with variance ribbon\nplot!(mean_y, ribbon=sqrt.(cov_y), \n      color=:orange, \n      fillalpha=0.3,\n      label=\"Predicted Mean ¬± Std Dev\")\n\n# Adding a vertical line to indicate the start of the future prediction\nvline!([length(y)-n_future], \n       label=\"Prediction Start\", \n       linestyle=:dash, \n       linecolor=:green)\n\n# Future (unobserved) data\nplot!(length(y)-n_future:length(y), data, label=\"Future Count\")\n\n# Adjusting the limits\nxlims!(slice)\n\n# Enhancing the plot with titles and labels\ntitle!(\"Bike Rental Demand Prediction\")\nxlabel!(\"Time\")\nylabel!(\"Bike Count\")\n\n# Adjust the legend\nlegend=:topright\n\n# Show the final plot\ndisplay(p)\n\n(Image: )\n\nusing Plots\n\n# Define a color palette\npalette = cgrad(:viridis)\n\n# Plot the hidden states with observations\np1 = plot(mean_x1, ribbon=sqrt.(cov_x1), color=palette[1], label=\"Hidden State 1\", legend=:topleft)\nplot!(df[!, :temp], color=:grey, label=\"Temperature\")\nvline!([length(y)-n_future], linestyle=:dash, color=:red, label=\"Prediction Start\")\nxlabel!(\"Time\")\nylabel!(\"Value\")\ntitle!(\"Temperature vs Hidden State 1\")\n\np2 = plot(mean_x2, ribbon=sqrt.(cov_x2), color=palette[2], label=\"Hidden State 2\", legend=:topleft)\nplot!(df[!, :atemp], color=:grey, label=\"Feels-Like Temp\")\nvline!([length(y)-n_future], linestyle=:dash, color=:red, label=\"\")\nxlabel!(\"Time\")\nylabel!(\"Value\")\ntitle!(\"Feels-Like Temp vs Hidden State 2\")\n\np3 = plot(mean_x3, ribbon=sqrt.(cov_x3), color=palette[3], label=\"Hidden State 3\", legend=:topleft)\nplot!(df[!, :humidity], color=:grey, label=\"Humidity\")\nvline!([length(y)-n_future], linestyle=:dash, color=:red, label=\"Prediction Start\")\nxlabel!(\"Time\")\nylabel!(\"Value\")\ntitle!(\"Humidity vs Hidden State 3\")\n\np4 = plot(mean_x4, ribbon=sqrt.(cov_x4), color=palette[4], label=\"Hidden State 4\", legend=:topleft)\nplot!(df[!, :windspeed], color=:grey, label=\"Windspeed\")\nvline!([length(y)-n_future], linestyle=:dash, color=:red, label=\"Prediction Start\")\nxlabel!(\"Time\")\nylabel!(\"Value\")\ntitle!(\"Windspeed vs Hidden State 4\")\n\nfor p in [p1, p2, p3, p4]\n    xlims!(p, first(slice), last(slice))\nend\n\nplot(p1, p2, p3, p4, layout=(2, 2), size=(800, 400))\n\n(Image: )","category":"section"},{"location":"categories/basic_examples/predicting_bike_rental_demand/#Improving-the-model","page":"Predicting Bike Rental Demand","title":"Improving the model","text":"While our current model's predictions may not closely match real-world data, it's important to recognize that certain assumptions and simplifications were made that might have affected the results. The model is essentially a theoretical framework, highlighting the ability to simultaneously deduce states, parameters, and predictions, with an emphasis on the analysis's predictive aspect.\n\nTo enhance the model and refine its predictions, we can employ variational message passing. This method enables us to eliminate loops within the model by substituting initial messages with initial marginal distributions. This is achieved by utilizing ContinuousTransition (also referred to as CTransition) and SoftDot (aka softdot) nodes. These nodes facilitate the variational approximation of the transition matrix and the dot product, respectively.\n\ntransformation = a -> reshape(a, state_dim, state_dim)\n\n#45 (generic function with 1 method)\n\n# model definction\n@model function bicycle_ssm_advanced(x, y, h0, Œ∏0, a0, P0, Œ≥0)\n\n    a ~ a0\n    Œ∏ ~ Œ∏0\n    h_prior ~ h0\n    P ~ P0\n    Œ≥ ~ Œ≥0\n\n    h_prev = h_prior\n    for i in eachindex(y)\n        \n        h[i] ~ CTransition(h_prev, a, P)\n        x[i]  ~ MvNormal(Œº=h[i], Œõ=diageye(state_dim))\n        _y[i] ~ softdot(Œ∏, h[i], Œ≥)\n        y[i] ~ Normal(Œº=softplus(_y[i]), Œ≥=1e4)\n        h_prev = h[i]\n    end\n\nend\n\nbicycle_ssm_advanced_meta = @meta begin \n    softplus() -> Linearization()\n    CTransition() -> CTMeta(transformation)\nend\n\nMeta: \n  softplus() -> ReactiveMP.Linearization()\n  ReactiveMP.ContinuousTransition() -> ReactiveMP.ContinuousTransitionMeta{\nMain.var\"##WeaveSandBox#277\".var\"#45#46\"}(Main.var\"##WeaveSandBox#277\".var\"\n#45#46\"())\n\nbicycle_ssm_advanced_constraints = @constraints begin\n    q(h_prior, h, a, P, Œ≥, _y, y, Œ∏) = q(h_prior, h)q(a)q(P)q(Œ≥)q(_y, y)q(Œ∏)\nend\n\nConstraints: \n  q(h_prior, h, a, P, Œ≥, _y, y, Œ∏) = q(h_prior, h)q(a)q(P)q(Œ≥)q(_y, y)q(Œ∏)\n\nprior_P = ExponentialFamily.WishartFast(state_dim+2, inv.(var(filter(!ismissing, X))) .* diageye(state_dim))\nprior_a = MvNormalMeanPrecision(ones(state_dim^2), diageye(state_dim^2));\n\nprior_Œ≥ = GammaShapeRate(1.0, var(filter(!ismissing, y)))\nprior_h = MvNormalMeanPrecision(X[1], diageye(state_dim))\nprior_Œ∏ = MvNormalMeanPrecision(ones(state_dim), diageye(state_dim))\n\nimarginals = @initialization begin \n    q(h) = prior_h\n    q(a) = prior_a\n    q(P) = prior_P\n    q(Œ≥) = prior_Œ≥\n    q(Œ∏) = prior_Œ∏\nend\n\nbicycle_model_advanced = bicycle_ssm_advanced(h0=prior_h, Œ∏0=prior_Œ∏, a0=prior_a, P0=prior_P, Œ≥0=prior_Œ≥)\n\nresult_advanced = infer(\n    model = bicycle_model_advanced,\n    data  = (x=X, y=y), \n    options = (limit_stack_depth = 500, ), \n    returnvars = KeepLast(),\n    predictvars = KeepLast(),\n    initialization = imarginals,\n    constraints = bicycle_ssm_advanced_constraints,\n    meta = bicycle_ssm_advanced_meta,\n    iterations = 10,\n    showprogress=true,\n)\n\nInference results:\n  Posteriors       | available for (a, P, _y, Œ≥, h, h_prior, Œ∏)\n  Predictions      | available for (y, x)\n\n# For a sake of this example, we extract only predictions\nmean_y, cov_y = mean.(result_advanced.predictions[:y]), cov.(result_advanced.predictions[:y])\n\n([16.000001019201765, 39.9999999771452, 32.00000029690829, 13.0000012305664\n04, 1.000001735201384, 1.0000019345942357, 2.0000015515352927, 3.0000014149\n59412, 8.000001680637501, 14.000001845050349  ‚Ä¶  30.82842295139951, 30.4929\n08849036418, 30.183612275461122, 29.894986174185842, 29.62244238693725, 29.\n362221778403438, 29.111291014204685, 28.867262253795694, 28.628327961897945\n, 28.393168163887722], [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0\n001, 0.0001, 0.0001, 0.0001  ‚Ä¶  0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0\n001, 0.0001, 0.0001, 0.0001, 0.0001])\n\nslice = (300, length(y))\ndata = df[:, \"count\"][length(y)-n_future:length(y)]\n\npa = scatter(y, \n            color=:darkblue, \n            markerstrokewidth=0,\n            label=\"Observed Count\", \n            alpha=0.6)\n\n# Plotting the mean prediction with variance ribbon\nplot!(mean_y, ribbon=sqrt.(cov_y), \n      color=:orange, \n      fillalpha=0.3,\n      label=\"Predicted Mean ¬± Std Dev\")\n\n# Adding a vertical line to indicate the start of the future prediction\nvline!([length(y)-n_future], \n       label=\"Prediction Start\", \n       linestyle=:dash, \n       linecolor=:green)\n\n# Future (unobserved) data\nplot!(length(y)-n_future:length(y), data, label=\"Future Count\")\n\n# Adjusting the limits\nxlims!(slice)\n\n# Enhancing the plot with titles and labels\ntitle!(\"Advanced model\")\nxlabel!(\"Time\")\nylabel!(\"Bike Count\")\n\n# Adjust the legend\nlegend=:topright\n\n# Show the final plot\nplot(pa, p, size=(800, 400))\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [336ed68f] CSV v0.10.16\n  [a93c6f00] DataFrames v1.8.1\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [4c63d2b9] StatsFuns v1.5.2\n\n\n","category":"section"},{"location":"categories/advanced_examples/infinite_data_stream/","page":"Infinite Data Stream","title":"Infinite Data Stream","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/infinite_data_stream/#Infinite-Data-Stream","page":"Infinite Data Stream","title":"Infinite Data Stream","text":"This example shows the capabilities of RxInfer to perform Bayesian inference on real-time signals. As usual, first, we start with importing necessary packages:\n\nusing RxInfer, Plots, Random, StableRNGs\n\nFor demonstration purposes we will create a synthetic environment that has a hidden underlying signal, which we cannot observer directly. Instead, we will observe a noised realisation of this hidden signal:\n\nmutable struct Environment\n    rng                   :: AbstractRNG\n    current_state         :: Float64\n    observation_precision :: Float64\n    history               :: Vector{Float64}\n    observations          :: Vector{Float64}\n    \n    Environment(current_state, observation_precision; seed = 123) = begin \n         return new(StableRNG(seed), current_state, observation_precision, [], [])\n    end\nend\n\nfunction getnext!(environment::Environment)\n    environment.current_state = environment.current_state + 1.0\n    nextstate  = 10sin(0.1 * environment.current_state)\n    observation = rand(NormalMeanPrecision(nextstate, environment.observation_precision))\n    push!(environment.history, nextstate)\n    push!(environment.observations, observation)\n    return observation\nend\n\nfunction gethistory(environment::Environment)\n    return environment.history\nend\n\nfunction getobservations(environment::Environment)\n    return environment.observations\nend\n\ngetobservations (generic function with 1 method)","category":"section"},{"location":"categories/advanced_examples/infinite_data_stream/#Model-specification","page":"Infinite Data Stream","title":"Model specification","text":"We assume that we don't know the shape of our signal in advance. So we try to fit a simple gaussian random walk with unknown observation noise:\n\n@model function kalman_filter(x_prev_mean, x_prev_var, œÑ_shape, œÑ_rate, y)\n    x_prev ~ Normal(mean = x_prev_mean, variance = x_prev_var)\n    œÑ ~ Gamma(shape = œÑ_shape, rate = œÑ_rate)\n\n    # Random walk with fixed precision\n    x_current ~ Normal(mean = x_prev, precision = 1.0)\n    y ~ Normal(mean = x_current, precision = œÑ)\n    \nend\n\n# We assume the following factorisation between variables \n# in the variational distribution\n@constraints function filter_constraints()\n    q(x_prev, x_current, œÑ) = q(x_prev, x_current)q(œÑ)\nend\n\nfilter_constraints (generic function with 1 method)","category":"section"},{"location":"categories/advanced_examples/infinite_data_stream/#Prepare-environment","page":"Infinite Data Stream","title":"Prepare environment","text":"initial_state         = 0.0\nobservation_precision = 0.1\n\n0.1\n\nAfter we have created the environment we can observe how our signal behaves:\n\ntestenvironment = Environment(initial_state, observation_precision);\n\nanimation = @animate for i in 1:100\n    getnext!(testenvironment)\n    \n    history = gethistory(testenvironment)\n    observations = getobservations(testenvironment)\n    \n    p = plot(size = (1000, 300))\n    \n    p = plot!(p, 1:i, history[1:i], label = \"Hidden signal\")\n    p = scatter!(p, 1:i, observations[1:i], ms = 4, alpha = 0.7, label = \"Observation\")\nend\n\ngif(animation, \"infinite-data-stream.gif\", fps = 24, show_msg = false);\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/infinite_data_stream/#Filtering-on-static-dataset","page":"Infinite Data Stream","title":"Filtering on static dataset","text":"RxInfer is flexible and allows for running inference both on real-time and static datasets. In the next section we show how to perform the filtering procedure on a static dataset. We also will verify our inference procedure by checking on the Bethe Free Energy values:\n\nn                  = 300\nstatic_environment = Environment(initial_state, observation_precision);\n\nfor i in 1:n\n    getnext!(static_environment)\nend\n\nstatic_history      = gethistory(static_environment)\nstatic_observations = getobservations(static_environment);\nstatic_datastream   = from(static_observations) |> map(NamedTuple{(:y,), Tuple{Float64}}, (d) -> (y = d, ));\n\nfunction run_static(environment, datastream)\n    \n    # `@autoupdates` structure specifies how to update our priors based on new posteriors\n    # For example, every time we have updated a posterior over `x_current` we update our priors\n    # over `x_prev`\n    autoupdates = @autoupdates begin \n        x_prev_mean, x_prev_var = mean_var(q(x_current))\n        œÑ_shape = shape(q(œÑ))\n        œÑ_rate = rate(q(œÑ))\n    end\n    \n    init = @initialization begin\n        q(x_current) = NormalMeanVariance(0.0, 1e3) \n        q(œÑ) = GammaShapeRate(1.0, 1.0)\n    end\n\n    engine = infer(\n        model          = kalman_filter(),\n        constraints    = filter_constraints(),\n        datastream     = datastream,\n        autoupdates    = autoupdates,\n        returnvars     = (:x_current, ),\n        keephistory    = 10_000,\n        historyvars    = (x_current = KeepLast(), œÑ = KeepLast()),\n        initialization = init,\n        iterations     = 10,\n        free_energy    = true,\n        autostart      = true,\n    )\n    \n    return engine\nend\n\nrun_static (generic function with 1 method)\n\nresult = run_static(static_environment, static_datastream);\n\nstatic_inference = @animate for i in 1:n\n    estimated = result.history[:x_current]\n    p = plot(1:i, mean.(estimated[1:i]), ribbon = var.(estimated[1:n]), label = \"Estimation\")\n    p = plot!(static_history[1:i], label = \"Real states\")    \n    p = scatter!(static_observations[1:i], ms = 2, label = \"Observations\")\n    p = plot(p, size = (1000, 300), legend = :bottomright)\nend\n\ngif(static_inference, \"infinite-data-stream-inference.gif\", fps = 24, show_msg = false);\n\n(Image: )\n\nplot(result.free_energy_history, label = \"Bethe Free Energy (averaged)\")\n\n(Image: )","category":"section"},{"location":"categories/advanced_examples/infinite_data_stream/#Filtering-on-realtime-dataset","page":"Infinite Data Stream","title":"Filtering on realtime dataset","text":"Next lets create a \"real\" infinite stream. We use timer() observable from Rocket.jlto emulate real-world scenario. In our example we are going to generate a new data point every ~41ms (24 data points per second). For demonstration purposes we force stop after n data points, but there is no principled limitation to run inference indefinite:\n\nfunction run_and_plot(environment, datastream)\n    \n    # `@autoupdates` structure specifies how to update our priors based on new posteriors\n    # For example, every time we have updated a posterior over `x_current` we update our priors\n    # over `x_prev`\n    autoupdates = @autoupdates begin \n        x_prev_mean, x_prev_var = mean_var(q(x_current))\n        œÑ_shape = shape(q(œÑ))\n        œÑ_rate = rate(q(œÑ))\n    end\n    \n    posteriors = []\n    \n    plotfn = (q_current) -> begin \n        IJulia.clear_output(true)\n        \n        push!(posteriors, q_current)\n\n        p = plot(mean.(posteriors), ribbon = var.(posteriors), label = \"Estimation\")\n        p = plot!(gethistory(environment), label = \"Real states\")    \n        p = scatter!(getobservations(environment), ms = 2, label = \"Observations\")\n        p = plot(p, size = (1000, 300), legend = :bottomright)\n\n        display(p)\n    end\n    \n    init = @initialization begin\n        q(x_current) = NormalMeanVariance(0.0, 1e3)\n        q(œÑ) = GammaShapeRate(1.0, 1.0)\n    end\n\n    engine = infer(\n        model         = kalman_filter(),\n        constraints   = filter_constraints(),\n        datastream    = datastream,\n        autoupdates   = autoupdates,\n        returnvars    = (:x_current, ),\n        initialization = init,\n        iterations    = 10,\n        autostart     = false,\n    )\n    \n    qsubscription = subscribe!(engine.posteriors[:x_current], plotfn)\n    \n    RxInfer.start(engine)\n    \n    return engine\nend\n\nrun_and_plot (generic function with 1 method)\n\n# This example runs in our documentation pipeline, which does not support \"real-time\" execution context\n# We skip this code if run not in Jupyter notebook (see below an example with gif)\nengine = nothing \nif isdefined(Main, :IJulia)\n    timegen      = 41 # 41 ms\n    environment  = Environment(initial_state, observation_precision);\n    observations = timer(timegen, timegen) |> map(Float64, (_) -> getnext!(environment)) |> take(n) # `take!` automatically stops after `n` observations\n    datastream   = observations |> map(NamedTuple{(:y,), Tuple{Float64}}, (d) -> (y = d, ));\n    engine = run_and_plot(environment, datastream)\nend;\n\nThe plot above is fully interactive and we can stop and unsubscribe from our datastream before it ends:\n\nif !isnothing(engine) && isdefined(Main, :IJulia)\n    RxInfer.stop(engine)\n    IJulia.clear_output(true)\nend;\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/problem_specific/universal_mixtures/","page":"Universal Mixtures","title":"Universal Mixtures","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/problem_specific/universal_mixtures/#Universal-Mixtures","page":"Universal Mixtures","title":"Universal Mixtures","text":"using RxInfer, Distributions, Random, Plots\n\nJohn and Jane are having a coin toss competition. Before they start, they both have the feeling that something is not right. The coin is unbalanced and favors one side over the other. However, both John and Jane do not know which side is being favored. John thinks that the coin favors heads and Jane thinks tails. Coincidentally, both John and Jane have a strong mathematics background and are aware of the appropriate likelihood function for this experiment\n\np(y_i mid theta) = mathrmBer(y_i mid theta)\n\nwhere y_i in 01 are the outcomes of the coin tosses, i.e. heads or tails, and where theta is the coin parameter. They express their gut feeling about the fairness of the coin in terms of a prior distribution over the coin parameter theta, which represents the probability of the coin landing on heads. Based on their gut feeling and the support of thetain01 they come up with the prior beliefs:\n\np(theta mid textJohn) = mathrmBeta(theta mid 7 2)\n\np(theta mid textJane) = mathrmBeta(theta mid 2 7)\n\nrŒ∏ = range(0, 1, length = 1000)\np = plot(title = \"prior beliefs\")\nplot!(rŒ∏, (x) -> pdf(Beta(7.0, 2.0), x), fillalpha=0.3, fillrange = 0, label=\"P(Œ∏) John\", c=1)\nplot!(rŒ∏, (x) -> pdf(Beta(2.0, 7.0), x), fillalpha=0.3, fillrange = 0, label=\"p(Œ∏) Jane\", c=3,)\n\n(Image: )\n\nJohn and Jane really want to clear the odds and decide to perform a lengthy experiment. They toss the unbalanced coin N = 10 times, because their favorite TV show is cancelled anyway and therefore they have plenty of time. \n\ntrue_coin = Bernoulli(0.25)\nnr_throws = 10\ndataset = Int.(rand(MersenneTwister(42), true_coin, nr_throws))\nnr_heads, nr_tails = sum(dataset), nr_throws-sum(dataset)\nprintln(\"experimental outcome: \\n - heads: \", nr_heads, \"\\n - tails: \", nr_tails);\n\nexperimental outcome: \n - heads: 5\n - tails: 5\n\nFor computing the posterior beliefs p(theta mid y) about the parameter theta, they will perform probabilistic inference in the model based on Bayes' rule. Luckily everything is tractable and therefore they can resort to exact inference. They decide to outsource these tedious computations using RxInfer.jl and specify the following models:","category":"section"},{"location":"categories/problem_specific/universal_mixtures/#John's-model:","page":"Universal Mixtures","title":"John's model:","text":"p(y theta mid textJohn) = p(theta mid textJohn) prod_i=1^N p(y_i mid theta)\n\n@model function beta_model_john(y)\n\n    # specify John's prior model over Œ∏\n    Œ∏ ~ Beta(7.0, 2.0)\n\n    # create likelihood models\n    y .~ Bernoulli(Œ∏)\n    \nend","category":"section"},{"location":"categories/problem_specific/universal_mixtures/#Jane's-model:","page":"Universal Mixtures","title":"Jane's model:","text":"p(y theta mid textJane) = p(theta mid textJane) prod_i=1^N p(y_i mid theta)\n\n@model function beta_model_jane(y)\n\n    # specify Jane's prior model over Œ∏\n    Œ∏ ~ Beta(2.0, 7.0)\n\n    # create likelihood models\n    y .~ Bernoulli(Œ∏)\n    \nend\n\nNow it is time to figure out whose prior belief was the best and who was actually right. They perform probabilistic inference automatically and compute the Bethe free energy to compare eachothers models. For acyclic models, the Bethe free energy mathrmF_B bounds the model evidence p(y) as \n\nmathrmF_Bpq geq - ln p(y)\n\nresult_john = infer(\n    model = beta_model_john(), \n    data  = (y = dataset, ),\n    free_energy = true,\n)\n\nInference results:\n  Posteriors       | available for (Œ∏)\n  Free Energy:     | Real[8.28853]\n\nresult_jane = infer(\n    model = beta_model_jane(), \n    data  = (y = dataset, ),\n    free_energy = true\n)\n\nInference results:\n  Posteriors       | available for (Œ∏)\n  Free Energy:     | Real[8.28853]\n\nFrom these results, they agree that Jane her gut feeling was right all along, as her Bethe free energy is lower and therefore her model evidence is higher. Nonetheless, after the 10 throws, they now have a better idea about the underlying theta parameter. They formulate this through the posterior distributions p(theta mid y textJohn) and p(theta mid y textJane):\n\nrŒ∏ = range(0, 1, length = 1000)\np = plot(title = \"posterior beliefs\")\nplot!(rŒ∏, (x) -> pdf(result_john.posteriors[:Œ∏], x), fillalpha=0.3, fillrange = 0, label=\"P(Œ∏|y) John\", c=1)\nplot!(rŒ∏, (x) -> pdf(result_jane.posteriors[:Œ∏], x), fillalpha=0.3, fillrange = 0, label=\"p(Œ∏|y) Jane\", c=3,)\n\n(Image: )\n\nWhat John and Jane did not know, was that Mary, their neighbour, was overhearing their conversation. She was also curious, but could not see the coin. She did not really know how to formulate a prior distribution over theta, so instead she combined both John and Jane their prior beliefs. She had the feeling that John his assessment was more correct, as he was often going to the casino. As a result, she mixed the prior beliefs of John and Jane with proportions 0.7 and 0.3, respectively. Her model for the environment is specified as\n\np(y theta c mid textMary) = p(c mid textMary)  p(theta mid textJohn)^c p(theta mid textJane)^1-c prod_i=1^N p(y_i mid theta)\n\nwhere c describes the probability of John being correct as \n\np(c mid textMary) = mathrmBer(c mid 07)\n\nThe predictive distribution p(theta mid textMary) for theta (similar to the prior beliefs of John and Jane) she obtained from the marginalisation over c as\n\np(theta mid textMary) = sum_cin01 p(cmidtextMary) p(theta mid textJohn)^c p(theta mid textJane)^1-c = 07 cdot p(theta mid textJohn) + 03 cdot p(theta mid textJane)\n\nrŒ∏ = range(0, 1, length = 1000)\np = plot(title = \"prior belief\")\nplot!(rŒ∏, (x) -> pdf(MixtureDistribution([Beta(2.0, 7.0), Beta(7.0, 2.0)], [ 0.3, 0.7 ]), x), fillalpha=0.3, fillrange = 0, label=\"P(Œ∏) Mary\", c=1)\nplot!(rŒ∏, (x) -> 0.7*pdf(Beta(7.0, 2.0), x), c=3, label=\"\")\nplot!(rŒ∏, (x) -> 0.3*pdf(Beta(2.0, 7.0), x), c=3, label=\"\")\n\n(Image: )\n\nShe was also interested in the results and used the new Mixture node and addons in ReactiveMP.jl. She specified her model as follows and performed inference in this model:\n\n@model function beta_model_mary(y)\n\n    # specify John's and Jane's prior models over Œ∏\n    Œ∏_jane ~ Beta(2.0, 7.0)\n    Œ∏_john ~ Beta(7.0, 2.0)\n\n    # specify initial guess as to who is right\n    john_is_right ~ Bernoulli(0.7) \n\n    # specify mixture prior Distribution\n    Œ∏ ~ Mixture(switch = john_is_right, inputs = [Œ∏_jane, Œ∏_john])\n\n    # create likelihood models\n    y .~ Bernoulli(Œ∏)\n    \nend\n\nThis Mixture node updates the belief over c on the performance of the individual models of both John and Jane using so-called scale factors, as introduced in Nguyen et al.. The specific update rules for this node can be found here.\n\nresult_mary = infer(\n    model = beta_model_mary(), \n    data  = (y = dataset, ),\n    returnvars = (Œ∏ = KeepLast(), Œ∏_john = KeepLast(), Œ∏_jane = KeepLast(), john_is_right = KeepLast()),\n    addons = AddonLogScale(),\n    postprocess = UnpackMarginalPostprocess(),\n)\n\nInference results:\n  Posteriors       | available for (john_is_right, Œ∏_john, Œ∏, Œ∏_jane)\n\nMary was happy, with her mixture prior, she beat John in terms of performance. However, it was not the best decision to think that John was right. In fact, after the experiment there was only a minor possibility remaining that John was right. Her posterior distribution over theta also changed, and as expected the estimate from Jane was more prominent.\n\nrŒ∏ = range(0, 1, length = 1000)\np = plot(title = \"posterior belief\")\nplot!(rŒ∏, (x) -> pdf(result_mary.posteriors[:Œ∏], x), fillalpha=0.3, fillrange = 0, label=\"P(Œ∏|y) Mary\", c=1)\nplot!(rŒ∏, (x) -> result_mary.posteriors[:Œ∏].weights[1] * pdf(component(result_mary.posteriors[:Œ∏], 1), x), label=\"\", c=3)\nplot!(rŒ∏, (x) -> result_mary.posteriors[:Œ∏].weights[2] * pdf(component(result_mary.posteriors[:Œ∏], 2), x), label=\"\", c=3)\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [31c24e10] Distributions v0.25.123\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"categories/advanced_examples/nonlinear_sensor_fusion/","page":"Nonlinear Sensor Fusion","title":"Nonlinear Sensor Fusion","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/nonlinear_sensor_fusion/#Nonlinear-Sensor-Fusion","page":"Nonlinear Sensor Fusion","title":"Nonlinear Sensor Fusion","text":"using RxInfer, Random, LinearAlgebra, Distributions, Plots, StatsPlots, Optimisers\nusing DataFrames, DelimitedFiles, StableRNGs\n\nIn a secret ongoing mission to Mars, NASA has deployed its custom lunar roving vehicle, called WALL-E, to explore the area and to discover hidden minerals. During one of the solar storm, WALL-E's GPS unit got damaged, preventing it from accurately locating itself. The engineers at NASA were devastated as they developed the project over the past couple of years and spend most of their funding on it. Without being able to locate WALL-E, they were unable to complete their mission.\n\nA smart group of engineers came up with a solution to locate WALL-E. They decided to repurpose 3 nearby satelites as beacons for WALL-E, allowing it to detect its relative location to these beacons. However, these satelites were old and therefore WALL-E was only able to obtain noisy estimates of its distance to these beacons. These distances were communicated back to earth, where the engineers tried to figure our WALL-E's location. Luckily they knew the locations of these satelites and together with the noisy estimates of the distance to WALL-E they can infer the exact location of the moving WALL-E.\n\nTo illustrate these noisy measurements, the engineers decided to plot them:\n\n# fetch measurements\nbeacon_locations = readdlm(\"data/beacons.txt\")\ndistances = readdlm(\"data/distances.txt\")\nposition = readdlm(\"data/position.txt\")\nnr_observations = size(distances, 1);\n\n# plot beacon and actual location of WALL-E\np1 = scatter(beacon_locations[:,1], beacon_locations[:,2], markershape=:utriangle, markersize=10, legend=:topleft, label=\"beacon locations\")\nplot!(position[1,:], position[2,:], label=\"actual location\", linewidth=3, linestyle=:dash, arrow=(:closed, 2.0), aspect_ratio=1.0)\nxlabel!(\"longitude [m]\"), ylabel!(\"latitude [m]\")\n\n# plot noisy distance measurements\np2 = plot(distances, legend=:topleft, linewidth=3, label=[\"distance to beacon 1\" \"distance to beacon 2\" \"distance to beacon 3\"])\nxlabel!(\"time [sec]\"), ylabel!(\"distance [m]\")\n\nplot(p1, p2, size=(1200, 500))\n\n(Image: )\n\nIn order to track the location of WALL-E based on the noisy distance measurements to the beacon, the engineers developed a probabilistic model for the movements for WALL-E and the distance measurements that followed from this. The engineers assumed that the position of WALL-E at time t, denoted by z_t, follows a 2-dimensional normal random walk:\n\nbeginaligned\n  p(z_t mid z_t - 1) = mathcalN(z_t mid z_t-1mathrmI_2)\nendaligned\n\nwhere mathrmI_2 denotes the 2-dimensional identity matrix. From the current position of WALL-E, we specify our noisy distance measurements y_t as a noisy set of the distances between WALL-E and the beacons, specified by s_i:\n\nbeginaligned\n  p(y_t mid z_t)  = mathcalN left (y_t left vert beginbmatrix  z_t - s_1  z_t - s_2  z_t - s_3endbmatrixmathrmI_3 right  right)\nendaligned\n\nThe engineers are smart enough to automate the probabilistic inference procedure using RxInfer.jl. They specify the probabilistic model as:\n\n# function to compute distance to beacons\nfunction compute_distances(z)    \n    distance1 = norm(z - beacon_locations[1,:])\n    distance2 = norm(z - beacon_locations[2,:])\n    distance3 = norm(z - beacon_locations[3,:])\n    distances = [distance1, distance2, distance3]\nend;\n\n@model function random_walk_model(y, W, R)\n    # specify initial estimates of the location\n    z[1] ~ MvNormalMeanCovariance(zeros(2), diageye(2)) \n    y[1] ~ MvNormalMeanCovariance(compute_distances(z[1]), diageye(3))\n\n    # loop over time steps\n    for t in 2:length(y)\n\n        # specify random walk state transition model\n        z[t] ~ MvNormalMeanPrecision(z[t-1], W)\n\n        # specify non-linear distance observations model\n        y[t] ~ MvNormalMeanPrecision(compute_distances(z[t]), R)\n        \n    end\n\nend;\n\nDue to non-linearity, exact probabilistic inference is intractable in this model. Therefore we resort to Conjugate-Computational Variational Inference (CVI) following the paper Probabilistic programming with stochastic variational message passing. This requires setting the @meta macro in RxInfer.jl.\n\nPlease note that we permit improper messages within the CVI procedure in this example by providing Val(false) to CVI constructor:\n\n    compute_distances(z) -> CVI(..., Val(false), ...)\n\nThis move may lead to numerical instabilities in other scenarios, however dissallowing improper messages in this case can lead to a biased estimates of posterior distribution. So, as a rule of thumb, you should try the default setting, and if it fails to find an unbiased result, enable improper messages.\n\n@meta function random_walk_model_meta(nr_samples, nr_iterations, rng)\n    compute_distances(z) -> CVI(rng, nr_samples, nr_iterations, Optimisers.Descent(0.1), ForwardDiffGrad(), 1, Val(false), false)\nend;\n\nNOTE: You can try out different meta for approximating the nonlinearity, e.g.\n\n@meta function random_walk_linear_meta()\n    compute_distances(z) -> Linearization()\nend;\n\n@meta function random_walk_unscented_meta()\n    compute_distances(z) -> Unscented()\nend;\n\ninit = @initialization begin \n    Œº(z) = MvNormalMeanPrecision(ones(2), 0.1 * diageye(2))\nend\n\nInitial state: \n  Œº(z) = MvNormalMeanPrecision(\nŒº: [1.0, 1.0]\nŒõ: [0.1 0.0; 0.0 0.1]\n)\n\nresults_fast = infer(\n    model = random_walk_model(W = diageye(2), R = diageye(3)),\n    meta = random_walk_model_meta(1, 3, StableRNG(42)), # or random_walk_unscented_meta()\n    data = (y = [distances[t,:] for t in 1:nr_observations],),\n    iterations = 20,\n    free_energy = false,\n    returnvars = (z = KeepLast(),),\n    initialization = init,\n);\n\nresults_accuracy = infer(\n    model = random_walk_model(W = diageye(2), R = diageye(3)),\n    meta = random_walk_model_meta(1000, 100, StableRNG(42)),\n    data = (y = [distances[t,:] for t in 1:nr_observations],),\n    iterations = 20,\n    free_energy = false,\n    returnvars = (z = KeepLast(),),\n    initialization = init,\n);\n\nAfter running this fast inference procedure, the engineers plot the results and evaluate the performance:\n\n# plot beacon and actual and estimated location of WALL-E (fast inference)\np1 = scatter(beacon_locations[:,1], beacon_locations[:,2], markershape=:utriangle, markersize=10, legend=:topleft, label=\"beacon locations\")\nplot!(position[1,:], position[2,:], label=\"actual location\", linewidth=3, linestyle=:dash, arrow=(:closed, 2.0), aspect_ratio=1.0)\nmap(posterior -> covellipse!(mean(posterior), cov(posterior), color=\"red\", label=\"\", n_std=2), results_fast.posteriors[:z])\nxlabel!(\"longitude [m]\"), ylabel!(\"latitude [m]\"), title!(\"Fast (1 sample, 3 iterations)\"); p1.series_list[end][:label] = \"estimated location ¬±2œÉ\"\n\n# plot beacon and actual and estimated location of WALL-E (accurate inference)\np2 = scatter(beacon_locations[:,1], beacon_locations[:,2], markershape=:utriangle, markersize=10, legend=:topleft, label=\"beacon locations\")\nplot!(position[1,:], position[2,:], label=\"actual location\", linewidth=3, linestyle=:dash, arrow=(:closed, 2.0), aspect_ratio=1.0)\nmap(posterior -> covellipse!(mean(posterior), cov(posterior), color=\"red\", label=\"\", n_std=2), results_accuracy.posteriors[:z])\nxlabel!(\"longitude [m]\"), ylabel!(\"latitude [m]\"), title!(\"Accurate (1000 samples, 100 iterations)\"); p2.series_list[end][:label] = \"estimated location ¬±2œÉ\"\n\nplot(p1, p2, size=(1200, 500))\n\n(Image: )\n\nThe engineers were very happy with the solution, as it meant that the Mars mission could continue. However, they noted that the estimates began to deviate after WALL-E moved further away from the beacons. They deemed this was likely due to the noise in the distance measurements. Therefore, the engineers decided to adapt the model, such that they would also infer the process and observation noise precision matrices, Q and R respectively. They did this by adding Wishart priors to those matrices:\n\nbeginaligned\n  p(Q) = mathcalW(Q mid 3 mathrmI_2) \n  p(R) = mathcalW(R mid 4 mathrmI_3) \n  p(z_t mid z_t - 1 Q) = mathcalN(z_t mid z_t-1 Q^-1)\n  p(y_t mid z_t R)  = mathcalN left (y_t left vert beginbmatrix  z_t - s_1  z_t - s_2  z_t - s_3endbmatrixR^-1 right  right)\nendaligned\n\n@model function random_walk_model_wishart(y)\n    # set priors on precision matrices\n    Q ~ Wishart(3, diageye(2))\n    R ~ Wishart(4, diageye(3))\n\n    # specify initial estimates of the location\n    z[1] ~ MvNormalMeanCovariance(zeros(2), diageye(2)) \n    y[1] ~ MvNormalMeanCovariance(compute_distances(z[1]), diageye(3))\n\n    # loop over time steps\n    for t in 2:length(y)\n\n        # specify random walk state transition model\n        z[t] ~ MvNormalMeanPrecision(z[t-1], Q)\n\n        # specify non-linear distance observations model\n        y[t] ~ MvNormalMeanPrecision(compute_distances(z[t]), R)\n        \n    end\n\nend;\n\nmeta = @meta begin \n    compute_distances(z) -> CVI(StableRNG(42), 1000, 100, Optimisers.Descent(0.01), ForwardDiffGrad(), 1, Val(false), false)\nend;\n\nBecause of the added complexity with the Wishart distributions, the engineers simplify the problem by employing a structured mean-field factorization:\n\nconstraints = @constraints begin\n    q(z, Q, R) = q(z)q(Q)q(R)\nend;\n\ninit = @initialization begin \n    Œº(z) = MvNormalMeanPrecision(zeros(2), 0.01 * diageye(2))\n    q(R) = Wishart(4, diageye(3))\n    q(Q) = Wishart(3, diageye(2))\nend;\n\nThe engineers run the inference procedure again and decide to track the inference performance using the Bethe free energy.\n\nresults_wishart = infer(\n    model = random_walk_model_wishart(),\n    data = (y = [distances[t,:] for t in 1:nr_observations],),\n    iterations = 20,\n    free_energy = true,\n    returnvars = (z = KeepLast(),),\n    constraints = constraints,\n    meta = meta,\n    initialization = init,\n);\n\nThey plot the new estimates and the performance over time, and luckily WALL-E is found!\n\n# plot beacon and actual and estimated location of WALL-E (fast inference)\np1 = scatter(beacon_locations[:,1], beacon_locations[:,2], markershape=:utriangle, markersize=10, legend=:topleft, label=\"beacon locations\")\nplot!(position[1,:], position[2,:], label=\"actual location\", linewidth=3, linestyle=:dash, arrow=(:closed, 2.0), aspect_ratio=1.0)\nmap(posterior -> covellipse!(mean(posterior), cov(posterior), color=\"red\", label=\"\", n_std=2), results_wishart.posteriors[:z])\nxlabel!(\"longitude [m]\"), ylabel!(\"latitude [m]\"); p1.series_list[end][:label] = \"estimated location ¬±2œÉ\"\n\n# plot bethe free energy performance\np2 = plot(results_wishart.free_energy[2:end], label = \"\")\nxlabel!(\"iteration\"), ylabel!(\"Bethe free energy [nats]\")\n\nplot(p1, p2, size=(1200, 500))\n\n(Image: )\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [a93c6f00] DataFrames v1.8.1\n  [8bb1440f] DelimitedFiles v1.9.1\n  [31c24e10] Distributions v0.25.123\n‚åÖ [3bd65402] Optimisers v0.3.4\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n  [f3b207a7] StatsPlots v0.15.8\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\nInfo Packages marked with ‚åÖ have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated`\n\n\n","category":"section"},{"location":"categories/experimental_examples/recurrent_switching_linear_dynamical_system/","page":"Recurrent Switching Linear Dynamical System","title":"Recurrent Switching Linear Dynamical System","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/experimental_examples/recurrent_switching_linear_dynamical_system/#Recurrent-Switching-Linear-Dynamical-System","page":"Recurrent Switching Linear Dynamical System","title":"Recurrent Switching Linear Dynamical System","text":"This is an experimental example of a Recurrent Switching Linear Dynamical System (RSLDS) model. The notebook requires patches to RxInfer and ReactiveMP, which are condensed in the hidden blocks below.\n\ndetails: Hidden block of RxInfer & ReactiveMP patches and extensions - click to expand\n\nusing ExponentialFamily, RxInfer, BayesBase, GraphPPL\nimport ReactiveMP: AbstractFactorNode, NodeInterface, IndexedNodeInterface, FactorNodeActivationOptions, Marginalisation,\n Deterministic, PredefinedNodeFunctionalForm,FunctionalDependencies, collect_functional_dependencies, activate!, functional_dependencies, \n collect_latest_messages, collect_latest_marginals, marginalrule, rule, name, getinboundinterfaces, clustername, getdependecies,\n messagein, ManyOf, getvariable\nimport ExponentialFamily: getnaturalparameters, exponential_family_typetag\nexport Gate, GateNode\n\n# Mixture Functional Form\nstruct Gate{N} end\n\nReactiveMP.as_node_symbol(::Type{<:Gate}) = :Gate\nReactiveMP.interfaces(::Type{<:Gate}) = Val((:out, :switch, :inputs))\nReactiveMP.alias_interface(::Type{<:Gate}, ::Int64, name::Symbol) = name\nReactiveMP.is_predefined_node(::Type{<:Gate}) = ReactiveMP.PredefinedNodeFunctionalForm()\nReactiveMP.sdtype(::Type{<:Gate}) = ReactiveMP.Deterministic()\nReactiveMP.collect_factorisation(::Type{<:Gate}, factorization) = GateNodeFactorisation()\n\nstruct GateNodeFactorisation end\n\nstruct GateNode{N} <: ReactiveMP.AbstractFactorNode\n    out    :: ReactiveMP.NodeInterface\n    switch :: ReactiveMP.NodeInterface\n    inputs :: NTuple{N, ReactiveMP.IndexedNodeInterface}\nend \n\nReactiveMP.functionalform(factornode::GateNode{N}) where {N} = Gate{N}\nReactiveMP.getinterfaces(factornode::GateNode) = (factornode.out, factornode.switch, factornode.inputs...)\nReactiveMP.sdtype(factornode::GateNode) = ReactiveMP.Deterministic()\n\nReactiveMP.interfaceindices(factornode::GateNode, iname::Symbol)                       = (ReactiveMP.interfaceindex(factornode, iname),)\nReactiveMP.interfaceindices(factornode::GateNode, inames::NTuple{N, Symbol}) where {N} = map(iname -> ReactiveMP.interfaceindex(factornode, iname), inames)\n\nReactiveMP.interfaceindex(factornode::GateNode, iname::Symbol) = begin\n    if iname === :out\n        return 1\n    elseif iname === :switch\n        return 2\n    elseif iname === :inputs\n        return 3\n    end\nend\n\nReactiveMP.factornode(::Type{<:Gate}, interfaces, factorization) = begin\n    outinterface = interfaces[findfirst(((name, variable),) -> name == :out, interfaces)]\n    switchinterface = interfaces[findfirst(((name, variable),) -> name == :switch, interfaces)]\n    inputinterfaces = filter(((name, variable),) -> name == :inputs, interfaces)\n    N = length(inputinterfaces)\n    return GateNode(ReactiveMP.NodeInterface(outinterface...), ReactiveMP.NodeInterface(switchinterface...), ntuple(i -> ReactiveMP.IndexedNodeInterface(i, ReactiveMP.NodeInterface(inputinterfaces[i]...)), N))\n    \nend\n\nstruct GateNodeInboundInterfaces end\n\nReactiveMP.getinboundinterfaces(::GateNode) = GateNodeInboundInterfaces()\nReactiveMP.clustername(::GateNodeInboundInterfaces) = :switch_inputs\n\n\nstruct GateNodeFunctionalDependencies <: FunctionalDependencies end\n\nReactiveMP.collect_functional_dependencies(::GateNode, ::Nothing) = GateNodeFunctionalDependencies()\nReactiveMP.collect_functional_dependencies(::GateNode, ::GateNodeFunctionalDependencies) = GateNodeFunctionalDependencies()\nReactiveMP.collect_functional_dependencies(::GateNode, ::Any) =\n    error(\"The functional dependencies for GateNode must be either `Nothing` or `GateNodeFunctionalDependencies`\")\n\nReactiveMP.activate!(factornode::GateNode, options::FactorNodeActivationOptions) = begin\n    dependencies = ReactiveMP.collect_functional_dependencies(factornode, ReactiveMP.getdependecies(options))\n    return ReactiveMP.activate!(dependencies, factornode, options)\nend\n\n\nReactiveMP.functional_dependencies(::GateNodeFunctionalDependencies, factornode::GateNode{N}, interface, iindex::Int) where {N} = begin\n    message_dependencies = if iindex === 1\n        # output depends on input messages:\n        (factornode.inputs, )\n    elseif iindex === 2\n        # switch depends on:\n        (factornode.out, factornode.inputs)\n    elseif 2 < iindex <= N + 2\n        # k'th input depends on:\n        (factornode.out, )\n    else\n        error(\"Bad index in functional_dependencies for MixtureNode\")\n    end\n\n    marginal_dependencies = if iindex === 1\n        # output depends on:\n        (factornode.switch, )\n    elseif iindex === 2\n        # switch depends on:\n        ( )\n    elseif 2 < iindex <= N + 2\n        # k'th input depends on:\n        (factornode.switch,)\n    else\n        error(\"Bad index in functional_dependencies for GateNode\")\n    end\n\n    return message_dependencies, marginal_dependencies\nend\n\n\nReactiveMP.collect_latest_messages(::GateNodeFunctionalDependencies, factornode::GateNode{N}, messages::Tuple{NodeInterface}) where {N} = begin\n    outputinterface = messages[1]\n\n    msgs_names = Val{(name(outputinterface),)}()\n    msgs_observable = combineLatestUpdates((messagein(outputinterface),), PushNew())\n    return msgs_names, msgs_observable\nend\n\nReactiveMP.collect_latest_marginals(::GateNodeFunctionalDependencies, factornode::GateNode{N}, marginals::Tuple{NodeInterface}) where {N} = begin\n    switchinterface = marginals[1]\n\n    marginal_names = Val{(name(switchinterface),)}()\n    marginal_observable = combineLatestUpdates((\n        getmarginal(getvariable(switchinterface), IncludeAll()),\n    ), PushNew())\n\n    return marginal_names, marginal_observable\nend\n\nReactiveMP.collect_latest_marginals(::GateNodeFunctionalDependencies, factornode::GateNode{N}, marginals::NTuple{N,IndexedNodeInterface}) where {N} = begin\n    inputsinterfaces = marginals\n    \n    marginal_names = Val{(name(first(inputsinterfaces)),)}()\n    marginal_observable = combineLatest(map(input -> getmarginal(getvariable(input), IncludeAll()), inputsinterfaces), PushNew()) |> map_to((ManyOf(map(input -> getmarginal(getvariable(input), IncludeAll()), inputsinterfaces)),))\n    \n    return marginal_names, marginal_observable\nend\n\nReactiveMP.collect_latest_messages(::GateNodeFunctionalDependencies, factornode::GateNode{N}, messages::Tuple{NodeInterface, NTuple{N, IndexedNodeInterface}}) where {N} = begin\n    output_or_switch_interface = messages[1]\n    inputsinterfaces = messages[2]\n\n    msgs_names = Val{(name(output_or_switch_interface), name(inputsinterfaces[1]))}()\n    msgs_observable =\n        combineLatest(\n            (messagein(output_or_switch_interface), combineLatest(map(input -> messagein(input), inputsinterfaces), PushNew())),\n            PushNew()\n        ) |> map_to((\n            messagein(output_or_switch_interface), \n            ManyOf(map(input -> messagein(input), inputsinterfaces))\n        ))\n    \n    return msgs_names, msgs_observable\nend\n\nReactiveMP.collect_latest_messages(::GateNodeFunctionalDependencies, factornode::GateNode{N}, messages::Tuple{NTuple{N,IndexedNodeInterface}}) where {N} = begin\n    inputsinterfaces = messages[1]\n    \n    msgs_names = Val{(name(first(inputsinterfaces)),)}()\n    msgs_observable = combineLatest(map(input -> messagein(input), inputsinterfaces), PushNew()) |> map_to((ManyOf(map(input -> messagein(input), inputsinterfaces)),))\n    \n    return msgs_names, msgs_observable\nend\n\n\nReactiveMP.marginalrule(fform::Type{<:Gate}, on::Val{:switch_inputs}, mnames::Any, messages::Any, qnames::Nothing, marginals::Nothing, meta::Nothing, __node::Any) = begin\n    # m_out = getdata(messages[1])\n    m_switch = getdata(messages[2])\n    m_inputs = getdata.(messages[3:end])\n\n\n    return FactorizedJoint((m_inputs..., m_switch))\nend\n\nReactiveMP.@rule Gate(:out, Marginalisation) (q_switch::Any, m_inputs::ManyOf{N, Any}) where {N} = begin\n    return MixtureDistribution(collect(m_inputs), probvec(q_switch))\nend\n\n\nReactiveMP.@rule Gate(:switch, Marginalisation) (m_out::Any, m_inputs::ManyOf{N, Any}) where {N} = begin\n    logscales = map(input -> compute_logscale(prod(GenericProd(),m_out,input), m_out, input), m_inputs)\n    p = softmax(collect(logscales))\n    return Multinomial(1, p)\nend\n\n\nReactiveMP.@rule Gate((:inputs, k), Marginalisation) (m_out::Any, q_switch::Any,) = begin\n    z = probvec(q_switch)[k]\n    ef_out = convert(ExponentialFamilyDistribution, m_out)\n    Œ∑      = getnaturalparameters(ef_out)\n    ef_opt = ExponentialFamilyDistribution(exponential_family_typetag(ef_out), Œ∑ * z)\n\n    return convert(Distribution, ef_opt)\nend\n\n\nReactiveMP.@rule typeof(*)(:out, Marginalisation) (m_A::PointMass, m_in::MixtureDistribution, meta::Any) = begin \n    comps = BayesBase.components(m_in)\n    new_components = similar(comps)\n    @inbounds for (i,component) in enumerate(comps)\n        new_components[i] = @call_rule typeof(*)(:out, Marginalisation) (m_A = m_A, m_in = component, meta = meta)\n    end\n    dist = MixtureDistribution(new_components, BayesBase.weights(m_in))\n    return dist\nend\n\nReactiveMP.@rule typeof(dot)(:out, Marginalisation) (m_in1::MixtureDistribution, m_in2::PointMass, meta::Any) = begin \n    comps = BayesBase.components(m_in1)\n    new_components = []\n    @inbounds for (i, component) in enumerate(comps)\n        push!(new_components, @call_rule typeof(dot)(:out, Marginalisation) (m_in1 = component, m_in2 = m_in2, meta = meta))\n    end\n    \n    mixture = MixtureDistribution(new_components, BayesBase.weights(m_in1))\n\n    return mixture\nend\n\n\n\n@rule typeof(dot)(:in1, Marginalisation) (m_out::MixtureDistribution, m_in2::PointMass, meta::Any) = begin \n    comps = BayesBase.components(m_out)\n    weights = BayesBase.weights(m_out)\n    new_comps = []\n    for (comp, weight) in zip(comps, weights)\n        new_comp = @call_rule typeof(dot)(:in1, Marginalisation) (m_out = comp, m_in2 = m_in2, meta = meta)\n        push!(new_comps, new_comp)\n    end\n    return MixtureDistribution(new_comps, weights)\nend\n\nfunction BayesBase.prod(::BayesBase.UnspecifiedProd, left::GaussianDistributionsFamily, right::MixtureDistribution)\n    comps = BayesBase.components(right)\n    weights = BayesBase.weights(right)\n    new_comps = []\n    for comp in comps\n        new_comp = prod(GenericProd(),left, comp)\n        push!(new_comps, new_comp)\n    end\n    \n    return MixtureDistribution(new_comps, weights)\nend\n\nBayesBase.prod(::BayesBase.UnspecifiedProd, left::MixtureDistribution, right::GaussianDistributionsFamily) = prod(GenericProd(),right, left)\nBayesBase.paramfloattype(::MixtureDistribution) = Float64\n\n\nimport ExponentialFamily.LogExpFunctions: logsumexp\nfunction BayesBase.prod(::GenericProd, left::Categorical, right::Multinomial)\n    @assert right.n == 1\n    right_cat = Categorical(right.p)\n\n    p = prod(GenericProd(), left, right_cat).p \n    return Multinomial(1, p)\n\nend\n\n\n\nBayesBase.prod(::GenericProd, left::Multinomial, right::Categorical) = prod(GenericProd(), right, left)\nfunction BayesBase.prod(::GenericProd, left::Multinomial, right::Multinomial) \n    @assert left.n == right.n\n\n    p = left.p .* right.p\n    p = p ./ sum(p)\n    return Multinomial(left.n, p)\nend\n\nBayesBase.prod(::BayesBase.UnspecifiedProd, left::Multinomial, right::Multinomial) = prod(GenericProd(), left, right)\n\n\nfunction BayesBase.compute_logscale(dist1::Multinomial, dist2::Multinomial, dist3::Multinomial) \n    logp1 = log.(dist1.p) - log(dist1.p[end])\n    logp2 = log.(dist2.p) - log(dist2.p[end])\n    logp3 = log.(dist3.p) - log(dist3.p[end])\n    return logsumexp(logp1) - logsumexp(logp2) - logsumexp(logp3)\nend\n\nBayesBase.compute_logscale(d1::ExponentialFamily.WishartFast, d2::ExponentialFamily.WishartFast, d3::ExponentialFamily.WishartFast) = begin\n    return logpartition(convert(ExponentialFamilyDistribution, d1)) - logpartition(convert(ExponentialFamilyDistribution, d2)) - logpartition(convert(ExponentialFamilyDistribution, d3))\nend\n\n\nExponentialFamily.probvec(d::Multinomial) = d.p\n\n@rule ContinuousTransition(:W, Marginalisation) (q_y_x::MultivariateNormalDistributionsFamily, q_a::MixtureDistribution, meta::Any) = begin \n    q_a_normal = convert(promote_variate_type(typeof(mean(q_a)), NormalMeanPrecision), mean(q_a), precision(q_a))\n    return @call_rule ContinuousTransition(:W, Marginalisation) (q_y_x = q_y_x, q_a = q_a_normal, meta = meta)\nend\n\n@rule ContinuousTransition(:y, Marginalisation) (m_x::MultivariateNormalDistributionsFamily, q_a::MixtureDistribution, q_W::Any, meta::Any) = begin \n    q_a_normal = convert(promote_variate_type(typeof(mean(q_a)), NormalMeanPrecision), mean(q_a), precision(q_a))\n    return @call_rule ContinuousTransition(:y, Marginalisation) (m_x = m_x, q_a = q_a_normal, q_W = q_W, meta = meta)\nend\n\n\n@rule ContinuousTransition(:a, Marginalisation) (q_y_x::MultivariateNormalDistributionsFamily, q_a::MixtureDistribution, q_W::Any, meta::Any) = begin \n    q_a_normal = convert(promote_variate_type(typeof(mean(q_a)), NormalMeanPrecision), mean(q_a), precision(q_a))\n    return @call_rule ContinuousTransition(:a, Marginalisation) (q_y_x = q_y_x, q_a = q_a_normal, q_W = q_W, meta = meta)\nend\n\n@rule ContinuousTransition(:x, Marginalisation) (m_y::MultivariateNormalDistributionsFamily , q_a::MixtureDistribution, q_W::Any, meta::Any) = begin \n    q_a_normal = convert(promote_variate_type(typeof(mean(q_a)), NormalMeanPrecision), mean(q_a), precision(q_a))\n    return @call_rule ContinuousTransition(:x, Marginalisation) (m_y = m_y, q_a = q_a_normal, q_W = q_W, meta = meta)\nend\n\n@rule ContinuousTransition(:y, Marginalisation) (m_x::MixtureDistribution, q_a::MultivariateNormalDistributionsFamily, q_W::Any, meta::Any) = begin \n    m_x_normal = convert(promote_variate_type(typeof(mean(m_x)), NormalMeanPrecision), mean(m_x), precision(m_x))\n    return @call_rule ContinuousTransition(:y, Marginalisation) (m_x = m_x_normal, q_a = q_a, q_W = q_W, meta = meta)\nend\n\n\n@marginalrule ContinuousTransition(:y_x) (m_y::MultivariateNormalDistributionsFamily, m_x::MixtureDistribution, q_a::MultivariateNormalDistributionsFamily, q_W::Any, meta::Any) = begin \n    m_x_normal = convert(promote_variate_type(typeof(mean(m_x)), NormalMeanPrecision), mean(m_x), precision(m_x))\n    return @call_marginalrule ContinuousTransition(:y_x) (m_y = m_y, m_x = m_x_normal, q_a = q_a, q_W = q_W, meta = meta)\nend\n\n@rule typeof(+)(:out, Marginalisation) (m_in1::MultivariateNormalDistributionsFamily, m_in2::MixtureDistribution, ) = begin \n    return @call_rule typeof(+)(:out, Marginalisation) (m_in1 = m_in1, m_in2 = convert(promote_variate_type(typeof(mean(m_in2)), NormalMeanPrecision), mean(m_in2), precision(m_in2)))\nend\n\n@rule typeof(+)(:in1, Marginalisation) (m_out::MultivariateNormalDistributionsFamily, m_in2::MixtureDistribution, ) = begin \n    return @call_rule typeof(+)(:in1, Marginalisation) (m_out = convert(promote_variate_type(typeof(mean(m_out)), NormalMeanPrecision), mean(m_out), precision(m_out)), m_in2 = convert(promote_variate_type(typeof(mean(m_in2)), NormalMeanPrecision), mean(m_in2), precision(m_in2)))\nend\n\n@rule DiscreteTransition(:out, Marginalisation) (m_in::Multinomial, q_a::DirichletCollection, ) = begin \n    @assert m_in.n == 1\n    p = probvec(m_in)\n    m_in_cat = Categorical(p)\n    return @call_rule DiscreteTransition(:out, Marginalisation) (m_in = m_in_cat, q_a = q_a)\nend\n\n@rule DiscreteTransition(:in, Marginalisation) (m_out::Multinomial, q_a::DirichletCollection, ) = begin \n    @assert m_out.n == 1\n    p = probvec(m_out)\n    m_out_cat = Categorical(p)\n    return @call_rule DiscreteTransition(:in, Marginalisation) (m_out = m_out_cat, q_a = q_a)\nend\n\n@marginalrule DiscreteTransition(:out_in) (m_out::Multinomial, m_in::Multinomial, q_a::DirichletCollection, ) = begin \n    @assert m_out.n == 1 && m_in.n == 1\n    p_out = probvec(m_out)\n    p_in = probvec(m_in)\n    m_out_cat = Categorical(p_out)\n    m_in_cat = Categorical(p_in)\n    return @call_marginalrule DiscreteTransition(:out_in) (m_out = m_out_cat, m_in = m_in_cat, q_a = q_a)\nend\n\n\nBase.length(d::MixtureDistribution) = length(d.components)\nBase.ndims(d::MixtureDistribution) = first(size(first(d.components)))\n\nExponentialFamily.probvec(d::Multinomial) = d.p\n\nBayesBase.entropy(d::MixtureDistribution) = mapreduce((c,w) -> w * BayesBase.entropy(c), +, d.components, d.weights)\n\nBayesBase.mean(f::F, itr::MixtureDistribution) where {F} = mapreduce((c,w) -> w * mean(f, c), +, itr.components, itr.weights)\n\nfunction create_P_matrix(n_switches)\n    P = zeros(n_switches, n_switches)\n    for i in 1:n_switches\n        P[i,:] = 0.5 * ones(n_switches)\n        P[i,i] = 1.0\n    end\n    return P\nend\n\nfunction BayesBase.mean(mixture::MixtureDistribution)\n    component_means = mean.(BayesBase.components(mixture))\n    component_weights = BayesBase.weights(mixture)\n    return mapreduce((m,w) -> w*m, +, component_means, component_weights)\nend\n\nfunction BayesBase.cov(mixture::MixtureDistribution)\n    component_cov = cov.(BayesBase.components(mixture))\n    component_means = mean.(BayesBase.components(mixture))\n    component_weights = BayesBase.weights(mixture)\n    mixture_mean = mean(mixture)\n    return mapreduce((v,m,w) -> w*(v + m*m'), +, component_cov, component_means, component_weights) - mixture_mean*mixture_mean'\nend\n\nBayesBase.precision(mixture::MixtureDistribution) = inv(cov(mixture))\n\nfunction BayesBase.var(mixture::MixtureDistribution)\n    component_vars = var.(BayesBase.components(mixture))\n    component_means = mean.(BayesBase.components(mixture))\n    component_weights = BayesBase.weights(mixture)\n    mixture_mean = mean(mixture)\n    return mapreduce((v,m,w) -> w*(v + m.^2), +, component_vars, component_means, component_weights) - mixture_mean.^2\nend\n\n\ndetails: Hidden block of RSLDS Model Specification - click to expand\n\nimport ExponentialFamily: softmax\n\n\"\"\"\n    RSLDSHyperparameters{T}\n\nStructure containing hyperparameters for the Recurrent Switching Linear Dynamical System (RSLDS) model.\n\n# Fields\n- `a_w::T = 2.0`: Shape parameter for the Gamma prior on precision parameter w (when n_switches=1)\n- `b_w::T = 2.0`: Rate parameter for the Gamma prior on precision parameter w (when n_switches=1)\n- `Œ®_w::Matrix{T}`: Scale matrix for the Wishart prior on precision matrix w (when n_switches>1)\n- `Œ®_R::Union{Matrix{T}, T}`: Scale matrix/parameter for the Wishart/Gamma prior on observation precision\n- `ŒΩ_R::T`: Degrees of freedom for the Wishart prior on observation precision\n- `Œ±::Matrix{T}`: Parameter matrix for the Dirichlet prior on transition probabilities\n- `C::Matrix{T}`: Observation matrix mapping latent states to observations\n\"\"\"\nBase.@kwdef struct RSLDSHyperparameters{T} \n   a_w::T = 2.0\n   b_w::T = 2.0\n   Œ®_w::Matrix{T}\n   Œ®_R::Union{Matrix{T}, T}\n   ŒΩ_R::T\n   Œ±::Matrix{T} \n   C::Matrix{T}\nend\n\n\"\"\"\n    get_hyperparameters(hyperparameters::RSLDSHyperparameters)\n\nExtract all hyperparameters from the RSLDSHyperparameters structure.\n\n# Arguments\n- `hyperparameters::RSLDSHyperparameters`: Structure containing the hyperparameters\n\n# Returns\nA tuple containing all hyperparameters in the order: a_w, b_w, Œ®_w, Œ®_R, ŒΩ_R, Œ±, C\n\"\"\"\nfunction get_hyperparameters(hyperparameters::RSLDSHyperparameters)\n    return hyperparameters.a_w, hyperparameters.b_w, hyperparameters.Œ®_w, hyperparameters.Œ®_R, hyperparameters.ŒΩ_R, hyperparameters.Œ±, hyperparameters.C\nend\n\n\"\"\"\n    default_hyperparameters(n_switches, obs_dim, dim_latent)\n\nCreate a default set of hyperparameters for the RSLDS model.\n\n# Arguments\n- `n_switches`: Number of switching states in the model\n- `obs_dim`: Dimension of the observation space\n- `dim_latent`: Dimension of the latent state space\n\n# Returns\nAn RSLDSHyperparameters structure with default values\n\"\"\"\nfunction default_hyperparameters(n_switches, obs_dim, dim_latent)\n    return RSLDSHyperparameters(\n        a_w = 2.0,\n        b_w = 2.0,\n        Œ®_w = diageye(n_switches),\n        Œ®_R = diageye(obs_dim),\n        ŒΩ_R = obs_dim + 2.0,\n        Œ± = ones(n_switches+1, n_switches+1),\n        C = diageye(obs_dim,dim_latent)\n    )\nend\n\n\n@model function rslds_model_learning(obs,n_obs,n_switches, dim_latent, Œ∑, Œ®, hyperparameters, learn_observation_covariance)\n    local H,A,Œõ,u\n    transformation  = (x) -> reshape(x, (dim_latent, dim_latent))\n    transformation2 = (x) -> reshape(x, (n_switches, dim_latent))\n    ##Hyperparameters\n    a_w, b_w, Œ®_w, Œ®_R,ŒΩ_R, Œ±, C = get_hyperparameters(hyperparameters)\n    ## Priors on the parameters \n    if n_switches == 1\n        w ~ GammaShapeRate(a_w, b_w)\n    else\n        w ~ Wishart(n_switches+2,Œ®_w)\n    end \n\n    if learn_observation_covariance\n        if n_obs == 1\n            R ~ GammaShapeRate(ŒΩ_R, Œ®_R)\n        else\n            R ~ Wishart(ŒΩ_R, Œ®_R) \n        end\n    else\n        R = Œ®_R\n    end\n    \n    for k in 1:n_switches+1\n        H[k] ~ MvNormalMeanCovariance(zeros(dim_latent^2), diageye(dim_latent^2))\n        Œõ[k] ~ Wishart(dim_latent+2, diageye(dim_latent))\n    end\n    P ~ DirichletCollection(Œ±)\n    œï ~ MvNormalMeanCovariance(zeros(dim_latent*n_switches), diageye(dim_latent*n_switches))\n    ## States Initialisation \n    x[1] ~ MvNormalMeanCovariance(zeros(dim_latent), diageye(dim_latent))\n    for t in eachindex(obs)  \n        ## Recurrent Layer\n        if n_switches == 1\n            u[t] ~ softdot(œï, x[t], w)\n        else\n            u[t] ~ ContinuousTransition(x[t], œï, w) where {meta = CTMeta(transformation2)}\n        end     \n        s[t] ~ MultinomialPolya(1, u[t]) where {dependencies = RequireMessageFunctionalDependencies(œà = convert(promote_variate_type(typeof(Œ∑), NormalWeightedMeanPrecision), Œ∑, Œ®))}   \n        s[t+1] ~ DiscreteTransition(s[t], P)\n        ##Transition Layer\n        A[t] := Gate(switch=s[t+1], inputs=H)\n        B[t] := Gate(switch=s[t+1], inputs=Œõ)\n        x[t+1] ~ ContinuousTransition(x[t], A[t], B[t]) where {meta = CTMeta(transformation)}\n        ## Observation Layer\n        obs[t] ~ MvNormalMeanPrecision(C*x[t+1], R)\n    end\nend\n\n@constraints  function rslds_learning_constraints(learn_observation_covariance)\n    if learn_observation_covariance\n        q(x,s,u,œï,w,P,H,A,Œõ,B,R) = q(x,u)q(A)q(s)q(œï)q(w)q(P)q(H)q(Œõ)q(B)q(R)\n    else\n        q(x,s,u,œï,w,P,H,A,Œõ,B) = q(x,u)q(A)q(s)q(œï)q(w)q(P)q(H)q(Œõ)q(B)\n    end\nend\n\n@initialization function rslds_learning_initmarginals(n_switches, dim_latent, obs_dim, learn_observation_covariance; rng = StableRNG(42))    \n    q(x) = vague(MvNormalWeightedMeanPrecision, dim_latent)\n    q(s) = Multinomial(1,softmax(randn(rng, n_switches+1)))\n    q(œï) = vague(MvNormalWeightedMeanPrecision, dim_latent*(n_switches))\n    if n_switches == 1\n        q(w) = vague(GammaShapeRate)\n    else\n        q(w) = vague(Wishart, n_switches)   \n    end\n    q(A) = vague(MvNormalWeightedMeanPrecision, dim_latent^2)\n    q(P) = DirichletCollection(ones(n_switches+1,n_switches+1))\n    q(Œõ) = vague(Wishart, dim_latent)\n    q(H) = vague(MvNormalWeightedMeanPrecision, dim_latent^2)\n    q(B) = vague(Wishart, dim_latent)\n    if learn_observation_covariance\n        if obs_dim == 1\n            q(R) = vague(GammaShapeRate)\n        else\n            q(R) = Wishart(obs_dim+2, diageye(obs_dim))\n        end\n    end\nend;\n\n\n\n\"\"\"\n    fit_rslds(data, n_switches, dim_latent, n_obs; kwargs...)\n\nFit a Recurrent Switching Linear Dynamical System (RSLDS) model to the provided data.\n\n# Arguments\n- `data`: Time series observation data\n- `n_switches`: Number of switching states in the model. Note: The user provides the total number of states,\n  but internally we use (n_switches-1) because the MultinomialPolya distribution adds an extra dimension\n  to represent the recurrent influence on state transitions.\n- `dim_latent`: Dimension of the latent state space\n- `n_obs`: Dimension of the observation space\n\n# Keyword Arguments\n- `iterations::Int = 60`: Number of inference iterations\n- `Œ∑ = nothing`: Mean parameter for the functional dependency in MultinomialPolya\n- `Œ® = nothing`: Precision parameter for the functional dependency in MultinomialPolya\n- `hyperparameters = nothing`: Custom hyperparameters for the model\n- `progress::Bool = false`: Whether to show progress during inference\n- `learn_observation_covariance::Bool = false`: Whether to learn the observation covariance\n\n# Returns\nThe result of the inference procedure\n\"\"\"\nfunction fit_rslds(data, n_switches, dim_latent, n_obs; iterations = 60, Œ∑ = nothing, Œ® = nothing, hyperparameters = nothing, progress = false, learn_observation_covariance = false)\n    @assert n_switches > 1 \"n_switches must be greater than 1\"\n    # We subtract 1 from n_switches because the MultinomialPolya distribution\n    # internally adds an extra dimension to represent the recurrent influence\n    # on state transitions. This convention allows the model to maintain the\n    # correct dimensionality while incorporating the recurrent dynamics.\n    n_switches = n_switches - 1\n\n    if hyperparameters === nothing\n        hyperparameters = default_hyperparameters(n_switches, length(data[1]), dim_latent)\n    end\n\n    if Œ∑ === nothing\n        if n_switches == 1\n            Œ∑ = 0.0\n        else\n            Œ∑ = zeros(n_switches)\n        end\n    end\n    if Œ® === nothing\n        if n_switches == 1\n            Œ® = 0.0001\n        else\n            Œ® = 0.0001*diageye(n_switches)\n        end\n    end\n    model = rslds_model_learning(n_obs = n_obs, n_switches = n_switches, dim_latent = dim_latent, Œ∑ = Œ∑, Œ® = Œ®, hyperparameters = hyperparameters, learn_observation_covariance = learn_observation_covariance)\n    constraints = rslds_learning_constraints(learn_observation_covariance)\n    initmarginals = rslds_learning_initmarginals(n_switches, dim_latent, n_obs, learn_observation_covariance)\n    \n    return infer(model = model, data = (obs=data, ), constraints = constraints, initialization = initmarginals, iterations = iterations,\n    showprogress = progress,\n    returnvars = KeepEach(),\n    free_energy = true,\n    options = (limit_stack_depth = 100,)\n    )\nend\n\n# \n\nfunction states_to_categorical(states)\n    return [argmax(states[t].p) for t in 1:length(states)]\nend\n\n\ndetails: Hidden block of Generating Synthetic Data - click to expand\n\nusing StableRNGs\n\nfunction generate_switching_data(T, A1, A2, c, Q, R, x_0;rng = StableRNG(42))\n    # Initialize arrays to store states and observations\n    x = zeros(2, T)  # State matrix: 2 dimensions √ó T timesteps\n    y = zeros(2, T)  # Observation matrix: 2 dimensions √ó T timesteps\n    \n    # Set initial state\n    x[:,1] = x_0\n    \n    # Generate state transitions and observations\n    for t in 2:T\n        # Switch dynamics multiple times through the sequence\n        if t < T/3 || (t >= T/2 && t < 3T/4)\n            x[:,t] = A2 * x[:,t-1] + rand(rng,MvNormal(zeros(2), Q))  # First regime\n        else\n            x[:,t] = A1 * x[:,t-1] + rand(rng,MvNormal(zeros(2), Q))  # Second regime\n        end\n        \n        # Generate observation from current state\n        y[:,t] = c * x[:,t] + rand(rng,MvNormal(zeros(2), R))\n    end\n\n    return x, y\nend\n        \n\n# System parameters\nT = 500  # Time horizon\nŒ∏ = œÄ / 15  # Rotation angle\n\n# Define system matrices\nA1 = [cos(Œ∏) -sin(Œ∏); sin(Œ∏) cos(Œ∏)]    # Rotation matrix\nA2 = [0.4 -0.01; 0.01 0.2]         \nc = [0.6 -0.02; -0.02 0.3]                   # Observation/distortion matrix\n\n# Noise parameters\nQ = [1.0 0.0; 0.0 1.0]                   # State noise covariance\nR =  [1.0 0.0; 0.0 1.0]            # Observation noise variance\nx_0 = [0.0, 0.0]                         # Initial state vector\n\n# Generate synthetic data\nx, y = generate_switching_data(T, A1, A2, c, Q, R, x_0)\ny = [y[:,i] for i in 1:T]\nx = [x[:,i] for i in 1:T]\n\n\nhyperparameters = RSLDSHyperparameters(\n    a_w = 0.01,\n    b_w = 0.01,\n    Œ®_w = 10.0*diageye(2), # n-1  \n    Œ®_R = inv(R),\n    ŒΩ_R = 4.0,\n    Œ± = ones(2,2), # n\n    C = c\n)\n\nMain.var\"##WeaveSandBox#277\".RSLDSHyperparameters{Float64}(0.01, 0.01, [10.\n0 0.0; 0.0 10.0], [1.0 0.0; 0.0 1.0], 4.0, [1.0 1.0; 1.0 1.0], [0.6 -0.02; \n-0.02 0.3])\n\nrslds_result = fit_rslds(y, 2, 2, 2; iterations = 150, hyperparameters = hyperparameters, progress = true)\n\nInference results:\n  Posteriors       | available for (œï, w, P, A, s, H, Œõ, B, u, x)\n  Free Energy:     | Real[386913.0, 75580.8, 2809.27, 2010.43, 1920.47, 186\n5.65, 1893.55, 1933.31, 1972.41, 2010.39  ‚Ä¶  1724.41, 1725.22, 1726.01, 172\n6.79, 1727.56, 1728.32, 1729.06, 1729.79, 1730.51, 1731.22]\n\nusing Plots\n\nswitching_state_posterior = rslds_result.posteriors[:s][end];\nstates = states_to_categorical(switching_state_posterior);\nscatter(states, label=\"Estimated Regimes\", color=\"blue\", linewidth=2)\n\n(Image: )\n\ncontinuous_state_posterior = rslds_result.posteriors[:x][end];\nindex = 1\nfrom = 1\nto = 500\n\nm_continuous = getindex.(mean.(continuous_state_posterior), index);\nvar_continuous = getindex.(var.(continuous_state_posterior), index);\nplot(m_continuous[from+1:to], ribbon=sqrt.(var_continuous[from+1:to]), label=\"Estimated States\", color=\"blue\",fillalpha=0.2, linewidth=2)\nplot!(getindex.(x,index)[from:to], label=\"True States\", color=\"green\", linewidth=1)\nscatter!(getindex.(y,index)[from:to], label=\"Observed Data\", color=\"black\", ms=1.3)\nlens!([10,50],[-3, 3],inset = (1, bbox(0.07, 0.6, 0.3, 0.3)), )\n\n(Image: )\n\nindex = 2\nm_continuous = getindex.(mean.(continuous_state_posterior), index);\nvar_continuous = getindex.(var.(continuous_state_posterior), index);\nplot(m_continuous[from+1:to], ribbon=sqrt.(var_continuous[from+1:to]), label=\"Estimated States\", color=\"blue\",fillalpha=0.2, linewidth=2)\nplot!(getindex.(x,index)[from:to], label=\"True States\", color=\"green\", linewidth=1)\nscatter!(getindex.(y,index)[from:to], label=\"Observed Data\", color=\"black\", ms=1.3)\nlens!([350,400],[-3, 3],inset = (1, bbox(0.07, 0.6, 0.3, 0.3)), )\n\n(Image: )\n\nprintln(\"Estimated continuous transition matrices:\")\nprintln(\"----------------------------------------\")\nfor i in 1:length(rslds_result.posteriors[:H][end])\n    println(\"Matrix $i:\")\n    println(reshape(mean(rslds_result.posteriors[:H][end][i]), 2, 2))\n    println()\nend\n\nEstimated continuous transition matrices:\n----------------------------------------\nMatrix 1:\n[0.9801827287287418 -0.20963425131252583; 0.1905047312811021 0.979149385152\n4096]\n\nMatrix 2:\n[0.5040325201488757 -0.32130428525440324; 0.10781013310896237 0.53512662956\n77641]\n\nprintln(\"Estimated discrete transition matrix for HMM layer:\")\nprintln(\"----------------------------------------\")\nprintln(mean(rslds_result.posteriors[:P][end]))\n\nEstimated discrete transition matrix for HMM layer:\n----------------------------------------\n[0.9866080421546886 0.008636213099697573; 0.01339195784531154 0.99136378690\n03025]\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [b4ee3484] BayesBase v1.5.8\n  [62312e5e] ExponentialFamily v2.2.0\n  [b3f8163a] GraphPPL v4.6.5\n  [91a5bcdd] Plots v1.41.6\n  [a194aa59] ReactiveMP v5.6.5\n  [86711068] RxInfer v4.7.0\n  [860ef19b] StableRNGs v1.0.4\n\n\n","category":"section"},{"location":"categories/advanced_examples/assessing_people_skills/","page":"Assessing People Skills","title":"Assessing People Skills","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/advanced_examples/assessing_people_skills/#Assessing-People‚Äôs-Skills","page":"Assessing People Skills","title":"Assessing People‚Äôs Skills","text":"The goal of this demo is to demonstrate the use of the @node and @rule macros, which allow the user to define custom factor nodes and associated update rules respectively. We will introduce these macros in the context of a root cause analysis on a student's test results. This demo is inspired by Chapter 2 of \"Model-Based Machine Learning\" by Winn et al.","category":"section"},{"location":"categories/advanced_examples/assessing_people_skills/#Problem-Statement","page":"Assessing People Skills","title":"Problem Statement","text":"We consider a student who takes a test that consists of three questions. Answering each question correctly requires a combination of skill and attitude. More precisely, has the student studied for the test, and have they partied the night before?\n\nWe model the result for question i as a continuous variable r_iin01, and skill/attitude as a binary variable s_i in 0 1, where s_1 represents whether the student has partied, and s_2 and s_3 represent whether the student has studied the chapters for the corresponding questions.\n\nWe assume the following logic:\n\nIf the student is alert (has not partied), then they will score on the first question;\nIf the student is alert or has studied chapter two, then they will score on question two;\nIf the student can answer question two and has studied chapter three, then they will score on question three.","category":"section"},{"location":"categories/advanced_examples/assessing_people_skills/#Generative-Model-Definition","page":"Assessing People Skills","title":"Generative Model Definition","text":"To model the probability for correct answers, we assume a latent state variable t_i in 01. The dependencies between the variables can then be modeled by the following Bayesian network:\n\n(s_1)   (s_2)   (s_3)\n  |       |       |\n  v       v       v\n(t_1)-->(t_2)-->(t_3)\n  |       |       |\n  v       v       v\n(r_1)   (r_2)   (r_3)\n\nAs prior beliefs, we assume that a student is equally likely to study/party or not: s_i sim Ber(05) for all i. Next, we model the domain logic as beginaligned   t_1 = s_1\n  t_2 = t_1  s_2\n  t_3 = t_2  s_3 endaligned For the scoring results we might not have a specific forward model in mind. However, we can define a backward mapping, from continuous results to discrete latent variables, as  t_i sim Ber(s_i) for all i.","category":"section"},{"location":"categories/advanced_examples/assessing_people_skills/#Custom-Nodes-and-Rules","page":"Assessing People Skills","title":"Custom Nodes and Rules","text":"The backward mapping from results to latents is quite specific to our application. Moreover, it does not define a proper generative forward model. In order to still define a full generative model for our application, we can define a custom Score node and define an update rule that implements the backward mapping from scores to latents as a message.\n\nIn RxInfer, the @node macro defines a factor node. This macro accepts the new node type, an indicator for a stochastic or deterministic relationship, and a list of interfaces.\n\nusing RxInfer, Random\n\n# Create Score node\nstruct Score end\n\n@node Score Stochastic [out, in]\n\nWe can now define the backward mapping as a sum-product message through the @rule macro. This macro accepts the node type, the (outbound) interface on which the message is sent, any relevant constraints, and the message/distribution types on the remaining (inbound) interfaces.\n\n# Adding update rule for the Score node\n@rule Score(:in, Marginalisation) (q_out::PointMass,) = begin\n    return Bernoulli(mean(q_out))\nend","category":"section"},{"location":"categories/advanced_examples/assessing_people_skills/#Generative-Model-Specification","page":"Assessing People Skills","title":"Generative Model Specification","text":"We can now build the full generative model.\n\n# GraphPPL.jl exports the `@model` macro for model specification\n# It accepts a regular Julia function and builds an FFG under the hood\n@model function skill_model(r)\n\n    local s\n    # Priors\n    for i in eachindex(r)\n        s[i] ~ Bernoulli(0.5)\n    end\n\n    # Domain logic\n    t[1] ~ ¬¨s[1]\n    t[2] ~ t[1] || s[2]\n    t[3] ~ t[2] && s[3]\n\n    # Results\n    for i in eachindex(r)\n        r[i] ~ Score(t[i])\n    end\nend","category":"section"},{"location":"categories/advanced_examples/assessing_people_skills/#Inference-Specification","page":"Assessing People Skills","title":"Inference Specification","text":"Let us assume that a student scored very low on all questions and set up and execute an inference algorithm.\n\ntest_results = [0.1, 0.1, 0.1]\ninference_result = infer(\n    model=skill_model(),\n    data=(r=test_results,)\n)\n\nInference results:\n  Posteriors       | available for (s, t)","category":"section"},{"location":"categories/advanced_examples/assessing_people_skills/#Results","page":"Assessing People Skills","title":"Results","text":"# Inspect the results\nmap(params, inference_result.posteriors[:s])\n\n3-element Vector{Tuple{Float64}}:\n (0.9872448979591837,)\n (0.06377551020408162,)\n (0.4719387755102041,)\n\nThese results suggest that this particular student was very likely out on the town last night.\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [86711068] RxInfer v4.7.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"},{"location":"how_to_contribute/#Contributing-to-RxInfer-Examples","page":"How to contribute","title":"Contributing to RxInfer Examples","text":"We welcome contributions from the community! This guide will help you understand how to add new examples or improve existing ones in the RxInfer Examples collection. Here are the steps to follow to add a new example:","category":"section"},{"location":"how_to_contribute/#Location-and-Structure","page":"How to contribute","title":"Location and Structure","text":"Create a new Jupyter notebook in the appropriate category folder. Use examples/Basic Examples/ for fundamental concepts, examples/Advanced Examples/ for complex applications, examples/Problem Specific/ for domain-specific use cases, or examples/Experimental Examples for some (potentially unpolished) experiments.\n\nnote: Note\nYou can also introduce a new category by creating a new folder in the examples/ directory. In this case, you should also add a new entry in the docs/make.jl file.\n\nEach example at the very least should have a clear, descriptive title, a meta.jl file in the same directory, a local Project.toml for dependencies, and any required data files. \n\nIf your example cannot be statically generated, put it inside the interactive folder instead.","category":"section"},{"location":"how_to_contribute/#Notebook-Guidelines","page":"How to contribute","title":"Notebook Guidelines","text":"First Cell Requirements The first cell must be a markdown cell. It should contain ONLY the title as # <title>. The title should be descriptive and unique (avoid \"Overview\").\nEnvironment Setup\nThe notebook will use the environment specified in the Project.toml file. Add any additional dependencies to the local project.\nNotebook should run regardless of what versions of dependencies are being used \nThe [compat] section inside each individual Project.toml will NOT be respected, do not rely on it\nContent Structure The notebook should have a clear introduction and problem description, model specification with explanations, inference procedure details, results analysis and visualization, and comprehensive comments for readability. It is perfectly fine to use LLMs to come up with a nice narrative and/or story for your example. Please, do NOT submit examples with just code. Always add some narrative, which explains why the example is doing what it is doing. If you notice an (old) example without explanations or narrative, please open an issue or (even better!) contribute by opening a PR! The examples in the examples/Experimental Examples folder might be less explanatory, but do not specifically put your example in this folder just to avoid writing the explanations!\nSelf-Contained Code\nExamples must be fully self-contained without using include() statements. The include() statements cannot be injected in the HTML version of the examples.\nAll code should be directly in the notebook cells\nDo not reference external Julia files\nUsers should be able to reproduce examples by simply copying and pasting from the documentation","category":"section"},{"location":"how_to_contribute/#Mathematical-Content","page":"How to contribute","title":"Mathematical Content","text":"note: Note\nThe automatic rendering of equations is handled by the make.jl script and it does not understand the spaces after the $$ or $. Below are the rules for formatting equations.\n\nEquation Formatting\nSome text\n\n$$\\begin{aligned}\n<latex equations here>\n\\end{aligned}$$\n\nSome other text\nDo not add spaces before or after the $$ or $\nEquation Rules\nNo space after opening $$ or $\nSeparate display equations with empty lines\nInline equations use single $...$, e.g. $$a + b$$ and not $$ a + b $$","category":"section"},{"location":"how_to_contribute/#Hidden/Collapsible-Code-Blocks","page":"How to contribute","title":"Hidden/Collapsible Code Blocks","text":"You can hide complex or supplementary code blocks behind collapsible sections to improve readability while still making all code available to users.\n\nCreating Hidden Blocks To create a collapsible code block, add special marker comments within your code blocks:\n### EXAMPLE_HIDDEN_BLOCK_START(Custom summary text) ###\n# This code will be hidden by default\nfunction complex_function()\n    # Implementation details\n    return result\nend\n\nnothing # to suppress the output in the notebook\n### EXAMPLE_HIDDEN_BLOCK_END ###\nImportant to note that these comments must be on the first and the last line of the code block respectively. If you want to suppress the output of the code block entirely, add nothing at the end of the code block.\nBest Practices\nUse hidden blocks for implementation details that would distract from the main tutorial flow\nProvide a descriptive summary that explains what the hidden code does\nEnsure the code within hidden blocks still runs correctly - it just gets hidden in the display\nUse for auxiliary functions, data processing, or complex implementations\nResult in Documentation The code block will be rendered as a collapsible \"details\" element with your custom summary text as the clickable header.","category":"section"},{"location":"how_to_contribute/#Visualization-and-figures","page":"How to contribute","title":"Visualization and figures","text":"All plots rendered with Plots.jl should display automatically\nAsset figures can be saved in the same directory as the notebook and referenced with ![](figure-name.png)\nSpecial figures (e.g., GIFs) should be saved to generated-in-the-notebook.gif in the same directory as the notebook\nReference saved figures as markdown with ![](generated-in-the-notebook.gif) right after the cell that generated it","category":"section"},{"location":"how_to_contribute/#Metadata-Requirements","page":"How to contribute","title":"Metadata Requirements","text":"Create a meta.jl file in your example's directory with:\n\nreturn (\n    title = \"Your Example Title\",\n    description = \"\"\"\n    A clear description of what the example demonstrates.\n    \"\"\",\n    tags = [\"category\", \"relevant\", \"tags\", \"here\"]\n)","category":"section"},{"location":"how_to_contribute/#Testing-Your-Example","page":"How to contribute","title":"Testing Your Example","text":"note: Note\nNote that building the examples locally requires Weave.jl package to be installed globally in your Julia environment. Use julia -e 'using Pkg; Pkg.add(\"Weave\")' to install it.\n\nLocal Testing\n# Test all examples\nmake examples\n\n# Test specific example\nmake example FILTER=YourNotebookName\n\n# Render the documentation\nmake docs\n\n# Preview the documentation\nmake preview\nBuild Caching\nThe build system caches the results of example compilation. If you make changes to an example and still see old errors after rebuilding:\n# Clear all build caches and artifacts\nmake clean\n\n# Then rebuild\nmake examples\nCommon Issues\nEnsure all dependencies are in Project.toml\nVerify plots display correctly\nTest with a clean environment\nIf errors persist after fixing, run make clean to clear cached builds","category":"section"},{"location":"how_to_contribute/#Important-Notes","page":"How to contribute","title":"Important Notes","text":"note: Plotting Package Preference\nPlease use Plots.jl instead of PyPlot. PyPlot's installation significantly impacts CI build times.\n\nwarning: Documentation Generation\nEnsure your notebook renders correctly in the documentation by:Following equation formatting rules\nUsing proper cell types\nIncluding all necessary resources","category":"section"},{"location":"how_to_contribute/#Getting-Help","page":"How to contribute","title":"Getting Help","text":"If you're unsure about anything:\n\nCheck existing examples for reference\nOpen an issue for guidance\nAsk in the discussions section\n\nYour contributions help make RxInfer.jl better for everyone!\n\n","category":"section"},{"location":"categories/experimental_examples/latent_vector_autoregressive_model/","page":"Latent Vector Autoregressive Model","title":"Latent Vector Autoregressive Model","text":"note: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n","category":"section"},{"location":"categories/experimental_examples/latent_vector_autoregressive_model/#Latent-Vector-Autoregressive-Model","page":"Latent Vector Autoregressive Model","title":"Latent Vector Autoregressive Model","text":"This is an experimental example of a Latent Vector Autoregressive Model (LVAR).\n\nusing RxInfer, Random, LinearAlgebra\n\nAt first let us define auxiliary functions for priors, c and b variables\n\nfunction generate_ar_process(order, Œ∏, n_samples; œÉ¬≤=1.0)\n    x = zeros(n_samples)\n    # Initialize with random noise\n    x[1:order] = randn(order) * sqrt(œÉ¬≤)\n    \n    for t in (order+1):n_samples\n        # AR equation: x[t] = Œ∏‚ÇÅx[t-1] + Œ∏‚ÇÇx[t-2] + ... + Œ∏‚Çöx[t-p] + Œµ[t]\n        x[t] = sum(Œ∏[i] * x[t-i] for i in 1:order) + randn() * sqrt(œÉ¬≤)\n    end\n    return x\nend\n\n# Set random seed for reproducibility\nRandom.seed!(42)\n\n# Define orders for each process\norders = 5 .* ones(Int, 20)\nn_samples = 120\nn_missing = 20\n\nn_ar_processes = length(orders)\nprocesses = []\n\n# Generate AR parameters and data for each process\nfor (i, order) in enumerate(orders)\n    # Generate stable AR parameters (using a simple method)\n    Œ∏ = 0.5 .^ (1:order)  # This ensures stability by having decreasing coefficients\n    \n    # Generate the AR process\n    x = generate_ar_process(order, Œ∏, n_samples)\n    push!(processes, x)\nend\n\n# Convert to the format needed for the model\ntrue_data = [[processes[j][i] for j in 1:n_ar_processes] for i in 1:n_samples]\nobservations = Any[[true_data[i][j] .+ randn() for j in 1:n_ar_processes] for i in 1:n_samples]\n\ntraining_set = deepcopy(observations[1:n_samples-n_missing])\n\n# Extend observations with missing values\nfor i in n_samples-n_missing:n_samples\n    push!(training_set, missing)\nend\n\nfunction form_priors(orders)\n    priors = (x = [], Œ≥ = [], Œ∏ = [])\n    for k in 1:length(orders)\n        push!(priors[:Œ≥], GammaShapeRate(1.0, 1.0))\n        push!(priors[:x], MvNormalMeanPrecision(zeros(orders[k]), diageye(orders[k])))\n        push!(priors[:Œ∏], MvNormalMeanPrecision(zeros(orders[k]), diageye(orders[k])))\n    end\n    return priors\nend\n\nfunction form_c_b(y, orders)\n    c = Any[]\n    b = Any[]\n    for k in 1:length(orders)\n        _c = ReactiveMP.ar_unit(Multivariate, orders[k])\n        _b = zeros(length(y[1])); _b[k] = 1.0\n        push!(c, _c)\n        push!(b, _b)\n    end\n    return c, b\nend\n\nform_c_b (generic function with 1 method)\n\nNext, we define a sub-model for a single AR-process\n\n@model function AR_sequence(x, index, length, priors, order)\n    Œ≥ ~ priors[:Œ≥][index]\n    Œ∏ ~ priors[:Œ∏][index]\n    x_prev ~ priors[:x][index]\n    for i in 1:length\n        x[index, i] ~ AR(x_prev, Œ∏, Œ≥) where {\n            meta = ARMeta(Multivariate, order, ARsafe())\n        }\n        x_prev = x[index, i]\n    end\nend\n\nNext, we define a tricky dot sequence\n\n@model function dot_sequence(out, k, i, orders, x, c, b)\n    if k === length(orders)\n        out ~ b[k] * dot(c[k], x[k, i])\n    else \n        next ~ dot_sequence(k = k + 1, i = i, orders = orders, x = x, c = c, b = b)\n        out  ~ b[k] * dot(c[k], x[k, i]) + next\n    end\nend\n\nAnd here is our final model spec\n\n@model function LVAR(y, orders)\n\n    priors   = form_priors(orders)\n    c, b     = form_c_b(y, orders)\n    y_length = length(y)\n    \n    local x # `x` is being initialized in the loop within submodels\n    for k in 1:length(orders)\n        x ~ AR_sequence(index  = k, length = y_length, priors = priors, order  = orders[k])\n    end\n\n    œÑ ~ GammaShapeRate(1.0, 1.0)\n    for i in 1:y_length\n        Œº[i] ~ dot_sequence(k = 1, i = i, orders = orders, x = x, c = c, b = b)\n        y[i] ~ MvNormalMeanScalePrecision(Œº[i], œÑ)\n    end\nend\n\n@constraints function lvar_constraints()\n    for q in AR_sequence\n        # This requires patch in GraphPPL though, see https://github.com/ReactiveBayes/GraphPPL.jl/issues/262\n        # A workaround is to use `constraints = MeanField()` in the `infer` function and initializing `q(x)` instead of `Œº(x)`\n        q(x, x_prev, Œ≥, Œ∏) = q(x, x_prev)q(Œ≥)q(Œ∏)\n    end\n    q(Œº, œÑ) = q(Œº)q(œÑ)\nend\n\nlvar_constraints (generic function with 1 method)\n\n@initialization function lvar_init(orders)\n    # This is a problem still\n    for init in AR_sequence\n        q(Œ≥) = GammaShapeRate(1.0, 1.0) \n        q(Œ∏) = MvNormalMeanPrecision(zeros(orders[1]), diageye(orders[1])) # `orders[1]` is sad... needs to be fixed\n    end\n    q(œÑ) = GammaShapeRate(1.0, 1.0)\n    Œº(x) = MvNormalMeanPrecision(zeros(orders[1]), diageye(orders[1]))\nend\n\nlvar_init (generic function with 1 method)\n\nmresult = infer(\n    model          = LVAR(orders = orders), \n    data           = (y = training_set, ), \n    constraints    = lvar_constraints(), \n    initialization = lvar_init(orders), \n    returnvars = KeepLast(), \n    options = (limit_stack_depth = 100, ),\n    showprogress = true,\n    iterations = 30,\n)\n\nInference results:\n  Posteriors       | available for (Œº, œÑ, x)\n  Predictions      | available for (y)\n\n## Plot results\n\nusing Plots\n\ntheme(:default)\n\ncombined_plot = plot(layout = (3, 1), size = (600, 800), legend = :topleft)\n\n# Plotting options\nmarker_alpha = 0.7 \nmarker_size = 5  \nribbon_alpha = 0.3\nobservation_color = :green\n\n# Define the training range indices\ntrain_indices = 1:(n_samples - n_missing)\n# Extract observations for the training range\ntrain_observations = observations[train_indices]\n\n# Plot for index 5 (Subplot 1)\nindex = 5\nplot!(combined_plot[1], getindex.(mean.(mresult.predictions[:y][end]), index), ribbon = getindex.(diag.(cov.(mresult.predictions[:y][end])), index), fillalpha=ribbon_alpha, label = \"Inferred $(index)\")\nplot!(combined_plot[1], getindex.(true_data, index), label = \"True $(index)\")\n# Plot only existing observations using train_indices as x-values\nscatter!(combined_plot[1], train_indices, getindex.(train_observations, index), label = \"Observations $(index)\", marker=:xcross, markeralpha=marker_alpha, markersize=marker_size, color=observation_color)\nvline!(combined_plot[1], [n_samples-n_missing], label=\"training/test split\", linestyle=:dash, color=:black)\nplot!(combined_plot[1], title = \"LVAR $(index)\")\n\n# Plot for index 10 (Subplot 2)\nindex = 10\nplot!(combined_plot[2], getindex.(mean.(mresult.predictions[:y][end]), index), ribbon = getindex.(diag.(cov.(mresult.predictions[:y][end])), index), fillalpha=ribbon_alpha, label = \"Inferred $(index)\")\nplot!(combined_plot[2], getindex.(true_data, index), label = \"True $(index)\")\n# Plot only existing observations\nscatter!(combined_plot[2], train_indices, getindex.(train_observations, index), label = \"Observations $(index)\", marker=:xcross, markeralpha=marker_alpha, markersize=marker_size, color=observation_color)\nvline!(combined_plot[2], [n_samples-n_missing], label=\"\", linestyle=:dash, color=:black) # No label for subsequent vlines\nplot!(combined_plot[2], title = \"LVAR $(index)\")\n\n# Plot for index 20 (Subplot 3)\nindex = 15\nplot!(combined_plot[3], getindex.(mean.(mresult.predictions[:y][end]), index), ribbon = getindex.(diag.(cov.(mresult.predictions[:y][end])), index), fillalpha=ribbon_alpha, label = \"Inferred $(index)\")\nplot!(combined_plot[3], getindex.(true_data, index), label = \"True $(index)\")\n# Plot only existing observations\nscatter!(combined_plot[3], train_indices, getindex.(train_observations, index), label = \"Observations $(index)\", marker=:xcross, markeralpha=marker_alpha, markersize=marker_size, color=observation_color)\nvline!(combined_plot[3], [n_samples-n_missing], label=\"\", linestyle=:dash, color=:black) # No label for subsequent vlines\nplot!(combined_plot[3], title = \"LVAR $(index)\")\n\n# Display the combined plot\ncombined_plot\n\n(Image: )\n\n\n\n\n\nnote: Contributing\nThis example was automatically generated from a Jupyter notebook in the RxInferExamples.jl repository.We welcome and encourage contributions! You can help by:Improving this example\nCreating new examples \nReporting issues or bugs\nSuggesting enhancementsVisit our GitHub repository to get started. Together we can make RxInfer.jl even better! üí™\n\n\n\ncompat: Environment\nThis example was executed in a clean, isolated environment. Below are the exact package versions used:For reproducibility:Use the same package versions when running locally\nReport any issues with package compatibility\n\nStatus `/tmp/jl_A77yVv/Project.toml`\n  [91a5bcdd] Plots v1.41.6\n  [86711068] RxInfer v4.7.0\n  [37e2e46d] LinearAlgebra v1.12.0\n  [9a3f8284] Random v1.11.0\n\n\n","category":"section"}]
}
