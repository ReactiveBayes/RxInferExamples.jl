{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d2455ff",
   "metadata": {},
   "source": [
    "# Reactive Pendulum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3f0235",
   "metadata": {},
   "source": [
    "**NOTE**: This notebook is written in Julia. Julia programming language compiles code on-the-fly and first executation is always very slow due to initial compilation. Sometimes the initial compilation takes several minutes before actual execution of the code (especially GLMakie...). I suggest click `Cell` -> `Run all` and grab a cup of coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5016b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two cells take a lot of time for the very first time, especially GLMakie, for interactive plotting\n",
    "# Installs all necessary packages\n",
    "import Pkg; Pkg.activate(\".\"); Pkg.instantiate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea544902",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RxInfer, Rocket, LinearAlgebra, GLMakie, DataStructures\n",
    "\n",
    "import ReactiveMP: getrecent, messageout, update!\n",
    "import Rocket: subscribe!\n",
    "\n",
    "# --- Logger (simple, file-backed) ---\n",
    "using Dates\n",
    "\n",
    "const RXINF_LOGFILE = joinpath(@__DIR__, \"rxinfer.log\")\n",
    "\n",
    "function rxlog(level::AbstractString, msg)\n",
    "    ts = Dates.format(Dates.now(), \"yyyy-mm-dd HH:MM:SS\")\n",
    "    open(RXINF_LOGFILE, \"a\") do io\n",
    "        println(io, \"[$ts] $(uppercase(level)) - $msg\")\n",
    "    end\n",
    "end\n",
    "\n",
    "rxlog(\"info\", \"Logger initialized for ReactiveInferencePendulum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bafba83",
   "metadata": {},
   "source": [
    "**Note**: This notebook uses 2 reactive libraries: `Observables.jl` and `Rocket.jl`. `Rocket.jl` has been developed in BIASlab and is highly efficient. `GLMakie.jl`, however, uses `Observables.jl`, because `Rocket.jl` did not exist at the moment. Please, do not confuse `Rocket.jl` observables/actors/subjects and `Observables.jl` observables. The functionality of the `Observables.jl` is very very simple, while `Rocket.jl` is a comprehensive self-contained reactive extensions framework with a lot of extra functionality (and also faster :))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aabea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utility functionality\n",
    "# Returns a variable argument function, that shifts a vector and put a new value at the end\n",
    "function shift(vector, value)\n",
    "    return (args...) -> begin \n",
    "        @inbounds for i in firstindex(vector):lastindex(vector)-1\n",
    "            vector[i] = vector[i + 1]\n",
    "        end\n",
    "        vector[end] = value[]\n",
    "        return vector\n",
    "    end\n",
    "end\n",
    "\n",
    "# These are utility functions and are not interesting, skip for now\n",
    "function shift(vector, subject::AbstractSubject)\n",
    "    return (_) -> begin \n",
    "        subscribe!(subject |> take(1), (value) -> shift(vector, value)())\n",
    "        return vector\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a09a0b",
   "metadata": {},
   "source": [
    "# Simulation preparation\n",
    "\n",
    "The very first step in our simulation would be to prepate the pendulum environment that we can play with. Our environment will consist of multiple global parameters, which we will change interactively later on. The parameters are implemented in the `WorldParameters` structure which will be created and shared globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32934797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our beautiful world parameters\n",
    "Base.@kwdef mutable struct PendulumWorldParameters\n",
    "    bob_mass           :: Float64 = 0.2 # grams\n",
    "    rod_length         :: Float64 = 0.2 # cm\n",
    "    friction           :: Float64 = 0.2\n",
    "    gravity            :: Float64 = 9.81\n",
    "    engine_max_power   :: Float64 = 1.0\n",
    "    observations_noise :: Float64 = 1e-6\n",
    "    worlds_clock_Î”t    :: Float64 = 1 / 30\n",
    "end\n",
    "\n",
    "# Its better not to rerun this cell as it defines the `const` global variable\n",
    "const parameters = PendulumWorldParameters();\n",
    "\n",
    "function pendulum_bob_position(angle)\n",
    "    return Point2f(parameters.rod_length * sin(angle), -parameters.rod_length * cos(angle))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f304c9a",
   "metadata": {},
   "source": [
    "## State transition functions\n",
    "\n",
    "The pendulum differential equations can be represented as a special case of a non-linear state-transition probabilistic model with the following state transition function. In the current simulation we assume that the dynamical model of the world is known. In our simulation we also want to ensure that the engine connected to the pendulum has a limited power. We model such a restriction with the `tanh` function, because its a function with a known inverse mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions restrict the engine power to a maximum value of `engine_max_power`\n",
    "function restrict_engine_power(action) \n",
    "    return parameters.engine_max_power * tanh(action / parameters.engine_max_power)\n",
    "end\n",
    "\n",
    "function state_transition(previous_state, action) \n",
    "    # Transition function modeling transition due to gravity, friction and engine control\n",
    "    (Î¸, Î¸Ì‡) = previous_state\n",
    "    Î¸Ìˆ = 1 / (parameters.bob_mass * parameters.rod_length ^ 2) * \n",
    "        (-parameters.bob_mass * parameters.gravity * parameters.rod_length * sin(Î¸) - \n",
    "            parameters.friction * Î¸Ì‡ .+ restrict_engine_power(action))\n",
    "    Î”s = (Î¸Ì‡, Î¸Ìˆ)\n",
    "    next_state = previous_state .+  Î”s .* parameters.worlds_clock_Î”t\n",
    "    return next_state\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a91c6b5",
   "metadata": {},
   "source": [
    "## The implementation of the WORLD\n",
    "\n",
    "Only one single pendulum exists in our simulated world, which makes our task a bit easier. We implement the world in the `PendulumWorld` structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c88c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEHOLD THE IMPLEMENTATION OF THE WHOLE WORLD\n",
    "Base.@kwdef mutable struct PendulumWorld\n",
    "    pendulum_hidden_state :: Tuple{Float64, Float64} = (0.0, 0.0)\n",
    "    next_registered_action  = 0.0\n",
    "    noise_free_observations = RecentSubject(Float64)\n",
    "    noisy_observations      = RecentSubject(Float64)\n",
    "    ticks                   = Subject(Bool)\n",
    "    observations_history    = CircularBuffer(30)\n",
    "    actions_history         = CircularBuffer(30)\n",
    "end\n",
    "\n",
    "# `tick` function is used to move the state of the world further and is independed from any agent\n",
    "# An agent can only `register` a new action in between with the `register_next_action`\n",
    "function tick(world::PendulumWorld)\n",
    "    next_hidden_state = state_transition(world.pendulum_hidden_state, world.next_registered_action)\n",
    "    stochastic_state  = rand(MvNormalMeanPrecision(collect(next_hidden_state), 1e10 * diageye(2)))\n",
    "            \n",
    "    noise_free_observation = first(stochastic_state)\n",
    "    noisy_observation      = rand(NormalMeanVariance(noise_free_observation, parameters.observations_noise))\n",
    "        \n",
    "    # Save history for debugging and plotting\n",
    "    push!(world.actions_history, restrict_engine_power(world.next_registered_action))\n",
    "    push!(world.observations_history, noisy_observation)\n",
    "    \n",
    "    world.next_registered_action = 0.0\n",
    "    world.pendulum_hidden_state = (stochastic_state[1], stochastic_state[2])\n",
    "    \n",
    "    # Fire tick events \n",
    "    next!(world.noise_free_observations, noise_free_observation)\n",
    "    next!(world.noisy_observations, noisy_observation)\n",
    "    next!(world.ticks, true)\n",
    "end\n",
    "\n",
    "function register_next_action(world::PendulumWorld, action)\n",
    "    world.next_registered_action = action\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867fe42b",
   "metadata": {},
   "source": [
    "## The implementation of the AGENT\n",
    "\n",
    "To implement the pendulum controlling agent we define the probabilistic model of the world with the `@model` macro from **RxInfer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af4a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function pendulum(T, P, C, m_s_t_min, v_s_t_min, m_u_t_min, v_u_t_min, x_t, m_u, v_u, m_x, v_x, n_alpha, n_theta)\n",
    "    \n",
    "    n ~ InverseGamma(n_alpha, n_theta)\n",
    "\n",
    "    s_t_min ~ MvNormal(mean = m_s_t_min, covariance = v_s_t_min) # Prior for previous state\n",
    "    u_t_min ~ Normal(mean = m_u_t_min, variance = v_u_t_min)   # Prior for previous action\n",
    "    u_s_min ~ state_transition(s_t_min, u_t_min)          # Deterministic state transition function\n",
    "    s_t     ~ MvNormal(mean = u_s_min, precision = P) # Transition uncertainty\n",
    "    x_t     ~ Normal(mean = dot(C, s_t), variance = n)   # Observational function\n",
    "    \n",
    "    s_k_min = s_t\n",
    "    \n",
    "    for k in 1:T\n",
    "        u[k]    ~ Normal(mean = m_u[k], variance = v_u[k])\n",
    "        u_s[k]  ~ state_transition(s_k_min, u[k])\n",
    "        s[k]    ~ MvNormal(mean = u_s[k], precision = P)\n",
    "        x[k]    ~ Normal(mean = dot(C, s[k]), variance = n)\n",
    "        x[k]    ~ Normal(mean = m_x[k], variance = v_x[k]) \n",
    "        s_k_min = s[k]\n",
    "    end\n",
    "    return s_t, m_s_t_min, v_s_t_min\n",
    "end\n",
    "\n",
    "@meta function pendulum_meta()\n",
    "    state_transition() -> DeltaMeta(method = Linearization())\n",
    "end\n",
    "\n",
    "@constraints function pendulum_constraints()\n",
    "    q(s_t, x, s, u, n) = q(x, s, u, s_t)q(n)\n",
    "end\n",
    "\n",
    "@initialization function pendulum_initialization()\n",
    "    q(u) = map(agent.mean_control_priors, agent.var_control_priors) do m, v\n",
    "        NormalMeanVariance(m, v)\n",
    "    end\n",
    "    q(n) = InverseGamma(4.0, 1.0)\n",
    "    q(s_t_min) = MvNormalMeanCovariance([0.0; 0.0], 1e-12*diageye(2))\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferred variance is very small, causes numerical instabilities\n",
    "pick_first_action = (actions) -> begin\n",
    "    return mean_var(first(actions))\n",
    "end\n",
    "\n",
    "pick_current_state = (states) -> begin\n",
    "    return (agent.mean_current_state_prior, agent.cov_current_state_prior)\n",
    "end\n",
    "\n",
    "soft_noise_prior = (noise) -> begin\n",
    "    Î¼ = mean(noise)\n",
    "    Î¼ = Î¼ > 0.1 ? 0.1 : Î¼\n",
    "    v = 0.1\n",
    "    Î± = Î¼ ^ 2 / v + 2\n",
    "    Î¸ = Î¼ * (Î± - 1)\n",
    "    return (Î±, Î¸)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49ccc5",
   "metadata": {},
   "source": [
    "Next step is to connect the agent with the outside world, for that purpose we create a special `SuperSmartRxInferAgent` structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mutable struct SuperSmartRxInferAgent\n",
    "    datastream               :: AbstractSubscribable\n",
    "    rxinfer_engine           :: Union{Nothing, RxInferenceEngine}\n",
    "    mean_control_priors      :: Vector{Float64}\n",
    "    var_control_priors       :: Vector{Float64}\n",
    "    mean_goal_priors         :: Vector{Float64}\n",
    "    var_goal_priors          :: Vector{Float64}\n",
    "    mean_current_state_prior :: Vector{Float64}\n",
    "    cov_current_state_prior  :: Matrix{Float64}\n",
    "    subscriptions            :: Vector{Teardown}\n",
    "    execution_time           :: AbstractSubject\n",
    "    vmp_iterations           :: AbstractSubject\n",
    "    recent_action            :: AbstractSubject\n",
    "    free_energy              :: AbstractSubject\n",
    "    the_goal_in_radians      :: AbstractSubject\n",
    "    the_goal_variance        :: AbstractSubject\n",
    "\n",
    "    function SuperSmartRxInferAgent(T::Int, datastream::AbstractSubscribable)\n",
    "        mean_control_priors = zeros(T)\n",
    "        var_control_priors  = zeros(T)\n",
    "        mean_goal_priors    = zeros(T)\n",
    "        var_goal_priors     = zeros(T)\n",
    "        mean_current_state_prior = zeros(2)\n",
    "        cov_current_state_prior  = zeros(2, 2)\n",
    "        execution_time           = Subject(Float64)\n",
    "        vmp_iterations           = BehaviorSubject(5)\n",
    "        recent_action            = RecentSubject(Float64)\n",
    "        free_energy              = Subject(Float64)\n",
    "        the_goal_in_radians      = BehaviorSubject(3.14)\n",
    "        the_goal_variance        = BehaviorSubject(1e-3)\n",
    "        subscriptions            = []\n",
    "\n",
    "        agent = new(datastream, nothing,\n",
    "            mean_control_priors, var_control_priors,\n",
    "            mean_goal_priors, var_goal_priors,\n",
    "            mean_current_state_prior, cov_current_state_prior,\n",
    "            subscriptions, execution_time, vmp_iterations, recent_action,\n",
    "            free_energy, the_goal_in_radians, the_goal_variance,\n",
    "        )\n",
    "\n",
    "        reset!(agent)\n",
    "\n",
    "        return agent\n",
    "    end\n",
    "end\n",
    "\n",
    "function reset!(agent::SuperSmartRxInferAgent)\n",
    "    # Use numeric large/small constants, not the functions `huge`/`tiny`\n",
    "    fill!(agent.mean_control_priors, 0.0)\n",
    "    fill!(agent.var_control_priors, 1e10)       # previously `huge` (function)\n",
    "    fill!(agent.mean_goal_priors, 0.0)\n",
    "    fill!(agent.var_goal_priors, 1e10)          # previously `huge`\n",
    "    agent.mean_current_state_prior = [ 0.0, 0.0 ]\n",
    "    agent.cov_current_state_prior = 1e-12 * diageye(2)  # previously `tiny * diageye(2)`\n",
    "\n",
    "    rxlog(\"debug\", \"reset! called: mean_control_priors=$(agent.mean_control_priors), var_control_priors=$(agent.var_control_priors)\")\n",
    "\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function start!(agent::SuperSmartRxInferAgent)\n",
    "    if !isnothing(agent.rxinfer_engine)\n",
    "        stop!(agent)\n",
    "    end\n",
    "\n",
    "    rxlog(\"info\", \"start! called - creating inference engine\")\n",
    "\n",
    "    # Slide helpers: replace `huge` with numeric large value\n",
    "    shift_mean_control_priors = shift(agent.mean_control_priors, 0.0)\n",
    "    shift_var_control_priors  = shift(agent.var_control_priors, 1e10)\n",
    "    shift_mean_goal_priors    = shift(agent.mean_goal_priors, agent.the_goal_in_radians)\n",
    "    shift_var_goal_priors     = shift(agent.var_goal_priors, agent.the_goal_variance)\n",
    "\n",
    "    autoupdates = @autoupdates begin\n",
    "        m_u = shift_mean_control_priors(q(u))\n",
    "        v_u = shift_var_control_priors(q(u))\n",
    "        m_x = shift_mean_goal_priors(q(x))\n",
    "        v_x = shift_var_goal_priors(q(x))\n",
    "        m_u_t_min, v_u_t_min = pick_first_action(q(u))\n",
    "        m_s_t_min, v_s_t_min = pick_current_state(q(s_t_min))\n",
    "        n_alpha, n_theta = soft_noise_prior(q(n))\n",
    "    end\n",
    "\n",
    "    initial_forces = map(agent.mean_control_priors, agent.var_control_priors) do m, v\n",
    "        return NormalMeanVariance(m, v)\n",
    "    end\n",
    "\n",
    "    T = length(agent.mean_control_priors)\n",
    "    iterations_ref = Ref(0)\n",
    "\n",
    "    vmp_iterations_subscription = subscribe!(agent.vmp_iterations, (vmp_iters) -> begin\n",
    "        iterations_ref[] = vmp_iters\n",
    "        rxlog(\"debug\", \"vmp_iterations => $vmp_iters\")\n",
    "        if !(isnothing(agent.rxinfer_engine))\n",
    "            agent.rxinfer_engine.fe_actor.score = zeros(vmp_iters, 30)\n",
    "            agent.rxinfer_engine.fe_actor.cframe = 1\n",
    "            agent.rxinfer_engine.fe_actor.cindex = 0\n",
    "            agent.rxinfer_engine.fe_actor.valid = falses(30)\n",
    "            rxlog(\"debug\", \"Reinitialized fe_actor scoring arrays\")\n",
    "        end\n",
    "    end)\n",
    "\n",
    "    engine = infer(\n",
    "        model = pendulum(\n",
    "            T=T, \n",
    "            P=1e10*diageye(2), \n",
    "            C=[1.0, 0.0],\n",
    "        ),\n",
    "        meta = pendulum_meta(),\n",
    "        constraints = pendulum_constraints(),\n",
    "        datastream = agent.datastream,\n",
    "        autoupdates = autoupdates,\n",
    "        initialization = pendulum_initialization(),\n",
    "        autostart = false,\n",
    "        returnvars = (:u, ),\n",
    "        historyvars = (u = KeepLast(), s_t = KeepLast(), n = KeepLast()),\n",
    "        keephistory = 30,\n",
    "        free_energy = true,\n",
    "        free_energy_diagnostics = nothing,\n",
    "        iterations = iterations_ref,\n",
    "        events = Val((:before_auto_update, :on_tick))\n",
    "    )\n",
    "\n",
    "    on_tick_events = engine.events |> filter(event -> event isa RxInferenceEvent{:on_tick})\n",
    "\n",
    "    on_tick_subscription = subscribe!(on_tick_events, (args...) -> begin\n",
    "        slide_msg_idx = 3\n",
    "        graph     = RxInfer.getmodel(engine.model)\n",
    "        returnval = RxInfer.getreturnval(graph)[1]\n",
    "        variable  = RxInfer.getvariable(RxInfer.getvarref(graph, returnval))\n",
    "        predictive_message = getrecent(messageout(variable, slide_msg_idx))\n",
    "        (m_s_t_min, v_s_t_min) = mean_cov(predictive_message)\n",
    "\n",
    "        agent.mean_current_state_prior = m_s_t_min\n",
    "        agent.cov_current_state_prior = v_s_t_min\n",
    "        # rxlog(\"debug\", \"on_tick updated agent mean/cov priors\")\n",
    "    end)\n",
    "\n",
    "    recent_action_subscription = subscribe!(engine.posteriors[:u], (actions) -> begin\n",
    "        next!(agent.recent_action, mode(first(actions)))\n",
    "    end)\n",
    "\n",
    "    free_energy_subscription = subscribe!(engine.free_energy, (value) -> begin\n",
    "        next!(agent.free_energy, value)\n",
    "    end)\n",
    "\n",
    "    # rxlog(\"debug\", \"All subscriptions created, adding to agent\")\n",
    "    push!(agent.subscriptions, vmp_iterations_subscription)\n",
    "    push!(agent.subscriptions, on_tick_subscription)\n",
    "    push!(agent.subscriptions, recent_action_subscription)\n",
    "    push!(agent.subscriptions, free_energy_subscription)\n",
    "\n",
    "    agent.rxinfer_engine = engine\n",
    "\n",
    "    rxlog(\"debug\", \"Starting inference engine\")\n",
    "    RxInfer.start(engine)\n",
    "    rxlog(\"info\", \"Agent started\")\n",
    "\n",
    "    return nothing, engine\n",
    "end\n",
    "\n",
    "function stop!(agent::SuperSmartRxInferAgent)\n",
    "    rxlog(\"info\", \"stop! called\")\n",
    "    if !isnothing(agent.rxinfer_engine)\n",
    "        RxInfer.stop(agent.rxinfer_engine)\n",
    "    end\n",
    "    foreach(subscription -> unsubscribe!(subscription), agent.subscriptions)\n",
    "    agent.rxinfer_engine = nothing\n",
    "    agent.subscriptions = []\n",
    "    rxlog(\"info\", \"Agent stopped and subscriptions removed\")\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc8ce7",
   "metadata": {},
   "source": [
    "# The most exciting part of the notebook\n",
    "\n",
    "**NOTE**: Note again that Julia initial compilation times are sometimes slow, so the initial execution of this cell takes some time to precompile. Also the `Activate agent` takes some time to precompile the agent, but after the initial compilation the code executes very fast.\n",
    "\n",
    "Making all run together! Fun fact: 99% code below is just plotting stuff. Slider ranges are controlled in the `SliderGrid` structure. \n",
    "\n",
    "P.S. There is some strange bug with \"zero range\" related to plotting in GLMakie, if that happens simply restart the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c7426e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup the space ship's dashboard\n",
    "\n",
    "# Some naming guidelines\n",
    "# `r_*` - indicates *R*eactive observable, either from `Observables.jl` or from `Rocket.jl`\n",
    "# `s_*` - indicates a *S*ubscription\n",
    "# `b_*` - indicates a *B*utton\n",
    "\n",
    "# Width of the controls\n",
    "c_width = 350\n",
    "c_fontsize = 14\n",
    "\n",
    "fig = Figure(fontsize=c_fontsize, resolution=(1080, 720))\n",
    "\n",
    "controls_grid = fig[1:4, 1] = GridLayout()\n",
    "pendulum_grid = fig[1:4, 2:3] = GridLayout()\n",
    "auxilary_grid = fig[1:4, 4] = GridLayout()\n",
    "\n",
    "display(fig, title=\"Pendulum with RxInferðŸ˜Ž\")\n",
    "\n",
    "free_energy_buffer = CircularBuffer{Float64}(100)\n",
    "\n",
    "r_world_isrunning = Observable(true) # Is simulation running\n",
    "r_origin = Observable([Point2f(0, 0), Point2f(0, 0)]) # Position of the origin\n",
    "r_rod = Observable([Point2f(0, 0), Point2f(0, 0)]) # Position of the rod\n",
    "r_bob = Observable([Point2f(0, 0)])  # Position of the bob\n",
    "r_goal = Observable([Point2f(0, 0)]) # Position of the goal\n",
    "r_observations = Observable(Point2f[]) # Positions of noibsy observations (history)\n",
    "r_actions = Observable([Point2f(0, 0), Point2f(0, 0)]) # Actions (history)\n",
    "r_noise_history = Observable(map(_ -> Point2f(0, 0), 1:30)) # Inferred noise (history)\n",
    "r_noise_bandl = Observable(map(_ -> Point2f(0, 0), 1:30)) # Inferred noise lower band (history)\n",
    "r_noise_bandu = Observable(map(_ -> Point2f(0, 0), 1:30)) # Inferred noise upper band (history)\n",
    "r_free_energy = Observable([Point2f(0, 0)])\n",
    "r_free_energy_acc = Observable([Point2f(0, 0)])\n",
    "\n",
    "ax_actions_history = Axis(auxilary_grid[1, 1], limits=(0, 30, -1.5, 1.5), title=\"Agents actions\")\n",
    "\n",
    "lines!(ax_actions_history, r_actions; linewidth=4, color=:blue)\n",
    "\n",
    "# Dashboard buttons and sliders\n",
    "b_grid = controls_grid[2, 1] = GridLayout()\n",
    "\n",
    "b_run = Button(b_grid[1, 1]; label=\"Activate agent\", width=c_width / 2, fontsize=c_fontsize)\n",
    "b_areset = Button(b_grid[2, 1]; label=\"Erase agents's memory\", width=c_width / 2, fontsize=c_fontsize)\n",
    "b_stop = Button(b_grid[3, 1]; label=\"Deactivate agent\", width=c_width / 2, fontsize=c_fontsize)\n",
    "\n",
    "b_corrupt = Button(b_grid[1, 2]; label=\"Corrupt world's state\", width=c_width / 2, fontsize=c_fontsize)\n",
    "b_wreset = Button(b_grid[2, 2]; label=\"Reset world's parameters\", width=c_width / 2, fontsize=c_fontsize)\n",
    "\n",
    "\n",
    "sg = SliderGrid(\n",
    "    controls_grid[1, 1],\n",
    "    (label=\"Bob's mass\", range=0.15:0.01:0.35, format=\"{:.3f}g\", startvalue=parameters.bob_mass,),\n",
    "    (label=\"Rod's Length\", range=0.15:0.01:0.25, format=\"{:.3f}cm\", startvalue=parameters.rod_length),\n",
    "    (label=\"Maximum engine power\", range=0.1:0.1:1.5, format=\"{:.1f}\", startvalue=parameters.engine_max_power),\n",
    "    (label=\"Pendulum's friction\", range=0.1:0.01:0.3, format=\"{:.3f}\", startvalue=parameters.friction),\n",
    "    (label=\"World's gravity\", range=1.0:0.1:50.0, format=\"{:.1f}\", startvalue=parameters.gravity),\n",
    "    (label=\"Observational noise\", range=exp10.(-8.0:0.1:-2), format=\"{:.6f}\", startvalue=parameters.observations_noise),\n",
    "    (label=\"VMP iterations\", range=1:25, startvalue=5),\n",
    "    (label=\"Goal\", range=0:0.01:2pi, startvalue=pi),\n",
    "    (label=\"Goal variance\", range=exp10.(-5.0:0.1:-2), startvalue=exp10(-3)),\n",
    "    width=c_width,\n",
    "    tellwidth=true,\n",
    "    tellheight=true\n",
    ")\n",
    "\n",
    "r_mass = sg.sliders[1].value\n",
    "r_length = sg.sliders[2].value\n",
    "r_power = sg.sliders[3].value\n",
    "r_friction = sg.sliders[4].value\n",
    "r_gravity = sg.sliders[5].value\n",
    "r_noise = sg.sliders[6].value\n",
    "r_iters = sg.sliders[7].value\n",
    "r_goalp = sg.sliders[8].value\n",
    "r_goalv = sg.sliders[9].value\n",
    "\n",
    "ax_limits = (-0.3, 0.3, -0.3, 0.3)\n",
    "ax_pendulum = Axis(pendulum_grid[1, 1], limits=ax_limits, title=\"Pendulum\", aspect=DataAspect())\n",
    "\n",
    "lines!(ax_pendulum, r_rod; linewidth=5, color=:black)\n",
    "scatter!(ax_pendulum, r_origin; strokewidth=2, strokecolor=:black, color=:black, markersize=20)\n",
    "scatter!(ax_pendulum, r_bob; strokewidth=2, strokecolor=:black, color=:black, markersize=map(m -> m * 500, r_mass))\n",
    "scatter!(ax_pendulum, r_goal; strokewidth=4, strokecolor=:red, color=(:red, 0.2), markersize=120)\n",
    "scatter!(ax_pendulum, r_observations; strokecolor=:green, color=(:green, :0.2), markersize=map(m -> m * 75, r_mass))\n",
    "\n",
    "ax_inferred_noise_history = Axis(auxilary_grid[2, 1], yscale=log10, limits=(0, 30, 1e-8, 1.0), title=\"Estimated noise precision\")\n",
    "\n",
    "lines!(ax_inferred_noise_history, r_noise_history; linewidth=4, color=:blue)\n",
    "band!(ax_inferred_noise_history, r_noise_bandl, r_noise_bandu, color=(:blue, 0.2))\n",
    "hlines!(ax_inferred_noise_history, map(e -> [e], r_noise), color=:red)\n",
    "\n",
    "ax_free_energy_history = Axis(auxilary_grid[3, 1], limits=((0, 100), nothing), xticklabelsvisible=false, yticklabelsvisible=false, title=\"Bethe Free Energy\")\n",
    "lines!(ax_free_energy_history, r_free_energy)\n",
    "\n",
    "ax_free_energy_acc_history = Axis(auxilary_grid[4, 1], limits=((1, 15), nothing), xticklabelsvisible=true, yticklabelsvisible=false, title=\"BFE minimization history\")\n",
    "lines!(ax_free_energy_acc_history, r_free_energy_acc)\n",
    "\n",
    "## Initialize the environment    \n",
    "\n",
    "world = PendulumWorld()\n",
    "agent = SuperSmartRxInferAgent(3, labeled(Val((:x_t,)), combineLatest(world.noisy_observations)))\n",
    "\n",
    "# Redraw the observations as soon as we have a new data point\n",
    "s_ticks = subscribe!(world.ticks, (_) -> begin\n",
    "    r_observations[] = map(angle -> pendulum_bob_position(angle), world.observations_history)\n",
    "    r_actions[] = map(((index, force),) -> Point2f(index, force), enumerate(world.actions_history))\n",
    "    r_free_energy[] = map(((index, value),) -> Point2f(index, value), enumerate(free_energy_buffer))\n",
    "\n",
    "    if !isnothing(agent.rxinfer_engine)\n",
    "        if length(agent.rxinfer_engine.history[:n]) == 30\n",
    "            rfem, rfev = mean(free_energy_buffer), clamp(var(free_energy_buffer), 1e-4, Inf)\n",
    "            if !isnan(rfem) && !isinf(rfem) && !isnan(rfev) && !isinf(rfev)\n",
    "                ylims!(ax_free_energy_history, clamp(rfem - 20sqrt(rfev), 1e-8, Inf), rfem + 20sqrt(rfev))\n",
    "            end\n",
    "            rfeaccmin, rfeaccmax = minimum(agent.rxinfer_engine.free_energy_history), maximum(agent.rxinfer_engine.free_energy_history)\n",
    "            rfeaccm, rfeaccv = mean(agent.rxinfer_engine.free_energy_history), clamp(var(agent.rxinfer_engine.free_energy_history), 1e-4, Inf)\n",
    "            if !isnan(rfeaccm) && !isinf(rfeaccm) && !isnan(rfeaccv) && !isinf(rfeaccv)\n",
    "                xlims!(ax_free_energy_acc_history, 1, length(agent.rxinfer_engine.free_energy_history))\n",
    "                ylims!(ax_free_energy_acc_history, clamp(rfeaccmin - sqrt(rfeaccv), 1e-8, Inf), rfeaccmax + sqrt(rfeaccv))\n",
    "            end\n",
    "\n",
    "            noise_means = map((q_n) -> mean(q_n), agent.rxinfer_engine.history[:n])\n",
    "            noise_vars = map((q_n) -> var(q_n), agent.rxinfer_engine.history[:n])\n",
    "            r_free_energy_acc[] = map(((index, value),) -> Point2f(index, value), enumerate(agent.rxinfer_engine.free_energy_history))\n",
    "            r_noise_history[] = map(((index, mean),) -> Point2f(index, mean), enumerate(noise_means))\n",
    "            r_noise_bandl[] = map(((index, mean), var) -> Point2f(index, clamp(mean - sqrt(var), 1e-10, Inf)), enumerate(noise_means), noise_vars)\n",
    "            r_noise_bandu[] = map(((index, mean), var) -> Point2f(index, clamp(mean + sqrt(var), 1e-10, Inf)), enumerate(noise_means), noise_vars)\n",
    "        end\n",
    "    end\n",
    "end)\n",
    "\n",
    "s_redraw = subscribe!(combineLatest(world.noise_free_observations, agent.the_goal_in_radians), ((angle, goal),) -> begin\n",
    "    origin_position = Point2f(0.0, 0.0)\n",
    "    bob_position = pendulum_bob_position(angle)\n",
    "    r_rod[] = [origin_position, bob_position]\n",
    "    r_bob[] = [bob_position]\n",
    "    r_goal[] = [pendulum_bob_position(goal)]\n",
    "end)\n",
    "\n",
    "# Register a new action as soon as we have it\n",
    "s_actions = subscribe!(agent.recent_action, (a) -> register_next_action(world, a))\n",
    "s_free_energy = subscribe!(agent.free_energy, (v) -> push!(free_energy_buffer, v))\n",
    "\n",
    "## START THE SHOW!!\n",
    "\n",
    "# The world runs independently of the agent, but can be force-stopped as well\n",
    "@async begin\n",
    "    try\n",
    "        while isopen(fig.scene) && r_world_isrunning[]\n",
    "            tick(world)\n",
    "            sleep(1 / 60)\n",
    "        end\n",
    "    catch err\n",
    "        println(\"An error happened inside our beautiful world!\")\n",
    "        showerror(stderr, err, catch_backtrace())\n",
    "    end\n",
    "    unsubscribe!(s_actions)\n",
    "    unsubscribe!(s_free_energy)\n",
    "    unsubscribe!(s_ticks)\n",
    "    unsubscribe!(s_redraw)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "# Implement buttons logic\n",
    "on(b_run.clicks) do clicks\n",
    "    try\n",
    "        reset!(agent)\n",
    "        start!(agent)\n",
    "    catch err\n",
    "        rxlog(\"error\", \"An error happened inside our beautiful click!: $err\")\n",
    "        println(\"An error happened inside our beautiful click!\")\n",
    "        showerror(stderr, err, catch_backtrace())\n",
    "    end\n",
    "end\n",
    "\n",
    "on(b_areset.clicks) do clicks\n",
    "    reset!(agent)\n",
    "end\n",
    "\n",
    "on(b_corrupt.clicks) do clicks\n",
    "    world.pendulum_hidden_state = (0.0, 0.0)\n",
    "end\n",
    "\n",
    "on(b_wreset.clicks) do clicks\n",
    "    local rparams = PendulumWorldParameters()\n",
    "    r_length[] = parameters.rod_length = rparams.rod_length\n",
    "    r_mass[] = parameters.bob_mass = rparams.bob_mass\n",
    "    r_friction[] = parameters.friction = rparams.friction\n",
    "    r_gravity[] = parameters.gravity = rparams.gravity\n",
    "    r_power[] = parameters.engine_max_power = rparams.engine_max_power\n",
    "    r_noise[] = parameters.observations_noise = rparams.observations_noise\n",
    "    parameters.worlds_clock_Î”t = rparams.worlds_clock_Î”t\n",
    "end\n",
    "\n",
    "on((_) -> stop!(agent), b_stop.clicks)\n",
    "\n",
    "# Implement sliders logic\n",
    "\n",
    "on((length) -> begin\n",
    "    global parameters.rod_length = length\n",
    "end, r_length)\n",
    "on((mass) -> begin\n",
    "    global parameters.bob_mass = mass\n",
    "end, r_mass)\n",
    "on((power) -> begin\n",
    "    global parameters.engine_max_power = power\n",
    "end, r_power)\n",
    "on((friction) -> begin\n",
    "    global parameters.friction = friction\n",
    "end, r_friction)\n",
    "on((gravity) -> begin\n",
    "    global parameters.gravity = gravity\n",
    "end, r_gravity)\n",
    "on((noise) -> begin\n",
    "    global parameters.observations_noise = noise\n",
    "end, r_noise)\n",
    "on((iters) -> begin\n",
    "    next!(agent.vmp_iterations, iters)\n",
    "end, r_iters)\n",
    "on((goal) -> begin\n",
    "    next!(agent.the_goal_in_radians, goal)\n",
    "end, r_goalp)\n",
    "on((var) -> begin\n",
    "    next!(agent.the_goal_variance, var)\n",
    "end, r_goalv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12.1",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
