{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "948e6218",
   "metadata": {},
   "source": [
    "# Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a4324d",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Warning: Maximum Unprincipledness Ahead ‚ö†Ô∏è\n",
    "\n",
    "### ‚ö†Ô∏è The speed of RxInfer will be bottlenecked by the speed of the LLM calls ‚ö†Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9529622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RxInfer, OpenAI, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fdc0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your OpenAI API key should be set in the environment variables\n",
    "secret_key = ENV[\"OPENAI_KEY\"];\n",
    "llm_model = \"gpt-4o-mini-2024-07-18\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcad379",
   "metadata": {},
   "source": [
    "**Disclaimer**: This is probably one of the most unprincipled notebooks in the `RxInferExamples` repository. We're about to hook Large Language Models directly into Bayesian inference using nothing but good vibes and questionable life choices. If you're looking for rigorous mathematical foundations, you might want to slowly back away from this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438313c6",
   "metadata": {},
   "source": [
    "That said, if you've ever wondered \"what happens if I treat LLMs' outputs like a probability distribution?\", you've come to the right place.\n",
    "We'll start with a gentle introduction to RxInfer for two reasons: first, we need to justify this madness of integrating LLMs with probabilistic models, and second, we want to explain what RxInfer is to newcomers in a single notebook with as few external references as possible. Think of this as \"Bayesian Inference for People Who Just Want to See the Cool Stuff.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaaf95b",
   "metadata": {},
   "source": [
    "## What is RxInfer? (The Gentle Introduction)\n",
    "\n",
    "Before we commit crimes against Bayesian inference (by the way we use the word inference to mean \"Bayesian inference\", not the forward pass of a neural network), let's understand what RxInfer actually is and why it accidentally makes LLM integration possible.\n",
    "\n",
    "RxInfer is a Julia package for Bayesian inference that takes a rather unusual approach: instead of treating your probabilistic model as one big mathematical beast that needs to be slayed with MCMC or variational inference, it breaks everything down into **small, local conversations between probability distributions**.\n",
    "\n",
    "Imagine your probabilistic model as a social network where probability distributions are people, and they're all gossiping about what they think the true parameters might be. RxInfer organizes this gossip into an efficient message-passing protocol on something called a **factor graph**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fc19bb",
   "metadata": {},
   "source": [
    "### Factor Graphs: The Social Network of Probability\n",
    "\n",
    "A **factor graph** is just a visual way to represent how different parts of your probabilistic model talk to each other. Think of it like this:\n",
    "\n",
    "- **Round nodes** (variables): These represent the things you want to learn about\n",
    "- **Square nodes** (factors): These represent relationships or constraints between variables  \n",
    "- **Edges**: These are the communication channels where probability distributions flow as \"messages\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3a7971",
   "metadata": {},
   "source": [
    "For example, if you want to model coin flips:\n",
    "```mermaid\n",
    "graph LR\n",
    "    %% Variable nodes (circles)\n",
    "    theta[\"Œ∏<br/>(coin fairness)\"]\n",
    "    x1[\"x‚ÇÅ<br/>(flip 1)\"]\n",
    "    x2[\"x‚ÇÇ<br/>(flip 2)\"]\n",
    "    x3[\"x‚ÇÉ<br/>(flip 3)\"]\n",
    "    \n",
    "    %% Factor nodes (squares)\n",
    "    prior[\"Beta<br/>Prior\"]\n",
    "    flip1[\"Bernoulli<br/>Flip\"]\n",
    "    flip2[\"Bernoulli<br/>Flip\"] \n",
    "    flip3[\"Bernoulli<br/>Flip\"]\n",
    "    \n",
    "    %% Connections\n",
    "    prior --- theta\n",
    "    theta --- flip1\n",
    "    theta --- flip2\n",
    "    theta --- flip3\n",
    "    flip1 --- x1\n",
    "    flip2 --- x2\n",
    "    flip3 --- x3\n",
    "    \n",
    "    %% Styling\n",
    "    classDef variable fill:#e1f5fe,stroke:#01579b,stroke-width:2px\n",
    "    classDef factor fill:#fff3e0,stroke:#e65100,stroke-width:2px\n",
    "    \n",
    "    class theta,x1,x2,x3 variable\n",
    "    class prior,flip1,flip2,flip3 factor\n",
    "```\n",
    "\n",
    "In this graph:\n",
    "- **Blue squares** are variables (things we want to learn about)\n",
    "- **Orange squares** are factors (probability distributions or relationships)\n",
    "- **Lines** are the communication channels where messages flow back and forth\n",
    "\n",
    "The magic happens when messages flow along these edges, updating beliefs as new information comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db91a60e",
   "metadata": {},
   "source": [
    "### The Philosophy: Local Conversations, Global Intelligence\n",
    "\n",
    "Here's what makes RxInfer special: instead of solving your entire probabilistic model in one giant computation, it breaks everything down into **local conversations**. \n",
    "\n",
    "Each node only needs to:\n",
    "1. Listen to messages from its neighbors\n",
    "2. Update its local beliefs\n",
    "3. Send updated messages to its neighbors\n",
    "\n",
    "Repeat this process, and eventually the entire network converges to the exact or approximate posterior distributions. It's like crowd-sourced intelligence, but with math.\n",
    "\n",
    "This approach has some nice properties:\n",
    "- **Modular**: You can swap out parts of your model without affecting others\n",
    "- **Parallel**: Different parts can update simultaneously  \n",
    "- **Interpretable**: You can inspect what each part of your model \"thinks\"\n",
    "- **Extensible**: You can add new types of nodes... like LLMs üëÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e8e9d",
   "metadata": {},
   "source": [
    "### The Beautiful Accident: RxInfer Doesn't Care What You Pass\n",
    "\n",
    "Here's where things get interesting (and unprincipled). \n",
    "\n",
    "RxInfer was designed for passing probability distributions along those edges. But here's the thing: **the framework doesn't actually care what you pass**. It just needs to know how to:\n",
    "1. Compute outgoing messages from incoming ones\n",
    "2. Update local beliefs (marginals)\n",
    "3. Calculate free energy contributions (we will skip this for now)\n",
    "\n",
    "As long as you can define these two (three) things, you can plug in **literally anything** as a node. A matrix multiplication? Sure. A neural network? Why not (see examples within the repository). A Large Language Model? Hold my coffee..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22028277",
   "metadata": {},
   "source": [
    "## The Moment of Questionable Judgment\n",
    "\n",
    "So here we were, understanding that RxInfer is basically a message-passing system that doesn't care what you pass, when someone (probably me) had a thought:\n",
    "\n",
    "*\"What if we just... asked ChatGPT to be a probability distribution?\"*\n",
    "\n",
    "Now, any reasonable person would immediately recognize this as a terrible idea. Probability distributions have well-defined mathematical properties. They integrate to 1. They have moments. They follow laws. Jaynes would be rolling in his grave.\n",
    "\n",
    "Large Language Models, on the other hand, are... vibes-based. They generate text that sounds plausible. They hallucinate. They change their mind if you ask the same question twice.\n",
    "\n",
    "But here's the thing about terrible ideas: sometimes they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65104ef9",
   "metadata": {},
   "source": [
    "## The Great LLM-Bayesian Integration Experiment\n",
    "\n",
    "The plan was simple (and deeply unscientific):\n",
    "\n",
    "1. **Create LLM nodes** that can participate in message passing\n",
    "2. **Teach LLMs to speak probability** through prompting\n",
    "3. **Let them gossip with real probability distributions** and see what happens\n",
    "4. **Hope nothing catches fire**\n",
    "\n",
    "Surprisingly, steps 1-3 worked. Step 4 is still ongoing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832aa536",
   "metadata": {},
   "source": [
    "## The Problem: Can We Cluster Text Using Bayesian Inference?\n",
    "\n",
    "Before we dive into the implementation, let's define a concrete problem that will motivate our LLM integration. We want to:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461dc004",
   "metadata": {},
   "source": [
    "**Cluster text snippets by sentiment, but with proper uncertainty quantification.**\n",
    "\n",
    "Here's our dataset - 5 text snippets about RxInfer.jl:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "26d734bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = [\n",
    "    \"RxInfer.jl is confusing and frustrating to use. I wouldn't recommend it.\",\n",
    "    \"RxInfer.jl made my Bayesian modeling workflow much easier and more efficient!\",\n",
    "    \"Absolutely love RxInfer.jl! It's revolutionized my approach to probabilistic programming.\",\n",
    "    \"I gave RxInfer.jl a try, but it just doesn't work for my needs at all.\",\n",
    "    \"I prefer apples over oranges.\"  # üçé Wait, this one's different...\n",
    "];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8933d3a",
   "metadata": {},
   "source": [
    "The challenges:\n",
    "1. **Two sentiment clusters**: Positive and negative opinions about RxInfer.jl\n",
    "2. **Unrelated text**: The last one isn't about RxInfer.jl at all\n",
    "3. **Uncertainty**: We want to know how confident we are about each classification\n",
    "\n",
    "Traditional clustering would give us hard assignments. We want **probabilistic clustering with uncertainty**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff0ced9",
   "metadata": {},
   "source": [
    "## The Model: Mixing Traditional Bayesian with LLM Magic\n",
    "\n",
    "Here's our probabilistic model for sentiment clustering (this will be the final model we will use):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8d28a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function language_mixture_model(c, context‚ÇÅ, context‚ÇÇ, task‚ÇÅ, task‚ÇÇ, likelihood_task)\n",
    "    # Mixture probability (how much of each sentiment type)\n",
    "    s ~ Beta(1.0, 1.0)\n",
    "    \n",
    "    # Two sentiment clusters with LLM-generated priors\n",
    "    m[1] ~ LLMPrior(context‚ÇÅ, task‚ÇÅ)  # Negative sentiment prior\n",
    "    w[1] ~ Gamma(shape = 0.01, rate = 0.01)\n",
    "    \n",
    "    m[2] ~ LLMPrior(context‚ÇÇ, task‚ÇÇ)  # Positive sentiment prior  \n",
    "    w[2] ~ Gamma(shape = 0.01, rate = 0.01)\n",
    "    \n",
    "    for i in eachindex(c)\n",
    "        z[i] ~ Bernoulli(s)  # Cluster assignment (0=negative, 1=positive)\n",
    "        y[i] ~ NormalMixture(switch = z[i], m = m, p = w)  # Latent sentiment score\n",
    "        c[i] ~ LLMObservation(y[i], likelihood_task)  # Observed text\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ab5e27",
   "metadata": {},
   "source": [
    "### What This Model Does\n",
    "\n",
    "Let's break this down:\n",
    "\n",
    "1. **`s ~ Beta(1,1)`**: Overall mixture proportion (how much positive vs negative sentiment in our dataset)\n",
    "\n",
    "2. **`m[1] ~ LLMPrior(context‚ÇÅ, task‚ÇÅ)`**: \n",
    "   - Ask an LLM: \"Given that RxInfer.jl is terrible, what satisfaction score distribution would you expect?\"\n",
    "   - LLM response becomes our **prior** for negative sentiment\n",
    "\n",
    "3. **`m[2] ~ LLMPrior(context‚ÇÇ, task‚ÇÇ)`**: \n",
    "   - Ask an LLM: \"Given that RxInfer.jl is great, what satisfaction score distribution would you expect?\"\n",
    "   - LLM response becomes our **prior** for positive sentiment\n",
    "\n",
    "4. **`z[i] ~ Bernoulli(s)`**: Each text snippet gets assigned to positive or negative cluster\n",
    "\n",
    "5. **`y[i] ~ NormalMixture(...)`**: Each snippet has a latent \"satisfaction score\" based on its cluster\n",
    "\n",
    "6. **`c[i] ~ LLMObservation(y[i], likelihood_task)`**: \n",
    "   - Ask an LLM: \"What sentiment score would generate this text?\"\n",
    "   - This connects our observed text to the latent satisfaction scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15be7dd",
   "metadata": {},
   "source": [
    "### The Insight: LLMs as Probabilistic Components\n",
    "\n",
    "The brilliant (and possibly insane) insight is that we're using LLMs as:\n",
    "\n",
    "- **LLMPrior**: A way to generate informed priors based on contextual knowledge\n",
    "- **LLMObservation**: A likelihood function that connects text to latent numerical variables\n",
    "\n",
    "This means the LLMs aren't just doing classification - they're participating in full Bayesian inference!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14f1f7c",
   "metadata": {},
   "source": [
    "## Creating the LLM Nodes\n",
    "\n",
    "Now that we understand *why* we need these nodes, let's see how to build them. Creating a custom node in RxInfer requires 4 steps (but we will skip the last two):\n",
    "\n",
    "1. **Create the node structure** using the `@node` macro\n",
    "2. **Define message passing rules** with the `@rule` macro  \n",
    "3. **Specify marginal computations** with the `@marginalrule` macro (skipped)\n",
    "4. **Implement free energy computation** with the `@average_energy` macro (skipped)\n",
    "\n",
    "The beauty is in the **message passing protocol**. Each node only needs to know how to:\n",
    "- Process incoming messages from neighbors\n",
    "- Send outgoing messages to neighbors  \n",
    "- Maintain local beliefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4553ea",
   "metadata": {},
   "source": [
    "Let's look at the actual implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251fe91e",
   "metadata": {},
   "source": [
    "### LLMPrior Node\n",
    "\n",
    "First, the node definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9000984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    LLMPrior\n",
    "\n",
    "Node that represents an LLM's prior beliefs about latent variables based on contextual information.\n",
    "The LLM interprets the context and task to produce a probability distribution as a prior.\n",
    "\n",
    "# Interfaces\n",
    "- `belief` (b): Output distribution representing the LLM's prior belief\n",
    "- `context` (c): Input text providing context for the prior\n",
    "- `task` (t): Input text describing what distribution to generate\n",
    "\"\"\"\n",
    "struct LLMPrior end\n",
    "\n",
    "@node LLMPrior Stochastic [ (b, aliases = [belief]), (c, aliases = [context]), (t, aliases = [task]) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e302694",
   "metadata": {},
   "source": [
    "Now here's the actual message passing rule that does the magic. This is going to be a forward rule that will provide a prior for the sentiment of the text. We understand that the syntax for the rule is a bit weird, so we refer the curious reader to the [documentation](https://docs.rxinfer.org/stable/reference/rules.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5c971a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "@rule LLMPrior(:b, Marginalisation) (q_c::PointMass{<:String}, q_t::PointMass{<:String}) = begin\n",
    "    # Build the conversation with the LLM\n",
    "    messages = [\n",
    "        Dict(\"role\" => \"system\",\n",
    "             \"content\" => \"\"\"\n",
    "                 You are an expert analyst who maps contextual cues to a\n",
    "                 Normal(mean, variance) distribution.\n",
    "\n",
    "                 ‚Ä¢ Think step-by-step internally.\n",
    "                 ‚Ä¢ **Only** output a JSON object that conforms to the schema below.\n",
    "                 ‚Ä¢ Do not wrap the JSON in markdown fences or add extra keys.\n",
    "             \"\"\"),\n",
    "\n",
    "        Dict(\"role\" => \"assistant\",\n",
    "             \"content\" => \"\"\"\n",
    "                 ## CONTEXT\n",
    "                 $(q_c.point)\n",
    "             \"\"\"),\n",
    "\n",
    "        Dict(\"role\" => \"user\",\n",
    "             \"content\" => \"\"\"\n",
    "                 ## TASK\n",
    "                 $(q_t.point)\n",
    "\n",
    "                 Using the context above, infer a Normal distribution and return:\n",
    "                   \"analysis\"  ‚Äì brief rationale (‚â§ 100 words)\n",
    "                   \"mean\"      ‚Äì number in [0, 10]\n",
    "                   \"variance\"  ‚Äì number in [1, 100]\n",
    "             \"\"\")\n",
    "    ]\n",
    "\n",
    "    # Define strict JSON schema for consistent responses\n",
    "    response_schema = Dict(\n",
    "        \"type\" => \"json_schema\",\n",
    "        \"json_schema\" => Dict(\n",
    "            \"name\"   => \"normal_estimate\",\n",
    "            \"schema\" => Dict(\n",
    "                \"type\"       => \"object\",\n",
    "                \"properties\" => Dict(\n",
    "                    \"analysis\" => Dict(\"type\" => \"string\"),\n",
    "                    \"mean\"     => Dict(\"type\" => \"number\", \"minimum\" => 0, \"maximum\" => 10),\n",
    "                    \"variance\" => Dict(\"type\" => \"number\", \"minimum\" => 1, \"maximum\" => 100)\n",
    "                ),\n",
    "                \"required\" => [\"analysis\", \"mean\", \"variance\"],\n",
    "                \"additionalProperties\" => false\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Call the LLM and parse the response\n",
    "    r = create_chat(secret_key, llm_model, messages; response_format = response_schema)\n",
    "    obj = JSON.parse(r.response[:choices][1][:message][:content])\n",
    "\n",
    "    return NormalMeanVariance(obj[\"mean\"], obj[\"variance\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2cb77a",
   "metadata": {},
   "source": [
    "### LLMObservation Node\n",
    "\n",
    "The node definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1c93fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    LLMObservation\n",
    "\n",
    "Node that represents an LLM's observation of data based on a latent belief and task description.\n",
    "The LLM takes a latent belief and task description to produce corresponding observed data.\n",
    "\n",
    "# Interfaces\n",
    "- `out`: Output observation data generated by the LLM\n",
    "- `belief` (b): Input latent variable/distribution that influences the observation\n",
    "- `task` (t): Input text describing how to generate observations from beliefs\n",
    "\"\"\"\n",
    "struct LLMObservation end\n",
    "\n",
    "@node LLMObservation Stochastic [ out, (b, aliases = [belief]), (t, aliases = [task]) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9f4f8b",
   "metadata": {},
   "source": [
    "Now we need to define the rule. Normally, we would have to define the rules for each interface (edge) of the node, but here we will skip this part and define only a backward rule from observations to a belief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "47a375b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@rule LLMObservation(:b, Marginalisation) (q_out::PointMass{<:String}, q_t::PointMass{<:String}) = begin\n",
    "    messages = [\n",
    "        Dict(\"role\" => \"system\",\n",
    "             \"content\" => \"\"\"\n",
    "                 You are **LLMObservation**, a senior evaluator who maps a text to\n",
    "                 a Normal(mean, variance) distribution.\n",
    "\n",
    "                 ‚Ä¢ Think step-by-step internally, but **only** output a JSON object\n",
    "                   that conforms to the provided schema.\n",
    "                 ‚Ä¢ Do not wrap the JSON in markdown fences or add extra keys.\n",
    "             \"\"\"),\n",
    "\n",
    "        Dict(\"role\" => \"assistant\",\n",
    "             \"content\" => \"\"\"\n",
    "                 ## TEXT\n",
    "                 $(q_out.point)\n",
    "             \"\"\"),\n",
    "\n",
    "        Dict(\"role\" => \"user\",\n",
    "             \"content\" => \"\"\"\n",
    "                 ## TASK\n",
    "                 $(q_t.point)\n",
    "\n",
    "                 Using the text above, infer a Gaussian distribution.\n",
    "                 Return a JSON object with keys:\n",
    "                   \"analysis\"  ‚Äì ‚â§ 100 words explaining your reasoning\n",
    "                   \"mean\"      ‚Äì number in [0, 10]\n",
    "                   \"variance\"  ‚Äì number in [0.1, 100]\n",
    "             \"\"\")\n",
    "    ]\n",
    "\n",
    "    response_schema = Dict(\n",
    "        \"type\" => \"json_schema\",\n",
    "        \"json_schema\" => Dict(\n",
    "            \"name\"   => \"normal_estimate\",\n",
    "            \"schema\" => Dict(\n",
    "                \"type\"       => \"object\",\n",
    "                \"properties\" => Dict(\n",
    "                    \"analysis\" => Dict(\"type\" => \"string\"),\n",
    "                    \"mean\"     => Dict(\"type\" => \"number\", \"minimum\" => 0, \"maximum\" => 10),\n",
    "                    \"variance\" => Dict(\"type\" => \"number\", \"minimum\" => 0.1, \"maximum\" => 100)\n",
    "                ),\n",
    "                \"required\" => [\"analysis\", \"mean\", \"variance\"],\n",
    "                \"additionalProperties\" => false\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    r = create_chat(secret_key, llm_model, messages; response_format = response_schema)\n",
    "    obj = JSON.parse(r.response[:choices][1][:message][:content])\n",
    "\n",
    "    return NormalMeanVariance(obj[\"mean\"], obj[\"variance\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0f4be579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Priors\n",
    "context‚ÇÅ = \"RxInfer.jl is absolutely terrible.\"\n",
    "context‚ÇÇ = \"RxInfer.jl is a great tool for Bayesian Inference.\"\n",
    "\n",
    "prior_task = \"\"\"\n",
    "Provide a distribution of the statement.\n",
    "- **Mean**: Most likely satisfaction score (0-10 scale)  \n",
    "- **Variance**: Uncertainty in your interpretation\n",
    "    - Low variance (2.0-4.0): Very clear sentiment\n",
    "    - Medium variance (4.1-6.0): Some ambiguity\n",
    "    - High variance (6.0-10.0): Unclear or mixed signals\n",
    "\"\"\"\n",
    "\n",
    "# Likelihood  \n",
    "likelihood_task = \"\"\"\n",
    "Evaluation of sentiment about RxInfer.jl and provide satisfaction score distribution.\n",
    "If expression is not related to RxInfer.jl, return distribution with mean 5 and high variance of 100.\n",
    "- **Mean**: Most likely satisfaction score (0-10 scale)\n",
    "- **Variance**: Uncertainty in interpretation  \n",
    "    - Low variance (0.1-1.0): Very clear sentiment, confident interpretation\n",
    "    - Medium variance (1.1-5.0): Some ambiguity in the text\n",
    "    - High variance (5.1-10.0): Unclear/mixed signals, or not related to RxInfer.jl\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce353a54",
   "metadata": {},
   "source": [
    "### What Happens During Inference\n",
    "\n",
    "1. **LLM Priors Generate Initial Beliefs**:\n",
    "   - Negative context ‚Üí Low satisfaction score (‚âà Gaussians with mean some mean between 0 and 5 and (perhaps) high variance) \n",
    "   - Positive context ‚Üí High satisfaction score (‚âà Gaussians with mean some mean between 5 and 10 and (perhaps) high variance)\n",
    "\n",
    "2. **LLM Observations Process Text**:\n",
    "   - \"RxInfer.jl is confusing...\" ‚Üí Low score, low uncertainty\n",
    "   - \"Absolutely love RxInfer.jl...\" ‚Üí High score, low uncertainty  \n",
    "   - \"I prefer apples over oranges\" ‚Üí Medium score, HIGH uncertainty (not related!)\n",
    "\n",
    "3. **Message Passing Updates Beliefs**:\n",
    "   - Traditional Bayesian update rules combine LLM outputs\n",
    "   - Cluster assignments emerge from the mixture model\n",
    "   - Uncertainty propagates through the network\n",
    "\n",
    "4. **Final Result**: Clean clustering with proper uncertainty quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61d002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Initial state: \n",
       "  q(s) = Beta{Float64}(Œ±=1.0, Œ≤=1.0)\n",
       "  q(m) = NormalMeanVariance{Float64}[NormalMeanVariance{Float64}(Œº=0.0, v=100.0), NormalMeanVariance{Float64}(Œº=10.0, v=100.0)]\n",
       "  q(y) = NormalMeanVariance{Float64}(Œº=5.0, v=100.0)\n",
       "  q(w) = GammaShapeRate{Float64}[GammaShapeRate{Float64}(a=0.01, b=0.01), GammaShapeRate{Float64}(a=0.01, b=0.01)]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some shennenigans to make inference work\n",
    "n_iterations = 5 # number of variational iterations to run\n",
    "\n",
    "# initial values for the variational distributions, we use uninformative distributions\n",
    "# If this looks weird to you, please refer to the documentation for the @initialization macro\n",
    "init = @initialization begin\n",
    "    q(s) = vague(Beta)\n",
    "    q(m) = [NormalMeanVariance(0.0, 1e2), NormalMeanVariance(10.0, 1e2)]\n",
    "    q(y) = NormalMeanVariance(5.0, 1e2) # centered initialization with broad uncertainty\n",
    "    q(w) = [GammaShapeRate(0.01, 0.01), GammaShapeRate(0.01, 0.01)]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "bda40744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Time: 0:00:39\u001b[39m\u001b[K\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inference results:\n",
       "  Posteriors       | available for (w, m, s, y, z)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ReactiveMP: rule_nm_switch_k, softmax!\n",
    "\n",
    "# Run Bayesian inference \n",
    "# Again, RxInfer is fast, LLMs are not, bare with inference\n",
    "results_language = infer(\n",
    "    model=language_mixture_model(context‚ÇÅ=context‚ÇÅ, context‚ÇÇ=context‚ÇÇ, task‚ÇÅ=prior_task, task‚ÇÇ=prior_task, likelihood_task=likelihood_task),\n",
    "    constraints=MeanField(), # This is needed for the mixture node\n",
    "    data=(c=observations,),\n",
    "    initialization=init,\n",
    "    iterations=n_iterations,\n",
    "    free_energy=false,\n",
    "    showprogress=true\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b1e612dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "# Create the animation object\n",
    "animation = @animate for i in 1:n_iterations\n",
    "\n",
    "    # Get the data for visualization\n",
    "    initial_means = [0.0, 10.0]\n",
    "    initial_vars = [1e2, 1e2]\n",
    "    posterior_means = [mean.(results_language.posteriors[:m][i])...]\n",
    "    posterior_vars = inv.([mean.(results_language.posteriors[:w][i])...])\n",
    "\n",
    "    x = -10:0.01:20\n",
    "\n",
    "    plt = plot(\n",
    "        title=\"RxLLM: Sentiment Clustering\",\n",
    "        xlabel=\"Sentiment Spectrum\",\n",
    "        ylabel=\"Density\",\n",
    "        size=(800, 500),\n",
    "        dpi=300,\n",
    "        background_color=:white,\n",
    "        titlefontsize=14,\n",
    "        legendfontsize=11\n",
    "    )\n",
    "\n",
    "    # Plot posteriors with fill\n",
    "    plot!(plt, x, pdf.(Normal(posterior_means[1], sqrt(posterior_vars[1])), x),\n",
    "        fillalpha=0.4, fillrange=0, fillcolor=:red,\n",
    "        linewidth=3, linecolor=:darkred,\n",
    "        label=\"Negative Sentiment\")\n",
    "\n",
    "    plot!(plt, x, pdf.(Normal(posterior_means[2], sqrt(posterior_vars[2])), x),\n",
    "        fillalpha=0.4, fillrange=0, fillcolor=:blue,\n",
    "        linewidth=3, linecolor=:darkblue,\n",
    "        label=\"Positive Sentiment\")\n",
    "\n",
    "    # Plot priors as lighter background\n",
    "    plot!(plt, x, pdf.(Normal(initial_means[1], sqrt(initial_vars[1])), x),\n",
    "        linewidth=1, linestyle=:dash, linecolor=:gray, alpha=0.6,\n",
    "        label=\"Initial Prior\")\n",
    "\n",
    "    plot!(plt, x, pdf.(Normal(initial_means[2], sqrt(initial_vars[2])), x),\n",
    "        linewidth=1, linestyle=:dash, linecolor=:gray, alpha=0.6,\n",
    "        label=\"\")\n",
    "\n",
    "    # Simple cluster probabilities visualization\n",
    "    cluster_probs = probvec.(results_language.posteriors[:z][i])\n",
    "    plt2 = bar(1:length(cluster_probs), [p[1] for p in cluster_probs],\n",
    "        title=\"Positive Sentiment Probability\", ylabel=\"P(Positive)\", xlabel=\"Data Point\")\n",
    "\n",
    "    plot(plt, plt2)\n",
    "\n",
    "end\n",
    "\n",
    "# Now you can save the animation\n",
    "gif(animation, \"inference_process.gif\", fps=1, show_msg=false);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d715705",
   "metadata": {},
   "source": [
    "![](inference_process.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474130fc",
   "metadata": {},
   "source": [
    "The model successfully:\n",
    "- **Clusters related text** into positive/negative sentiment\n",
    "- **Identifies unrelated text** through high uncertainty\n",
    "- **Quantifies confidence** in each assignment\n",
    "- **Updates beliefs** through proper Bayesian inference\n",
    "\n",
    "Most importantly, the LLMs aren't just doing text classification - they're participating in a full probabilistic reasoning process where their outputs are combined with traditional statistical models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36555da",
   "metadata": {},
   "source": [
    "### Why This Matters: Beyond Prompt Chains\n",
    "\n",
    "This approach opens up possibilities that go far beyond traditional LLM applications:\n",
    "\n",
    "1. **Uncertainty-Aware LLM Agents**\n",
    "Instead of binary decisions, agents can maintain probability distributions over their beliefs and actions.\n",
    "\n",
    "2. **Rigorous Decision-Making Frameworks**  \n",
    "LLM outputs become part of formal decision theory with some uncertainty quantification.\n",
    "\n",
    "3. **Compositional Reasoning**\n",
    "Complex problems can be decomposed into smaller LLM nodes that communicate through message passing.\n",
    "\n",
    "4. **Continual Learning**\n",
    "As new data arrives, beliefs update through established Bayesian mechanisms rather than retraining.\n",
    "\n",
    "5. **Explainable AI**\n",
    "The factor graph structure makes the reasoning process transparent and interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f06ed2c",
   "metadata": {},
   "source": [
    "## Lessons Learned and Future Directions\n",
    "\n",
    "### What Worked Well\n",
    "- **Natural integration**: LLMs fit surprisingly well into message passing\n",
    "- **Uncertainty handling**: LLMs can express uncertainty when prompted correctly\n",
    "- **Compositionality**: Multiple LLM nodes can work together in complex models\n",
    "\n",
    "### Current Limitations  \n",
    "- **Prompt engineering**: Requires prompt design for consistent distribution formats\n",
    "- **Computational cost**: LLM queries are expensive compared to traditional operations\n",
    "- **Reliability**: LLM responses need robust parsing and error handling\n",
    "\n",
    "### Future Opportunities\n",
    "- **Multimodal integration**: Extend to vision/audio LLMs\n",
    "- **Online learning**: Update LLM beliefs through experience\n",
    "- **Hierarchical models**: Use LLMs at different abstraction levels\n",
    "- **Meta-learning**: Learn better prompting strategies through inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9df4a9",
   "metadata": {},
   "source": [
    "## What's Missing: Current Limitations\n",
    "\n",
    "While our LLM-Bayesian integration works, this is very much a proof-of-concept with several important limitations that need to be addressed:\n",
    "\n",
    "### 1. Fixed Functional Forms\n",
    "Currently, our LLM nodes are hardcoded to output `Normal` distributions with specific parameter ranges. This isn't very flexible:\n",
    "\n",
    "```julia\n",
    "# Current: Always returns Normal(mean, variance)\n",
    "return NormalMeanVariance(obj[\"mean\"], obj[\"variance\"])\n",
    "```\n",
    "\n",
    "**The issue**: What if we want LLMs to output other distributions? Gamma? Beta? Categorical? Or even mixture distributions?\n",
    "\n",
    "**Easy extension**: The nodes should be generic and allow the user to specify the desired output distribution family through the task description.\n",
    "\n",
    "### 2. Message Products Not Addressed\n",
    "In real factor graphs, you often need to combine multiple incoming messages before processing them. Our current implementation only handles single messages:\n",
    "\n",
    "```julia\n",
    "# Current: Only handles one message at a time\n",
    "@rule LLMPrior(:b, Marginalisation) (q_c::PointMass{<:String}, q_t::PointMass{<:String})\n",
    "```\n",
    "\n",
    "**The issue**: What happens when multiple messages arrive at an LLM node? How do we combine them before sending to the LLM?\n",
    "\n",
    "**Missing**: Rules for message products and handling multiple incoming probability distributions simultaneously.\n",
    "\n",
    "### 3. The Uncertainty Quantification Problem\n",
    "\n",
    "Perhaps the most philosophically questionable aspect of our approach is how we handle uncertainty. We're essentially asking LLMs:\n",
    "\n",
    "*\"What do you think about your own confidence?\"*\n",
    "\n",
    "This is arguably unprincipled for several reasons:\n",
    "\n",
    "**Text-to-Text Uncertainty**: When we prompt an LLM to express uncertainty about its own output, we're asking it to introspect about its own reasoning process. But LLMs don't actually have access to their internal uncertainty - they're just generating text that sounds like uncertainty based on their training.\n",
    "\n",
    "```julia\n",
    "# This is basically what we're doing:\n",
    "\"I think this text expresses positive sentiment with variance 0.8\"\n",
    "# vs\n",
    "\"I think this text expresses positive sentiment with variance 2.5\"\n",
    "```\n",
    "\n",
    "The LLM is pattern-matching to training examples where humans expressed different levels of confidence, but it's not performing genuine uncertainty quantification.\n",
    "\n",
    "**Log-Probability Limitations**: An alternative approach might be to use the LLM's token log-probabilities as uncertainty proxies:\n",
    "\n",
    "```julia\n",
    "# Instead of asking the LLM about uncertainty, use its output probabilities\n",
    "token_probs = model.logprobs(response)\n",
    "uncertainty = -sum(token_probs)  # Entropy-based uncertainty\n",
    "```\n",
    "\n",
    "But this is also problematic because:\n",
    "\n",
    "1. **Confidence ‚â† Correctness**: An LLM can be very confident (high probability) about completely wrong outputs\n",
    "2. **Sequence-level vs Token-level**: High token probabilities don't necessarily mean the overall semantic content is reliable\n",
    "3. **Distribution Mismatch**: Token probabilities reflect linguistic patterns, not epistemic uncertainty about the underlying task\n",
    "4. **Training Artifacts**: LLM confidence is heavily influenced by training data patterns rather than true knowledge uncertainty\n",
    "\n",
    "**Why We Do It Anyway**: Despite being unprincipled, this approach can be useful in the absence of other information. When you have no other source of uncertainty quantification, asking an LLM to express its confidence can provide a rough proxy that's better than no uncertainty at all.\n",
    "\n",
    "It's a bit like asking someone \"how sure are you?\" - not perfect, but often practically useful.\n",
    "\n",
    "**The Better Path**: True uncertainty quantification would require:\n",
    "- Explicit modeling of different uncertainty sources (aleatoric vs epistemic)\n",
    "- Integration with proper Bayesian model uncertainty\n",
    "- Integration of subjective logic frameworks\n",
    "\n",
    "But for a proof-of-concept showing LLMs can participate in message passing? Text-based uncertainty estimation gets the job done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e7f63d",
   "metadata": {},
   "source": [
    "## Grounding Agentic Systems in Bayesian Reasoning\n",
    "\n",
    "Beyond fixing current limitations, we're thinking through something much more ambitious: **simultaneous integration of agents and Bayesian models working together across trust networks**.\n",
    "\n",
    "The vision is agentic systems where:\n",
    "\n",
    "```julia\n",
    "# Agent submodel with trust and capability\n",
    "@model function agent(capability, trust_prior, task)\n",
    "    trust ~ Beta(trust_prior...)\n",
    "    performance := capability * trust * exp(-task)\n",
    "end\n",
    "\n",
    "# Main ecosystem using nested models\n",
    "@model function networked_agent_ecosystem(tasks, trust_priors, capabilities)\n",
    "    for i in eachindex(tasks)\n",
    "        # GraphPPL interpolates performance for each agent\n",
    "        agent_perf[i] ~ agent(\n",
    "            capability = capabilities[i], \n",
    "            trust_prior = trust_priors[i],\n",
    "            task = tasks[i]\n",
    "        )\n",
    "    end\n",
    "end\n",
    "```\n",
    "\n",
    "### The Trust Layer\n",
    "\n",
    "Traditional agentic systems lack principled uncertainty about *which agent to trust for what task*. One can imagine a system where:\n",
    "\n",
    "- **Trust becomes a probabilistic belief** that updates through Bayesian mechanisms\n",
    "- **Agent capabilities are distributions** over competency domains  \n",
    "- **Task allocation emerges** from probabilistic reasoning about trust and capability\n",
    "- **Cross-validation happens naturally** through message passing between agents\n",
    "\n",
    "### Grounded Agentic Reasoning\n",
    "\n",
    "The most principled path forward is **grounding LLMs in Bayesian reasoning**. Instead of heuristic agent coordination, we get:\n",
    "\n",
    "- **Principled uncertainty** about agent outputs and capabilities\n",
    "- **Trust propagation** through established probabilistic mechanisms  \n",
    "- **Emergent collaboration** from agents reasoning about each other's uncertainty\n",
    "- **Robust coordination** that degrades gracefully under failure\n",
    "\n",
    "This isn't just multi-agent systems‚Äîit's **probabilistic agent networks** where trust, capability, and task execution all become part of one coherent Bayesian model.\n",
    "\n",
    "The goal: agentic systems that can reason about their own reasoning, trust each other appropriately, and coordinate complex tasks through principled uncertainty quantification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546863ee",
   "metadata": {},
   "source": [
    "## Conclusion: The Weird Idea That Worked\n",
    "\n",
    "What started as a lunch conversation about reactive systems turned into a working prototype that treats LLMs as first-class citizens in Bayesian inference.\n",
    "\n",
    "The key insight wasn't just technical‚Äîit was philosophical. Instead of trying to make LLMs more like traditional ML models, we asked: what if we make traditional Bayesian inference more like natural reasoning?\n",
    "\n",
    "By hooking LLMs into RxInfer's message passing framework, we've created a bridge between LLMs and Bayesian inference.\n",
    "\n",
    "This opens a path toward agentic systems grounded in principled uncertainty‚Äîwhere trust networks, capability reasoning, and task coordination all emerge from coherent Bayesian models.\n",
    "\n",
    "Sometimes the best discoveries happen when you stop overthinking and just try the crazy idea.\n",
    "\n",
    "And it all started with the realization that RxInfer doesn't care what you pass through those edges.\n",
    "\n",
    "As long as you can define the rules, you can pass anything and be reactive about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60937f1e",
   "metadata": {},
   "source": [
    "### A few caveats about NormalMixture node\n",
    "\n",
    "There few known issues with `NormalMixture` node:\n",
    "- Iterations matter: with VMP, more iterations can materially change posteriors; too many iterations can lead to overconfident or wrong clusters.\n",
    "- Mixture limitation: `NormalMixture` under meanfield tends to collapse to a single Normal on its output edge, losing multi‚Äëmodality and corrupting downstream beliefs.\n",
    "- Prefer gating/mixtures: use a gating/expert setup (`rSLDS`‚Äëstyle see [rSLDS.jl](https://examples.rxinfer.com/categories/experimental_examples/recurrent_switching_linear_dynamical_system/)) that propagates the full mixture (preserve z‚Äìy dependence) instead of moment‚Äëmatching to one Normal.\n",
    "- If keeping this model: increase iterations and use stronger priors/initialization; but for robust results, favor gating or explicit mixture propagation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
