# This file was automatically generated from /home/trim/Documents/GitHub/RxInferExamples.jl/examples/Basic Examples/Bayesian Networks/Bayesian Networks.ipynb
# by notebooks_to_scripts.jl at 2025-04-21T06:26:05.004
#
# Source notebook: Bayesian Networks.ipynb

# Set ENV variable to prevent Plots from opening GUI window
ENV["GKSwstype"] = "100"

using Pkg

# --- Dependency Check ---
@info "Checking dependencies..."
let 
    # Added Optim
    needed_packages = [:RxInfer, :Plots, :GraphViz, :Logging, :Printf, :Random, :Optim]
    installed_package_names = keys(Pkg.project().dependencies)
    missing_packages = []
    for pkg in needed_packages
        if !(string(pkg) in installed_package_names)
            push!(missing_packages, pkg)
        end
    end

    if !isempty(missing_packages)
        @warn "Missing required packages: $(join(string.(missing_packages), ", "))"
        print("Install missing packages? [y/N]: ")
        if occursin(r"^[yY]", readline())
            Pkg.add([String(p) for p in missing_packages])
        else
            @error "Cannot proceed without required packages. Exiting."
            exit(1)
        end
    else
        @info "All dependencies are satisfied."
    end
end

using RxInfer, Plots, GraphViz, Logging, Printf, Random, LinearAlgebra, Optim # Added Optim
using Dates: now, format

# --- Setup ---
# Use Logging standard library for messages
global_logger(ConsoleLogger(stderr, Logging.Info))

# Include visualization utilities
include("visualization_utils.jl")

# Create output directory based on script name and timestamp
script_name = splitext(basename(@__FILE__))[1]
output_dir = joinpath("output", script_name, format(now(), "yyyy-mm-dd_HHMMSS"))
mkpath(output_dir)
@info "Output will be saved to: $(output_dir)"

# Seed for reproducibility
Random.seed!(42)
@info "Random seed set to 42 for reproducibility."

# --- Model Definition: Initial Sprinkler Model ---
@info "Defining the initial sprinkler model..."
@model function sprinkler_model_basic(wet_grass)
    clouded ~ Categorical([0.5, 0.5]) # P(cloudy=true) = 0.5
    # P(rain | clouded) - CPT represented row-wise: [P(rain=false|cloud=false) P(rain=true|cloud=false); P(rain=false|cloud=true) P(rain=true|cloud=true)]
    rain ~ DiscreteTransition(clouded, [0.8 0.2; 0.2 0.8])
    # P(sprinkler | clouded) - CPT represented row-wise: [P(sprinkler=false|cloud=false) P(sprinkler=true|cloud=false); P(sprinkler=false|cloud=true) P(sprinkler=true|cloud=true)]
    sprinkler ~ DiscreteTransition(clouded, [0.5 0.9; 0.5 0.1])
    # P(wet_grass | sprinkler, rain) - CPT represented as [P(wet=f|sprink=f,rain=f) P(wet=t|sprink=f,rain=f); P(wet=f|sprink=t,rain=f) P(wet=t|sprink=t,rain=f)] ;;; [P(wet=f|sprink=f,rain=t) P(wet=t|sprink=f,rain=t); P(wet=f|sprink=t,rain=t) P(wet=t|sprink=t,rain=t)]
    wet_grass ~ DiscreteTransition(sprinkler, [1.0 0.1; 0.0 0.9;;; 0.1 0.01; 0.9 0.99], rain)
end

# --- Model Visualization (Optional) ---
@info "Attempting to visualize model structure (requires GraphViz)..."
try
    model_generator = sprinkler_model_basic() | (wet_grass = [ 1.0, 0.0 ], ) # Use dummy data for structure
    model_to_plot   = RxInfer.getmodel(RxInfer.create_model(model_generator))
    gv_plot = GraphViz.load(model_to_plot, strategy = :simple)
    # Saving GraphViz output might require specific handling depending on GraphViz.jl version
    # For now, just log success. A file save might need `dot` command line tool or specific libraries.
    @info "Model visualization generated by GraphViz (display or saving might require manual setup)."
catch e
    @warn "GraphViz visualization failed. This might be due to GraphViz package issues or missing system dependencies (like the 'dot' executable). Skipping visualization."
    println(stderr, "GraphViz error details: ", e)
end

# --- Inference: Scenario 1 (Grass is Dry) ---
@info "Running inference for scenario 1: Grass is dry."
initialization_basic = @initialization begin
    μ(sprinkler) = Categorical([0.5, 0.5]) # Initialize sprinkler belief (needed for loop)
end

data_dry = (wet_grass = [1.0, 0.0],) # Observation: Grass is dry (index 1 = false, index 2 = true)

result_dry = infer(model=sprinkler_model_basic(), data=data_dry, iterations=10, initialization=initialization_basic)
@info "Inference complete for scenario 1."

# Plotting Scenario 1 Results using utility function
@info "Plotting posterior probabilities for scenario 1..."
plot_dry_path = joinpath(output_dir, "posteriors_grass_dry.png")
plot_posterior_bars_basic(result_dry.posteriors, "Grass=Dry", plot_dry_path)


# --- Inference: Scenario 2 (Grass is Wet) ---
@info "Running inference for scenario 2: Grass is wet."
data_wet = (wet_grass = [0.0, 1.0],) # Observation: Grass is wet

result_wet = infer(model=sprinkler_model_basic(), data=data_wet, iterations=10, initialization=initialization_basic)
@info "Inference complete for scenario 2."

# Plotting Scenario 2 Results using utility function
@info "Plotting posterior probabilities for scenario 2..."
plot_wet_path = joinpath(output_dir, "posteriors_grass_wet.png")
plot_posterior_bars_basic(result_wet.posteriors, "Grass=Wet", plot_wet_path)

# --- Model Definition: Extended Model for Missing Data ---
@info "Defining extended sprinkler model to handle observed/missing data nodes..."
# This version includes nodes for observing each variable directly
@model function sprinkler_model_extended(wet_grass_data, sprinkler_data, rain_data, clouded_data)
    # Latent variables
    clouded ~ Categorical([0.5, 0.5])
    rain ~ DiscreteTransition(clouded, [0.8 0.2; 0.2 0.8])
    sprinkler ~ DiscreteTransition(clouded, [0.5 0.9; 0.5 0.1])
    wet_grass ~ DiscreteTransition(sprinkler, [1.0 0.1; 0.0 0.9;;; 0.1 0.01; 0.9 0.99], rain)
    
    # Observation nodes (using identity transition matrix)
    clouded_data ~ DiscreteTransition(clouded, Matrix(Diagonal(ones(2))))
    rain_data ~ DiscreteTransition(rain, Matrix(Diagonal(ones(2))))
    sprinkler_data ~ DiscreteTransition(sprinkler, Matrix(Diagonal(ones(2))))
    wet_grass_data ~ DiscreteTransition(wet_grass, Matrix(Diagonal(ones(2))))
end

# Define initialization for the extended model (same as basic for sprinkler)
initialization_extended = @initialization begin
    μ(sprinkler) = Categorical([0.5, 0.5])
end

# --- Inference: Scenario 3 (Missing Data 1) --- 
@info "Running inference for scenario 3: Wet grass, Sprinkler ON observed."
data_missing1 = (
    wet_grass_data = [0.0, 1.0], # Wet
    sprinkler_data = [0.0, 1.0], # On
    rain_data      = missing,
    clouded_data   = missing
)
result_missing1 = infer(model=sprinkler_model_extended(), data=data_missing1, iterations=10, initialization=initialization_extended)
@info "Inference complete for scenario 3."

# Plotting Scenario 3 Results using utility function
@info "Plotting posterior probabilities for scenario 3..."
plot_m1_path = joinpath(output_dir, "posteriors_missing1_wet_sprinkler_on.png")
plot_posterior_bars_extended(result_missing1.posteriors, 
                             [:clouded, :rain], 
                             [["No", "Yes"], ["No", "Yes"]], 
                             "Wet, Sprinkler=On", 
                             plot_m1_path,
                             layout_dims=(1,2), # Specify layout
                             size_dims=(600,300))

# --- Inference: Scenario 4 (Missing Data 2) ---
@info "Running inference for scenario 4: Sprinkler OFF, Rain YES observed."
data_missing2 = (
    wet_grass_data = missing,
    sprinkler_data = [1.0, 0.0], # Off
    rain_data      = [0.0, 1.0], # Yes
    clouded_data   = missing
)
result_missing2 = infer(model=sprinkler_model_extended(), data=data_missing2, iterations=10, initialization=initialization_extended)
@info "Inference complete for scenario 4."

# Plotting Scenario 4 Results using utility function
@info "Plotting posterior probabilities for scenario 4..."
plot_m2_path = joinpath(output_dir, "posteriors_missing2_sprinkler_off_rain_yes.png")
plot_posterior_bars_extended(result_missing2.posteriors, 
                             [:rain, :clouded, :sprinkler, :wet_grass], 
                             [["No", "Yes"], ["No", "Yes"], ["Off", "On"], ["No", "Yes"]], 
                             "Sprinkler=Off, Rain=Yes", 
                             plot_m2_path,
                             size_dims=(1200,300))

# --- Inference: Scenario 5 (Missing Data 3) ---
@info "Running inference for scenario 5: Wet grass, Not Cloudy observed."
data_missing3 = (
    wet_grass_data = [0.0, 1.0], # Wet
    sprinkler_data = missing,
    rain_data      = missing,
    clouded_data   = [1.0, 0.0]  # Not Cloudy
)
result_missing3 = infer(model=sprinkler_model_extended(), data=data_missing3, iterations=10, initialization=initialization_extended)
@info "Inference complete for scenario 5."

# Plotting Scenario 5 Results using utility function
@info "Plotting posterior probabilities for scenario 5..."
plot_m3_path = joinpath(output_dir, "posteriors_missing3_wet_cloudy_no.png")
plot_posterior_bars_extended(result_missing3.posteriors, 
                             [:rain, :clouded, :sprinkler, :wet_grass], 
                             [["No", "Yes"], ["No", "Yes"], ["Off", "On"], ["No", "Yes"]], 
                             "Wet, Cloudy=No", 
                             plot_m3_path,
                             size_dims=(1200,300))

# --- Learning CPTs from Data using Optim.jl ---
@info "Generating synthetic data to learn CPTs..."
# Generate synthetic data from the true model (using the probabilities from sprinkler_model_basic)
n_samples = 10000

# Initialize arrays to store the samples (1=false, 2=true)
clouded_samples = zeros(Int, n_samples)
rain_samples = zeros(Int, n_samples)
sprinkler_samples = zeros(Int, n_samples) 
wet_grass_samples = zeros(Int, n_samples)

# Sample from the true model probabilities
# True CPTs:
# P(Cloudy) = [0.5, 0.5]
# P(Rain|Cloudy) = [0.8 0.2; 0.2 0.8] -> P(Rain=T|C=F)=0.2, P(Rain=T|C=T)=0.8
# P(Sprinkler|Cloudy) = [0.5 0.9; 0.5 0.1] -> P(Sprinkler=T|C=F)=0.9, P(Sprinkler=T|C=T)=0.1
# P(Wet|Sprinkler,Rain): P(W=T|S=F,R=F)=0.0, P(W=T|S=T,R=F)=0.9, P(W=T|S=F,R=T)=0.9, P(W=T|S=T,R=T)=0.99

for i in 1:n_samples
    # Sample clouded (prior: P(C=T)=0.5)
    clouded_samples[i] = rand() < 0.5 ? 2 : 1 # 2 = True, 1 = False
    
    # Sample rain (depends on clouded)
    p_rain_true = clouded_samples[i] == 2 ? 0.8 : 0.2 # P(Rain=T|Clouded=T) vs P(Rain=T|Clouded=F)
    rain_samples[i] = rand() < p_rain_true ? 2 : 1
    
    # Sample sprinkler (depends on clouded)
    p_sprinkler_true = clouded_samples[i] == 2 ? 0.1 : 0.9 # P(Sprinkler=T|Clouded=T) vs P(Sprinkler=T|Clouded=F)
    sprinkler_samples[i] = rand() < p_sprinkler_true ? 2 : 1
    
    # Sample wet grass (depends on rain and sprinkler)
    s_idx = sprinkler_samples[i]
    r_idx = rain_samples[i]
    
    if r_idx == 2 && s_idx == 2 # Rain=T, Sprinkler=T
        wet_prob_true = 0.99
    elseif r_idx == 2 && s_idx == 1 # Rain=T, Sprinkler=F
        wet_prob_true = 0.9
    elseif r_idx == 1 && s_idx == 2 # Rain=F, Sprinkler=T
        wet_prob_true = 0.9
    else # Rain=F, Sprinkler=F
        wet_prob_true = 0.0
    end
    wet_grass_samples[i] = rand() < wet_prob_true ? 2 : 1
end
@info "Generated $(n_samples) synthetic samples."

# Convert to one-hot encoding for RxInfer input format (vector of vectors)
clouded_data_learn = [[i == s ? 1.0 : 0.0 for i in 1:2] for s in clouded_samples]
rain_data_learn = [[i == s ? 1.0 : 0.0 for i in 1:2] for s in rain_samples]
sprinkler_data_learn = [[i == s ? 1.0 : 0.0 for i in 1:2] for s in sprinkler_samples]
wet_grass_data_learn = [[i == s ? 1.0 : 0.0 for i in 1:2] for s in wet_grass_samples];
@info "Converted synthetic data to one-hot encoding."

# --- Define Likelihood Model for Optim.jl ---
@info "Defining the likelihood model for parameter optimization..."

# Define the main likelihood model using an explicit loop and POSITIONAL arguments only
@model function sprinkler_likelihood_model(clouded_data, rain_data, sprinkler_data, wet_grass_data, cpt_cr, cpt_cs, cpt_srw)
    N = length(clouded_data)

    # Explicit loop for plate notation over N data points
    for i in 1:N
        # Latent variables specific to this data point `i`
        clouded_latent ~ Categorical([0.5, 0.5]) 
        rain_latent ~ DiscreteTransition(clouded_latent, cpt_cr) # Use passed positional arg
        sprinkler_latent ~ DiscreteTransition(clouded_latent, cpt_cs) # Use passed positional arg
        wet_grass_latent ~ DiscreteTransition(sprinkler_latent, cpt_srw, rain_latent) # Use passed positional arg

        # Observation nodes - Link latent variables to the i-th data point
        clouded_data[i] ~ DiscreteTransition(clouded_latent, Matrix(Diagonal(ones(2))))
        rain_data[i] ~ DiscreteTransition(rain_latent, Matrix(Diagonal(ones(2))))
        sprinkler_data[i] ~ DiscreteTransition(sprinkler_latent, Matrix(Diagonal(ones(2))))
        wet_grass_data[i] ~ DiscreteTransition(wet_grass_latent, Matrix(Diagonal(ones(2))))
    end
end

# --- Define Loss Function (Negative Free Energy) ---
@info "Defining the loss function (negative free energy)..."

# Global data object (only observational data)
const learning_data_obs = (clouded_data=clouded_data_learn, rain_data=rain_data_learn, sprinkler_data=sprinkler_data_learn, wet_grass_data=wet_grass_data_learn)

function calculate_neg_free_energy(logit_params)
    # Convert logits to CPT probabilities
    cpt_cr, cpt_cs, cpt_srw = logits_to_cpts(logit_params)

    # Create the ModelGenerator (takes no arguments)
    model_generator = sprinkler_likelihood_model()

    # Combine ALL model arguments (data and params) into the `data` tuple for infer
    # Order must match the model function definition
    all_args = (;
        clouded_data=learning_data_obs.clouded_data, 
        rain_data=learning_data_obs.rain_data, 
        sprinkler_data=learning_data_obs.sprinkler_data, 
        wet_grass_data=learning_data_obs.wet_grass_data,
        cpt_cr=cpt_cr, 
        cpt_cs=cpt_cs, 
        cpt_srw=cpt_srw
    )

    # Provide basic initialization for latent variables
    likelihood_init = @initialization begin
        μ(clouded_latent) = Categorical([0.5, 0.5])
        μ(rain_latent) = Categorical([0.5, 0.5])
        μ(sprinkler_latent) = Categorical([0.5, 0.5])
        μ(wet_grass_latent) = Categorical([0.5, 0.5])
    end

    # Run inference with the specific model generator for these params
    result = infer(
        model          = model_generator,
        data           = all_args, # Pass ALL args here
        initialization = likelihood_init, 
        iterations     = 1, 
        free_energy    = true,
        warn           = false,
        options        = (limit_stack_depth=500,) 
    )

    fe = result.free_energy
    if isnan(last(fe)) || isinf(last(fe))
        @warn "Free energy calculation resulted in NaN or Inf for parameters: $(logit_params). Returning high loss."
        return Inf 
    end

    return -last(fe)
end

# --- Test Objective Function Sensitivity ---
@info "Testing objective function sensitivity..."
initial_logits = zeros(8)
perturbed_logits = initial_logits .+ 0.1 # Small perturbation

val_initial = calculate_neg_free_energy(initial_logits)
val_perturbed = calculate_neg_free_energy(perturbed_logits)

@info "Objective at initial logits (0.0): $(val_initial)"
@info "Objective at perturbed logits (+0.1): $(val_perturbed)"
if abs(val_initial - val_perturbed) < 1e-9
    @warn "Objective function still appears insensitive to parameter changes!"
else
    @info "Objective function is sensitive to parameter changes."
end

# --- Run Optimization --- 
@info "Starting parameter optimization using Optim.jl..."

# Initial parameters (logits = 0 corresponds to P=0.5)
# 2 logits for P(R|C), 2 for P(S|C), 4 for P(W|S,R) = 8 total parameters
initial_logit_params = zeros(8)

# Define optimization options (optional)
# Consider gradient-based methods like LBFGS or ConjugateGradient
# For simplicity, using NelderMead
optim_options = Optim.Options(show_trace=true, iterations=1000) # Increased iterations for NelderMead

# Run the optimization using NelderMead
# optim_result = Optim.optimize(calculate_neg_free_energy, initial_logit_params, LBFGS(), optim_options)
optim_result = Optim.optimize(calculate_neg_free_energy, initial_logit_params, NelderMead(), optim_options)

@info "Optimization complete."
println(optim_result) # Print optimization summary

# Extract and process optimized parameters
if Optim.converged(optim_result)
    @info "Optimization converged successfully."
    optimized_logits = Optim.minimizer(optim_result)
    learned_cpt_cr, learned_cpt_cs, learned_cpt_srw = logits_to_cpts(optimized_logits)
    
    @info "Learned P(Rain|Cloudy):\n$(learned_cpt_cr)"
    @info "Learned P(Sprinkler|Cloudy):\n$(learned_cpt_cs)"
    @info "Learned P(Wet|Sprinkler,Rain) [P(Wet=True|S,R)]:\n$(learned_cpt_srw[2,:,:])"
    
    # --- Plot Learned CPTs --- 
    @info "Plotting the learned CPTs..."
    plot_learn_path = joinpath(output_dir, "learned_cpts_optim.png")
    plot_learned_cpts(learned_cpt_cr, learned_cpt_cs, learned_cpt_srw, plot_learn_path)
else
    @warn "Optimization did not converge."
    # Optionally, still plot the CPTs from the non-converged result
    optimized_logits = Optim.minimizer(optim_result)
    learned_cpt_cr, learned_cpt_cs, learned_cpt_srw = logits_to_cpts(optimized_logits)
    @info "CPTs from non-converged result:"
    @info "Learned P(Rain|Cloudy):\n$(learned_cpt_cr)"
    @info "Learned P(Sprinkler|Cloudy):\n$(learned_cpt_cs)"
    @info "Learned P(Wet|Sprinkler,Rain) [P(Wet=True|S,R)]:\n$(learned_cpt_srw[2,:,:])"
    plot_learn_path = joinpath(output_dir, "learned_cpts_optim_nonconverged.png")
    plot_learned_cpts(learned_cpt_cr, learned_cpt_cs, learned_cpt_srw, plot_learn_path)
end

@info "Script execution finished."