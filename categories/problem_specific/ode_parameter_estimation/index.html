<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Ode Parameter Estimation ¬∑ RxInfer.jl Examples</title><meta name="title" content="Ode Parameter Estimation ¬∑ RxInfer.jl Examples"/><meta property="og:title" content="Ode Parameter Estimation ¬∑ RxInfer.jl Examples"/><meta property="twitter:title" content="Ode Parameter Estimation ¬∑ RxInfer.jl Examples"/><meta name="description" content="ODE Parameter Estimation with RxInfer.jl\nAn example of solving Lotka Volterra ODE with RxInfer.jl. Reference: [Lotka Volterra ODE](https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations).\n\nCheck more examples and tutorials at https://examples.rxinfer.com\n"/><meta property="og:description" content="ODE Parameter Estimation with RxInfer.jl\nAn example of solving Lotka Volterra ODE with RxInfer.jl. Reference: [Lotka Volterra ODE](https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations).\n\nCheck more examples and tutorials at https://examples.rxinfer.com\n"/><meta property="twitter:description" content="ODE Parameter Estimation with RxInfer.jl\nAn example of solving Lotka Volterra ODE with RxInfer.jl. Reference: [Lotka Volterra ODE](https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations).\n\nCheck more examples and tutorials at https://examples.rxinfer.com\n"/><meta property="og:url" content="https://examples.rxinfer.com/categories/problem_specific/ode_parameter_estimation/"/><meta property="twitter:url" content="https://examples.rxinfer.com/categories/problem_specific/ode_parameter_estimation/"/><link rel="canonical" href="https://examples.rxinfer.com/categories/problem_specific/ode_parameter_estimation/"/><script async src="https://www.googletagmanager.com/gtag/js?id=G-GMFX620VEP"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-GMFX620VEP', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/theme.css" rel="stylesheet" type="text/css"/><link href="../../../assets/header.css" rel="stylesheet" type="text/css"/><script src="../../../assets/header.js"></script><script src="../../../assets/chat.js"></script><link href="../../../assets/favicon.ico" rel="icon" type="image/x-icon"/>
    <meta property="og:title" content="ODE Parameter Estimation - RxInfer Examples">
    <meta name="description" content="An example of solving Lotka Volterra ODE with RxInfer.jl. Reference: [Lotka Volterra ODE](https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations).
">
    <meta property="og:description" content="An example of solving Lotka Volterra ODE with RxInfer.jl. Reference: [Lotka Volterra ODE](https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations).
">
    <meta name="keywords" content="rxinfer, julia, bayesian inference, examples, probabilistic programming, message passing, probabilistic numerics, variational inference, belief propagation, problem specific, ode, differential equations">
    <link rel="sitemap" type="application/xml" title="Sitemap" href="https://examples.rxinfer.com/sitemap.xml">
    </head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img class="docs-light-only" src="../../../assets/logo.svg" alt="RxInfer.jl Examples logo"/><img class="docs-dark-only" src="../../../assets/logo-dark.svg" alt="RxInfer.jl Examples logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">RxInfer.jl Examples</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><a class="tocitem" href="../../../how_to_contribute/">How to contribute</a></li><li><a class="tocitem" href="../../../autogenerated/list_of_examples/">List of Examples</a></li><li><span class="tocitem">Basic Examples</span><ul><li><a class="tocitem" href="../../basic_examples/bayesian_binomial_regression/">Bayesian Binomial Regression</a></li><li><a class="tocitem" href="../../basic_examples/bayesian_linear_regression/">Bayesian Linear Regression</a></li><li><a class="tocitem" href="../../basic_examples/bayesian_multinomial_regression/">Bayesian Multinomial Regression</a></li><li><a class="tocitem" href="../../basic_examples/bayesian_networks/">Bayesian Networks</a></li><li><a class="tocitem" href="../../basic_examples/coin_toss_model/">Coin Toss Model</a></li><li><a class="tocitem" href="../../basic_examples/contextual_bandits/">Contextual Bandits</a></li><li><a class="tocitem" href="../../basic_examples/feature_functions_in_bayesian_regression/">Feature Functions In Bayesian Regression</a></li><li><a class="tocitem" href="../../basic_examples/forgetting_factors_for_online_inference/">Forgetting Factors For Online Inference</a></li><li><a class="tocitem" href="../../basic_examples/hidden_markov_model/">Hidden Markov Model</a></li><li><a class="tocitem" href="../../basic_examples/incomplete_data/">Incomplete Data</a></li><li><a class="tocitem" href="../../basic_examples/kalman_filtering_and_smoothing/">Kalman Filtering And Smoothing</a></li><li><a class="tocitem" href="../../basic_examples/pomdp_control/">Pomdp Control</a></li><li><a class="tocitem" href="../../basic_examples/predicting_bike_rental_demand/">Predicting Bike Rental Demand</a></li></ul></li><li><span class="tocitem">Advanced Examples</span><ul><li><a class="tocitem" href="../../advanced_examples/active_inference_mountain_car/">Active Inference Mountain Car</a></li><li><a class="tocitem" href="../../advanced_examples/advanced_tutorial/">Advanced Tutorial</a></li><li><a class="tocitem" href="../../advanced_examples/assessing_people_skills/">Assessing People Skills</a></li><li><a class="tocitem" href="../../advanced_examples/bayesian_structured_time_series/">Bayesian Structured Time Series</a></li><li><a class="tocitem" href="../../advanced_examples/chance_constraints/">Chance Constraints</a></li><li><a class="tocitem" href="../../advanced_examples/conjugate-computational_variational_message_passing/">Conjugate-Computational Variational Message Passing</a></li><li><a class="tocitem" href="../../advanced_examples/drone_dynamics/">Drone Dynamics</a></li><li><a class="tocitem" href="../../advanced_examples/gp_regression_by_ssm/">Gp Regression By Ssm</a></li><li><a class="tocitem" href="../../advanced_examples/infinite_data_stream/">Infinite Data Stream</a></li><li><a class="tocitem" href="../../advanced_examples/integrating_neural_networks_with_flux.jl/">Integrating Neural Networks With Flux.Jl</a></li><li><a class="tocitem" href="../../advanced_examples/learning_dynamics_with_vaes/">Learning Dynamics With Vaes</a></li><li><a class="tocitem" href="../../advanced_examples/multi-agent_trajectory_planning/">Multi-Agent Trajectory Planning</a></li><li><a class="tocitem" href="../../advanced_examples/nonlinear_sensor_fusion/">Nonlinear Sensor Fusion</a></li><li><a class="tocitem" href="../../advanced_examples/parameter_optimisation_with_optim.jl/">Parameter Optimisation With Optim.Jl</a></li><li><a class="tocitem" href="../../advanced_examples/robotic_arm/">Robotic Arm</a></li></ul></li><li><span class="tocitem">Problem Specific</span><ul><li><a class="tocitem" href="../autoregressive_models/">Autoregressive Models</a></li><li><a class="tocitem" href="../gamma_mixture/">Gamma Mixture</a></li><li><a class="tocitem" href="../gaussian_mixture/">Gaussian Mixture</a></li><li><a class="tocitem" href="../hierarchical_gaussian_filter/">Hierarchical Gaussian Filter</a></li><li><a class="tocitem" href="../invertible_neural_network_tutorial/">Invertible Neural Network Tutorial</a></li><li><a class="tocitem" href="../ising_model/">Ising Model</a></li><li><a class="tocitem" href="../litter_model/">Litter Model</a></li><li class="is-active"><a class="tocitem" href>Ode Parameter Estimation</a><ul class="internal"><li><a class="tocitem" href="#Introduction-to-Lotka-Volterra-Equations"><span>Introduction to Lotka-Volterra Equations</span></a></li><li><a class="tocitem" href="#The-Runge-Kutta-4th-Order-(RK4)-Method"><span>The Runge-Kutta 4th Order (RK4) Method</span></a></li><li class="toplevel"><a class="tocitem" href="#Data-Generation"><span>Data Generation</span></a></li><li class="toplevel"><a class="tocitem" href="#Data-Visualization"><span>Data Visualization</span></a></li><li class="toplevel"><a class="tocitem" href="#First-Alternative:-Global-Parameter-Optimization"><span>First Alternative: Global Parameter Optimization</span></a></li><li class="toplevel"><a class="tocitem" href="#Free-Energy-Computation"><span>Free Energy Computation</span></a></li><li class="toplevel"><a class="tocitem" href="#Second-Alternative:-RxInfer-Model-with-Prior-on-the-Parameters"><span>Second Alternative: RxInfer Model with Prior on the Parameters</span></a></li><li class="toplevel"><a class="tocitem" href="#Prior-Initialization-by-means-of-Free-Energy-Minimization"><span>Prior Initialization by means of Free Energy Minimization</span></a></li><li class="toplevel"><a class="tocitem" href="#Parameter-Inference"><span>Parameter Inference</span></a></li><li><a class="tocitem" href="#Third-Alternative:-RxInfer-Model-with-Exponential-Transformation-on-the-Parameters"><span>Third Alternative: RxInfer Model with Exponential Transformation on the Parameters</span></a></li></ul></li><li><a class="tocitem" href="../probit_model/">Probit Model</a></li><li><a class="tocitem" href="../rts_vs_bifm_smoothing/">Rts Vs Bifm Smoothing</a></li><li><a class="tocitem" href="../simple_nonlinear_node/">Simple Nonlinear Node</a></li><li><a class="tocitem" href="../structural_dynamics_with_augmented_kalman_filter/">Structural Dynamics With Augmented Kalman Filter</a></li><li><a class="tocitem" href="../universal_mixtures/">Universal Mixtures</a></li></ul></li><li><span class="tocitem">Experimental Examples</span><ul><li><a class="tocitem" href="../../experimental_examples/bayesian_trust_learning/">Bayesian Trust Learning</a></li><li><a class="tocitem" href="../../experimental_examples/large_language_models/">Large Language Models</a></li><li><a class="tocitem" href="../../experimental_examples/latent_vector_autoregressive_model/">Latent Vector Autoregressive Model</a></li><li><a class="tocitem" href="../../experimental_examples/recurrent_switching_linear_dynamical_system/">Recurrent Switching Linear Dynamical System</a></li></ul></li><li><a class="tocitem" href="../../../how_build_works/">How we build the examples</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Problem Specific</a></li><li class="is-active"><a href>Ode Parameter Estimation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Ode Parameter Estimation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInferExamples.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ÔÇõ</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInferExamples.jl" title="View source on GitHub"><span class="docs-icon fa-solid">ÔÖú</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><div class="admonition is-info" id="Contributing-baba9dc142ba7ccb"><header class="admonition-header">Contributing<a class="admonition-anchor" href="#Contributing-baba9dc142ba7ccb" title="Permalink"></a></header><div class="admonition-body"><p>This example was automatically generated from a Jupyter notebook in the <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">RxInferExamples.jl</a> repository.</p><p>We welcome and encourage contributions! You can help by:</p><ul><li>Improving this example</li><li>Creating new examples </li><li>Reporting issues or bugs</li><li>Suggesting enhancements</li></ul><p>Visit our <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">GitHub repository</a> to get started. Together we can make <a href="https://github.com/ReactiveBayes/RxInfer.jl">RxInfer.jl</a> even better! üí™</p></div></div><hr/><h1 id="ODE-Parameter-Estimation"><a class="docs-heading-anchor" href="#ODE-Parameter-Estimation">ODE Parameter Estimation</a><a id="ODE-Parameter-Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#ODE-Parameter-Estimation" title="Permalink"></a></h1><p>In this notebook we will explore how we can solve and learn the parameters of an ODE simultaneously using RxInfer. To illustrate how we can can utilize RxInfer, we will take Lotka-Volterra differential equation as an example. We will explore three different alternatives to parameter estimation. The first alternative will demonstrate how we can use free energy to obtain point estimates. The second alternative will demonstrate how we can use a prior distribution on the parameters to obtain a posterior estimate for the unknown parameters of the ODE. The second alternative will do parameter learning in two stages. The first stage will obtain the initialization for the prior hyper-parameters and then use these initial values of the prior to obtain the posterior by message passing. The third alternative will use purely message passing. </p><pre><code class="language-julia hljs">using RxInfer, Optim, LinearAlgebra, Plots,  StaticArrays, StableRNGs</code></pre><h2 id="Introduction-to-Lotka-Volterra-Equations"><a class="docs-heading-anchor" href="#Introduction-to-Lotka-Volterra-Equations">Introduction to Lotka-Volterra Equations</a><a id="Introduction-to-Lotka-Volterra-Equations-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction-to-Lotka-Volterra-Equations" title="Permalink"></a></h2><p>The Lotka-Volterra equations, are a pair of first-order nonlinear differential equations frequently used to describe the dynamics of biological systems in which two species interact: one as a predator and the other as prey. The equations are defined as follows:</p><p>Prey Population Dynamics:   <span>$\frac{dx}{dt} = \alpha x - \beta xy$</span></p><p>Predator Population Dynamics:   <span>$\frac{dy}{dt} = -\gamma y + \delta xy$</span></p><p>In this ODE, <span>$x$</span> is the population of the prey (e.g., rabbits), <span>$y$</span> is the population of the predator (e.g., foxes), <span>$\alpha$</span> represents the maximum growth rate of the prey, <span>$\beta$</span> is the rate of predation, <span>$\gamma$</span> is the predator&#39;s per capita death rate and <span>$\delta$</span> is the growth rate of the predator population based on the availability of prey.</p><pre><code class="language-julia hljs">function lotka_volterra(u, z, p, t)
    Œ±, Œ≤, Œ¥, Œ≥ = p[SA[1,2,3,4]]
    x, y = u[SA[1, 2]]
    du1 = Œ± * x - Œ≤ * x * y
    du2 = -Œ¥ * y + Œ≥ * x * y

    return [du1, du2]
end;</code></pre><h2 id="The-Runge-Kutta-4th-Order-(RK4)-Method"><a class="docs-heading-anchor" href="#The-Runge-Kutta-4th-Order-(RK4)-Method">The Runge-Kutta 4th Order (RK4) Method</a><a id="The-Runge-Kutta-4th-Order-(RK4)-Method-1"></a><a class="docs-heading-anchor-permalink" href="#The-Runge-Kutta-4th-Order-(RK4)-Method" title="Permalink"></a></h2><p>The Runge-Kutta 4th order method is one of the most widely used numerical techniques for solving ordinary differential equations (ODEs). For a system of the form:</p><p class="math-container">\[\frac{dx}{dt} = f(x, t)\]</p><p>where <span>$x$</span> can be a scalar or vector-valued function, RK4 provides a numerical approximation with local truncation error of order <span>$O(h^5)$</span> and global error of order <span>$O(h^4)$</span>.</p><h3 id="Algorithm"><a class="docs-heading-anchor" href="#Algorithm">Algorithm</a><a id="Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithm" title="Permalink"></a></h3><p>Given the current state <span>$x_n$</span> at time <span>$t_n$</span>, RK4 computes the state at <span>$t_{n+1} = t_n + dt$</span> using four intermediate evaluations:</p><p class="math-container">\[\begin{aligned}
k_1 &amp;= f(x_n, t_n) \\
k_2 &amp;= f(x_n + \frac{dt}{2}k_1, t_n + \frac{dt}{2}) \\
k_3 &amp;= f(x_n + \frac{dt}{2}k_2, t_n + \frac{dt}{2}) \\
k_4 &amp;= f(x_n + dt\,k_3, t_n + dt)
\end{aligned}\]</p><p>The solution is then advanced using a weighted average of these evaluations:</p><p class="math-container">\[x_{n+1} = x_n + \frac{dt}{6}(k_1 + 2k_2 + 2k_3 + k_4)\]</p><pre><code class="language-julia hljs">function rk4_step(f::Function, x, u, Œ∏, t, dt; supersample = 1)
    
    @inbounds for i in 1:supersample
        dt_i = dt/supersample
        k1 = f(x, u, Œ∏, t)
        k2 = f(x + dt_i/2*k1, u, Œ∏, t + dt_i/2)
        k3 = f(x + dt_i/2*k2, u, Œ∏, t + dt_i/2)
        k4 = f(x + dt_i*k3, u, Œ∏, t + dt_i)
        x += dt_i/6*(k1 + 2*k2 + 2*k3 + k4)
    end
    return x

end

function lotka_volterra_rk4(x, Œ∏, t, dt, supersample = 1)
    return rk4_step(lotka_volterra, x, 0, Œ∏, t, dt)
  
end</code></pre><pre><code class="nohighlight hljs">lotka_volterra_rk4 (generic function with 2 methods)</code></pre><h1 id="Data-Generation"><a class="docs-heading-anchor" href="#Data-Generation">Data Generation</a><a id="Data-Generation-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Generation" title="Permalink"></a></h1><p>Lotka Volterra data is generated using the RK4 method. The data is then corrupted with noise to simulate real-world observations. </p><p>DISCLAIMER: Since Lotka-Volterra equations model prey and predator dynamics, adding a Gaussian noise is not realistic. Although adding other noise forms are possible it will complicate the inference process. Therefore, we will use Gaussian noise for instructive purposes. </p><pre><code class="language-julia hljs">function generate_data(Œ∏; x = ones(2), t =0.0, dt = 0.001, n = 1000, v = 1, seed = 123)
    rng = StableRNG(seed)
    data = Vector{Vector{Float64}}(undef, n)
    ts = Vector{Float64}(undef, n)
    for i in 1:n
        data[i] = lotka_volterra_rk4(x, Œ∏, t, dt)
        x = data[i]
        t += dt
        ts[i] = t
    end
    noisy_data = map(data) do d
        noise = sqrt(v) * [randn(rng), randn(rng)]
        d + noise
    end
    return data, noisy_data, ts
end

dt = 0.1 # sample_interval
noisev = 0.35
n = 10000
true_params = [1.0, 1.5, 3.0, 1.0]
data_long, noisy_data_long, ts_long = generate_data(true_params,dt = dt, n = n, v = noisev);

## We create a smaller dataset for the global parameter optimization. Utilizing the entire dataset for the global optimization will take too much time. 
n_train = 100
data = data_long[1:n_train]
noisy_data = noisy_data_long[1:n_train]
ts = ts_long[1:n_train];</code></pre><h1 id="Data-Visualization"><a class="docs-heading-anchor" href="#Data-Visualization">Data Visualization</a><a id="Data-Visualization-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Visualization" title="Permalink"></a></h1><pre><code class="language-julia hljs">p = plot(layout=(2,1))
plot!(subplot=1, ts, [d[1] for d in data], label=&quot;True x‚ÇÅ&quot;, color=:blue)
plot!(subplot=1, ts, [d[1] for d in noisy_data], seriestype=:scatter, label=&quot;Noisy x‚ÇÅ&quot;, color=:blue, alpha=0.3, markersize=1.3)
plot!(subplot=2, ts, [d[2] for d in data], label=&quot;True x‚ÇÇ&quot;, color=:red)
plot!(subplot=2, ts, [d[2] for d in noisy_data], seriestype=:scatter, label=&quot;Noisy x‚ÇÇ&quot;, color=:red, alpha=0.3, markersize=1.3)
xlabel!(&quot;Time&quot;)
ylabel!(subplot=1, &quot;Prey Population&quot;)
ylabel!(subplot=2, &quot;Predator Population&quot;)</code></pre><p><img src="ODE Parameter Estimation_5_1.png" alt/></p><h1 id="First-Alternative:-Global-Parameter-Optimization"><a class="docs-heading-anchor" href="#First-Alternative:-Global-Parameter-Optimization">First Alternative: Global Parameter Optimization</a><a id="First-Alternative:-Global-Parameter-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#First-Alternative:-Global-Parameter-Optimization" title="Permalink"></a></h1><p>In the first alternative we will construct one time-segment of Lotka-Volterra equation. We will use <code>lotka_volterra_rk4</code> function to create non-linear node. This function was defined earlier to numerically solve the Lotka-Volterra equations using the 4th order Runge-Kutta method. </p><pre><code class="language-julia hljs">@model function lotka_volterra_model_without_prior(obs, mprev, Vprev, dt, t, Œ∏)
    xprev ~ MvNormalMeanCovariance(mprev, Vprev)
    x     := lotka_volterra_rk4(xprev, Œ∏, t, dt)
    obs   ~ MvNormalMeanCovariance(x,  noisev * diageye(length(mprev)))
end</code></pre><p>Non-linear deterministic nodes require meta specification that will determine the type of message approximations to be used. In this case, we can use the <code>Linearization</code> method that will trigger an Extended Kalman Filter (EKF) type of approximation or the <code>Unscented</code> method that will trigger an Unscented Kalman Filter (UKF) type of approximation. Moreover, because we are using RxInfer in an online setting we need to specify how the mean and covariance of the Gaussian distribution will be updated. We do this by using the <code>@autoupdates</code> macro and initialize using the <code>@initialization</code> macro. </p><pre><code class="language-julia hljs">delta_meta = @meta begin
    lotka_volterra_rk4() -&gt;  Linearization()
end

autoupdates_without_prior = @autoupdates begin
    mprev, Vprev= mean_cov(q(x))
end

@initialization function initialize_without_prior(mx, Vx)
    q(x) = MvNormalMeanCovariance(mx, Vx)
end;</code></pre><h1 id="Free-Energy-Computation"><a class="docs-heading-anchor" href="#Free-Energy-Computation">Free Energy Computation</a><a id="Free-Energy-Computation-1"></a><a class="docs-heading-anchor-permalink" href="#Free-Energy-Computation" title="Permalink"></a></h1><p>We will now define the free energy function that will be minimized to infer the parameters of the model. Since the parameters of the model are not constrained to be positive, we will use the <code>exp</code> function to transform the parameters to the positive domain. We will set the free energy to true to keep track of the free energy values. </p><pre><code class="language-julia hljs">function compute_free_energy_without_prior(Œ∏ ; mx = ones(2), Vx = 1e-6 * diageye(2))
    Œ∏ = exp.(Œ∏)
    result = infer(
        model = lotka_volterra_model_without_prior(dt = dt, Œ∏ = Œ∏),
        data = (obs = noisy_data, t= ts),
        initialization = initialize_without_prior(mx, Vx),
        meta = delta_meta,
        autoupdates = autoupdates_without_prior,
        keephistory = length(noisy_data),
        free_energy = true
    )
    return sum(result.free_energy_final_only_history)
end;</code></pre><p>Now we are ready to perform the parameter inference by minimizing the free energy function. We will use the <code>optimize</code> function from the <code>Optim</code> package to perform the optimization. We will use the <code>NelderMead</code> method as the optimizer as it doesn&#39;t require gradient information and is faster.</p><pre><code class="language-julia hljs">res_without_prior  = optimize(compute_free_energy_without_prior, zeros(4), NelderMead(), Optim.Options(show_trace = true, show_every = 300));</code></pre><pre><code class="nohighlight hljs">Iter     Function value    ‚àö(Œ£(y·µ¢-yÃÑ)¬≤)/n 
------   --------------    --------------
     0     1.274436e+03     9.650180e+00
 * time: 0.04586601257324219</code></pre><pre><code class="language-julia hljs">Œ∏_minimizer_without_prior = exp.(res_without_prior.minimizer)
println(&quot;\nEstimated point mass valued parameters:&quot;)
for (i, (name, val)) in enumerate(zip([&quot;Œ±&quot;, &quot;Œ≤&quot;, &quot;Œ≥&quot;, &quot;Œ¥&quot;], Œ∏_minimizer_without_prior))
    println(&quot; * $name: $(round(val, digits=3))&quot;)
end

println(&quot;\nActual parameters used to generate data:&quot;)
for (i, (name, val)) in enumerate(zip([&quot;Œ±&quot;, &quot;Œ≤&quot;, &quot;Œ≥&quot;, &quot;Œ¥&quot;], true_params))
    println(&quot; * $name: $(round(val, digits=3))&quot;)
end</code></pre><pre><code class="nohighlight hljs">Estimated point mass valued parameters:
 * Œ±: 0.994
 * Œ≤: 1.491
 * Œ≥: 3.054
 * Œ¥: 0.997

Actual parameters used to generate data:
 * Œ±: 1.0
 * Œ≤: 1.5
 * Œ≥: 3.0
 * Œ¥: 1.0</code></pre><h1 id="Second-Alternative:-RxInfer-Model-with-Prior-on-the-Parameters"><a class="docs-heading-anchor" href="#Second-Alternative:-RxInfer-Model-with-Prior-on-the-Parameters">Second Alternative: RxInfer Model with Prior on the Parameters</a><a id="Second-Alternative:-RxInfer-Model-with-Prior-on-the-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Second-Alternative:-RxInfer-Model-with-Prior-on-the-Parameters" title="Permalink"></a></h1><p>We will now define the corresponding RxInfer model with the prior distribution on the parameters. For this, we will use the <code>@model</code> macro to create a time segment for the ODE using the deterministic ODE solver <code>lotka_volterra_rk4</code> as a non-linear node in the RxInfer model. For the prior distribution of the parameters, we will use a multivariate Gaussian distribution with mean <code>mŒ∏</code> and covariance <code>VŒ∏</code> that will be initialized using the <code>initialize</code> macro.</p><pre><code class="language-julia hljs">@model function lotka_volterra_model(obs, mprev, Vprev, dt, t, mŒ∏, VŒ∏)
    Œ∏     ~ MvNormalMeanCovariance(mŒ∏, VŒ∏)
    xprev ~ MvNormalMeanCovariance(mprev, Vprev)
    x     := lotka_volterra_rk4(xprev, Œ∏, t, dt)
    obs   ~ MvNormalMeanCovariance(x,  noisev * diageye(length(mprev)))
end</code></pre><pre><code class="language-julia hljs">autoupdates = @autoupdates begin
    mprev, Vprev= mean_cov(q(x))
    mŒ∏, VŒ∏ = mean_cov(q(Œ∏))
end

@initialization function initialize(mx, Vx, mŒ∏, VŒ∏)
    q(x) = MvNormalMeanCovariance(mx, Vx)
    q(Œ∏) = MvNormalMeanCovariance(mŒ∏, VŒ∏)
end;</code></pre><h1 id="Prior-Initialization-by-means-of-Free-Energy-Minimization"><a class="docs-heading-anchor" href="#Prior-Initialization-by-means-of-Free-Energy-Minimization">Prior Initialization by means of Free Energy Minimization</a><a id="Prior-Initialization-by-means-of-Free-Energy-Minimization-1"></a><a class="docs-heading-anchor-permalink" href="#Prior-Initialization-by-means-of-Free-Energy-Minimization" title="Permalink"></a></h1><p>We will now define the free energy function that will be minimized to infer the initial hyper-parameters of the prior distribution. Since we have 4 parameters, we will initialize the mean of the prior distribution with 4 elements and the diagonal elements of the covariance matrix. Again, we will use the <code>exp</code> function to transform the parameters to the positive domain. </p><pre><code class="language-julia hljs">function compute_free_energy(Œ∏ ; mx = ones(2), Vx = 1e-6 * diageye(2))
    Œ∏ = exp.(Œ∏)
    mŒ∏ = Œ∏[1:4]
    VŒ∏ = Diagonal(Œ∏[5:end])
    result = infer(
        model = lotka_volterra_model(dt = dt,),
        data = (obs = noisy_data, t = ts),
        initialization = initialize(mx, Vx, mŒ∏, VŒ∏),
        meta = delta_meta,
        autoupdates = autoupdates,
        keephistory = length(noisy_data),
        free_energy = true
    )
    return sum(result.free_energy_final_only_history)
end;</code></pre><h1 id="Parameter-Inference"><a class="docs-heading-anchor" href="#Parameter-Inference">Parameter Inference</a><a id="Parameter-Inference-1"></a><a class="docs-heading-anchor-permalink" href="#Parameter-Inference" title="Permalink"></a></h1><p>We will now perform the parameter inference by minimizing the free energy function. We will use the <code>optimize</code> function from the <code>Optim</code> package to perform the optimization. We will use the <code>NelderMead</code> method as the optimizer as it doesn&#39;t require gradient information and is faster.</p><pre><code class="language-julia hljs">res = optimize(compute_free_energy, [zeros(4); 0.1ones(4)], NelderMead(), Optim.Options(show_trace = true, show_every = 300));</code></pre><pre><code class="nohighlight hljs">Iter     Function value    ‚àö(Œ£(y·µ¢-yÃÑ)¬≤)/n 
------   --------------    --------------
     0     2.814831e+02     2.192538e-01
 * time: 0.00013399124145507812
   300     2.714613e+02     1.554900e-03
 * time: 7.524245023727417
   600     2.712411e+02     6.805548e-07
 * time: 14.785998821258545</code></pre><pre><code class="language-julia hljs">Œ∏_minimizer = exp.(res.minimizer)
mŒ∏_init = Œ∏_minimizer[1:4]
VŒ∏_init = Diagonal(Œ∏_minimizer[5:end])

println(&quot;\nEstimated initialization parameters for the prior distribution:&quot;)
for (i, (name, val, var)) in enumerate(zip([&quot;Œ±&quot;, &quot;Œ≤&quot;, &quot;Œ≥&quot;, &quot;Œ¥&quot;], mŒ∏_init, Œ∏_minimizer[5:8]))
    println(&quot; * $name: $(round(val, digits=3)) ¬± $(round(sqrt(var), digits=3))&quot;)
end

println(&quot;\nActual parameters used to generate data:&quot;)
for (i, (name, val)) in enumerate(zip([&quot;Œ±&quot;, &quot;Œ≤&quot;, &quot;Œ≥&quot;, &quot;Œ¥&quot;], true_params))
    println(&quot; * $name: $(round(val, digits=3))&quot;)
end</code></pre><pre><code class="nohighlight hljs">Estimated initialization parameters for the prior distribution:
 * Œ±: 2.279 ¬± 1.275
 * Œ≤: 1.91 ¬± 2.119
 * Œ≥: 1.636 ¬± 2.228
 * Œ¥: 0.962 ¬± 0.693

Actual parameters used to generate data:
 * Œ±: 1.0
 * Œ≤: 1.5
 * Œ≥: 3.0
 * Œ¥: 1.0</code></pre><p>Having estimated the initial hyper-parameters of the prior distribution, we can now perform the parameter inference by online message passing. We will use the <code>infer</code> function to perform the inference. </p><pre><code class="language-julia hljs">result = infer(
    model = lotka_volterra_model(dt = dt,),
    data = (obs = noisy_data_long, t= ts_long),
    initialization = initialize(ones(2), 1e-6 * diageye(2), mŒ∏_init, VŒ∏_init),
    meta = delta_meta,
    autoupdates = autoupdates,
    keephistory = length(noisy_data_long),
    free_energy = true
);</code></pre><pre><code class="language-julia hljs">mŒ∏_posterior = mean.(result.history[:Œ∏])
VŒ∏_posterior = var.(result.history[:Œ∏])

p = plot(layout=(4,1), size=(800,1000), legend=:right)

param_names = [&quot;Œ±&quot;, &quot;Œ≤&quot;, &quot;Œ≥&quot;, &quot;Œ¥&quot;]

for i in 1:4
    means = [m[i] for m in mŒ∏_posterior]
    stds = [2sqrt(v[i]) for v in VŒ∏_posterior]
    
    plot!(p[i], means, ribbon=stds, label=&quot;Posterior&quot;, subplot=i)
    hline!(p[i], [true_params[i]], label=&quot;True value&quot;, linestyle=:dash, color=:red, subplot=i)
    
    title!(p[i], param_names[i], subplot=i)
    if i == 4 
        xlabel!(p[i], &quot;Time step&quot;, subplot=i)
    end
end

# Place legend at top right for all subplots
plot!(p, legend=:topright)

display(p)
final_means = last(mŒ∏_posterior)
final_vars = last(VŒ∏_posterior)
final_stds = sqrt.(final_vars)

# Print results
println(&quot;\nFinal Parameter Estimates:&quot;)
for (param, mean, std) in zip(param_names, final_means, final_stds)
    println(&quot;$param: $mean ¬± $(std)&quot;)
end

# Get final covariance matrix
final_cov = cov(last(result.history[:Œ∏]))
println(&quot;\nFinal Parameter Covariance Matrix:&quot;)
display(final_cov)</code></pre><pre><code class="nohighlight hljs">Final Parameter Estimates:
Œ±: 0.9873125810392338 ¬± 0.022683193282629927
Œ≤: 1.4928568988039574 ¬± 0.026900704209026783
Œ≥: 3.0329956989098488 ¬± 0.12553964480470822
Œ¥: 1.0192425653899293 ¬± 0.03383241259684531

Final Parameter Covariance Matrix:
4√ó4 Matrix{Float64}:
 0.000514527   0.00038494    8.38569e-5   3.78402e-5
 0.00038494    0.000723648  -8.1867e-5   -4.44924e-5
 8.38569e-5   -8.1867e-5     0.0157602    0.00373872
 3.78402e-5   -4.44924e-5    0.00373872   0.00114463</code></pre><p><img src="ODE Parameter Estimation_17_1.png" alt/></p><pre><code class="language-julia hljs">from = 1
skip = 1        
to = 500

# Get state estimates and variances
mx = mean.(result.history[:x])
Vx = var.(result.history[:x])

# Plot state estimates with uncertainty bands
p1 = plot(ts_long[from:skip:to] , getindex.(mx, 1)[from:skip:to], ribbon=2*sqrt.(getindex.(Vx, 1)[from:skip:to]), 
          label=&quot;Prey estimate&quot;, legend=:topright)
scatter!(p1, ts_long[from:skip:to], getindex.(noisy_data_long, 1)[from:skip:to], label=&quot;Noisy prey observations&quot;, alpha=0.5,ms=1)
plot!(p1, ts_long[from:skip:to], getindex.(data_long, 1)[from:skip:to], label=&quot;True prey&quot;, linestyle=:dash)
title!(p1, &quot;Prey Population&quot;)

p2 = plot(ts_long[from:skip:to], getindex.(mx, 2)[from:skip:to], ribbon=2*sqrt.(getindex.(Vx, 2)[from:skip:to]), 
          label=&quot;Predator estimate&quot;, legend=:topright)
scatter!(p2, ts_long[from:skip:to], getindex.(noisy_data_long, 2)[from:skip:to], label=&quot;Noisy predator observations&quot;, alpha=0.5, ms=1)
plot!(p2, ts_long[from:skip:to], getindex.(data_long, 2)[from:skip:to] , label=&quot;True predator&quot;, linestyle=:dash)
title!(p2, &quot;Predator Population&quot;)

plot(p1, p2, layout=(2,1), size=(1000,600))</code></pre><p><img src="ODE Parameter Estimation_18_1.png" alt/></p><h2 id="Third-Alternative:-RxInfer-Model-with-Exponential-Transformation-on-the-Parameters"><a class="docs-heading-anchor" href="#Third-Alternative:-RxInfer-Model-with-Exponential-Transformation-on-the-Parameters">Third Alternative: RxInfer Model with Exponential Transformation on the Parameters</a><a id="Third-Alternative:-RxInfer-Model-with-Exponential-Transformation-on-the-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Third-Alternative:-RxInfer-Model-with-Exponential-Transformation-on-the-Parameters" title="Permalink"></a></h2><p>So far we have used the <code>exp</code> function to transform the parameters to the positive domain and computed free energy. This transformation was done outside of <code>@model</code> macro. In this approach, we will use the <code>exp</code> function to transform the parameters to the positive domain but within the <code>@model</code> macro. We will then use the <code>Unscented</code> method to approximate the non-linear deterministic node. This approach is more computationally efficient than the previous one, however it may suffer from accuracy issues as we may not have a good hyper-parameter initialization. </p><p>NOTE: We can not use <code>exp.()</code> inside the <code>@model</code> macro as the model macro doesn&#39;t support broadcasting yet. So we need to define a function that will apply the <code>exp</code> function to the parameters. </p><pre><code class="language-julia hljs">lotka_volterra_rk4_transformed(x,Œ∏,t,dt) = lotka_volterra_rk4(x, exp.(Œ∏), t, dt)## This function is used to apply the exp function to the parameters within the @model macro

@model function lotka_volterra_model2(obs, mprev, Vprev, dt, t, mŒ∏, VŒ∏)
    Œ∏     ~ MvNormalMeanCovariance(mŒ∏, VŒ∏)
    xprev ~ MvNormalMeanCovariance(mprev, Vprev)
    x     := lotka_volterra_rk4_transformed(xprev, Œ∏, t, dt)
    obs   ~ MvNormalMeanCovariance(x,  noisev * diageye(length(mprev)))
end

delta_meta2 = @meta begin
    lotka_volterra_rk4_transformed() -&gt;  Unscented()
end

autoupdates2 = @autoupdates begin
    mprev, Vprev= mean_cov(q(x))
    mŒ∏, VŒ∏ = mean_cov(q(Œ∏))
end

@initialization function initialize2(mx, Vx, mŒ∏, VŒ∏)
    q(x) = MvNormalMeanCovariance(mx, Vx)
    q(Œ∏) = MvNormalMeanCovariance(mŒ∏, VŒ∏)
end


result2  = infer(
    model = lotka_volterra_model2(dt = dt,),
    data = (obs = noisy_data_long, t= ts_long),
    initialization = initialize2(ones(2),  1e-6diageye(2), zeros(4), 0.1*diageye(4)),
    meta = delta_meta2,
    autoupdates = autoupdates2,
    keephistory = length(noisy_data_long),
    free_energy = true
)</code></pre><pre><code class="nohighlight hljs">RxInferenceEngine:
  Posteriors stream    | enabled for (Œ∏, xprev, x)
  Free Energy stream   | enabled
  Posteriors history   | available for (Œ∏, xprev, x)
  Free Energy history  | available
  Enabled events       | [  ]</code></pre><pre><code class="language-julia hljs">mŒ∏ =  mean.(result2.history[:Œ∏])
VŒ∏ = cov.(result2.history[:Œ∏])
expf(Œ∏) = exp.(Œ∏)
Œ∏dists = map((m,v) -&gt; MvNormalMeanCovariance(m, v), mŒ∏, VŒ∏)
Œ∏_exp_dists = map(Œ∏dist -&gt; ReactiveMP.approximate(Unscented(), expf, (Œ∏dist,)), Œ∏dists)

mŒ∏_exp =  mean.(Œ∏_exp_dists)
VŒ∏_exp = cov.(Œ∏_exp_dists)

# Plot the inferred parameters with uncertainty
p1 = plot(ts_long, getindex.(mŒ∏_exp, 1), ribbon=2*sqrt.(getindex.(VŒ∏_exp, 1,1)), label=&quot;Œ±&quot;, legend=:topright)
plot!(p1, ts_long, fill(true_params[1], length(ts_long)), label=&quot;True Œ±&quot;, linestyle=:dash)
title!(p1, &quot;Parameter Œ±&quot;)

p2 = plot(ts_long, getindex.(mŒ∏_exp, 2), ribbon=2*sqrt.(getindex.(VŒ∏_exp, 2,2)), label=&quot;Œ≤&quot;, legend=:topright)
plot!(p2, ts_long, fill(true_params[2], length(ts_long)), label=&quot;True Œ≤&quot;, linestyle=:dash)
title!(p2, &quot;Parameter Œ≤&quot;)

p3 = plot(ts_long, getindex.(mŒ∏_exp, 3), ribbon=2*sqrt.(getindex.(VŒ∏_exp, 3,3)), label=&quot;Œ≥&quot;, legend=:topright)
plot!(p3, ts_long, fill(true_params[3], length(ts_long)), label=&quot;True Œ≥&quot;, linestyle=:dash)
title!(p3, &quot;Parameter Œ≥&quot;)

p4 = plot(ts_long, getindex.(mŒ∏_exp, 4), ribbon=2*sqrt.(getindex.(VŒ∏_exp, 4,4)), label=&quot;Œ¥&quot;, legend=:topright)
plot!(p4, ts_long, fill(true_params[4], length(ts_long)), label=&quot;True Œ¥&quot;, linestyle=:dash)
title!(p4, &quot;Parameter Œ¥&quot;)

plot(p1, p2, p3, p4, layout=(4,1), size=(1000,800))</code></pre><p><img src="ODE Parameter Estimation_20_1.png" alt/></p><pre><code class="language-julia hljs"># Print final parameter estimates and covariance
final_means = last(mŒ∏_exp)
final_vars = diag(last(VŒ∏_exp))
final_stds = sqrt.(final_vars)

# Print results
println(&quot;\nFinal Parameter Estimates:&quot;)
for (param, mean, std) in zip(param_names, final_means, final_stds)
    println(&quot;$param: $mean ¬± $(std)&quot;)
end

println(&quot;\nFinal parameter covariance matrix:&quot;)
display(last(VŒ∏_exp))</code></pre><pre><code class="nohighlight hljs">Final Parameter Estimates:
Œ±: 1.0466420644370373 ¬± 0.023551898981352345
Œ≤: 1.5267272962373681 ¬± 0.027682602680033756
Œ≥: 2.7961085961433128 ¬± 0.12150864747658563
Œ¥: 0.9428781820606673 ¬± 0.032860835936904864

Final parameter covariance matrix:
4√ó4 Matrix{Float64}:
 0.000554692   0.000437206   8.94158e-5   3.93331e-5
 0.000437206   0.000766326  -7.64945e-5  -5.57011e-5
 8.94158e-5   -7.64945e-5    0.0147644    0.00347717
 3.93331e-5   -5.57011e-5    0.00347717   0.00107983</code></pre><pre><code class="language-julia hljs">
# Get state estimates and variances
mx = mean.(result2.history[:x])
Vx = var.(result2.history[:x])

# Plot state estimates with uncertainty bands
p1 = plot(ts_long[from:skip:to] , getindex.(mx, 1)[from:skip:to], ribbon=2*sqrt.(getindex.(Vx, 1)[from:skip:to]), 
          label=&quot;Prey estimate&quot;, legend=:topright)
scatter!(p1, ts_long[from:skip:to], getindex.(noisy_data_long, 1)[from:skip:to], label=&quot;Noisy prey observations&quot;, alpha=0.5,ms=1)
plot!(p1, ts_long[from:skip:to], getindex.(data_long, 1)[from:skip:to], label=&quot;True prey&quot;, linestyle=:dash)
title!(p1, &quot;Prey Population&quot;)

p2 = plot(ts_long[from:skip:to], getindex.(mx, 2)[from:skip:to], ribbon=2*sqrt.(getindex.(Vx, 2)[from:skip:to]), 
          label=&quot;Predator estimate&quot;, legend=:topright)
scatter!(p2, ts_long[from:skip:to], getindex.(noisy_data_long, 2)[from:skip:to], label=&quot;Noisy predator observations&quot;, alpha=0.5, ms=1)
plot!(p2, ts_long[from:skip:to], getindex.(data_long, 2)[from:skip:to] , label=&quot;True predator&quot;, linestyle=:dash)
title!(p2, &quot;Predator Population&quot;)

plot(p1, p2, layout=(2,1), size=(1000,600))</code></pre><p><img src="ODE Parameter Estimation_22_1.png" alt/></p><hr/><div class="admonition is-info" id="Contributing-baba9dc142ba7ccb"><header class="admonition-header">Contributing<a class="admonition-anchor" href="#Contributing-baba9dc142ba7ccb" title="Permalink"></a></header><div class="admonition-body"><p>This example was automatically generated from a Jupyter notebook in the <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">RxInferExamples.jl</a> repository.</p><p>We welcome and encourage contributions! You can help by:</p><ul><li>Improving this example</li><li>Creating new examples </li><li>Reporting issues or bugs</li><li>Suggesting enhancements</li></ul><p>Visit our <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">GitHub repository</a> to get started. Together we can make <a href="https://github.com/ReactiveBayes/RxInfer.jl">RxInfer.jl</a> even better! üí™</p></div></div><hr/><div class="admonition is-compat" id="Environment-ead41e814a894220"><header class="admonition-header">Environment<a class="admonition-anchor" href="#Environment-ead41e814a894220" title="Permalink"></a></header><div class="admonition-body"><p>This example was executed in a clean, isolated environment. Below are the exact package versions used:</p><p>For reproducibility:</p><ul><li>Use the same package versions when running locally</li><li>Report any issues with package compatibility</li></ul></div></div><pre><code class="nohighlight hljs">Status `/tmp/jl_A77yVv/Project.toml`
‚åÉ [be0214bd] NonlinearSolveBase v1.14.0
‚åÖ [429524aa] Optim v1.13.3
  [91a5bcdd] Plots v1.41.6
  [86711068] RxInfer v4.7.0
  [860ef19b] StableRNGs v1.0.4
  [90137ffa] StaticArrays v1.9.17
  [37e2e46d] LinearAlgebra v1.12.0
Info Packages marked with ‚åÉ and ‚åÖ have new versions available. Those with ‚åÉ may be upgradable, but those with ‚åÖ are restricted by compatibility constraints from upgrading. To see why use `status --outdated`
</code></pre><script type="module">import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
mermaid.initialize({
    startOnLoad: true,
    theme: "neutral"
});
</script></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../litter_model/">¬´ Litter Model</a><a class="docs-footer-nextpage" href="../probit_model/">Probit Model ¬ª</a><div class="flexbox-break"></div><p class="footer-message">Created in <a href="https://biaslab.github.io/">BIASlab</a>, maintained by <a href="https://github.com/ReactiveBayes">ReactiveBayes</a>, powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.17.0 on <span class="colophon-date" title="Wednesday 25 February 2026 15:00">Wednesday 25 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
