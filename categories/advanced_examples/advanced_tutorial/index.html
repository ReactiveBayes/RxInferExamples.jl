<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Advanced Tutorial Â· RxInfer.jl Examples</title><meta name="title" content="Advanced Tutorial Â· RxInfer.jl Examples"/><meta property="og:title" content="Advanced Tutorial Â· RxInfer.jl Examples"/><meta property="twitter:title" content="Advanced Tutorial Â· RxInfer.jl Examples"/><meta name="description" content="Advanced Tutorial with RxInfer.jl\nThis notebook covers the fundamentals and advanced usage of the `RxInfer.jl` package.\n\nCheck more examples and tutorials at https://examples.rxinfer.com\n"/><meta property="og:description" content="Advanced Tutorial with RxInfer.jl\nThis notebook covers the fundamentals and advanced usage of the `RxInfer.jl` package.\n\nCheck more examples and tutorials at https://examples.rxinfer.com\n"/><meta property="twitter:description" content="Advanced Tutorial with RxInfer.jl\nThis notebook covers the fundamentals and advanced usage of the `RxInfer.jl` package.\n\nCheck more examples and tutorials at https://examples.rxinfer.com\n"/><meta property="og:url" content="https://examples.rxinfer.com/categories/advanced_examples/advanced_tutorial/"/><meta property="twitter:url" content="https://examples.rxinfer.com/categories/advanced_examples/advanced_tutorial/"/><link rel="canonical" href="https://examples.rxinfer.com/categories/advanced_examples/advanced_tutorial/"/><script async src="https://www.googletagmanager.com/gtag/js?id=G-GMFX620VEP"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-GMFX620VEP', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/theme.css" rel="stylesheet" type="text/css"/><link href="../../../assets/header.css" rel="stylesheet" type="text/css"/><script src="../../../assets/header.js"></script><script src="../../../assets/chat.js"></script><link href="../../../assets/favicon.ico" rel="icon" type="image/x-icon"/>
    <meta property="og:title" content="Advanced Tutorial - RxInfer Examples">
    <meta name="description" content="This notebook covers the fundamentals and advanced usage of the `RxInfer.jl` package.
">
    <meta property="og:description" content="This notebook covers the fundamentals and advanced usage of the `RxInfer.jl` package.
">
    <meta name="keywords" content="rxinfer, julia, bayesian inference, examples, probabilistic programming, message passing, probabilistic numerics, variational inference, belief propagation, advanced examples, tutorial, fundamentals">
    <link rel="sitemap" type="application/xml" title="Sitemap" href="https://examples.rxinfer.com/sitemap.xml">
    </head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img class="docs-light-only" src="../../../assets/logo.svg" alt="RxInfer.jl Examples logo"/><img class="docs-dark-only" src="../../../assets/logo-dark.svg" alt="RxInfer.jl Examples logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">RxInfer.jl Examples</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><a class="tocitem" href="../../../how_to_contribute/">How to contribute</a></li><li><a class="tocitem" href="../../../autogenerated/list_of_examples/">List of Examples</a></li><li><span class="tocitem">Basic Examples</span><ul><li><a class="tocitem" href="../../basic_examples/bayesian_binomial_regression/">Bayesian Binomial Regression</a></li><li><a class="tocitem" href="../../basic_examples/bayesian_linear_regression/">Bayesian Linear Regression</a></li><li><a class="tocitem" href="../../basic_examples/bayesian_multinomial_regression/">Bayesian Multinomial Regression</a></li><li><a class="tocitem" href="../../basic_examples/bayesian_networks/">Bayesian Networks</a></li><li><a class="tocitem" href="../../basic_examples/coin_toss_model/">Coin Toss Model</a></li><li><a class="tocitem" href="../../basic_examples/contextual_bandits/">Contextual Bandits</a></li><li><a class="tocitem" href="../../basic_examples/feature_functions_in_bayesian_regression/">Feature Functions In Bayesian Regression</a></li><li><a class="tocitem" href="../../basic_examples/forgetting_factors_for_online_inference/">Forgetting Factors For Online Inference</a></li><li><a class="tocitem" href="../../basic_examples/hidden_markov_model/">Hidden Markov Model</a></li><li><a class="tocitem" href="../../basic_examples/incomplete_data/">Incomplete Data</a></li><li><a class="tocitem" href="../../basic_examples/kalman_filtering_and_smoothing/">Kalman Filtering And Smoothing</a></li><li><a class="tocitem" href="../../basic_examples/pomdp_control/">Pomdp Control</a></li><li><a class="tocitem" href="../../basic_examples/predicting_bike_rental_demand/">Predicting Bike Rental Demand</a></li></ul></li><li><span class="tocitem">Advanced Examples</span><ul><li><a class="tocitem" href="../active_inference_mountain_car/">Active Inference Mountain Car</a></li><li class="is-active"><a class="tocitem" href>Advanced Tutorial</a><ul class="internal"><li><a class="tocitem" href="#General-model-specification-syntax"><span>General model specification syntax</span></a></li><li><a class="tocitem" href="#Probabilistic-inference-in-RxInfer.jl"><span>Probabilistic inference in RxInfer.jl</span></a></li><li><a class="tocitem" href="#Coin-Toss-Model"><span>Coin Toss Model</span></a></li><li><a class="tocitem" href="#Reactive-Online-Inference"><span>Reactive Online Inference</span></a></li><li><a class="tocitem" href="#Variational-inference"><span>Variational inference</span></a></li><li><a class="tocitem" href="#Creating-custom-nodes-and-message-computation-rules"><span>Creating custom nodes and message computation rules</span></a></li></ul></li><li><a class="tocitem" href="../assessing_people_skills/">Assessing People Skills</a></li><li><a class="tocitem" href="../bayesian_structured_time_series/">Bayesian Structured Time Series</a></li><li><a class="tocitem" href="../chance_constraints/">Chance Constraints</a></li><li><a class="tocitem" href="../conjugate-computational_variational_message_passing/">Conjugate-Computational Variational Message Passing</a></li><li><a class="tocitem" href="../drone_dynamics/">Drone Dynamics</a></li><li><a class="tocitem" href="../gp_regression_by_ssm/">Gp Regression By Ssm</a></li><li><a class="tocitem" href="../infinite_data_stream/">Infinite Data Stream</a></li><li><a class="tocitem" href="../integrating_neural_networks_with_flux.jl/">Integrating Neural Networks With Flux.Jl</a></li><li><a class="tocitem" href="../learning_dynamics_with_vaes/">Learning Dynamics With Vaes</a></li><li><a class="tocitem" href="../multi-agent_trajectory_planning/">Multi-Agent Trajectory Planning</a></li><li><a class="tocitem" href="../nonlinear_sensor_fusion/">Nonlinear Sensor Fusion</a></li><li><a class="tocitem" href="../parameter_optimisation_with_optim.jl/">Parameter Optimisation With Optim.Jl</a></li><li><a class="tocitem" href="../robotic_arm/">Robotic Arm</a></li></ul></li><li><span class="tocitem">Problem Specific</span><ul><li><a class="tocitem" href="../../problem_specific/autoregressive_models/">Autoregressive Models</a></li><li><a class="tocitem" href="../../problem_specific/gamma_mixture/">Gamma Mixture</a></li><li><a class="tocitem" href="../../problem_specific/gaussian_mixture/">Gaussian Mixture</a></li><li><a class="tocitem" href="../../problem_specific/hierarchical_gaussian_filter/">Hierarchical Gaussian Filter</a></li><li><a class="tocitem" href="../../problem_specific/invertible_neural_network_tutorial/">Invertible Neural Network Tutorial</a></li><li><a class="tocitem" href="../../problem_specific/ising_model/">Ising Model</a></li><li><a class="tocitem" href="../../problem_specific/litter_model/">Litter Model</a></li><li><a class="tocitem" href="../../problem_specific/ode_parameter_estimation/">Ode Parameter Estimation</a></li><li><a class="tocitem" href="../../problem_specific/probit_model/">Probit Model</a></li><li><a class="tocitem" href="../../problem_specific/rts_vs_bifm_smoothing/">Rts Vs Bifm Smoothing</a></li><li><a class="tocitem" href="../../problem_specific/simple_nonlinear_node/">Simple Nonlinear Node</a></li><li><a class="tocitem" href="../../problem_specific/structural_dynamics_with_augmented_kalman_filter/">Structural Dynamics With Augmented Kalman Filter</a></li><li><a class="tocitem" href="../../problem_specific/universal_mixtures/">Universal Mixtures</a></li></ul></li><li><span class="tocitem">Experimental Examples</span><ul><li><a class="tocitem" href="../../experimental_examples/bayesian_trust_learning/">Bayesian Trust Learning</a></li><li><a class="tocitem" href="../../experimental_examples/large_language_models/">Large Language Models</a></li><li><a class="tocitem" href="../../experimental_examples/latent_vector_autoregressive_model/">Latent Vector Autoregressive Model</a></li><li><a class="tocitem" href="../../experimental_examples/recurrent_switching_linear_dynamical_system/">Recurrent Switching Linear Dynamical System</a></li></ul></li><li><a class="tocitem" href="../../../how_build_works/">How we build the examples</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Advanced Examples</a></li><li class="is-active"><a href>Advanced Tutorial</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Advanced Tutorial</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInferExamples.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ï‚›</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInferExamples.jl" title="View source on GitHub"><span class="docs-icon fa-solid">ï…œ</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><div class="admonition is-info" id="Contributing-baba9dc142ba7ccb"><header class="admonition-header">Contributing<a class="admonition-anchor" href="#Contributing-baba9dc142ba7ccb" title="Permalink"></a></header><div class="admonition-body"><p>This example was automatically generated from a Jupyter notebook in the <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">RxInferExamples.jl</a> repository.</p><p>We welcome and encourage contributions! You can help by:</p><ul><li>Improving this example</li><li>Creating new examples </li><li>Reporting issues or bugs</li><li>Suggesting enhancements</li></ul><p>Visit our <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">GitHub repository</a> to get started. Together we can make <a href="https://github.com/ReactiveBayes/RxInfer.jl">RxInfer.jl</a> even better! ðŸ’ª</p></div></div><hr/><h1 id="Advanced-Tutorial"><a class="docs-heading-anchor" href="#Advanced-Tutorial">Advanced Tutorial</a><a id="Advanced-Tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-Tutorial" title="Permalink"></a></h1><pre><code class="language-julia hljs">using RxInfer, Plots</code></pre><p>This notebook covers the fundamentals and advanced usage of the <code>RxInfer.jl</code> package.</p><h2 id="General-model-specification-syntax"><a class="docs-heading-anchor" href="#General-model-specification-syntax">General model specification syntax</a><a id="General-model-specification-syntax-1"></a><a class="docs-heading-anchor-permalink" href="#General-model-specification-syntax" title="Permalink"></a></h2><p>We use the <code>@model</code> macro from the <code>GraphPPL.jl</code> package to create a probabilistic model <span>$p(s, y)$</span> and we also specify extra constraints on the variational family of distributions <span>$\mathcal{Q}$</span>, used for approximating intractable posterior distributions. Below there is a simple example of the general syntax for model specification. In this tutorial we do not cover all possible ways to create models or advanced features of <code>GraphPPL.jl</code>.  Instead we refer the interested reader to the documentation for a more rigorous explanation and illustrative examples.</p><pre><code class="language-julia hljs"># the `@model` macro accepts a regular Julia function
@model function test_model1(s_mean, s_precision, y)
    
    # the `tilde` operator creates a functional dependency
    # between variables in our model and can be read as 
    # `sampled from` or `is modeled by`
    s ~ Normal(mean = s_mean, precision = s_precision)
    y ~ Normal(mean = s, precision = 1.0)
    
    # It is possible to return something from the model specification (including variables and nodes)
    return &quot;Hello world&quot;
end</code></pre><p>The <code>@model</code> macro creates a function with the same name and with the same set of input arguments as the original function (<code>test_model1(s_mean, s_precision, y)</code> in this example). The arguments are however converted to the keyword arguments. The <code>@model</code> macro does not support positional arguments.</p><p>It is also possible to use control flow statements such as <code>if</code> or <code>for</code> blocks in the model specification function. In general, any valid snippet of Julia code can be used inside the <code>@model</code> block. As an example consider the following (valid!) model:</p><pre><code class="language-julia hljs">@model function test_model2(y)
    
    if length(y) &lt;= 1
        error(&quot;The `length` of `y` argument must be greater than one.&quot;)
    end
    
    s[1] ~ Normal(mean = 0.0, precision = 0.1)
    y[1] ~ Normal(mean = s[1], precision = 1.0)
    
    for i in eachindex(y)
        s[i] ~ Normal(mean = s[i - 1], precision = 1.0)
        y[i] ~ Normal(mean = s[i], precision = 1.0)
    end
    
end</code></pre><p>It is also possible to use complex expressions inside the functional dependency expressions</p><pre><code class="language-julia hljs">y ~ Normal(mean = 2.0 * (s + 1.0), precision = 1.0)</code></pre><p>The <code>~</code> operator automatically creates a random variable if none was created before with the same name and throws an error if this name already exists</p><pre><code class="language-julia hljs"># `~` creates random variables automatically
s ~ Normal(mean = 0.0, precision1.0)</code></pre><h2 id="Probabilistic-inference-in-RxInfer.jl"><a class="docs-heading-anchor" href="#Probabilistic-inference-in-RxInfer.jl">Probabilistic inference in RxInfer.jl</a><a id="Probabilistic-inference-in-RxInfer.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Probabilistic-inference-in-RxInfer.jl" title="Permalink"></a></h2><p><code>RxInfer.jl</code> uses the <code>Rocket.jl</code> package API for inference routines. <code>Rocket.jl</code> is a reactive programming extension for Julia that is higly inspired by <code>RxJS</code> and similar libraries from the <code>Rx</code> ecosystem. It consists of <strong>observables</strong>, <strong>actors</strong>, <strong>subscriptions</strong> and <strong>operators</strong>. For more information and rigorous examples see <a href="https://github.com/biaslab/Rocket.jl">Rocket.jl github page</a>.</p><h3 id="Observables"><a class="docs-heading-anchor" href="#Observables">Observables</a><a id="Observables-1"></a><a class="docs-heading-anchor-permalink" href="#Observables" title="Permalink"></a></h3><p>Observables are lazy push-based collections and they deliver their values over time.</p><pre><code class="language-julia hljs"># Timer that emits a new value every second and has an initial one second delay 
observable = timer(300, 300)</code></pre><pre><code class="nohighlight hljs">TimerObservable(300, 300)</code></pre><p>A subscription allows us to subscribe on future values of some observable, and actors specify what to do with these new values:</p><pre><code class="language-julia hljs">actor = (value) -&gt; println(value)
subscription1 = subscribe!(observable, actor)</code></pre><pre><code class="nohighlight hljs">TimerSubscription()</code></pre><pre><code class="language-julia hljs"># We always need to unsubscribe from some observables
unsubscribe!(subscription1)</code></pre><pre><code class="language-julia hljs"># We can modify our observables
modified = observable |&gt; filter(d -&gt; rem(d, 2) === 1) |&gt; map(Int, d -&gt; d ^ 2)</code></pre><pre><code class="nohighlight hljs">ProxyObservable(Int64, MapProxy(Int64))</code></pre><pre><code class="language-julia hljs">subscription2 = subscribe!(modified, (value) -&gt; println(value))</code></pre><pre><code class="nohighlight hljs">TimerSubscription()</code></pre><pre><code class="language-julia hljs">unsubscribe!(subscription2)</code></pre><h2 id="Coin-Toss-Model"><a class="docs-heading-anchor" href="#Coin-Toss-Model">Coin Toss Model</a><a id="Coin-Toss-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Coin-Toss-Model" title="Permalink"></a></h2><pre><code class="language-julia hljs">@model function coin_toss_model(y)
    # We endow Î¸ parameter of our model with some prior
    Î¸  ~ Beta(2.0, 7.0)
    # We assume that the outcome of each coin flip 
    # is modeled by a Bernoulli distribution
    y .~ Bernoulli(Î¸)
end</code></pre><p>We can call the <code>infer</code> function to run inference in such model:</p><pre><code class="language-julia hljs">p = 0.75 # Bias of a coin

dataset = float.(rand(Bernoulli(p), 500));

result = infer(
    model = coin_toss_model(),
    data  = (y = dataset, )
)

println(&quot;Inferred bias is &quot;, mean(result.posteriors[:Î¸]), &quot; with standard deviation is &quot;, std(result.posteriors[:Î¸]))</code></pre><pre><code class="nohighlight hljs">Inferred bias is 0.730844793713163 with standard deviation is 0.01963943018
699018</code></pre><p>We can see that the inferred bias is quite close to the actual value we used in the dataset generation with a low standard deviation.</p><h2 id="Reactive-Online-Inference"><a class="docs-heading-anchor" href="#Reactive-Online-Inference">Reactive Online Inference</a><a id="Reactive-Online-Inference-1"></a><a class="docs-heading-anchor-permalink" href="#Reactive-Online-Inference" title="Permalink"></a></h2><p>RxInfer.jl naturally supports reactive streams of data and it is possible to run reactive inference with some external datasource.</p><pre><code class="language-julia hljs">@model function online_coin_toss_model(Î¸_a, Î¸_b, y)
    Î¸ ~ Beta(Î¸_a, Î¸_b)
    y ~ Bernoulli(Î¸)
end</code></pre><pre><code class="language-julia hljs">autoupdates = @autoupdates begin 
    Î¸_a, Î¸_b = params(q(Î¸))
end</code></pre><pre><code class="nohighlight hljs">@autoupdates begin
    (Î¸_a, Î¸_b) = params(q(Î¸))
end</code></pre><pre><code class="language-julia hljs">init = @initialization begin
    q(Î¸) = vague(Beta)
end</code></pre><pre><code class="nohighlight hljs">Initial state: 
  q(Î¸) = Distributions.Beta{Float64}(Î±=1.0, Î²=1.0)</code></pre><pre><code class="language-julia hljs">rxresult = infer(
    model = online_coin_toss_model(),
    data  = (y = dataset, ),
    autoupdates = autoupdates,
    historyvars = (Î¸ = KeepLast(), ),
    keephistory = length(dataset),
    initialization = init,
    autostart = true
);</code></pre><pre><code class="language-julia hljs">animation = @animate for i in 1:length(dataset)
    plot(mean.(rxresult.history[:Î¸][1:i]), ribbon = std.(rxresult.history[:Î¸][1:i]), title = &quot;Online coin bias inference&quot;, label = &quot;Inferred bias&quot;, legend = :bottomright)
    hline!([ p ], label = &quot;Real bias&quot;, size = (600, 200))
end

gif(animation, &quot;online-coin-bias-inference.gif&quot;, fps = 24, show_msg = false);</code></pre><p><img src="online-coin-bias-inference.gif" alt/></p><p>In this example we used static dataset and the <code>history</code> field of the reactive inference result, but the <code>rxinference</code> function also supports any real-time reactive stream and can run indefinitely.</p><p>That was an example of exact Bayesian inference with Sum-Product (or Belief Propagation) algorithm. However, <code>RxInfer</code> is not limited to only the sum-product algorithm but it also supports variational message passing with <a href="https://www.mdpi.com/1099-4300/23/7/807">Constrained Bethe Free Energy Minimisation</a>.</p><h2 id="Variational-inference"><a class="docs-heading-anchor" href="#Variational-inference">Variational inference</a><a id="Variational-inference-1"></a><a class="docs-heading-anchor-permalink" href="#Variational-inference" title="Permalink"></a></h2><p>On a very high-level, <code>RxInfer</code> is aimed to solve the Constrained Bethe Free Energy minimisation problem. For this task we approximate our exact posterior marginal distribution by some family of distributions <span>$q \in \mathcal{Q}$</span>. Often this involves assuming some factorization over <span>$q$</span>. </p><pre><code class="language-julia hljs">@model function test_model6(y)
    Ï„ ~ Gamma(shape = 1.0, rate = 1.0) 
    Î¼ ~ Normal(mean = 0.0, variance = 100.0)
    for i in eachindex(y)
        y[i] ~ Normal(mean = Î¼, precision = Ï„)
    end
end</code></pre><p>In this example we want to specify extra constraints for <span>$q_a$</span> for Bethe factorisation:</p><p class="math-container">\[\begin{aligned}
q(s) = \prod_{a \in \mathcal{V}} q_a(s_a) \prod_{i \in \mathcal{E}} q_i^{-1}(s_i)
\end{aligned}\]</p><p><code>RxInfer.jl</code> package exports <code>@constraints</code> macro to simplify factorisation and form constraints specification. Read more about <code>@constraints</code> macro in the corresponding documentation section, here we show a simple example of the same factorisation constraints specification, but with <code>@constraints</code> macro:</p><pre><code class="language-julia hljs">constraints6 = @constraints begin
     q(Î¼, Ï„) = q(Î¼)q(Ï„) # Mean-Field over `Î¼` and `Ï„`
end</code></pre><pre><code class="nohighlight hljs">Constraints: 
  q(Î¼, Ï„) = q(Î¼)q(Ï„)</code></pre><pre><code class="language-julia hljs">init = @initialization begin
    q(Î¼) = vague(NormalMeanPrecision)
    q(Ï„) = vague(GammaShapeRate)
end</code></pre><pre><code class="nohighlight hljs">Initial state: 
  q(Î¼) = ExponentialFamily.NormalMeanPrecision{Float64}(Î¼=0.0, w=1.0e-12)
  q(Ï„) = ExponentialFamily.GammaShapeRate{Float64}(a=1.0, b=1.0e-12)</code></pre><h3 id="Inference"><a class="docs-heading-anchor" href="#Inference">Inference</a><a id="Inference-1"></a><a class="docs-heading-anchor-permalink" href="#Inference" title="Permalink"></a></h3><p>To run inference in this model we again need to create a synthetic dataset and call the <code>infer</code> function.</p><pre><code class="language-julia hljs">dataset = rand(Normal(-3.0, inv(sqrt(5.0))), 1000);
result = infer(
    model          = test_model6(),
    data           = (y = dataset, ),
    constraints    = constraints6, 
    initialization = init,
    returnvars     = (Î¼ = KeepLast(), Ï„ = KeepLast()),
    iterations     = 10,
    free_energy    = true,
    showprogress   = true
)</code></pre><pre><code class="nohighlight hljs">Inference results:
  Posteriors       | available for (Î¼, Ï„)
  Free Energy:     | Real[14763.3, 3276.02, 662.74, 621.834, 621.834, 621.8
34, 621.834, 621.834, 621.834, 621.834]</code></pre><pre><code class="language-julia hljs">println(&quot;Î¼: mean = &quot;, mean(result.posteriors[:Î¼]), &quot;, std = &quot;, std(result.posteriors[:Î¼]))</code></pre><pre><code class="nohighlight hljs">Î¼: mean = -3.0085681853002453, std = 0.014141102648437598</code></pre><pre><code class="language-julia hljs">println(&quot;Ï„: mean = &quot;, mean(result.posteriors[:Ï„]), &quot;, std = &quot;, std(result.posteriors[:Ï„]))</code></pre><pre><code class="nohighlight hljs">Ï„: mean = 5.000720503870371, std = 0.22341571554336895</code></pre><h3 id="Form-constraints"><a class="docs-heading-anchor" href="#Form-constraints">Form constraints</a><a id="Form-constraints-1"></a><a class="docs-heading-anchor-permalink" href="#Form-constraints" title="Permalink"></a></h3><p>In order to support form constraints, the <code>@constraints</code> macro supports additional type specifications for posterior marginals.  For example, here how we can perform the EM algorithm with <code>PointMass</code> form constraint.</p><p><img src="posterior.png" alt/></p><pre><code class="language-julia hljs">@model function test_model7(y)
    Ï„ ~ Gamma(shape = 1.0, rate = 1.0) 
    Î¼ ~ Normal(mean = 0.0, variance = 100.0)
    for i in eachindex(y)
        y[i] ~ Normal(mean = Î¼, precision = Ï„)
    end
end</code></pre><p>As in the previous example we can use <code>@constraints</code> macro to achieve the same goal with a nicer syntax:</p><pre><code class="language-julia hljs">constraints7 = @constraints begin 
    q(Î¼) :: PointMassFormConstraint()
    
    q(Î¼, Ï„) = q(Î¼)q(Ï„) # Mean-Field over `Î¼` and `Ï„`
end</code></pre><pre><code class="nohighlight hljs">Constraints: 
  q(Î¼, Ï„) = q(Î¼)q(Ï„)
  q(Î¼) :: PointMassFormConstraint()</code></pre><pre><code class="language-julia hljs">dataset = rand(Normal(-3.0, inv(sqrt(5.0))), 1000);
result = infer(
    model          = test_model7(),
    data           = (y = dataset, ),
    constraints    = constraints7, 
    initialization = init,
    returnvars     = (Î¼ = KeepLast(), Ï„ = KeepLast()),
    iterations     = 10,
    free_energy    = true,
    showprogress   = true
)</code></pre><pre><code class="nohighlight hljs">Inference results:
  Posteriors       | available for (Î¼, Ï„)
  Free Energy:     | Real[14766.5, 2051.94, 614.755, 614.755, 614.755, 614.
755, 614.755, 614.755, 614.755, 614.755]</code></pre><pre><code class="language-julia hljs">println(&quot;Î¼: mean = &quot;, mean(result.posteriors[:Î¼]), &quot;, std = &quot;, std(result.posteriors[:Î¼]))</code></pre><pre><code class="nohighlight hljs">Î¼: mean = -3.018736475303153, std = 0.0</code></pre><pre><code class="language-julia hljs">println(&quot;Ï„: mean = &quot;, mean(result.posteriors[:Ï„]), &quot;, std = &quot;, std(result.posteriors[:Ï„]))</code></pre><pre><code class="nohighlight hljs">Ï„: mean = 5.043215606990412, std = 0.22531425673624408</code></pre><h3 id="Meta-data-specification"><a class="docs-heading-anchor" href="#Meta-data-specification">Meta data specification</a><a id="Meta-data-specification-1"></a><a class="docs-heading-anchor-permalink" href="#Meta-data-specification" title="Permalink"></a></h3><p>During model specification some functional dependencies may accept an optional <code>meta</code> object in the <code>where { ... }</code> clause. The purpose of the <code>meta</code> object is to adjust, modify or supply some extra information to the inference backend during the computations of the messages. The <code>meta</code> object for example may contain an approximation method that needs to be used during various approximations or it may specify the tradeoff between accuracy and performance:</p><pre><code class="language-julia hljs"># In this example the `meta` object for the autoregressive `AR` node specifies the variate type of 
# the autoregressive process and its order. In addition it specifies that the message computation rules should
# respect accuracy over speed with the `ARsafe()` strategy. In contrast, `ARunsafe()` strategy tries to speedup computations
# by cost of possible numerical instabilities during an inference procedure
s[i] ~ AR(s[i - 1], Î¸, Î³) where { meta = ARMeta(Multivariate, order, ARsafe()) }
...
s[i] ~ AR(s[i - 1], Î¸, Î³) where { meta = ARMeta(Univariate, order, ARunsafe()) }</code></pre><p>Another example with <code>GaussianControlledVariance</code>, or simply <code>GCV</code> [see Hierarchical Gaussian Filter], node:</p><pre><code class="language-julia hljs"># In this example we specify structured factorisation and flag meta with `GaussHermiteCubature` 
# method with `21` sigma points for approximation of non-lineariety between hierarchy layers
xt ~ GCV(xt_min, zt, real_k, real_w) where { meta = GCVMetadata(GaussHermiteCubature(21)) }</code></pre><p>The Meta object is useful to pass any extra information to a node that is not a random variable or constant model variable. It may include extra approximation methods, differentiation methods, optional non-linear functions, extra inference parameters etc.</p><h3 id="GraphPPL.jl-@meta-macro"><a class="docs-heading-anchor" href="#GraphPPL.jl-@meta-macro">GraphPPL.jl <code>@meta</code> macro</a><a id="GraphPPL.jl-@meta-macro-1"></a><a class="docs-heading-anchor-permalink" href="#GraphPPL.jl-@meta-macro" title="Permalink"></a></h3><p>Users can use <code>@meta</code> macro from the <code>GraphPPL.jl</code> package to achieve the same goal. Read more about <code>@meta</code> macro in the corresponding documentation section. Here is a simple example of the same meta specification:</p><pre><code class="language-julia hljs">@meta begin 
     AR(s, Î¸, Î³) -&gt; ARMeta(Multivariate, 5, ARsafe())
end</code></pre><pre><code class="nohighlight hljs">Meta: 
  ReactiveMP.AR(s, Î¸, Î³) -&gt; ReactiveMP.ARMeta{Distributions.Multivariate, R
eactiveMP.ARsafe}(5, ReactiveMP.ARsafe())</code></pre><h2 id="Creating-custom-nodes-and-message-computation-rules"><a class="docs-heading-anchor" href="#Creating-custom-nodes-and-message-computation-rules">Creating custom nodes and message computation rules</a><a id="Creating-custom-nodes-and-message-computation-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-custom-nodes-and-message-computation-rules" title="Permalink"></a></h2><h3 id="Custom-nodes"><a class="docs-heading-anchor" href="#Custom-nodes">Custom nodes</a><a id="Custom-nodes-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-nodes" title="Permalink"></a></h3><p>To create a custom functional form and to make it available during model specification the <code>ReactiveMP</code> inference engine exports the <code>@node</code> macro:</p><pre><code class="language-julia hljs"># `@node` macro accepts a name of the functional form, its type, either `Stochastic` or `Deterministic` and an array of interfaces:
@node NormalMeanVariance Stochastic [ out, Î¼, v ]

# Interfaces may have aliases for their names that might be convenient for factorisation constraints specification
@node NormalMeanVariance Stochastic [ out, (Î¼, aliases = [ mean ]), (v, aliases = [ var ]) ]

# `NormalMeanVariance` structure declaration must exist, otherwise `@node` macro will throw an error
struct NormalMeanVariance end 

@node NormalMeanVariance Stochastic [ out, Î¼, v ]

# It is also possible to use function objects as a node functional form
function dot end

# Syntax for functions is a bit differet, as it is necesssary to use `typeof(...)` function for them 
# out = dot(x, a)
@node typeof(dot) Deterministic [ out, x, a ]</code></pre><p>After that it is possible to use the newly created node during model specification:</p><pre><code class="language-julia hljs">@model function test_model()
    ...
    y ~ dot(x, a)
    ...
end</code></pre><h3 id="Custom-messages-computation-rules"><a class="docs-heading-anchor" href="#Custom-messages-computation-rules">Custom messages computation rules</a><a id="Custom-messages-computation-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-messages-computation-rules" title="Permalink"></a></h3><p><code>RxInfer.jl</code> exports the <code>@rule</code> macro to create custom message computation rules. For example let us create a simple <code>+</code> node to be available for usage in the model specification usage. We refer to <em>A Factor Graph Approach to Signal Modelling , System Identification and Filtering</em> [ Sascha Korl, 2005, page 32 ] for a rigorous explanation of the <code>+</code> node in factor graphs. According to Korl, assuming that inputs are Gaussian Sum-Product message computation rule for <code>+</code> node is the following:</p><p class="math-container">\[\begin{aligned}
\mu_z = \mu_x + \mu_y\\
V_z = V_x + V_y
\end{aligned}\]</p><p>To specify this in <code>RxInfer.jl</code> we use the <code>@node</code> and <code>@rule</code> macros:</p><pre><code class="language-julia hljs">@node typeof(+) Deterministic  [ z, x, y ]

@rule typeof(+)(:z, Marginalisation) (m_x::UnivariateNormalDistributionsFamily, m_y::UnivariateNormalDistributionsFamily) = begin
    x_mean, x_var = mean_var(m_x)
    y_mean, y_var = mean_var(m_y)
    return NormalMeanVariance(x_mean + y_mean, x_var + y_var)
end</code></pre><p>In this example, for the <code>@rule</code> macro, we specify a type of our functional form: <code>typeof(+)</code>. Next, we specify an edge we are going to compute an outbound message for. <code>Marginalisation</code> indicates that the corresponding message respects the marginalisation constraint for posterior over corresponding edge:</p><p class="math-container">\[\begin{aligned}
q(z) = \int q(z, x, y) \mathrm{d}x\mathrm{d}y
\end{aligned}\]</p><p>If we look on difference between sum-product rules and variational rules with mean-field assumption we notice that they require different local information to compute an outgoing message:</p><p><img src="sp.png" alt/> <img src="vmp.png" alt/></p><p class="math-container">\[\begin{aligned}
\mu(z) = \int f(x, y, z)\mu(x)\mu(y)\mathrm{d}x\mathrm{d}y
\end{aligned}\]</p><p class="math-container">\[\begin{aligned}
\nu(z) = \exp{ \int \log f(x, y, z)q(x)q(y)\mathrm{d}x\mathrm{d}y }
\end{aligned}\]</p><p>The <code>@rule</code> macro supports both cases with special prefixes during rule specification:</p><ul><li><code>m_</code> prefix corresponds to the incoming message on a specific edge</li><li><code>q_</code> prefix corresponds to the posterior marginal of a specific edge</li></ul><p>Example of a Sum-Product rule with <code>m_</code> messages used:</p><pre><code class="language-julia hljs">@rule NormalMeanPrecision(:Î¼, Marginalisation) (m_out::UnivariateNormalDistributionsFamily, m_Ï„::PointMass) = begin 
    m_out_mean, m_out_cov = mean_cov(m_out)
    return NormalMeanPrecision(m_out_mean, inv(m_out_cov + inv(mean(m_Ï„))))
end</code></pre><p>Example of a Variational rule with Mean-Field assumption with <code>q_</code> posteriors used:</p><pre><code class="language-julia hljs">@rule NormalMeanPrecision(:Î¼, Marginalisation) (q_out::Any, q_Ï„::Any) = begin 
    return NormalMeanPrecision(mean(q_out), mean(q_Ï„))
end</code></pre><p><code>RxInfer.jl</code> also supports structured rules. It is possible to obtain joint marginal over a set of edges:</p><pre><code class="language-julia hljs">@rule NormalMeanPrecision(:Ï„, Marginalisation) (q_out_Î¼::Any, ) = begin
    m, V = mean_cov(q_out_Î¼)
    Î¸ = 2 / (V[1,1] - V[1,2] - V[2,1] + V[2,2] + abs2(m[1] - m[2]))
    Î± = convert(typeof(Î¸), 1.5)
    return Gamma(Î±, Î¸)
end</code></pre><p><strong>NOTE</strong>: In the <code>@rule</code> specification the messages or marginals arguments <strong>must</strong> be in order with interfaces specification from <code>@node</code> macro:</p><pre><code class="language-julia hljs"># Inference backend expects arguments in `@rule` macro to be in the same order
@node NormalMeanPrecision Stochastic [ out, Î¼, Ï„ ]</code></pre><p>Any rule always has access to the meta information with hidden the <code>meta::Any</code> variable:</p><pre><code class="language-julia hljs">@rule MyCustomNode(:out, Marginalisation) (m_in1::Any, m_in2::Any) = begin 
    ...
    println(meta)
    ...
end</code></pre><p>It is also possible to dispatch on a specific type of a meta object:</p><pre><code class="language-julia hljs">@rule MyCustomNode(:out, Marginalisation) (m_in1::Any, m_in2::Any, meta::LaplaceApproximation) = begin 
    ...
end</code></pre><p>or</p><pre><code class="language-julia hljs">@rule MyCustomNode(:out, Marginalisation) (m_in1::Any, m_in2::Any, meta::GaussHermiteCubature) = begin 
    ...
end</code></pre><h3 id="Customizing-messages-computational-pipeline"><a class="docs-heading-anchor" href="#Customizing-messages-computational-pipeline">Customizing messages computational pipeline</a><a id="Customizing-messages-computational-pipeline-1"></a><a class="docs-heading-anchor-permalink" href="#Customizing-messages-computational-pipeline" title="Permalink"></a></h3><p>In certain situations it might be convenient to customize the default message computational pipeline. <code>RxInfer.jl</code> supports the <code>pipeline</code> keyword in the <code>where { ... }</code> clause to add some extra steps after a message has been computed. A use case might be an extra approximation method to preserve conjugacy in the model, debugging or simple printing.</p><p><img src="pipeline.png" alt/></p><pre><code class="language-julia hljs"># Logs all outbound messages
y[i] ~ Normal(mean = x[i], precision = 1.0) where { pipeline = LoggerPipelineStage() }
# In principle, it is possible to approximate outbound messages with Laplace Approximation (this is not an implemented feature, but a concept)
y[i] ~ Normal(mean = x[i], precision = 1.0) where { pipeline = LaplaceApproximation() }</code></pre><p>Let us return to the coin toss model, but this time we want to print flowing messages:</p><pre><code class="language-julia hljs">@model function coin_toss_model_log(y)
    Î¸ ~ Beta(2.0, 7.0) where { pipeline = LoggerPipelineStage(&quot;Î¸&quot;) }
    for i in eachindex(y)
        y[i] ~ Bernoulli(Î¸)  where { pipeline = LoggerPipelineStage(&quot;y[$i]&quot;) }
    end
end</code></pre><pre><code class="language-julia hljs">dataset = float.(rand(Bernoulli(p), 5));
result = infer(
    model = coin_toss_model_log(),
    data  = (y = dataset, )
)</code></pre><pre><code class="nohighlight hljs">[Î¸]: [Distributions.Beta][out]: DeferredMessage([ use `as_message` to compu
te the message ])
[y[1]]: [Distributions.Bernoulli][p]: DeferredMessage([ use `as_message` to
 compute the message ])
[y[2]]: [Distributions.Bernoulli][p]: DeferredMessage([ use `as_message` to
 compute the message ])
[y[3]]: [Distributions.Bernoulli][p]: DeferredMessage([ use `as_message` to
 compute the message ])
[y[4]]: [Distributions.Bernoulli][p]: DeferredMessage([ use `as_message` to
 compute the message ])
[y[5]]: [Distributions.Bernoulli][p]: DeferredMessage([ use `as_message` to
 compute the message ])
Inference results:
  Posteriors       | available for (Î¸)</code></pre><hr/><div class="admonition is-info" id="Contributing-baba9dc142ba7ccb"><header class="admonition-header">Contributing<a class="admonition-anchor" href="#Contributing-baba9dc142ba7ccb" title="Permalink"></a></header><div class="admonition-body"><p>This example was automatically generated from a Jupyter notebook in the <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">RxInferExamples.jl</a> repository.</p><p>We welcome and encourage contributions! You can help by:</p><ul><li>Improving this example</li><li>Creating new examples </li><li>Reporting issues or bugs</li><li>Suggesting enhancements</li></ul><p>Visit our <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">GitHub repository</a> to get started. Together we can make <a href="https://github.com/ReactiveBayes/RxInfer.jl">RxInfer.jl</a> even better! ðŸ’ª</p></div></div><hr/><div class="admonition is-compat" id="Environment-ead41e814a894220"><header class="admonition-header">Environment<a class="admonition-anchor" href="#Environment-ead41e814a894220" title="Permalink"></a></header><div class="admonition-body"><p>This example was executed in a clean, isolated environment. Below are the exact package versions used:</p><p>For reproducibility:</p><ul><li>Use the same package versions when running locally</li><li>Report any issues with package compatibility</li></ul></div></div><pre><code class="nohighlight hljs">Status `/tmp/jl_A77yVv/Project.toml`
  [91a5bcdd] Plots v1.41.6
  [86711068] RxInfer v4.7.0
</code></pre><script type="module">import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
mermaid.initialize({
    startOnLoad: true,
    theme: "neutral"
});
</script></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../active_inference_mountain_car/">Â« Active Inference Mountain Car</a><a class="docs-footer-nextpage" href="../assessing_people_skills/">Assessing People Skills Â»</a><div class="flexbox-break"></div><p class="footer-message">Created in <a href="https://biaslab.github.io/">BIASlab</a>, maintained by <a href="https://github.com/ReactiveBayes">ReactiveBayes</a>, powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.17.0 on <span class="colophon-date" title="Wednesday 25 February 2026 15:00">Wednesday 25 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
