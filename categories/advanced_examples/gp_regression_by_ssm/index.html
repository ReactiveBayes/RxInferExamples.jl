<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Gp Regression By Ssm · RxInfer.jl Examples</title><meta name="title" content="Gp Regression By Ssm · RxInfer.jl Examples"/><meta property="og:title" content="Gp Regression By Ssm · RxInfer.jl Examples"/><meta property="twitter:title" content="Gp Regression By Ssm · RxInfer.jl Examples"/><meta name="description" content="Solve GP regression by SDE with RxInfer.jl\nIn this notebook, we solve a GP regression problem by using &#39;Stochastic Differential Equation&#39; (SDE). This method is well described in the dissertation &#39;Stochastic differential equation methods for spatio-temporal Gaussian process regression.&#39; by Arno Solin and &#39;Sequential Inference for Latent Temporal Gaussian Process Models&#39; by Jouni Hartikainen.\n\nCheck more examples and tutorials at https://examples.rxinfer.com\n"/><meta property="og:description" content="Solve GP regression by SDE with RxInfer.jl\nIn this notebook, we solve a GP regression problem by using &#39;Stochastic Differential Equation&#39; (SDE). This method is well described in the dissertation &#39;Stochastic differential equation methods for spatio-temporal Gaussian process regression.&#39; by Arno Solin and &#39;Sequential Inference for Latent Temporal Gaussian Process Models&#39; by Jouni Hartikainen.\n\nCheck more examples and tutorials at https://examples.rxinfer.com\n"/><meta property="twitter:description" content="Solve GP regression by SDE with RxInfer.jl\nIn this notebook, we solve a GP regression problem by using &#39;Stochastic Differential Equation&#39; (SDE). This method is well described in the dissertation &#39;Stochastic differential equation methods for spatio-temporal Gaussian process regression.&#39; by Arno Solin and &#39;Sequential Inference for Latent Temporal Gaussian Process Models&#39; by Jouni Hartikainen.\n\nCheck more examples and tutorials at https://examples.rxinfer.com\n"/><meta property="og:url" content="https://examples.rxinfer.com/categories/advanced_examples/gp_regression_by_ssm/"/><meta property="twitter:url" content="https://examples.rxinfer.com/categories/advanced_examples/gp_regression_by_ssm/"/><link rel="canonical" href="https://examples.rxinfer.com/categories/advanced_examples/gp_regression_by_ssm/"/><script async src="https://www.googletagmanager.com/gtag/js?id=G-GMFX620VEP"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-GMFX620VEP', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/theme.css" rel="stylesheet" type="text/css"/><link href="../../../assets/header.css" rel="stylesheet" type="text/css"/><script src="../../../assets/header.js"></script><script src="../../../assets/chat.js"></script><link href="../../../assets/favicon.ico" rel="icon" type="image/x-icon"/>
    <meta property="og:title" content="Solve GP regression by SDE - RxInfer Examples">
    <meta name="description" content="In this notebook, we solve a GP regression problem by using 'Stochastic Differential Equation' (SDE). This method is well described in the dissertation 'Stochastic differential equation methods for spatio-temporal Gaussian process regression.' by Arno Solin and 'Sequential Inference for Latent Temporal Gaussian Process Models' by Jouni Hartikainen.
">
    <meta property="og:description" content="In this notebook, we solve a GP regression problem by using 'Stochastic Differential Equation' (SDE). This method is well described in the dissertation 'Stochastic differential equation methods for spatio-temporal Gaussian process regression.' by Arno Solin and 'Sequential Inference for Latent Temporal Gaussian Process Models' by Jouni Hartikainen.
">
    <meta name="keywords" content="rxinfer, julia, bayesian inference, examples, probabilistic programming, message passing, probabilistic numerics, variational inference, belief propagation, advanced examples, gaussian process, sde, regression, state space model">
    <link rel="sitemap" type="application/xml" title="Sitemap" href="https://examples.rxinfer.com/sitemap.xml">
    </head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img class="docs-light-only" src="../../../assets/logo.svg" alt="RxInfer.jl Examples logo"/><img class="docs-dark-only" src="../../../assets/logo-dark.svg" alt="RxInfer.jl Examples logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">RxInfer.jl Examples</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><a class="tocitem" href="../../../how_to_contribute/">How to contribute</a></li><li><a class="tocitem" href="../../../autogenerated/list_of_examples/">List of Examples</a></li><li><span class="tocitem">Basic Examples</span><ul><li><a class="tocitem" href="../../basic_examples/bayesian_binomial_regression/">Bayesian Binomial Regression</a></li><li><a class="tocitem" href="../../basic_examples/bayesian_linear_regression/">Bayesian Linear Regression</a></li><li><a class="tocitem" href="../../basic_examples/bayesian_multinomial_regression/">Bayesian Multinomial Regression</a></li><li><a class="tocitem" href="../../basic_examples/bayesian_networks/">Bayesian Networks</a></li><li><a class="tocitem" href="../../basic_examples/coin_toss_model/">Coin Toss Model</a></li><li><a class="tocitem" href="../../basic_examples/contextual_bandits/">Contextual Bandits</a></li><li><a class="tocitem" href="../../basic_examples/feature_functions_in_bayesian_regression/">Feature Functions In Bayesian Regression</a></li><li><a class="tocitem" href="../../basic_examples/forgetting_factors_for_online_inference/">Forgetting Factors For Online Inference</a></li><li><a class="tocitem" href="../../basic_examples/hidden_markov_model/">Hidden Markov Model</a></li><li><a class="tocitem" href="../../basic_examples/incomplete_data/">Incomplete Data</a></li><li><a class="tocitem" href="../../basic_examples/kalman_filtering_and_smoothing/">Kalman Filtering And Smoothing</a></li><li><a class="tocitem" href="../../basic_examples/pomdp_control/">Pomdp Control</a></li><li><a class="tocitem" href="../../basic_examples/predicting_bike_rental_demand/">Predicting Bike Rental Demand</a></li></ul></li><li><span class="tocitem">Advanced Examples</span><ul><li><a class="tocitem" href="../active_inference_mountain_car/">Active Inference Mountain Car</a></li><li><a class="tocitem" href="../advanced_tutorial/">Advanced Tutorial</a></li><li><a class="tocitem" href="../assessing_people_skills/">Assessing People Skills</a></li><li><a class="tocitem" href="../chance_constraints/">Chance Constraints</a></li><li><a class="tocitem" href="../conjugate-computational_variational_message_passing/">Conjugate-Computational Variational Message Passing</a></li><li><a class="tocitem" href="../drone_dynamics/">Drone Dynamics</a></li><li class="is-active"><a class="tocitem" href>Gp Regression By Ssm</a><ul class="internal"><li><a class="tocitem" href="#Create-state-space-model-for-GP-regression"><span>Create state space model for GP regression</span></a></li><li><a class="tocitem" href="#Generate-data"><span>Generate data</span></a></li><li><a class="tocitem" href="#Covariance-function:-Matern-3/2"><span>Covariance function: Matern-3/2</span></a></li><li><a class="tocitem" href="#Covariance-function:-Matern-5/2"><span>Covariance function: Matern-5/2</span></a></li><li><a class="tocitem" href="#Result"><span>Result</span></a></li></ul></li><li><a class="tocitem" href="../infinite_data_stream/">Infinite Data Stream</a></li><li><a class="tocitem" href="../integrating_neural_networks_with_flux.jl/">Integrating Neural Networks With Flux.Jl</a></li><li><a class="tocitem" href="../learning_dynamics_with_vaes/">Learning Dynamics With Vaes</a></li><li><a class="tocitem" href="../multi-agent_trajectory_planning/">Multi-Agent Trajectory Planning</a></li><li><a class="tocitem" href="../nonlinear_sensor_fusion/">Nonlinear Sensor Fusion</a></li><li><a class="tocitem" href="../parameter_optimisation_with_optim.jl/">Parameter Optimisation With Optim.Jl</a></li><li><a class="tocitem" href="../robotic_arm/">Robotic Arm</a></li></ul></li><li><span class="tocitem">Problem Specific</span><ul><li><a class="tocitem" href="../../problem_specific/autoregressive_models/">Autoregressive Models</a></li><li><a class="tocitem" href="../../problem_specific/gamma_mixture/">Gamma Mixture</a></li><li><a class="tocitem" href="../../problem_specific/gaussian_mixture/">Gaussian Mixture</a></li><li><a class="tocitem" href="../../problem_specific/hierarchical_gaussian_filter/">Hierarchical Gaussian Filter</a></li><li><a class="tocitem" href="../../problem_specific/invertible_neural_network_tutorial/">Invertible Neural Network Tutorial</a></li><li><a class="tocitem" href="../../problem_specific/litter_model/">Litter Model</a></li><li><a class="tocitem" href="../../problem_specific/ode_parameter_estimation/">Ode Parameter Estimation</a></li><li><a class="tocitem" href="../../problem_specific/probit_model/">Probit Model</a></li><li><a class="tocitem" href="../../problem_specific/rts_vs_bifm_smoothing/">Rts Vs Bifm Smoothing</a></li><li><a class="tocitem" href="../../problem_specific/simple_nonlinear_node/">Simple Nonlinear Node</a></li><li><a class="tocitem" href="../../problem_specific/structural_dynamics_with_augmented_kalman_filter/">Structural Dynamics With Augmented Kalman Filter</a></li><li><a class="tocitem" href="../../problem_specific/universal_mixtures/">Universal Mixtures</a></li></ul></li><li><span class="tocitem">Experimental Examples</span><ul><li><a class="tocitem" href="../../experimental_examples/bayesian_trust_learning/">Bayesian Trust Learning</a></li><li><a class="tocitem" href="../../experimental_examples/large_language_models/">Large Language Models</a></li><li><a class="tocitem" href="../../experimental_examples/latent_vector_autoregressive_model/">Latent Vector Autoregressive Model</a></li><li><a class="tocitem" href="../../experimental_examples/recurrent_switching_linear_dynamical_system/">Recurrent Switching Linear Dynamical System</a></li></ul></li><li><a class="tocitem" href="../../../how_build_works/">How we build the examples</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Advanced Examples</a></li><li class="is-active"><a href>Gp Regression By Ssm</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Gp Regression By Ssm</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInferExamples.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInferExamples.jl" title="View source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><div class="admonition is-info" id="Contributing-64592202d51b8d51"><header class="admonition-header">Contributing<a class="admonition-anchor" href="#Contributing-64592202d51b8d51" title="Permalink"></a></header><div class="admonition-body"><p>This example was automatically generated from a Jupyter notebook in the <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">RxInferExamples.jl</a> repository.</p><p>We welcome and encourage contributions! You can help by:</p><ul><li>Improving this example</li><li>Creating new examples </li><li>Reporting issues or bugs</li><li>Suggesting enhancements</li></ul><p>Visit our <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">GitHub repository</a> to get started. Together we can make <a href="https://github.com/ReactiveBayes/RxInfer.jl">RxInfer.jl</a> even better! 💪</p></div></div><hr/><h1 id="Solve-GP-regression-by-SDE"><a class="docs-heading-anchor" href="#Solve-GP-regression-by-SDE">Solve GP regression by SDE</a><a id="Solve-GP-regression-by-SDE-1"></a><a class="docs-heading-anchor-permalink" href="#Solve-GP-regression-by-SDE" title="Permalink"></a></h1><p>In this notebook, we solve a GP regression problem by using &quot;Stochastic Differential Equation&quot; (SDE). This method is well described in the dissertation &quot;Stochastic differential equation methods for spatio-temporal Gaussian process regression.&quot; by Arno Solin and &quot;Sequential Inference for Latent Temporal Gaussian Process Models&quot; by Jouni Hartikainen. The idea of the method is as follows.</p><p>Suppose a function <span>$f(x)$</span> follows a zero-mean Gaussian Process <span>$\begin{aligned} f(x) \sim \mathcal{GP}(0, k(x,x&#39;)). \end{aligned}$</span></p><p>When the dimensionality of <span>$x$</span> is 1, we can consider <span>$f(x)$</span> as a stochastic process over time, i.e. <span>$f(t)$</span>. For a certain classses of covariance functions, <span>$f(t)$</span> is a solution to an <span>$m$</span>-th order linear stochastic differential equation (SDE) <span>$\begin{aligned} a_0 f(t) + a_1 \frac{d f(t)}{dt} + \dots + a_m \frac{d^m f(t)}{dt^m} = w(t)  \end{aligned}$</span></p><p>where <span>$w(t)$</span> is a zero-mean white noise process with spectral density <span>$Q_c$</span>. If we define a vector-valued function <span>$\mathbf{f}(t) = (f(t),\, d/dt f(t),\dots,\, d^{m-1}/dt^{m-1}f(t))$</span>, then we can rewrite the above SDE under the companion form</p><p class="math-container">\[\begin{aligned}
\frac{d \mathbf{f}(t)}{dt} = \mathbf{F}\, \mathbf{f}(t) + \mathbf{L} w(t) \quad (1)
\end{aligned}\]</p><p>where <span>$\mathbf{F}$</span> and <span>$\mathbf{L}$</span> are defined based on the choice of covariance functions.  From (1), we have the following state-space model: <span>$\begin{aligned} \mathbf{f}_k = \mathbf{A}_{k-1} \, \mathbf{f}_{k-1} + \mathbf{q}_{k-1}, \quad \mathbf{q}_{k-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{Q}_{k-1}) \quad(2a) \\
y_k = \mathbf{H} \, \mathbf{f}(t_k) + \epsilon_k , \quad \epsilon_k \sim \mathcal{N}(0, \sigma^2_{noise}) \quad(2b). \\
\end{aligned}$</span></p><p>where <span>$\mathbf{A}_k = \exp{(\mathbf{F}\,\Delta t_k)}$</span>, with <span>$\Delta t_k = t_{k+1} - t_k$</span>, is called the discrete-time state transition matrix, and <span>$\mathbf{Q}_k$</span> the process noise covariance matrix. For the computation of <span>$\mathbf{Q}_k$</span>, we will come back later. According to Arno Solin and Jouni Hartikainen&#39;s dissertation, the GP regression problem amounts to the inference problem of the above state-space model, and this can be solved by RTS-smoothing. The state-space model starts from  the initial state <span>$f_0 \sim \mathcal{N}(\mathbf{0},\, \mathbf{P}_0)$</span>. For stationary covariance function, the SDE has a stationary state <span>$f_\infty \sim \mathcal{N}(\mathbf{0},\, \mathbf{P}_\infty)$</span>, where <span>$\mathbf{P}_\infty$</span> is the solution to <span>$\begin{aligned} \frac{d\mathbf{P}_\infty}{dt} = \mathbf{F} \mathbf{P}_\infty + \mathbf{P}_\infty \mathbf{F}^T + \mathbf{L} \mathbf{Q}_c \mathbf{L}^T = 0 \quad (\mathrm{Lyapunov \, equation}). \end{aligned}$</span></p><p>With this stationary condition, the process noise covariance <span>$\mathbf{Q}_k$</span> is computed as follows <span>$\begin{aligned} \mathbf{Q}_k = \mathbf{P}_\infty - \mathbf{A}_k \mathbf{P}_\infty \mathbf{A}_k^T  \end{aligned}$</span></p><p>For one-dimensional problem the SDE representation of the GP is defined by the matrices <span>$\mathbf{F}, \, \mathbf{L}, \, \mathbf{Q}_c, \, \mathbf{P}_0$</span> and <span>$\mathbf{H}$</span>. Once we obtain all the matrices, we can do GP regression by implementing RTS-smoothing on the state-space model (2). In this notebook we will particularly use the Matern class of covariance functions for Gaussian Process.</p><pre><code class="language-julia hljs">using RxInfer, Random, Distributions, LinearAlgebra, Plots</code></pre><h2 id="Create-state-space-model-for-GP-regression"><a class="docs-heading-anchor" href="#Create-state-space-model-for-GP-regression">Create state space model for GP regression</a><a id="Create-state-space-model-for-GP-regression-1"></a><a class="docs-heading-anchor-permalink" href="#Create-state-space-model-for-GP-regression" title="Permalink"></a></h2><p>Here we create a state-space model <span>$\begin{aligned} \mathbf{f}_k = \mathbf{A}_{k-1} \, \mathbf{f}_{k-1} + \mathbf{q}_{k-1}, \quad \mathbf{q}_{k-1} \sim \mathcal{N}(\mathbf{0}, \mathbf{Q}_{k-1}) \\
y_k = \mathbf{H} \, \mathbf{f}(t_k) + \epsilon_k , \quad \epsilon_k \sim \mathcal{N}(0, \sigma^2_{noise}), \\
\end{aligned}$</span> where <span>$y_k$</span> is the noisy observation of the function <span>$f$</span> at time <span>$t_k$</span>, and <span>$\sigma^2_{noise}$</span> is the noise variance and assumed to be known.</p><pre><code class="language-julia hljs">@model function gp_regression(y, P, A, Q, H, var_noise)
    f_prev ~ MvNormal(μ = zeros(length(H)), Σ = P) #initial state
    for i in eachindex(y)
        f[i] ~ MvNormal(μ = A[i] * f_prev,Σ = Q[i])
        y[i] ~ Normal(μ = dot(H, f[i]), var = var_noise)
        f_prev = f[i]
    end
end</code></pre><h2 id="Generate-data"><a class="docs-heading-anchor" href="#Generate-data">Generate data</a><a id="Generate-data-1"></a><a class="docs-heading-anchor-permalink" href="#Generate-data" title="Permalink"></a></h2><pre><code class="language-julia hljs">Random.seed!(10)
n = 100
σ²_noise = 0.04;
t = collect(range(-2, 2, length=n)); #timeline
f_true = sinc.(t); # true process
f_noisy = f_true + sqrt(σ²_noise)*randn(n); #noisy process

pos = sort(randperm(75)[1:2:75]); 
t_obser = t[pos]; # time where we observe data

y_data = Array{Union{Float64,Missing}}(missing, n)
for i in pos 
    y_data[i] = f_noisy[i]
end

θ = [1., 1.]; # store [l, σ²]
Δt = [t[1]]; # time difference
append!(Δt, t[2:end] - t[1:end-1]);</code></pre><h3 id="Let&#39;s-visualize-our-data"><a class="docs-heading-anchor" href="#Let&#39;s-visualize-our-data">Let&#39;s visualize our data</a><a id="Let&#39;s-visualize-our-data-1"></a><a class="docs-heading-anchor-permalink" href="#Let&#39;s-visualize-our-data" title="Permalink"></a></h3><pre><code class="language-julia hljs">plot(t, f_true, label=&quot;True process f(t)&quot;)
scatter!(t_obser, y_data[pos], label = &quot;Noisy observations&quot;)
xlabel!(&quot;t&quot;)
ylabel!(&quot;f(t)&quot;)</code></pre><p><img src="GP Regression by SSM_4_1.png" alt/></p><h2 id="Covariance-function:-Matern-3/2"><a class="docs-heading-anchor" href="#Covariance-function:-Matern-3/2">Covariance function: Matern-3/2</a><a id="Covariance-function:-Matern-3/2-1"></a><a class="docs-heading-anchor-permalink" href="#Covariance-function:-Matern-3/2" title="Permalink"></a></h2><p>The Matern is a stationary covariance function and defined as follows <span>$\begin{aligned} k(\tau) = \sigma^2 \frac{2^{1-\nu}}{\Gamma(\nu)} \left(\frac{\sqrt{2\nu}\tau}{l} \right)^\nu K_\nu\left(\frac{\sqrt{2\nu}\tau}{l} \right) \end{aligned}$</span> where  <span>$\begin{aligned} \sigma^2: \text{the magnitude scale hyperparameter}\\
l: \text{the characteristic length-scale}\\
\nu: \text{the smoothness hyperparameter}\\
K_\nu(.): \text{the modified Bessel function of the second kind}. \end{aligned}$</span> When we say the Matern-3/2, we mean <span>$\nu=3/2$</span>. The matrices for the state space model are computed as follows <span>$\begin{aligned} \mathbf{F} = \begin{pmatrix} 0 &amp; 1\\
-\lambda^2 &amp; -2\lambda \end{pmatrix} ,\quad \quad \mathbf{L} = \begin{pmatrix} 0 \\ 1 \end{pmatrix}, \quad \quad \mathbf{P}_\infty = \begin{pmatrix} \sigma^2 &amp; 0 \\ 0 &amp; \lambda^2\sigma^2 \end{pmatrix} ,\quad \quad \mathbf{H} = \begin{pmatrix} 1 &amp; 0 \end{pmatrix}, \quad \quad Q_c = 4\lambda^3\sigma^2 \end{aligned}$</span>  where <span>$\lambda = \frac{\sqrt{3}}{l} $. From these matrices, we can define $\mathbf{A}_k$</span> and <span>$\mathbf{Q}_k$</span>.</p><pre><code class="language-julia hljs">λ = sqrt(3)/θ[1];
#### compute matrices for the state-space model ######
L = [0., 1.];
H = [1., 0.];
F = [0. 1.; -λ^2 -2λ]
P∞ = [θ[2] 0.; 0. (λ^2*θ[2]) ]
A = [exp(F * i) for i in Δt]; 
Q = [P∞ - i*P∞*i&#39; for i in A];</code></pre><pre><code class="language-julia hljs">result_32 = infer(
    model = gp_regression(P = P∞, A = A, Q = Q, H = H, var_noise = σ²_noise),
    data = (y = y_data,)
)</code></pre><pre><code class="nohighlight hljs">Inference results:
  Posteriors       | available for (f, f_prev)
  Predictions      | available for (y)</code></pre><h2 id="Covariance-function:-Matern-5/2"><a class="docs-heading-anchor" href="#Covariance-function:-Matern-5/2">Covariance function: Matern-5/2</a><a id="Covariance-function:-Matern-5/2-1"></a><a class="docs-heading-anchor-permalink" href="#Covariance-function:-Matern-5/2" title="Permalink"></a></h2><p>Now let&#39;s try the Matern-5/2 kernel. The matrices for the SDE representation of the Matern-5/2 are:</p><p class="math-container">\[\begin{aligned}
\mathbf{F} = \begin{pmatrix}
0 &amp; 1 &amp; 0\\
0 &amp; 0 &amp; 1 \\
-\lambda^3 &amp; -3\lambda^2 &amp; -3\lambda
\end{pmatrix} ,\quad \quad \mathbf{L} = \begin{pmatrix}
0 \\ 0 \\ 1
\end{pmatrix}, \quad \quad \mathbf{H} = \begin{pmatrix}
1 &amp; 0 &amp; 0
\end{pmatrix}, \quad \quad Q_c = \frac{16}{3} \sigma^2 \lambda^5, 
\end{aligned}\]</p><p>where <span>$\lambda = \sqrt{5} / l$</span>. To find <span>$\mathbf{P}_\infty$</span>, we solve the Lyapunov equation</p><p class="math-container">\[\begin{aligned}
\frac{d\mathbf{P}_\infty}{dt} = \mathbf{F} \mathbf{P}_\infty + \mathbf{P}_\infty \mathbf{F}^T + \mathbf{L} \mathbf{Q}_c \mathbf{L}^T = 0,
\end{aligned}\]</p><p>of which the solution is</p><p class="math-container">\[\begin{aligned}
vec(\mathbf{P}_\infty) = (\mathbf{I} \otimes \mathbf{F} + \mathbf{F}\otimes\mathbf{I})^{-1}\, vec(-\mathbf{L}Q_c\mathbf{L}^T)
\end{aligned}\]</p><p>where <span>$vec(.)$</span> is the vectorization operator and <span>$\otimes$</span> denotes the Kronecker product. Now we can find <span>$\mathbf{A}_k$</span> and <span>$\mathbf{Q}_k$</span> </p><p class="math-container">\[\begin{aligned}
\mathbf{A}_k = \exp{(\mathbf{F}\Delta t_k)} 
\end{aligned}\]</p><p class="math-container">\[\begin{aligned}
\mathbf{Q}_k = \mathbf{P}_\infty - \mathbf{A}_k \mathbf{P}_\infty \mathbf{A}_k^T  
\end{aligned}\]</p><pre><code class="language-julia hljs">λ = sqrt(5)/θ[1];
#### compute matrices for the state-space model ######
L = [0., 0., 1.];
H = [1., 0., 0.];
F = [0. 1. 0.; 0. 0. 1.;-λ^3 -3λ^2 -3λ]
Qc = 16/3 * θ[2] * λ^5;

I = diageye(3) ; 
vec_P = inv(kron(I,F) + kron(F,I)) * vec(-L * Qc * L&#39;); 
P∞ = reshape(vec_P,3,3);
A = [exp(F * i) for i in Δt]; 
Q = [P∞ - i*P∞*i&#39; for i in A];</code></pre><pre><code class="language-julia hljs">result_52 = infer(
    model = gp_regression(P = P∞, A = A, Q = Q, H = H, var_noise = σ²_noise),
    data = (y = y_data,)
)</code></pre><pre><code class="nohighlight hljs">Inference results:
  Posteriors       | available for (f, f_prev)
  Predictions      | available for (y)</code></pre><h2 id="Result"><a class="docs-heading-anchor" href="#Result">Result</a><a id="Result-1"></a><a class="docs-heading-anchor-permalink" href="#Result" title="Permalink"></a></h2><pre><code class="language-julia hljs">slicedim(dim) = (a) -&gt; map(e -&gt; e[dim], a)

plot(t, mean.(result_32.posteriors[:f]) |&gt; slicedim(1), ribbon = var.(result_32.posteriors[:f]) |&gt; slicedim(1) .|&gt; sqrt, label =&quot;Approx. process_M32&quot;, title = &quot;Matern-3/2&quot;, legend =false, lw = 2)
plot!(t, mean.(result_52.posteriors[:f]) |&gt; slicedim(1), ribbon = var.(result_52.posteriors[:f]) |&gt; slicedim(1) .|&gt; sqrt, label =&quot;Approx. process_M52&quot;,legend = :bottomleft, title = &quot;GPRegression by SSM&quot;, lw = 2)
plot!(t, f_true,label=&quot;true process&quot;, lw = 2)
scatter!(t_obser, f_noisy[pos], label=&quot;Observations&quot;)
xlabel!(&quot;t&quot;)
ylabel!(&quot;f(t)&quot;)</code></pre><p><img src="GP Regression by SSM_9_1.png" alt/></p><p>As we can see from the plot, both cases of Matern kernel provide good approximations (small variance) to the true process at the area with dense observations (namely from t = 0 to around 3.5), and when we move far away from this region the approximated processes become less accurate (larger variance). This result makes sense because GP regression exploits the correlation between observations to predict unobserved points, and the choice of covariance functions as well as their hyperparameters might not be optimal. We can increase the accuracy of the approximated processes by simply adding more observations. This way of improvement does not trouble the state-space method much but it might cause computational problem for naive GP regression, because with N observations the complexity of naive GP regression scales with <span>$N^3$</span> while the state-space method scales linearly with N.     </p><hr/><div class="admonition is-info" id="Contributing-64592202d51b8d51"><header class="admonition-header">Contributing<a class="admonition-anchor" href="#Contributing-64592202d51b8d51" title="Permalink"></a></header><div class="admonition-body"><p>This example was automatically generated from a Jupyter notebook in the <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">RxInferExamples.jl</a> repository.</p><p>We welcome and encourage contributions! You can help by:</p><ul><li>Improving this example</li><li>Creating new examples </li><li>Reporting issues or bugs</li><li>Suggesting enhancements</li></ul><p>Visit our <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">GitHub repository</a> to get started. Together we can make <a href="https://github.com/ReactiveBayes/RxInfer.jl">RxInfer.jl</a> even better! 💪</p></div></div><hr/><div class="admonition is-compat" id="Environment-3e440e2b2e9811bf"><header class="admonition-header">Environment<a class="admonition-anchor" href="#Environment-3e440e2b2e9811bf" title="Permalink"></a></header><div class="admonition-body"><p>This example was executed in a clean, isolated environment. Below are the exact package versions used:</p><p>For reproducibility:</p><ul><li>Use the same package versions when running locally</li><li>Report any issues with package compatibility</li></ul></div></div><pre><code class="nohighlight hljs">Status `~/work/RxInferExamples.jl/RxInferExamples.jl/docs/src/categories/advanced_examples/gp_regression_by_ssm/Project.toml`
  [31c24e10] Distributions v0.25.121
  [91a5bcdd] Plots v1.41.1
  [86711068] RxInfer v4.6.0
  [37e2e46d] LinearAlgebra v1.11.0
  [9a3f8284] Random v1.11.0
</code></pre><script type="module">import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
mermaid.initialize({
    startOnLoad: true,
    theme: "neutral"
});
</script></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../drone_dynamics/">« Drone Dynamics</a><a class="docs-footer-nextpage" href="../infinite_data_stream/">Infinite Data Stream »</a><div class="flexbox-break"></div><p class="footer-message">Created in <a href="https://biaslab.github.io/">BIASlab</a>, maintained by <a href="https://github.com/ReactiveBayes">ReactiveBayes</a>, powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Friday 3 October 2025 10:27">Friday 3 October 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
