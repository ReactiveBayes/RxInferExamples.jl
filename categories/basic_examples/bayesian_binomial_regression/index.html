<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Bayesian Binomial Regression Â· RxInfer.jl Examples</title><meta name="title" content="Bayesian Binomial Regression Â· RxInfer.jl Examples"/><meta property="og:title" content="Bayesian Binomial Regression Â· RxInfer.jl Examples"/><meta property="twitter:title" content="Bayesian Binomial Regression Â· RxInfer.jl Examples"/><meta name="description" content="Bayesian Binomial Regression with RxInfer.jl\n    An introductory tutorial to Bayesian binomial regression with RxInfer. \n    Learn how to model binary outcomes using logistic regression with proper Bayesian inference.\n    The example demonstrates the use of Expectation Propagation (EP) algorithm and Polya-Gamma augmentation.\n\nCheck more examples and tutorials at https://examples.rxinfer.com\n"/><meta property="og:description" content="Bayesian Binomial Regression with RxInfer.jl\n    An introductory tutorial to Bayesian binomial regression with RxInfer. \n    Learn how to model binary outcomes using logistic regression with proper Bayesian inference.\n    The example demonstrates the use of Expectation Propagation (EP) algorithm and Polya-Gamma augmentation.\n\nCheck more examples and tutorials at https://examples.rxinfer.com\n"/><meta property="twitter:description" content="Bayesian Binomial Regression with RxInfer.jl\n    An introductory tutorial to Bayesian binomial regression with RxInfer. \n    Learn how to model binary outcomes using logistic regression with proper Bayesian inference.\n    The example demonstrates the use of Expectation Propagation (EP) algorithm and Polya-Gamma augmentation.\n\nCheck more examples and tutorials at https://examples.rxinfer.com\n"/><meta property="og:url" content="https://examples.rxinfer.com/categories/basic_examples/bayesian_binomial_regression/"/><meta property="twitter:url" content="https://examples.rxinfer.com/categories/basic_examples/bayesian_binomial_regression/"/><link rel="canonical" href="https://examples.rxinfer.com/categories/basic_examples/bayesian_binomial_regression/"/><script async src="https://www.googletagmanager.com/gtag/js?id=G-GMFX620VEP"></script><script>  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-GMFX620VEP', {'page_path': location.pathname + location.search + location.hash});
</script><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/theme.css" rel="stylesheet" type="text/css"/><link href="../../../assets/header.css" rel="stylesheet" type="text/css"/><script src="../../../assets/header.js"></script><script src="../../../assets/chat.js"></script><link href="../../../assets/favicon.ico" rel="icon" type="image/x-icon"/>
    <meta property="og:title" content="Bayesian Binomial Regression - RxInfer Examples">
    <meta name="description" content="    An introductory tutorial to Bayesian binomial regression with RxInfer. 
    Learn how to model binary outcomes using logistic regression with proper Bayesian inference.
    The example demonstrates the use of Expectation Propagation (EP) algorithm and Polya-Gamma augmentation.
">
    <meta property="og:description" content="    An introductory tutorial to Bayesian binomial regression with RxInfer. 
    Learn how to model binary outcomes using logistic regression with proper Bayesian inference.
    The example demonstrates the use of Expectation Propagation (EP) algorithm and Polya-Gamma augmentation.
">
    <meta name="keywords" content="rxinfer, julia, bayesian inference, examples, probabilistic programming, message passing, probabilistic numerics, variational inference, belief propagation, basic examples, regression, multivariate, expectation propagation, polya-gamma">
    <link rel="sitemap" type="application/xml" title="Sitemap" href="https://examples.rxinfer.com/sitemap.xml">
    </head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img class="docs-light-only" src="../../../assets/logo.svg" alt="RxInfer.jl Examples logo"/><img class="docs-dark-only" src="../../../assets/logo-dark.svg" alt="RxInfer.jl Examples logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">RxInfer.jl Examples</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Home</a></li><li><a class="tocitem" href="../../../how_to_contribute/">How to contribute</a></li><li><a class="tocitem" href="../../../autogenerated/list_of_examples/">List of Examples</a></li><li><span class="tocitem">Basic Examples</span><ul><li class="is-active"><a class="tocitem" href>Bayesian Binomial Regression</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Likelihood-Specification"><span>Likelihood Specification</span></a></li><li class="toplevel"><a class="tocitem" href="#Prior-Distributions"><span>Prior Distributions</span></a></li><li class="toplevel"><a class="tocitem" href="#Model-Specification"><span>Model Specification</span></a></li><li class="toplevel"><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../bayesian_linear_regression/">Bayesian Linear Regression</a></li><li><a class="tocitem" href="../bayesian_multinomial_regression/">Bayesian Multinomial Regression</a></li><li><a class="tocitem" href="../bayesian_networks/">Bayesian Networks</a></li><li><a class="tocitem" href="../coin_toss_model/">Coin Toss Model</a></li><li><a class="tocitem" href="../contextual_bandits/">Contextual Bandits</a></li><li><a class="tocitem" href="../feature_functions_in_bayesian_regression/">Feature Functions In Bayesian Regression</a></li><li><a class="tocitem" href="../forgetting_factors_for_online_inference/">Forgetting Factors For Online Inference</a></li><li><a class="tocitem" href="../hidden_markov_model/">Hidden Markov Model</a></li><li><a class="tocitem" href="../incomplete_data/">Incomplete Data</a></li><li><a class="tocitem" href="../kalman_filtering_and_smoothing/">Kalman Filtering And Smoothing</a></li><li><a class="tocitem" href="../pomdp_control/">Pomdp Control</a></li><li><a class="tocitem" href="../predicting_bike_rental_demand/">Predicting Bike Rental Demand</a></li></ul></li><li><span class="tocitem">Advanced Examples</span><ul><li><a class="tocitem" href="../../advanced_examples/active_inference_mountain_car/">Active Inference Mountain Car</a></li><li><a class="tocitem" href="../../advanced_examples/advanced_tutorial/">Advanced Tutorial</a></li><li><a class="tocitem" href="../../advanced_examples/assessing_people_skills/">Assessing People Skills</a></li><li><a class="tocitem" href="../../advanced_examples/bayesian_structured_time_series/">Bayesian Structured Time Series</a></li><li><a class="tocitem" href="../../advanced_examples/chance_constraints/">Chance Constraints</a></li><li><a class="tocitem" href="../../advanced_examples/conjugate-computational_variational_message_passing/">Conjugate-Computational Variational Message Passing</a></li><li><a class="tocitem" href="../../advanced_examples/drone_dynamics/">Drone Dynamics</a></li><li><a class="tocitem" href="../../advanced_examples/gp_regression_by_ssm/">Gp Regression By Ssm</a></li><li><a class="tocitem" href="../../advanced_examples/infinite_data_stream/">Infinite Data Stream</a></li><li><a class="tocitem" href="../../advanced_examples/integrating_neural_networks_with_flux.jl/">Integrating Neural Networks With Flux.Jl</a></li><li><a class="tocitem" href="../../advanced_examples/learning_dynamics_with_vaes/">Learning Dynamics With Vaes</a></li><li><a class="tocitem" href="../../advanced_examples/multi-agent_trajectory_planning/">Multi-Agent Trajectory Planning</a></li><li><a class="tocitem" href="../../advanced_examples/nonlinear_sensor_fusion/">Nonlinear Sensor Fusion</a></li><li><a class="tocitem" href="../../advanced_examples/parameter_optimisation_with_optim.jl/">Parameter Optimisation With Optim.Jl</a></li><li><a class="tocitem" href="../../advanced_examples/robotic_arm/">Robotic Arm</a></li></ul></li><li><span class="tocitem">Problem Specific</span><ul><li><a class="tocitem" href="../../problem_specific/autoregressive_models/">Autoregressive Models</a></li><li><a class="tocitem" href="../../problem_specific/gamma_mixture/">Gamma Mixture</a></li><li><a class="tocitem" href="../../problem_specific/gaussian_mixture/">Gaussian Mixture</a></li><li><a class="tocitem" href="../../problem_specific/hierarchical_gaussian_filter/">Hierarchical Gaussian Filter</a></li><li><a class="tocitem" href="../../problem_specific/invertible_neural_network_tutorial/">Invertible Neural Network Tutorial</a></li><li><a class="tocitem" href="../../problem_specific/ising_model/">Ising Model</a></li><li><a class="tocitem" href="../../problem_specific/litter_model/">Litter Model</a></li><li><a class="tocitem" href="../../problem_specific/ode_parameter_estimation/">Ode Parameter Estimation</a></li><li><a class="tocitem" href="../../problem_specific/probit_model/">Probit Model</a></li><li><a class="tocitem" href="../../problem_specific/rts_vs_bifm_smoothing/">Rts Vs Bifm Smoothing</a></li><li><a class="tocitem" href="../../problem_specific/simple_nonlinear_node/">Simple Nonlinear Node</a></li><li><a class="tocitem" href="../../problem_specific/structural_dynamics_with_augmented_kalman_filter/">Structural Dynamics With Augmented Kalman Filter</a></li><li><a class="tocitem" href="../../problem_specific/universal_mixtures/">Universal Mixtures</a></li></ul></li><li><span class="tocitem">Experimental Examples</span><ul><li><a class="tocitem" href="../../experimental_examples/bayesian_trust_learning/">Bayesian Trust Learning</a></li><li><a class="tocitem" href="../../experimental_examples/large_language_models/">Large Language Models</a></li><li><a class="tocitem" href="../../experimental_examples/latent_vector_autoregressive_model/">Latent Vector Autoregressive Model</a></li><li><a class="tocitem" href="../../experimental_examples/recurrent_switching_linear_dynamical_system/">Recurrent Switching Linear Dynamical System</a></li></ul></li><li><a class="tocitem" href="../../../how_build_works/">How we build the examples</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Basic Examples</a></li><li class="is-active"><a href>Bayesian Binomial Regression</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Bayesian Binomial Regression</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInferExamples.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ï‚›</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ReactiveBayes/RxInferExamples.jl" title="View source on GitHub"><span class="docs-icon fa-solid">ï…œ</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><div class="admonition is-info" id="Contributing-baba9dc142ba7ccb"><header class="admonition-header">Contributing<a class="admonition-anchor" href="#Contributing-baba9dc142ba7ccb" title="Permalink"></a></header><div class="admonition-body"><p>This example was automatically generated from a Jupyter notebook in the <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">RxInferExamples.jl</a> repository.</p><p>We welcome and encourage contributions! You can help by:</p><ul><li>Improving this example</li><li>Creating new examples </li><li>Reporting issues or bugs</li><li>Suggesting enhancements</li></ul><p>Visit our <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">GitHub repository</a> to get started. Together we can make <a href="https://github.com/ReactiveBayes/RxInfer.jl">RxInfer.jl</a> even better! ðŸ’ª</p></div></div><hr/><h1 id="Bayesian-Binomial-Regression"><a class="docs-heading-anchor" href="#Bayesian-Binomial-Regression">Bayesian Binomial Regression</a><a id="Bayesian-Binomial-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-Binomial-Regression" title="Permalink"></a></h1><p>This notebook is an introductory tutorial to Bayesian binomial regression with <code>RxInfer</code>.</p><pre><code class="language-julia hljs">using RxInfer, ReactiveMP, Random, Plots, StableRNGs, LinearAlgebra, StatsPlots, LaTeXStrings</code></pre><h1 id="Likelihood-Specification"><a class="docs-heading-anchor" href="#Likelihood-Specification">Likelihood Specification</a><a id="Likelihood-Specification-1"></a><a class="docs-heading-anchor-permalink" href="#Likelihood-Specification" title="Permalink"></a></h1><p>For observations <span>$y_i$</span> with predictors <span>$\mathbf{x}_i$</span>, Binomial regression models the number of successes <span>$y_i$</span> as a function of the predictors <span>$\mathbf{x}_i$</span> and the regression coefficients <span>$\boldsymbol{\beta}$</span></p><p class="math-container">\[\begin{equation}
y_i \sim \text{Binomial}(n_i, p_i)\,,
\end{equation}\]</p><p>where:</p><p class="math-container">\[y_i\]</p><p>is the number of successes, <span>$n_i$</span> is the number of trials, <span>$p_i$</span> is the probability of success. The probability <span>$p_i$</span> is linked to the predictors through the logistic function:</p><p class="math-container">\[\begin{equation}
p_i = \frac{1}{1 + e^{-\mathbf{x}_i^T\boldsymbol{\beta}}}
\end{equation}\]</p><h1 id="Prior-Distributions"><a class="docs-heading-anchor" href="#Prior-Distributions">Prior Distributions</a><a id="Prior-Distributions-1"></a><a class="docs-heading-anchor-permalink" href="#Prior-Distributions" title="Permalink"></a></h1><p>We specify priors for the regression coefficients:</p><p class="math-container">\[\begin{equation}
\boldsymbol{\beta} \sim \mathcal{N}_{\xi}(\boldsymbol{\xi}, \boldsymbol{\Lambda})
\end{equation}\]</p><p>as a Normal distribution in precision-weighted mean form.</p><h1 id="Model-Specification"><a class="docs-heading-anchor" href="#Model-Specification">Model Specification</a><a id="Model-Specification-1"></a><a class="docs-heading-anchor-permalink" href="#Model-Specification" title="Permalink"></a></h1><p>The likelihood and the prior distributions form the probabilistic model</p><p class="math-container">\[p(y, x, \beta, n) = p(\beta) \prod_{i=1}^N p(y_i \mid x_i, \beta, n_i),\]</p><p>where the goal is to infer the posterior distributions <span>$p(\beta \mid y, x, n)$</span>. Due to logistic link function, the posterior distribution is not conjugate to the prior distribution. This means that we need to use a more complex inference algorithm to infer the posterior distribution. Before dwelling into the details of the inference algorithm, let&#39;s first generate some synthetic data to work with.</p><pre><code class="language-julia hljs">function generate_synthetic_binomial_data(
    n_samples::Int,
    true_beta::Vector{Float64};
    seed::Int=42
)
    n_features = length(true_beta)
    rng = StableRNG(seed)
    
    X = randn(rng, n_samples, n_features)
    
    n_trials = rand(rng, 5:20, n_samples)
    
    logits = X * true_beta
    probs = 1 ./ (1 .+ exp.(-logits))
    
    y = [rand(rng, Binomial(n_trials[i], probs[i])) for i in 1:n_samples]
    
    return X, y, n_trials, probs
end


n_samples = 10000
true_beta =  [-3.0 , 2.6]

X, y, n_trials,probs = generate_synthetic_binomial_data(n_samples, true_beta);
X = [collect(row) for row in eachrow(X)];</code></pre><p>We generate <code>X</code> as the design matrix and <code>y</code> as the number of successes and <code>n_trials</code> as the number of trials. Next task is to define the graphical model. RxInfer provides a <code>BinomialPolya</code> factor node that is a combination of a Binomial distribution and a PolyaGamma distribution introduced in [1]. The <code>BinomialPolya</code> factor node is used to model the likelihood of the binomial distribution. </p><p>Due to non-conjugacy of the likelihood and the prior distribution, we need to use a more complex inference algorithm. RxInfer provides an Expectation Propagation (EP) [2] algorithm to infer the posterior distribution. Due to EP&#39;s approximation, we need to specify an inbound message for the regression coefficients while using the <code>BinomialPolya</code> factor node. This feature is implemented in the <code>dependencies</code> keyword argument during the creation of the <code>BinomialPolya</code> factor node. <code>ReactiveMP.jl</code> provides a <code>RequireMessageFunctionalDependencies</code> type that is used to specify the inbound message for the regression coefficients <code>Î²</code>. Refer to the ReactiveMP.jl documentation for more information.</p><pre><code class="language-julia hljs">@model function binomial_model(prior_xi, prior_precision, n_trials, X, y) 
    Î² ~ MvNormalWeightedMeanPrecision(prior_xi, prior_precision)
    for i in eachindex(y)
        y[i] ~ BinomialPolya(X[i], n_trials[i], Î²) where {
            dependencies = RequireMessageFunctionalDependencies(Î² = MvNormalWeightedMeanPrecision(prior_xi, prior_precision))
        }
    end
end</code></pre><p>This example uses the precision-weighted mean parametrization (<code>MvNormalWeightedMeanPrecision</code>) of the Gaussian distribution for efficiency reasons. While this is less conventional than the standard mean-covariance form, the example would work equally well with any parametrization. The choice of parametrization mainly affects computational efficiency and numerical stability, not the underlying model or results.</p><p>Having specified the model, we can now utilize the <code>infer</code> function to infer the posterior distribution.</p><pre><code class="language-julia hljs">n_features = length(true_beta)
results = infer(
    model = binomial_model(prior_xi = zeros(n_features), prior_precision = diageye(n_features),),
    data = (X=X, y=y,n_trials=n_trials),
    iterations = 30,
    free_energy = true,
    showprogress = true,
    options = (
        limit_stack_depth = 100, # to prevent stack-overflow errors
    )
)</code></pre><pre><code class="nohighlight hljs">Inference results:
  Posteriors       | available for (Î²)
  Free Energy:     | Real[21992.9, 16235.8, 13785.0, 12519.7, 11800.1, 1136
6.2, 11094.1, 10918.7, 10803.3, 10726.3  â€¦  10561.6, 10560.6, 10559.9, 1055
9.4, 10559.0, 10558.8, 10558.6, 10558.5, 10558.4, 10558.3]</code></pre><p>We can now plot the free energy to see if the inference algorithm is converging.</p><pre><code class="language-julia hljs">plot(results.free_energy,fontfamily = &quot;Computer Modern&quot;, label=&quot;Free Energy&quot;, xlabel=&quot;Iteration&quot;, ylabel=&quot;Free Energy&quot;, title=&quot;Free Energy Convergence&quot;)</code></pre><p><img src="Bayesian Binomial Regression_5_1.png" alt/></p><p>Free energy is converging to a stable value, indicating that the inference algorithm is converging. Let&#39;s visualize the posterior distribution and how it compares to the true parameters.</p><pre><code class="language-julia hljs"># Create an animation showing how posterior evolves
anim = @animate for i in 1:length(results.posteriors[:Î²])
    # Get posterior at current iteration
    m_i = mean(results.posteriors[:Î²][i])
    Î£_i = cov(results.posteriors[:Î²][i])
    
    # Calculate dynamic limits based on current mean and covariance
    # Add some padding (3 standard deviations) to ensure true parameters are visible
    x_std = sqrt(Î£_i[1,1])
    y_std = sqrt(Î£_i[2,2])
    
    x_min = min(m_i[1] - 3*x_std, true_beta[1] - 0.1)
    x_max = max(m_i[1] + 3*x_std, true_beta[1] + 0.1)
    y_min = min(m_i[2] - 3*y_std, true_beta[2] - 0.1)
    y_max = max(m_i[2] + 3*y_std, true_beta[2] + 0.1)
    
    p = plot(xlims=(x_min, x_max), ylims=(y_min, y_max),
             fontfamily = &quot;Computer Modern&quot;,
             title=&quot;Iteration $i&quot;, aspect_ratio=1)
    
    # Plot confidence ellipses
    covellipse!(m_i, Î£_i, n_std=1, label=&quot;1Ïƒ Contour&quot;, color=:green, fillalpha=0.2)
    covellipse!(m_i, Î£_i, n_std=3, label=&quot;3Ïƒ Contour&quot;, color=:blue, fillalpha=0.2)
    
    # Plot mean estimate and true parameters
    scatter!([m_i[1]], [m_i[2]], label=&quot;Current Estimate&quot;, color=:blue)
    scatter!([true_beta[1]], [true_beta[2]], label=&quot;True Parameters&quot;, color=:red)
end

# Save the animation as a GIF
gif(anim, &quot;bayesian_regression_posterior.gif&quot;, fps=3)</code></pre><pre><code class="nohighlight hljs">Plots.AnimatedGif(&quot;/home/runner/work/RxInferExamples.jl/RxInferExamples.jl/
docs/src/categories/basic_examples/bayesian_binomial_regression/bayesian_re
gression_posterior.gif&quot;)</code></pre><p><img src="bayesian_regression_posterior.gif" alt/></p><p>We can perform prediction by augmenting the data with missing values. For that, we can create a new vector <code>y_with_missing</code> that contains missing values for the last 2000 samples.</p><pre><code class="language-julia hljs">y_with_missing = Vector{Union{Missing, Int}}(missing, n_samples)
for i in 1:n_samples
    if i &gt; 8000
        y_with_missing[i] = missing
    else
        y_with_missing[i] = y[i]
    end
end</code></pre><pre><code class="language-julia hljs">results_with_missing = infer(
    model = binomial_model(prior_xi = zeros(n_features), prior_precision = diageye(n_features),),
    data = (X=X, y=y_with_missing,n_trials=n_trials),
    iterations = 30,
    showprogress = true,
    options = (
        limit_stack_depth = 100, # to prevent stack-overflow errors
    )
)</code></pre><pre><code class="nohighlight hljs">Inference results:
  Posteriors       | available for (Î²)
  Predictions      | available for (y)</code></pre><pre><code class="language-julia hljs">probs_prediction = map(d -&gt; d.p,results_with_missing.predictions[:y][end][8000:end])
err = probs_prediction .- probs[8000:end]
mse = mean(err.^2)
println(&quot;Mean squared error: &quot;, mse)</code></pre><pre><code class="nohighlight hljs">Mean squared error: 3.541846183800687e-6</code></pre><pre><code class="language-julia hljs">function bin_predictions(true_probs, pred_probs; n_bins=20)
    bins = range(0, 1, length=n_bins+1)
    bin_means = Float64[]
    bin_stds = Float64[]
    bin_centers = Float64[]
    
    for i in 1:n_bins
        mask = (true_probs .&gt;= bins[i]) .&amp; (true_probs .&lt; bins[i+1])
        if any(mask)
            push!(bin_means, mean(pred_probs[mask]))
            push!(bin_stds, std(pred_probs[mask]))
            push!(bin_centers, (bins[i] + bins[i+1])/2)
        end
    end
    return bin_centers, bin_means, bin_stds
end

# Create the plot
bin_centers, bin_means, bin_stds = bin_predictions(probs[8000:end], probs_prediction)

p = plot(
    xlabel = &quot;True Probability&quot;,
    ylabel = &quot;Predicted Probability&quot;,
    title = &quot;Prediction Performance&quot;,
    aspect_ratio = 1,
    legend = :bottomright,
    grid = true,
    fontfamily = &quot;Computer Modern&quot;,
    dpi = 300
)

# Add perfect prediction line
plot!([0, 1], [0, 1], 
    label = &quot;Perfect Prediction&quot;, 
    color = :black, 
    linestyle = :dash,
    linewidth = 2
)

# Add scatter plot with reduced opacity and size
scatter!(
    probs[8000:end], 
    probs_prediction,
    label = &quot;Individual Predictions&quot;,
    alpha = 0.1,  # Reduced opacity
    color = :blue,
    markersize = 1,
    markerstrokewidth = 0
)

# Add binned means with error bars
scatter!(
    bin_centers,
    bin_means,
    yerror = bin_stds,
    label = &quot;Binned Mean Â± SD&quot;,
    color = :red,
    markersize = 4
)

annotate!(
    0.05, 
    0.95, 
    text(&quot;MSE = $(round(mse, digits=8))&quot;, 8, :left, :top)
)

# Customize axes
plot!(
    xlims = (0,1),
    ylims = (0,1),
    xticks = 0:0.2:1,
    yticks = 0:0.2:1
)</code></pre><p><img src="Bayesian Binomial Regression_10_1.png" alt/></p><h1 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h1><p>[1] Polson, N. G., Scott, J. G., &amp; Windle, J. (2013). Bayesian inference for logistic models using Polya-Gamma latent variables. <em>Journal of the American Statistical Association</em>, 108(1), 136-146.</p><p>[2] Minka, T. (2001). Expectation Propagation for approximate Bayesian inference. <em>Uncertainty in Artificial Intelligence</em>, 2, 362-369.</p><hr/><div class="admonition is-info" id="Contributing-baba9dc142ba7ccb"><header class="admonition-header">Contributing<a class="admonition-anchor" href="#Contributing-baba9dc142ba7ccb" title="Permalink"></a></header><div class="admonition-body"><p>This example was automatically generated from a Jupyter notebook in the <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">RxInferExamples.jl</a> repository.</p><p>We welcome and encourage contributions! You can help by:</p><ul><li>Improving this example</li><li>Creating new examples </li><li>Reporting issues or bugs</li><li>Suggesting enhancements</li></ul><p>Visit our <a href="https://github.com/ReactiveBayes/RxInferExamples.jl">GitHub repository</a> to get started. Together we can make <a href="https://github.com/ReactiveBayes/RxInfer.jl">RxInfer.jl</a> even better! ðŸ’ª</p></div></div><hr/><div class="admonition is-compat" id="Environment-ead41e814a894220"><header class="admonition-header">Environment<a class="admonition-anchor" href="#Environment-ead41e814a894220" title="Permalink"></a></header><div class="admonition-body"><p>This example was executed in a clean, isolated environment. Below are the exact package versions used:</p><p>For reproducibility:</p><ul><li>Use the same package versions when running locally</li><li>Report any issues with package compatibility</li></ul></div></div><pre><code class="nohighlight hljs">Status `/tmp/jl_A77yVv/Project.toml`
  [b964fa9f] LaTeXStrings v1.4.0
  [91a5bcdd] Plots v1.41.6
  [a194aa59] ReactiveMP v5.6.5
  [86711068] RxInfer v4.7.0
  [860ef19b] StableRNGs v1.0.4
  [f3b207a7] StatsPlots v0.15.8
  [37e2e46d] LinearAlgebra v1.12.0
  [9a3f8284] Random v1.11.0
</code></pre><script type="module">import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
mermaid.initialize({
    startOnLoad: true,
    theme: "neutral"
});
</script></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../../autogenerated/list_of_examples/">Â« List of Examples</a><a class="docs-footer-nextpage" href="../bayesian_linear_regression/">Bayesian Linear Regression Â»</a><div class="flexbox-break"></div><p class="footer-message">Created in <a href="https://biaslab.github.io/">BIASlab</a>, maintained by <a href="https://github.com/ReactiveBayes">ReactiveBayes</a>, powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.17.0 on <span class="colophon-date" title="Wednesday 25 February 2026 15:00">Wednesday 25 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
